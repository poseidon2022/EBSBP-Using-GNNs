/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Assign.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2007 Michael Olbrich <michael.olbrich@gmx.net>
    5|       |// Copyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    7|       |//
    8|       |// This Source Code Form is subject to the terms of the Mozilla
    9|       |// Public License v. 2.0. If a copy of the MPL was not distributed
   10|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   11|       |
   12|       |#ifndef EIGEN_ASSIGN_H
   13|       |#define EIGEN_ASSIGN_H
   14|       |
   15|       |// IWYU pragma: private
   16|       |#include "./InternalHeaderCheck.h"
   17|       |
   18|       |namespace Eigen {
   19|       |
   20|       |template <typename Derived>
   21|       |template <typename OtherDerived>
   22|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::lazyAssign(const DenseBase<OtherDerived>& other) {
   23|       |  enum { SameType = internal::is_same<typename Derived::Scalar, typename OtherDerived::Scalar>::value };
   24|       |
   25|       |  EIGEN_STATIC_ASSERT_LVALUE(Derived)
   26|       |  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(Derived, OtherDerived)
   27|       |  EIGEN_STATIC_ASSERT(
   28|       |      SameType,
   29|       |      YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY)
   30|       |
   31|       |  eigen_assert(rows() == other.rows() && cols() == other.cols());
   32|       |  internal::call_assignment_no_alias(derived(), other.derived());
   33|       |
   34|       |  return derived();
   35|       |}
   36|       |
   37|       |template <typename Derived>
   38|       |template <typename OtherDerived>
   39|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::operator=(const DenseBase<OtherDerived>& other) {
   40|       |  internal::call_assignment(derived(), other.derived());
   41|       |  return derived();
   42|       |}
   43|       |
   44|       |template <typename Derived>
   45|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::operator=(const DenseBase& other) {
   46|       |  internal::call_assignment(derived(), other.derived());
   47|       |  return derived();
   48|       |}
   49|       |
   50|       |template <typename Derived>
   51|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::operator=(const MatrixBase& other) {
   52|       |  internal::call_assignment(derived(), other.derived());
   53|       |  return derived();
   54|       |}
   55|       |
   56|       |template <typename Derived>
   57|       |template <typename OtherDerived>
   58|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::operator=(const DenseBase<OtherDerived>& other) {
   59|      0|  internal::call_assignment(derived(), other.derived());
   60|      0|  return derived();
   61|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEaSINS_9TransposeIKNS_5BlockIKNS2_IS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEERS7_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEaSINS_5BlockINS2_IS3_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEERS7_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEaSINS_3MapINS2_IS3_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEERS5_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEaSIS4_EERS7_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEaSINS_9TransposeIKNS2_IS3_Li1ELin1ELi1ELi1ELin1EEEEEEERS7_RKNS_9DenseBaseIT_EE
  ------------------
   62|       |
   63|       |template <typename Derived>
   64|       |template <typename OtherDerived>
   65|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::operator=(const EigenBase<OtherDerived>& other) {
   66|       |  internal::call_assignment(derived(), other.derived());
   67|       |  return derived();
   68|       |}
   69|       |
   70|       |template <typename Derived>
   71|       |template <typename OtherDerived>
   72|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::operator=(
   73|       |    const ReturnByValue<OtherDerived>& other) {
   74|       |  other.derived().evalTo(derived());
   75|       |  return derived();
   76|       |}
   77|       |
   78|       |}  // end namespace Eigen
   79|       |
   80|       |#endif  // EIGEN_ASSIGN_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/AssignEvaluator.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2011 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2011-2014 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |// Copyright (C) 2011-2012 Jitse Niesen <jitse@maths.leeds.ac.uk>
    7|       |//
    8|       |// This Source Code Form is subject to the terms of the Mozilla
    9|       |// Public License v. 2.0. If a copy of the MPL was not distributed
   10|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   11|       |
   12|       |#ifndef EIGEN_ASSIGN_EVALUATOR_H
   13|       |#define EIGEN_ASSIGN_EVALUATOR_H
   14|       |
   15|       |// IWYU pragma: private
   16|       |#include "./InternalHeaderCheck.h"
   17|       |
   18|       |namespace Eigen {
   19|       |
   20|       |// This implementation is based on Assign.h
   21|       |
   22|       |namespace internal {
   23|       |
   24|       |/***************************************************************************
   25|       | * Part 1 : the logic deciding a strategy for traversal and unrolling       *
   26|       | ***************************************************************************/
   27|       |
   28|       |// copy_using_evaluator_traits is based on assign_traits
   29|       |
   30|       |template <typename DstEvaluator, typename SrcEvaluator, typename AssignFunc, int MaxPacketSize = -1>
   31|       |struct copy_using_evaluator_traits {
   32|       |  typedef typename DstEvaluator::XprType Dst;
   33|       |  typedef typename Dst::Scalar DstScalar;
   34|       |
   35|       |  enum { DstFlags = DstEvaluator::Flags, SrcFlags = SrcEvaluator::Flags };
   36|       |
   37|       | public:
   38|       |  enum {
   39|       |    DstAlignment = DstEvaluator::Alignment,
   40|       |    SrcAlignment = SrcEvaluator::Alignment,
   41|       |    DstHasDirectAccess = (DstFlags & DirectAccessBit) == DirectAccessBit,
   42|       |    JointAlignment = plain_enum_min(DstAlignment, SrcAlignment)
   43|       |  };
   44|       |
   45|       | private:
   46|       |  enum {
   47|       |    InnerSize = int(Dst::IsVectorAtCompileTime) ? int(Dst::SizeAtCompileTime)
   48|       |                : int(DstFlags) & RowMajorBit   ? int(Dst::ColsAtCompileTime)
   49|       |                                                : int(Dst::RowsAtCompileTime),
   50|       |    InnerMaxSize = int(Dst::IsVectorAtCompileTime) ? int(Dst::MaxSizeAtCompileTime)
   51|       |                   : int(DstFlags) & RowMajorBit   ? int(Dst::MaxColsAtCompileTime)
   52|       |                                                   : int(Dst::MaxRowsAtCompileTime),
   53|       |    RestrictedInnerSize = min_size_prefer_fixed(InnerSize, MaxPacketSize),
   54|       |    RestrictedLinearSize = min_size_prefer_fixed(Dst::SizeAtCompileTime, MaxPacketSize),
   55|       |    OuterStride = int(outer_stride_at_compile_time<Dst>::ret),
   56|       |    MaxSizeAtCompileTime = Dst::SizeAtCompileTime
   57|       |  };
   58|       |
   59|       |  // TODO distinguish between linear traversal and inner-traversals
   60|       |  typedef typename find_best_packet<DstScalar, RestrictedLinearSize>::type LinearPacketType;
   61|       |  typedef typename find_best_packet<DstScalar, RestrictedInnerSize>::type InnerPacketType;
   62|       |
   63|       |  enum {
   64|       |    LinearPacketSize = unpacket_traits<LinearPacketType>::size,
   65|       |    InnerPacketSize = unpacket_traits<InnerPacketType>::size
   66|       |  };
   67|       |
   68|       | public:
   69|       |  enum {
   70|       |    LinearRequiredAlignment = unpacket_traits<LinearPacketType>::alignment,
   71|       |    InnerRequiredAlignment = unpacket_traits<InnerPacketType>::alignment
   72|       |  };
   73|       |
   74|       | private:
   75|       |  enum {
   76|       |    DstIsRowMajor = DstFlags & RowMajorBit,
   77|       |    SrcIsRowMajor = SrcFlags & RowMajorBit,
   78|       |    StorageOrdersAgree = (int(DstIsRowMajor) == int(SrcIsRowMajor)),
   79|       |    MightVectorize = bool(StorageOrdersAgree) && (int(DstFlags) & int(SrcFlags) & ActualPacketAccessBit) &&
   80|       |                     bool(functor_traits<AssignFunc>::PacketAccess),
   81|       |    MayInnerVectorize = MightVectorize && int(InnerSize) != Dynamic && int(InnerSize) % int(InnerPacketSize) == 0 &&
   82|       |                        int(OuterStride) != Dynamic && int(OuterStride) % int(InnerPacketSize) == 0 &&
   83|       |                        (EIGEN_UNALIGNED_VECTORIZE || int(JointAlignment) >= int(InnerRequiredAlignment)),
   84|       |    MayLinearize = bool(StorageOrdersAgree) && (int(DstFlags) & int(SrcFlags) & LinearAccessBit),
   85|       |    MayLinearVectorize = bool(MightVectorize) && bool(MayLinearize) && bool(DstHasDirectAccess) &&
   86|       |                         (EIGEN_UNALIGNED_VECTORIZE || (int(DstAlignment) >= int(LinearRequiredAlignment)) ||
   87|       |                          MaxSizeAtCompileTime == Dynamic),
   88|       |    /* If the destination isn't aligned, we have to do runtime checks and we don't unroll,
   89|       |       so it's only good for large enough sizes. */
   90|       |    MaySliceVectorize = bool(MightVectorize) && bool(DstHasDirectAccess) &&
   91|       |                        (int(InnerMaxSize) == Dynamic ||
   92|       |                         int(InnerMaxSize) >= (EIGEN_UNALIGNED_VECTORIZE ? InnerPacketSize : (3 * InnerPacketSize)))
   93|       |    /* slice vectorization can be slow, so we only want it if the slices are big, which is
   94|       |       indicated by InnerMaxSize rather than InnerSize, think of the case of a dynamic block
   95|       |       in a fixed-size matrix
   96|       |       However, with EIGEN_UNALIGNED_VECTORIZE and unrolling, slice vectorization is still worth it */
   97|       |  };
   98|       |
   99|       | public:
  100|       |  enum {
  101|       |    Traversal = int(Dst::SizeAtCompileTime) == 0
  102|       |                    ? int(AllAtOnceTraversal)  // If compile-size is zero, traversing will fail at compile-time.
  103|       |                : (int(MayLinearVectorize) && (LinearPacketSize > InnerPacketSize)) ? int(LinearVectorizedTraversal)
  104|       |                : int(MayInnerVectorize)                                            ? int(InnerVectorizedTraversal)
  105|       |                : int(MayLinearVectorize)                                           ? int(LinearVectorizedTraversal)
  106|       |                : int(MaySliceVectorize)                                            ? int(SliceVectorizedTraversal)
  107|       |                : int(MayLinearize)                                                 ? int(LinearTraversal)
  108|       |                                                                                    : int(DefaultTraversal),
  109|       |    Vectorized = int(Traversal) == InnerVectorizedTraversal || int(Traversal) == LinearVectorizedTraversal ||
  110|       |                 int(Traversal) == SliceVectorizedTraversal
  111|       |  };
  112|       |
  113|       |  typedef std::conditional_t<int(Traversal) == LinearVectorizedTraversal, LinearPacketType, InnerPacketType> PacketType;
  114|       |
  115|       | private:
  116|       |  enum {
  117|       |    ActualPacketSize = int(Traversal) == LinearVectorizedTraversal ? LinearPacketSize
  118|       |                       : Vectorized                                ? InnerPacketSize
  119|       |                                                                   : 1,
  120|       |    UnrollingLimit = EIGEN_UNROLLING_LIMIT * ActualPacketSize,
  121|       |    MayUnrollCompletely =
  122|       |        int(Dst::SizeAtCompileTime) != Dynamic &&
  123|       |        int(Dst::SizeAtCompileTime) * (int(DstEvaluator::CoeffReadCost) + int(SrcEvaluator::CoeffReadCost)) <=
  124|       |            int(UnrollingLimit),
  125|       |    MayUnrollInner =
  126|       |        int(InnerSize) != Dynamic &&
  127|       |        int(InnerSize) * (int(DstEvaluator::CoeffReadCost) + int(SrcEvaluator::CoeffReadCost)) <= int(UnrollingLimit)
  128|       |  };
  129|       |
  130|       | public:
  131|       |  enum {
  132|       |    Unrolling = (int(Traversal) == int(InnerVectorizedTraversal) || int(Traversal) == int(DefaultTraversal))
  133|       |                    ? (int(MayUnrollCompletely) ? int(CompleteUnrolling)
  134|       |                       : int(MayUnrollInner)    ? int(InnerUnrolling)
  135|       |                                                : int(NoUnrolling))
  136|       |                : int(Traversal) == int(LinearVectorizedTraversal)
  137|       |                    ? (bool(MayUnrollCompletely) &&
  138|       |                               (EIGEN_UNALIGNED_VECTORIZE || (int(DstAlignment) >= int(LinearRequiredAlignment)))
  139|       |                           ? int(CompleteUnrolling)
  140|       |                           : int(NoUnrolling))
  141|       |                : int(Traversal) == int(LinearTraversal)
  142|       |                    ? (bool(MayUnrollCompletely) ? int(CompleteUnrolling) : int(NoUnrolling))
  143|       |#if EIGEN_UNALIGNED_VECTORIZE
  144|       |                : int(Traversal) == int(SliceVectorizedTraversal)
  145|       |                    ? (bool(MayUnrollInner) ? int(InnerUnrolling) : int(NoUnrolling))
  146|       |#endif
  147|       |                    : int(NoUnrolling)
  148|       |  };
  149|       |
  150|       |#ifdef EIGEN_DEBUG_ASSIGN
  151|       |  static void debug() {
  152|       |    std::cerr << "DstXpr: " << typeid(typename DstEvaluator::XprType).name() << std::endl;
  153|       |    std::cerr << "SrcXpr: " << typeid(typename SrcEvaluator::XprType).name() << std::endl;
  154|       |    std::cerr.setf(std::ios::hex, std::ios::basefield);
  155|       |    std::cerr << "DstFlags"
  156|       |              << " = " << DstFlags << " (" << demangle_flags(DstFlags) << " )" << std::endl;
  157|       |    std::cerr << "SrcFlags"
  158|       |              << " = " << SrcFlags << " (" << demangle_flags(SrcFlags) << " )" << std::endl;
  159|       |    std::cerr.unsetf(std::ios::hex);
  160|       |    EIGEN_DEBUG_VAR(DstAlignment)
  161|       |    EIGEN_DEBUG_VAR(SrcAlignment)
  162|       |    EIGEN_DEBUG_VAR(LinearRequiredAlignment)
  163|       |    EIGEN_DEBUG_VAR(InnerRequiredAlignment)
  164|       |    EIGEN_DEBUG_VAR(JointAlignment)
  165|       |    EIGEN_DEBUG_VAR(InnerSize)
  166|       |    EIGEN_DEBUG_VAR(InnerMaxSize)
  167|       |    EIGEN_DEBUG_VAR(LinearPacketSize)
  168|       |    EIGEN_DEBUG_VAR(InnerPacketSize)
  169|       |    EIGEN_DEBUG_VAR(ActualPacketSize)
  170|       |    EIGEN_DEBUG_VAR(StorageOrdersAgree)
  171|       |    EIGEN_DEBUG_VAR(MightVectorize)
  172|       |    EIGEN_DEBUG_VAR(MayLinearize)
  173|       |    EIGEN_DEBUG_VAR(MayInnerVectorize)
  174|       |    EIGEN_DEBUG_VAR(MayLinearVectorize)
  175|       |    EIGEN_DEBUG_VAR(MaySliceVectorize)
  176|       |    std::cerr << "Traversal"
  177|       |              << " = " << Traversal << " (" << demangle_traversal(Traversal) << ")" << std::endl;
  178|       |    EIGEN_DEBUG_VAR(SrcEvaluator::CoeffReadCost)
  179|       |    EIGEN_DEBUG_VAR(DstEvaluator::CoeffReadCost)
  180|       |    EIGEN_DEBUG_VAR(Dst::SizeAtCompileTime)
  181|       |    EIGEN_DEBUG_VAR(UnrollingLimit)
  182|       |    EIGEN_DEBUG_VAR(MayUnrollCompletely)
  183|       |    EIGEN_DEBUG_VAR(MayUnrollInner)
  184|       |    std::cerr << "Unrolling"
  185|       |              << " = " << Unrolling << " (" << demangle_unrolling(Unrolling) << ")" << std::endl;
  186|       |    std::cerr << std::endl;
  187|       |  }
  188|       |#endif
  189|       |};
  190|       |
  191|       |/***************************************************************************
  192|       | * Part 2 : meta-unrollers
  193|       | ***************************************************************************/
  194|       |
  195|       |/************************
  196|       |*** Default traversal ***
  197|       |************************/
  198|       |
  199|       |template <typename Kernel, int Index, int Stop>
  200|       |struct copy_using_evaluator_DefaultTraversal_CompleteUnrolling {
  201|       |  // FIXME: this is not very clean, perhaps this information should be provided by the kernel?
  202|       |  typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
  203|       |  typedef typename DstEvaluatorType::XprType DstXprType;
  204|       |
  205|       |  enum { outer = Index / DstXprType::InnerSizeAtCompileTime, inner = Index % DstXprType::InnerSizeAtCompileTime };
  206|       |
  207|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel) {
  208|       |    kernel.assignCoeffByOuterInner(outer, inner);
  209|       |    copy_using_evaluator_DefaultTraversal_CompleteUnrolling<Kernel, Index + 1, Stop>::run(kernel);
  210|       |  }
  211|       |};
  212|       |
  213|       |template <typename Kernel, int Stop>
  214|       |struct copy_using_evaluator_DefaultTraversal_CompleteUnrolling<Kernel, Stop, Stop> {
  215|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel&) {}
  216|       |};
  217|       |
  218|       |template <typename Kernel, int Index_, int Stop>
  219|       |struct copy_using_evaluator_DefaultTraversal_InnerUnrolling {
  220|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel, Index outer) {
  221|       |    kernel.assignCoeffByOuterInner(outer, Index_);
  222|       |    copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, Index_ + 1, Stop>::run(kernel, outer);
  223|       |  }
  224|       |};
  225|       |
  226|       |template <typename Kernel, int Stop>
  227|       |struct copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, Stop, Stop> {
  228|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel&, Index) {}
  229|       |};
  230|       |
  231|       |/***********************
  232|       |*** Linear traversal ***
  233|       |***********************/
  234|       |
  235|       |template <typename Kernel, int Index, int Stop>
  236|       |struct copy_using_evaluator_LinearTraversal_CompleteUnrolling {
  237|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel) {
  238|       |    kernel.assignCoeff(Index);
  239|       |    copy_using_evaluator_LinearTraversal_CompleteUnrolling<Kernel, Index + 1, Stop>::run(kernel);
  240|       |  }
  241|       |};
  242|       |
  243|       |template <typename Kernel, int Stop>
  244|       |struct copy_using_evaluator_LinearTraversal_CompleteUnrolling<Kernel, Stop, Stop> {
  245|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel&) {}
  246|       |};
  247|       |
  248|       |/**************************
  249|       |*** Inner vectorization ***
  250|       |**************************/
  251|       |
  252|       |template <typename Kernel, int Index, int Stop>
  253|       |struct copy_using_evaluator_innervec_CompleteUnrolling {
  254|       |  // FIXME: this is not very clean, perhaps this information should be provided by the kernel?
  255|       |  typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
  256|       |  typedef typename DstEvaluatorType::XprType DstXprType;
  257|       |  typedef typename Kernel::PacketType PacketType;
  258|       |
  259|       |  enum {
  260|       |    outer = Index / DstXprType::InnerSizeAtCompileTime,
  261|       |    inner = Index % DstXprType::InnerSizeAtCompileTime,
  262|       |    SrcAlignment = Kernel::AssignmentTraits::SrcAlignment,
  263|       |    DstAlignment = Kernel::AssignmentTraits::DstAlignment
  264|       |  };
  265|       |
  266|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel) {
  267|       |    kernel.template assignPacketByOuterInner<DstAlignment, SrcAlignment, PacketType>(outer, inner);
  268|       |    enum { NextIndex = Index + unpacket_traits<PacketType>::size };
  269|       |    copy_using_evaluator_innervec_CompleteUnrolling<Kernel, NextIndex, Stop>::run(kernel);
  270|       |  }
  271|       |};
  272|       |
  273|       |template <typename Kernel, int Stop>
  274|       |struct copy_using_evaluator_innervec_CompleteUnrolling<Kernel, Stop, Stop> {
  275|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel&) {}
  276|       |};
  277|       |
  278|       |template <typename Kernel, int Index_, int Stop, int SrcAlignment, int DstAlignment>
  279|       |struct copy_using_evaluator_innervec_InnerUnrolling {
  280|       |  typedef typename Kernel::PacketType PacketType;
  281|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel, Index outer) {
  282|       |    kernel.template assignPacketByOuterInner<DstAlignment, SrcAlignment, PacketType>(outer, Index_);
  283|       |    enum { NextIndex = Index_ + unpacket_traits<PacketType>::size };
  284|       |    copy_using_evaluator_innervec_InnerUnrolling<Kernel, NextIndex, Stop, SrcAlignment, DstAlignment>::run(kernel,
  285|       |                                                                                                           outer);
  286|       |  }
  287|       |};
  288|       |
  289|       |template <typename Kernel, int Stop, int SrcAlignment, int DstAlignment>
  290|       |struct copy_using_evaluator_innervec_InnerUnrolling<Kernel, Stop, Stop, SrcAlignment, DstAlignment> {
  291|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel&, Index) {}
  292|       |};
  293|       |
  294|       |/***************************************************************************
  295|       | * Part 3 : implementation of all cases
  296|       | ***************************************************************************/
  297|       |
  298|       |// dense_assignment_loop is based on assign_impl
  299|       |
  300|       |template <typename Kernel, int Traversal = Kernel::AssignmentTraits::Traversal,
  301|       |          int Unrolling = Kernel::AssignmentTraits::Unrolling>
  302|       |struct dense_assignment_loop;
  303|       |
  304|       |/************************
  305|       |***** Special Cases *****
  306|       |************************/
  307|       |
  308|       |// Zero-sized assignment is a no-op.
  309|       |template <typename Kernel, int Unrolling>
  310|       |struct dense_assignment_loop<Kernel, AllAtOnceTraversal, Unrolling> {
  311|       |  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE EIGEN_CONSTEXPR run(Kernel& /*kernel*/) {
  312|       |    EIGEN_STATIC_ASSERT(int(Kernel::DstEvaluatorType::XprType::SizeAtCompileTime) == 0,
  313|       |                        EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT)
  314|       |  }
  315|       |};
  316|       |
  317|       |/************************
  318|       |*** Default traversal ***
  319|       |************************/
  320|       |
  321|       |template <typename Kernel>
  322|       |struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling> {
  323|      0|  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel& kernel) {
  324|      0|    for (Index outer = 0; outer < kernel.outerSize(); ++outer) {
  325|      0|      for (Index inner = 0; inner < kernel.innerSize(); ++inner) {
  326|      0|        kernel.assignCoeffByOuterInner(outer, inner);
  327|      0|      }
  328|      0|    }
  329|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_41restricted_packet_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS3_INS_7ProductIS6_S6_Li1EEEEENS0_9assign_opIS5_S5_EEEELi0ELi0EE3runERSD_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_41restricted_packet_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS3_INS_7ProductINS8_IS6_S6_Li0EEES6_Li1EEEEENS0_9assign_opIS5_S5_EEEELi0ELi0EE3runERSE_
  ------------------
  330|       |};
  331|       |
  332|       |template <typename Kernel>
  333|       |struct dense_assignment_loop<Kernel, DefaultTraversal, CompleteUnrolling> {
  334|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel) {
  335|       |    typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
  336|       |    copy_using_evaluator_DefaultTraversal_CompleteUnrolling<Kernel, 0, DstXprType::SizeAtCompileTime>::run(kernel);
  337|       |  }
  338|       |};
  339|       |
  340|       |template <typename Kernel>
  341|       |struct dense_assignment_loop<Kernel, DefaultTraversal, InnerUnrolling> {
  342|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel) {
  343|       |    typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
  344|       |
  345|       |    const Index outerSize = kernel.outerSize();
  346|       |    for (Index outer = 0; outer < outerSize; ++outer)
  347|       |      copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, 0, DstXprType::InnerSizeAtCompileTime>::run(kernel,
  348|       |                                                                                                               outer);
  349|       |  }
  350|       |};
  351|       |
  352|       |/***************************
  353|       |*** Linear vectorization ***
  354|       |***************************/
  355|       |
  356|       |// The goal of unaligned_dense_assignment_loop is simply to factorize the handling
  357|       |// of the non vectorizable beginning and ending parts
  358|       |
  359|       |template <bool IsAligned = false>
  360|       |struct unaligned_dense_assignment_loop {
  361|       |  // if IsAligned = true, then do nothing
  362|       |  template <typename Kernel>
  363|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel&, Index, Index) {}
  364|       |};
  365|       |
  366|       |template <>
  367|       |struct unaligned_dense_assignment_loop<false> {
  368|       |  // MSVC must not inline this functions. If it does, it fails to optimize the
  369|       |  // packet access path.
  370|       |  // FIXME check which version exhibits this issue
  371|       |#if EIGEN_COMP_MSVC
  372|       |  template <typename Kernel>
  373|       |  static EIGEN_DONT_INLINE void run(Kernel& kernel, Index start, Index end)
  374|       |#else
  375|       |  template <typename Kernel>
  376|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel, Index start, Index end)
  377|       |#endif
  378|       |  {
  379|       |    for (Index index = start; index < end; ++index) kernel.assignCoeff(index);
  380|       |  }
  381|       |};
  382|       |
  383|       |template <typename Kernel, int Index, int Stop>
  384|       |struct copy_using_evaluator_linearvec_CompleteUnrolling {
  385|       |  // FIXME: this is not very clean, perhaps this information should be provided by the kernel?
  386|       |  typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
  387|       |  typedef typename DstEvaluatorType::XprType DstXprType;
  388|       |  typedef typename Kernel::PacketType PacketType;
  389|       |
  390|       |  enum { SrcAlignment = Kernel::AssignmentTraits::SrcAlignment, DstAlignment = Kernel::AssignmentTraits::DstAlignment };
  391|       |
  392|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel) {
  393|       |    kernel.template assignPacket<DstAlignment, SrcAlignment, PacketType>(Index);
  394|       |    enum { NextIndex = Index + unpacket_traits<PacketType>::size };
  395|       |    copy_using_evaluator_linearvec_CompleteUnrolling<Kernel, NextIndex, Stop>::run(kernel);
  396|       |  }
  397|       |};
  398|       |
  399|       |template <typename Kernel, int Stop>
  400|       |struct copy_using_evaluator_linearvec_CompleteUnrolling<Kernel, Stop, Stop> {
  401|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel&) {}
  402|       |};
  403|       |
  404|       |template <typename Kernel>
  405|       |struct dense_assignment_loop<Kernel, LinearVectorizedTraversal, NoUnrolling> {
  406|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel) {
  407|       |    const Index size = kernel.size();
  408|       |    typedef typename Kernel::Scalar Scalar;
  409|       |    typedef typename Kernel::PacketType PacketType;
  410|       |    enum {
  411|       |      requestedAlignment = Kernel::AssignmentTraits::LinearRequiredAlignment,
  412|       |      packetSize = unpacket_traits<PacketType>::size,
  413|       |      dstIsAligned = int(Kernel::AssignmentTraits::DstAlignment) >= int(requestedAlignment),
  414|       |      dstAlignment = packet_traits<Scalar>::AlignedOnScalar ? int(requestedAlignment)
  415|       |                                                            : int(Kernel::AssignmentTraits::DstAlignment),
  416|       |      srcAlignment = Kernel::AssignmentTraits::JointAlignment
  417|       |    };
  418|       |    const Index alignedStart =
  419|       |        dstIsAligned ? 0 : internal::first_aligned<requestedAlignment>(kernel.dstDataPtr(), size);
  420|       |    const Index alignedEnd = alignedStart + ((size - alignedStart) / packetSize) * packetSize;
  421|       |
  422|       |    unaligned_dense_assignment_loop<dstIsAligned != 0>::run(kernel, 0, alignedStart);
  423|       |
  424|       |    for (Index index = alignedStart; index < alignedEnd; index += packetSize)
  425|       |      kernel.template assignPacket<dstAlignment, srcAlignment, PacketType>(index);
  426|       |
  427|       |    unaligned_dense_assignment_loop<>::run(kernel, alignedEnd, size);
  428|       |  }
  429|       |};
  430|       |
  431|       |template <typename Kernel>
  432|       |struct dense_assignment_loop<Kernel, LinearVectorizedTraversal, CompleteUnrolling> {
  433|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel) {
  434|       |    typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
  435|       |    typedef typename Kernel::PacketType PacketType;
  436|       |
  437|       |    enum {
  438|       |      size = DstXprType::SizeAtCompileTime,
  439|       |      packetSize = unpacket_traits<PacketType>::size,
  440|       |      alignedSize = (int(size) / packetSize) * packetSize
  441|       |    };
  442|       |
  443|       |    copy_using_evaluator_linearvec_CompleteUnrolling<Kernel, 0, alignedSize>::run(kernel);
  444|       |    copy_using_evaluator_LinearTraversal_CompleteUnrolling<Kernel, alignedSize, size>::run(kernel);
  445|       |  }
  446|       |};
  447|       |
  448|       |/**************************
  449|       |*** Inner vectorization ***
  450|       |**************************/
  451|       |
  452|       |template <typename Kernel>
  453|       |struct dense_assignment_loop<Kernel, InnerVectorizedTraversal, NoUnrolling> {
  454|       |  typedef typename Kernel::PacketType PacketType;
  455|       |  enum { SrcAlignment = Kernel::AssignmentTraits::SrcAlignment, DstAlignment = Kernel::AssignmentTraits::DstAlignment };
  456|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel) {
  457|       |    const Index innerSize = kernel.innerSize();
  458|       |    const Index outerSize = kernel.outerSize();
  459|       |    const Index packetSize = unpacket_traits<PacketType>::size;
  460|       |    for (Index outer = 0; outer < outerSize; ++outer)
  461|       |      for (Index inner = 0; inner < innerSize; inner += packetSize)
  462|       |        kernel.template assignPacketByOuterInner<DstAlignment, SrcAlignment, PacketType>(outer, inner);
  463|       |  }
  464|       |};
  465|       |
  466|       |template <typename Kernel>
  467|       |struct dense_assignment_loop<Kernel, InnerVectorizedTraversal, CompleteUnrolling> {
  468|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel) {
  469|       |    typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
  470|       |    copy_using_evaluator_innervec_CompleteUnrolling<Kernel, 0, DstXprType::SizeAtCompileTime>::run(kernel);
  471|       |  }
  472|       |};
  473|       |
  474|       |template <typename Kernel>
  475|       |struct dense_assignment_loop<Kernel, InnerVectorizedTraversal, InnerUnrolling> {
  476|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel& kernel) {
  477|       |    typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
  478|       |    typedef typename Kernel::AssignmentTraits Traits;
  479|       |    const Index outerSize = kernel.outerSize();
  480|       |    for (Index outer = 0; outer < outerSize; ++outer)
  481|       |      copy_using_evaluator_innervec_InnerUnrolling<Kernel, 0, DstXprType::InnerSizeAtCompileTime, Traits::SrcAlignment,
  482|       |                                                   Traits::DstAlignment>::run(kernel, outer);
  483|       |  }
  484|       |};
  485|       |
  486|       |/***********************
  487|       |*** Linear traversal ***
  488|       |***********************/
  489|       |
  490|       |template <typename Kernel>
  491|       |struct dense_assignment_loop<Kernel, LinearTraversal, NoUnrolling> {
  492|      4|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel) {
  493|      4|    const Index size = kernel.size();
  494|  7.55k|    for (Index i = 0; i < size; ++i) kernel.assignCoeff(i);
  495|      4|  }
  ------------------
  | _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS3_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEENS0_9assign_opIS5_S5_EELi0EEELi1ELi0EE3runERSF_:
  |  492|      1|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel) {
  |  493|      1|    const Index size = kernel.size();
  |  494|     51|    for (Index i = 0; i < size; ++i) kernel.assignCoeff(i);
  |  495|      1|  }
  ------------------
  | _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS3_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEENS0_9assign_opIS5_S5_EELi0EEELi1ELi0EE3runERSF_:
  |  492|      3|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel) {
  |  493|      3|    const Index size = kernel.size();
  |  494|  7.50k|    for (Index i = 0; i < size; ++i) kernel.assignCoeff(i);
  |  495|      3|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS3_INS_9TransposeIKNS_5BlockIKNS5_IS6_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEENS0_9assign_opIS6_S6_EELi0EEELi1ELi0EE3runERSM_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEES7_NS0_9assign_opIS5_S5_EELi0EEELi1ELi0EE3runERSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEENS3_INS_5BlockIKNS_7ProductINS4_IS5_Lin1ELin1ELi0ELin1ELin1EEESA_Li0EEELi1ELin1ELb0EEEEENS0_9assign_opIS5_S5_EELi0EEELi1ELi0EE3runERSH_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEES7_NS0_9assign_opIS5_S5_EELi0EEELi1ELi0EE3runERSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS3_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS6_EES7_EEEENS0_9assign_opIS6_S6_EELi0EEELi1ELi0EE3runERSJ_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS3_INS_5BlockINS5_IS6_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEENS0_9assign_opIS6_S6_EELi0EEELi1ELi0EE3runERSI_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEENS3_INS_13CwiseBinaryOpINS0_17scalar_product_opIS6_S6_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS6_EEKNS5_IS6_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISG_Li1ENS_6StrideILi0ELi0EEEEEEEEENS0_13add_assign_opIS6_S6_EELi0EEELi1ELi0EE3runERST_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEENS3_INS_3MapINS5_IS6_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS0_9assign_opIS6_S6_EELi0EEELi1ELi0EE3runERSI_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS3_IS7_EENS0_9assign_opIS6_S6_EELi0EEELi1ELi0EE3runERSF_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS3_INS_13CwiseBinaryOpINS0_17scalar_product_opIS5_S5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKS6_EEKNS_3MapIS6_Li1ENS_6StrideILi0ELi0EEEEEEEEENS0_13add_assign_opIS5_S5_EELi0EEELi1ELi0EE3runERSQ_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS3_INS_3MapIS6_Li1ENS_6StrideILi0ELi0EEEEEEENS0_9assign_opIS5_S5_EELi0EEELi1ELi0EE3runERSF_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS3_INS_9TransposeIKNS5_IS6_Li1ELin1ELi1ELi1ELin1EEEEEEENS0_9assign_opIS6_S6_EELi0EEELi1ELi0EE3runERSJ_
  ------------------
  496|       |};
  497|       |
  498|       |template <typename Kernel>
  499|       |struct dense_assignment_loop<Kernel, LinearTraversal, CompleteUnrolling> {
  500|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel) {
  501|       |    typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
  502|       |    copy_using_evaluator_LinearTraversal_CompleteUnrolling<Kernel, 0, DstXprType::SizeAtCompileTime>::run(kernel);
  503|       |  }
  504|       |};
  505|       |
  506|       |/**************************
  507|       |*** Slice vectorization ***
  508|       |***************************/
  509|       |
  510|       |template <typename Kernel>
  511|       |struct dense_assignment_loop<Kernel, SliceVectorizedTraversal, NoUnrolling> {
  512|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel) {
  513|       |    typedef typename Kernel::Scalar Scalar;
  514|       |    typedef typename Kernel::PacketType PacketType;
  515|       |    enum {
  516|       |      packetSize = unpacket_traits<PacketType>::size,
  517|       |      requestedAlignment = int(Kernel::AssignmentTraits::InnerRequiredAlignment),
  518|       |      alignable =
  519|       |          packet_traits<Scalar>::AlignedOnScalar || int(Kernel::AssignmentTraits::DstAlignment) >= sizeof(Scalar),
  520|       |      dstIsAligned = int(Kernel::AssignmentTraits::DstAlignment) >= int(requestedAlignment),
  521|       |      dstAlignment = alignable ? int(requestedAlignment) : int(Kernel::AssignmentTraits::DstAlignment)
  522|       |    };
  523|       |    const Scalar* dst_ptr = kernel.dstDataPtr();
  524|       |    if ((!bool(dstIsAligned)) && (std::uintptr_t(dst_ptr) % sizeof(Scalar)) > 0) {
  525|       |      // the pointer is not aligned-on scalar, so alignment is not possible
  526|       |      return dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>::run(kernel);
  527|       |    }
  528|       |    const Index packetAlignedMask = packetSize - 1;
  529|       |    const Index innerSize = kernel.innerSize();
  530|       |    const Index outerSize = kernel.outerSize();
  531|       |    const Index alignedStep = alignable ? (packetSize - kernel.outerStride() % packetSize) & packetAlignedMask : 0;
  532|       |    Index alignedStart =
  533|       |        ((!alignable) || bool(dstIsAligned)) ? 0 : internal::first_aligned<requestedAlignment>(dst_ptr, innerSize);
  534|       |
  535|       |    for (Index outer = 0; outer < outerSize; ++outer) {
  536|       |      const Index alignedEnd = alignedStart + ((innerSize - alignedStart) & ~packetAlignedMask);
  537|       |      // do the non-vectorizable part of the assignment
  538|       |      for (Index inner = 0; inner < alignedStart; ++inner) kernel.assignCoeffByOuterInner(outer, inner);
  539|       |
  540|       |      // do the vectorizable part of the assignment
  541|       |      for (Index inner = alignedStart; inner < alignedEnd; inner += packetSize)
  542|       |        kernel.template assignPacketByOuterInner<dstAlignment, Unaligned, PacketType>(outer, inner);
  543|       |
  544|       |      // do the non-vectorizable part of the assignment
  545|       |      for (Index inner = alignedEnd; inner < innerSize; ++inner) kernel.assignCoeffByOuterInner(outer, inner);
  546|       |
  547|       |      alignedStart = numext::mini((alignedStart + alignedStep) % packetSize, innerSize);
  548|       |    }
  549|       |  }
  550|       |};
  551|       |
  552|       |#if EIGEN_UNALIGNED_VECTORIZE
  553|       |template <typename Kernel>
  554|       |struct dense_assignment_loop<Kernel, SliceVectorizedTraversal, InnerUnrolling> {
  555|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel& kernel) {
  556|       |    typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
  557|       |    typedef typename Kernel::PacketType PacketType;
  558|       |
  559|       |    enum {
  560|       |      innerSize = DstXprType::InnerSizeAtCompileTime,
  561|       |      packetSize = unpacket_traits<PacketType>::size,
  562|       |      vectorizableSize = (int(innerSize) / int(packetSize)) * int(packetSize),
  563|       |      size = DstXprType::SizeAtCompileTime
  564|       |    };
  565|       |
  566|       |    for (Index outer = 0; outer < kernel.outerSize(); ++outer) {
  567|       |      copy_using_evaluator_innervec_InnerUnrolling<Kernel, 0, vectorizableSize, 0, 0>::run(kernel, outer);
  568|       |      copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, vectorizableSize, innerSize>::run(kernel, outer);
  569|       |    }
  570|       |  }
  571|       |};
  572|       |#endif
  573|       |
  574|       |/***************************************************************************
  575|       | * Part 4 : Generic dense assignment kernel
  576|       | ***************************************************************************/
  577|       |
  578|       |// This class generalize the assignment of a coefficient (or packet) from one dense evaluator
  579|       |// to another dense writable evaluator.
  580|       |// It is parametrized by the two evaluators, and the actual assignment functor.
  581|       |// This abstraction level permits to keep the evaluation loops as simple and as generic as possible.
  582|       |// One can customize the assignment using this generic dense_assignment_kernel with different
  583|       |// functors, or by completely overloading it, by-passing a functor.
  584|       |template <typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor, int Version = Specialized>
  585|       |class generic_dense_assignment_kernel {
  586|       | protected:
  587|       |  typedef typename DstEvaluatorTypeT::XprType DstXprType;
  588|       |  typedef typename SrcEvaluatorTypeT::XprType SrcXprType;
  589|       |
  590|       | public:
  591|       |  typedef DstEvaluatorTypeT DstEvaluatorType;
  592|       |  typedef SrcEvaluatorTypeT SrcEvaluatorType;
  593|       |  typedef typename DstEvaluatorType::Scalar Scalar;
  594|       |  typedef copy_using_evaluator_traits<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor> AssignmentTraits;
  595|       |  typedef typename AssignmentTraits::PacketType PacketType;
  596|       |
  597|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE generic_dense_assignment_kernel(DstEvaluatorType& dst,
  598|       |                                                                        const SrcEvaluatorType& src,
  599|       |                                                                        const Functor& func, DstXprType& dstExpr)
  600|      4|      : m_dst(dst), m_src(src), m_functor(func), m_dstExpr(dstExpr) {
  601|       |#ifdef EIGEN_DEBUG_ASSIGN
  602|       |    AssignmentTraits::debug();
  603|       |#endif
  604|      4|  }
  ------------------
  | _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS4_EES5_EEEENS0_9assign_opIS4_S4_EELi0EEC2ERS6_RKSB_RKSD_RS5_:
  |  600|      1|      : m_dst(dst), m_src(src), m_functor(func), m_dstExpr(dstExpr) {
  |  601|       |#ifdef EIGEN_DEBUG_ASSIGN
  |  602|       |    AssignmentTraits::debug();
  |  603|       |#endif
  |  604|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductIS5_S5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EEC2ERS6_RKS9_RKSB_RS5_
  ------------------
  | _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS4_EES5_EEEENS0_9assign_opIS4_S4_EELi0EEC2ERS6_RKSB_RKSD_RS5_:
  |  600|      3|      : m_dst(dst), m_src(src), m_functor(func), m_dstExpr(dstExpr) {
  |  601|       |#ifdef EIGEN_DEBUG_ASSIGN
  |  602|       |    AssignmentTraits::debug();
  |  603|       |#endif
  |  604|      3|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_9TransposeIKNS_5BlockIKNS4_IS5_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEENS0_9assign_opIS5_S5_EELi0EEC2ERSA_RKSI_RKSK_RS9_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEES6_NS0_9assign_opIS4_S4_EELi0EEC2ERS6_RKS6_RKS8_RS5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductINS7_IS5_S5_Li0EEES5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EEC2ERS6_RKSA_RKSC_RS5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEENS2_INS_5BlockIKNS_7ProductINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEES9_Li0EEELi1ELin1ELb0EEEEENS0_9assign_opIS4_S4_EELi0EEC2ERS6_RKSD_RKSF_RS5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEES6_NS0_9assign_opIS4_S4_EELi0EEC2ERS6_RKS6_RKS8_RS5_
  ------------------
  605|       |
  606|      4|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_dstExpr.size(); }
  ------------------
  | _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS4_EES5_EEEENS0_9assign_opIS4_S4_EELi0EE4sizeEv:
  |  606|      1|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_dstExpr.size(); }
  ------------------
  | _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS4_EES5_EEEENS0_9assign_opIS4_S4_EELi0EE4sizeEv:
  |  606|      3|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_dstExpr.size(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_9TransposeIKNS_5BlockIKNS4_IS5_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEENS0_9assign_opIS5_S5_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEES6_NS0_9assign_opIS4_S4_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEENS2_INS_5BlockIKNS_7ProductINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEES9_Li0EEELi1ELin1ELb0EEEEENS0_9assign_opIS4_S4_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEES6_NS0_9assign_opIS4_S4_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEENS0_9assign_opIS5_S5_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS2_INS_5BlockINS4_IS5_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEENS0_9assign_opIS5_S5_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEENS2_INS_13CwiseBinaryOpINS0_17scalar_product_opIS5_S5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKNS4_IS5_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISF_Li1ENS_6StrideILi0ELi0EEEEEEEEENS0_13add_assign_opIS5_S5_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEENS2_INS_3MapINS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS0_9assign_opIS5_S5_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS2_IS6_EENS0_9assign_opIS5_S5_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS2_INS_13CwiseBinaryOpINS0_17scalar_product_opIS4_S4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKS5_EEKNS_3MapIS5_Li1ENS_6StrideILi0ELi0EEEEEEEEENS0_13add_assign_opIS4_S4_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS2_INS_3MapIS5_Li1ENS_6StrideILi0ELi0EEEEEEENS0_9assign_opIS4_S4_EELi0EE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_9TransposeIKNS4_IS5_Li1ELin1ELi1ELi1ELin1EEEEEEENS0_9assign_opIS5_S5_EELi0EE4sizeEv
  ------------------
  607|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index innerSize() const EIGEN_NOEXCEPT { return m_dstExpr.innerSize(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductIS5_S5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE9innerSizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductINS7_IS5_S5_Li0EEES5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE9innerSizeEv
  ------------------
  608|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index outerSize() const EIGEN_NOEXCEPT { return m_dstExpr.outerSize(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductIS5_S5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE9outerSizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductINS7_IS5_S5_Li0EEES5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE9outerSizeEv
  ------------------
  609|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_dstExpr.rows(); }
  610|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_dstExpr.cols(); }
  611|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index outerStride() const EIGEN_NOEXCEPT { return m_dstExpr.outerStride(); }
  612|       |
  613|       |  EIGEN_DEVICE_FUNC DstEvaluatorType& dstEvaluator() EIGEN_NOEXCEPT { return m_dst; }
  614|       |  EIGEN_DEVICE_FUNC const SrcEvaluatorType& srcEvaluator() const EIGEN_NOEXCEPT { return m_src; }
  615|       |
  616|       |  /// Assign src(row,col) to dst(row,col) through the assignment functor.
  617|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(Index row, Index col) {
  618|      0|    m_functor.assignCoeff(m_dst.coeffRef(row, col), m_src.coeff(row, col));
  619|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductIS5_S5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE11assignCoeffEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductINS7_IS5_S5_Li0EEES5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE11assignCoeffEll
  ------------------
  620|       |
  621|       |  /// \sa assignCoeff(Index,Index)
  622|  7.55k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(Index index) {
  623|  7.55k|    m_functor.assignCoeff(m_dst.coeffRef(index), m_src.coeff(index));
  624|  7.55k|  }
  ------------------
  | _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS4_EES5_EEEENS0_9assign_opIS4_S4_EELi0EE11assignCoeffEl:
  |  622|     50|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(Index index) {
  |  623|     50|    m_functor.assignCoeff(m_dst.coeffRef(index), m_src.coeff(index));
  |  624|     50|  }
  ------------------
  | _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS4_EES5_EEEENS0_9assign_opIS4_S4_EELi0EE11assignCoeffEl:
  |  622|  7.50k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(Index index) {
  |  623|  7.50k|    m_functor.assignCoeff(m_dst.coeffRef(index), m_src.coeff(index));
  |  624|  7.50k|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_9TransposeIKNS_5BlockIKNS4_IS5_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEENS0_9assign_opIS5_S5_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEES6_NS0_9assign_opIS4_S4_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEENS2_INS_5BlockIKNS_7ProductINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEES9_Li0EEELi1ELin1ELb0EEEEENS0_9assign_opIS4_S4_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEES6_NS0_9assign_opIS4_S4_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEENS0_9assign_opIS5_S5_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS2_INS_5BlockINS4_IS5_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEENS0_9assign_opIS5_S5_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEENS2_INS_13CwiseBinaryOpINS0_17scalar_product_opIS5_S5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKNS4_IS5_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISF_Li1ENS_6StrideILi0ELi0EEEEEEEEENS0_13add_assign_opIS5_S5_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEENS2_INS_3MapINS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS0_9assign_opIS5_S5_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEENS2_IS6_EENS0_9assign_opIS5_S5_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS2_INS_13CwiseBinaryOpINS0_17scalar_product_opIS4_S4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKS5_EEKNS_3MapIS5_Li1ENS_6StrideILi0ELi0EEEEEEEEENS0_13add_assign_opIS4_S4_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEENS2_INS_3MapIS5_Li1ENS_6StrideILi0ELi0EEEEEEENS0_9assign_opIS4_S4_EELi0EE11assignCoeffEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS2_INS_9TransposeIKNS4_IS5_Li1ELin1ELi1ELi1ELin1EEEEEEENS0_9assign_opIS5_S5_EELi0EE11assignCoeffEl
  ------------------
  625|       |
  626|       |  /// \sa assignCoeff(Index,Index)
  627|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeffByOuterInner(Index outer, Index inner) {
  628|      0|    Index row = rowIndexByOuterInner(outer, inner);
  629|      0|    Index col = colIndexByOuterInner(outer, inner);
  630|      0|    assignCoeff(row, col);
  631|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductIS5_S5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE23assignCoeffByOuterInnerEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductINS7_IS5_S5_Li0EEES5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE23assignCoeffByOuterInnerEll
  ------------------
  632|       |
  633|       |  template <int StoreMode, int LoadMode, typename Packet>
  634|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignPacket(Index row, Index col) {
  635|       |    m_functor.template assignPacket<StoreMode>(&m_dst.coeffRef(row, col),
  636|       |                                               m_src.template packet<LoadMode, Packet>(row, col));
  637|       |  }
  638|       |
  639|       |  template <int StoreMode, int LoadMode, typename Packet>
  640|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignPacket(Index index) {
  641|       |    m_functor.template assignPacket<StoreMode>(&m_dst.coeffRef(index), m_src.template packet<LoadMode, Packet>(index));
  642|       |  }
  643|       |
  644|       |  template <int StoreMode, int LoadMode, typename Packet>
  645|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignPacketByOuterInner(Index outer, Index inner) {
  646|       |    Index row = rowIndexByOuterInner(outer, inner);
  647|       |    Index col = colIndexByOuterInner(outer, inner);
  648|       |    assignPacket<StoreMode, LoadMode, Packet>(row, col);
  649|       |  }
  650|       |
  651|      0|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Index rowIndexByOuterInner(Index outer, Index inner) {
  652|      0|    typedef typename DstEvaluatorType::ExpressionTraits Traits;
  653|      0|    return int(Traits::RowsAtCompileTime) == 1          ? 0
  654|      0|           : int(Traits::ColsAtCompileTime) == 1        ? inner
  655|      0|           : int(DstEvaluatorType::Flags) & RowMajorBit ? outer
  656|      0|                                                        : inner;
  657|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductIS5_S5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE20rowIndexByOuterInnerEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductINS7_IS5_S5_Li0EEES5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE20rowIndexByOuterInnerEll
  ------------------
  658|       |
  659|      0|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Index colIndexByOuterInner(Index outer, Index inner) {
  660|      0|    typedef typename DstEvaluatorType::ExpressionTraits Traits;
  661|      0|    return int(Traits::ColsAtCompileTime) == 1          ? 0
  662|      0|           : int(Traits::RowsAtCompileTime) == 1        ? inner
  663|      0|           : int(DstEvaluatorType::Flags) & RowMajorBit ? inner
  664|      0|                                                        : outer;
  665|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductIS5_S5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE20colIndexByOuterInnerEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal31generic_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductINS7_IS5_S5_Li0EEES5_Li1EEEEENS0_9assign_opIS4_S4_EELi1EE20colIndexByOuterInnerEll
  ------------------
  666|       |
  667|       |  EIGEN_DEVICE_FUNC const Scalar* dstDataPtr() const { return m_dstExpr.data(); }
  668|       |
  669|       | protected:
  670|       |  DstEvaluatorType& m_dst;
  671|       |  const SrcEvaluatorType& m_src;
  672|       |  const Functor& m_functor;
  673|       |  // TODO find a way to avoid the needs of the original expression
  674|       |  DstXprType& m_dstExpr;
  675|       |};
  676|       |
  677|       |// Special kernel used when computing small products whose operands have dynamic dimensions.  It ensures that the
  678|       |// PacketSize used is no larger than 4, thereby increasing the chance that vectorized instructions will be used
  679|       |// when computing the product.
  680|       |
  681|       |template <typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor>
  682|       |class restricted_packet_dense_assignment_kernel
  683|       |    : public generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, BuiltIn> {
  684|       | protected:
  685|       |  typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, BuiltIn> Base;
  686|       |
  687|       | public:
  688|       |  typedef typename Base::Scalar Scalar;
  689|       |  typedef typename Base::DstXprType DstXprType;
  690|       |  typedef copy_using_evaluator_traits<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, 4> AssignmentTraits;
  691|       |  typedef typename AssignmentTraits::PacketType PacketType;
  692|       |
  693|       |  EIGEN_DEVICE_FUNC restricted_packet_dense_assignment_kernel(DstEvaluatorTypeT& dst, const SrcEvaluatorTypeT& src,
  694|       |                                                              const Functor& func, DstXprType& dstExpr)
  695|      0|      : Base(dst, src, func, dstExpr) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal41restricted_packet_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductIS5_S5_Li1EEEEENS0_9assign_opIS4_S4_EEEC2ERS6_RKS9_RKSB_RS5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal41restricted_packet_dense_assignment_kernelINS0_9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS2_INS_7ProductINS7_IS5_S5_Li0EEES5_Li1EEEEENS0_9assign_opIS4_S4_EEEC2ERS6_RKSA_RKSC_RS5_
  ------------------
  696|       |};
  697|       |
  698|       |/***************************************************************************
  699|       | * Part 5 : Entry point for dense rectangular assignment
  700|       | ***************************************************************************/
  701|       |
  702|       |template <typename DstXprType, typename SrcXprType, typename Functor>
  703|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize_if_allowed(DstXprType& dst, const SrcXprType& src,
  704|      0|                                                             const Functor& /*func*/) {
  705|      0|  EIGEN_ONLY_USED_FOR_DEBUG(dst);
  706|      0|  EIGEN_ONLY_USED_FOR_DEBUG(src);
  707|      0|  eigen_assert(dst.rows() == src.rows() && dst.cols() == src.cols());
  708|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS4_S4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKNS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISD_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS3_S3_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS3_EEKS4_EEKNS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  709|       |
  710|       |template <typename DstXprType, typename SrcXprType, typename T1, typename T2>
  711|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize_if_allowed(DstXprType& dst, const SrcXprType& src,
  712|      4|                                                             const internal::assign_op<T1, T2>& /*func*/) {
  713|      4|  Index dstRows = src.rows();
  714|      4|  Index dstCols = src.cols();
  715|      4|  if (((dst.rows() != dstRows) || (dst.cols() != dstCols))) dst.resize(dstRows, dstCols);
  716|      4|  eigen_assert(dst.rows() == dstRows && dst.cols() == dstCols);
  717|      4|}
  ------------------
  | _ZN5Eigen8internal17resize_if_allowedINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_14CwiseNullaryOpINS0_14scalar_zero_opIS3_EES4_EES3_S3_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE:
  |  712|      1|                                                             const internal::assign_op<T1, T2>& /*func*/) {
  |  713|      1|  Index dstRows = src.rows();
  |  714|      1|  Index dstCols = src.cols();
  |  715|      1|  if (((dst.rows() != dstRows) || (dst.cols() != dstCols))) dst.resize(dstRows, dstCols);
  |  716|      1|  eigen_assert(dst.rows() == dstRows && dst.cols() == dstCols);
  |  717|      1|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductIS4_S4_Li1EEES3_S3_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | _ZN5Eigen8internal17resize_if_allowedINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_14CwiseNullaryOpINS0_14scalar_zero_opIS3_EES4_EES3_S3_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE:
  |  712|      3|                                                             const internal::assign_op<T1, T2>& /*func*/) {
  |  713|      3|  Index dstRows = src.rows();
  |  714|      3|  Index dstCols = src.cols();
  |  715|      3|  if (((dst.rows() != dstRows) || (dst.cols() != dstCols))) dst.resize(dstRows, dstCols);
  |  716|      3|  eigen_assert(dst.rows() == dstRows && dst.cols() == dstCols);
  |  717|      3|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS_5BlockIKNS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEES4_S4_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEES4_S3_S3_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductINS5_IS4_S4_Li0EEES4_Li1EEES3_S3_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS_5BlockIKNS_7ProductINS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEES3_S3_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_S3_S3_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_14CwiseNullaryOpINS0_14scalar_zero_opIS4_EES5_EES4_S4_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_5BlockINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEES4_S4_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_3MapINS3_IS4_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES4_S4_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_S4_S4_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEES3_S3_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17resize_if_allowedINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEES4_S4_EEvRT_RKT0_RKNS0_9assign_opIT1_T2_EE
  ------------------
  718|       |
  719|       |template <typename DstXprType, typename SrcXprType, typename Functor>
  720|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void call_dense_assignment_loop(DstXprType& dst,
  721|       |                                                                                      const SrcXprType& src,
  722|      4|                                                                                      const Functor& func) {
  723|      4|  typedef evaluator<DstXprType> DstEvaluatorType;
  724|      4|  typedef evaluator<SrcXprType> SrcEvaluatorType;
  725|       |
  726|      4|  SrcEvaluatorType srcEvaluator(src);
  727|       |
  728|       |  // NOTE To properly handle A = (A*A.transpose())/s with A rectangular,
  729|       |  // we need to resize the destination after the source evaluator has been created.
  730|      4|  resize_if_allowed(dst, src, func);
  731|       |
  732|      4|  DstEvaluatorType dstEvaluator(dst);
  733|       |
  734|      4|  typedef generic_dense_assignment_kernel<DstEvaluatorType, SrcEvaluatorType, Functor> Kernel;
  735|      4|  Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
  736|       |
  737|      4|  dense_assignment_loop<Kernel>::run(kernel);
  738|      4|}
  ------------------
  | _ZN5Eigen8internal26call_dense_assignment_loopINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_14CwiseNullaryOpINS0_14scalar_zero_opIS3_EES4_EENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_:
  |  722|      1|                                                                                      const Functor& func) {
  |  723|      1|  typedef evaluator<DstXprType> DstEvaluatorType;
  |  724|      1|  typedef evaluator<SrcXprType> SrcEvaluatorType;
  |  725|       |
  |  726|      1|  SrcEvaluatorType srcEvaluator(src);
  |  727|       |
  |  728|       |  // NOTE To properly handle A = (A*A.transpose())/s with A rectangular,
  |  729|       |  // we need to resize the destination after the source evaluator has been created.
  |  730|      1|  resize_if_allowed(dst, src, func);
  |  731|       |
  |  732|      1|  DstEvaluatorType dstEvaluator(dst);
  |  733|       |
  |  734|      1|  typedef generic_dense_assignment_kernel<DstEvaluatorType, SrcEvaluatorType, Functor> Kernel;
  |  735|      1|  Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
  |  736|       |
  |  737|      1|  dense_assignment_loop<Kernel>::run(kernel);
  |  738|      1|}
  ------------------
  | _ZN5Eigen8internal26call_dense_assignment_loopINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_14CwiseNullaryOpINS0_14scalar_zero_opIS3_EES4_EENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_:
  |  722|      3|                                                                                      const Functor& func) {
  |  723|      3|  typedef evaluator<DstXprType> DstEvaluatorType;
  |  724|      3|  typedef evaluator<SrcXprType> SrcEvaluatorType;
  |  725|       |
  |  726|      3|  SrcEvaluatorType srcEvaluator(src);
  |  727|       |
  |  728|       |  // NOTE To properly handle A = (A*A.transpose())/s with A rectangular,
  |  729|       |  // we need to resize the destination after the source evaluator has been created.
  |  730|      3|  resize_if_allowed(dst, src, func);
  |  731|       |
  |  732|      3|  DstEvaluatorType dstEvaluator(dst);
  |  733|       |
  |  734|      3|  typedef generic_dense_assignment_kernel<DstEvaluatorType, SrcEvaluatorType, Functor> Kernel;
  |  735|      3|  Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
  |  736|       |
  |  737|      3|  dense_assignment_loop<Kernel>::run(kernel);
  |  738|      3|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS_5BlockIKNS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEES4_NS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS_5BlockIKNS_7ProductINS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_NS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_14CwiseNullaryOpINS0_14scalar_zero_opIS4_EES5_EENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_5BlockINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS4_S4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKNS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISD_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_3MapINS3_IS4_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_NS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS3_S3_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS3_EEKS4_EEKNS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26call_dense_assignment_loopINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  739|       |
  740|       |template <typename DstXprType, typename SrcXprType>
  741|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_dense_assignment_loop(DstXprType& dst, const SrcXprType& src) {
  742|       |  call_dense_assignment_loop(dst, src, internal::assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>());
  743|       |}
  744|       |
  745|       |/***************************************************************************
  746|       | * Part 6 : Generic assignment
  747|       | ***************************************************************************/
  748|       |
  749|       |// Based on the respective shapes of the destination and source,
  750|       |// the class AssignmentKind determine the kind of assignment mechanism.
  751|       |// AssignmentKind must define a Kind typedef.
  752|       |template <typename DstShape, typename SrcShape>
  753|       |struct AssignmentKind;
  754|       |
  755|       |// Assignment kind defined in this file:
  756|       |struct Dense2Dense {};
  757|       |struct EigenBase2EigenBase {};
  758|       |
  759|       |template <typename, typename>
  760|       |struct AssignmentKind {
  761|       |  typedef EigenBase2EigenBase Kind;
  762|       |};
  763|       |template <>
  764|       |struct AssignmentKind<DenseShape, DenseShape> {
  765|       |  typedef Dense2Dense Kind;
  766|       |};
  767|       |
  768|       |// This is the main assignment class
  769|       |template <typename DstXprType, typename SrcXprType, typename Functor,
  770|       |          typename Kind = typename AssignmentKind<typename evaluator_traits<DstXprType>::Shape,
  771|       |                                                  typename evaluator_traits<SrcXprType>::Shape>::Kind,
  772|       |          typename EnableIf = void>
  773|       |struct Assignment;
  774|       |
  775|       |// The only purpose of this call_assignment() function is to deal with noalias() / "assume-aliasing" and automatic
  776|       |// transposition. Indeed, I (Gael) think that this concept of "assume-aliasing" was a mistake, and it makes thing quite
  777|       |// complicated. So this intermediate function removes everything related to "assume-aliasing" such that Assignment does
  778|       |// not has to bother about these annoying details.
  779|       |
  780|       |template <typename Dst, typename Src>
  781|      2|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_assignment(Dst& dst, const Src& src) {
  782|      2|  call_assignment(dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
  783|      2|}
  ------------------
  | _ZN5Eigen8internal15call_assignmentINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_7ProductINS5_INS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES6_Li0EEES4_Li0EEEEEvRT_RKT0_:
  |  781|      1|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_assignment(Dst& dst, const Src& src) {
  |  782|      1|  call_assignment(dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
  |  783|      1|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS_5BlockIKNS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEEvRT_RKT0_
  ------------------
  | _ZN5Eigen8internal15call_assignmentINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductINS5_IS4_S4_Li0EEES4_Li0EEEEEvRT_RKT0_:
  |  781|      1|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_assignment(Dst& dst, const Src& src) {
  |  782|      1|  call_assignment(dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
  |  783|      1|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_5BlockINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEEvRT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_3MapINS3_IS4_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEEvRT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_EEvRT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEEEEvRT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEEEEvRT_RKT0_
  ------------------
  784|       |template <typename Dst, typename Src>
  785|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_assignment(const Dst& dst, const Src& src) {
  786|       |  call_assignment(dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
  787|       |}
  788|       |
  789|       |// Deal with "assume-aliasing"
  790|       |template <typename Dst, typename Src, typename Func>
  791|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void call_assignment(
  792|      2|    Dst& dst, const Src& src, const Func& func, std::enable_if_t<evaluator_assume_aliasing<Src>::value, void*> = 0) {
  793|      2|  typename plain_matrix_type<Src>::type tmp(src);
  794|      2|  call_assignment_no_alias(dst, tmp, func);
  795|      2|}
  ------------------
  | _ZN5Eigen8internal15call_assignmentINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_7ProductINS5_INS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES6_Li0EEES4_Li0EEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXsr25evaluator_assume_aliasingISD_EE5valueEPvE4typeE:
  |  792|      1|    Dst& dst, const Src& src, const Func& func, std::enable_if_t<evaluator_assume_aliasing<Src>::value, void*> = 0) {
  |  793|      1|  typename plain_matrix_type<Src>::type tmp(src);
  |  794|      1|  call_assignment_no_alias(dst, tmp, func);
  |  795|      1|}
  ------------------
  | _ZN5Eigen8internal15call_assignmentINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductINS5_IS4_S4_Li0EEES4_Li0EEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXsr25evaluator_assume_aliasingISC_EE5valueEPvE4typeE:
  |  792|      1|    Dst& dst, const Src& src, const Func& func, std::enable_if_t<evaluator_assume_aliasing<Src>::value, void*> = 0) {
  |  793|      1|  typename plain_matrix_type<Src>::type tmp(src);
  |  794|      1|  call_assignment_no_alias(dst, tmp, func);
  |  795|      1|}
  ------------------
  796|       |
  797|       |template <typename Dst, typename Src, typename Func>
  798|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_assignment(
  799|      0|    Dst& dst, const Src& src, const Func& func, std::enable_if_t<!evaluator_assume_aliasing<Src>::value, void*> = 0) {
  800|      0|  call_assignment_no_alias(dst, src, func);
  801|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS_5BlockIKNS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXntsr25evaluator_assume_aliasingISK_EE5valueEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_5BlockINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXntsr25evaluator_assume_aliasingISG_EE5valueEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS4_S4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKNS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISD_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS4_S4_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXntsr25evaluator_assume_aliasingISR_EE5valueEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_3MapINS3_IS4_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXntsr25evaluator_assume_aliasingISG_EE5valueEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_NS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXntsr25evaluator_assume_aliasingISD_EE5valueEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS3_S3_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS3_EEKS4_EEKNS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS3_S3_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXntsr25evaluator_assume_aliasingISO_EE5valueEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXntsr25evaluator_assume_aliasingISD_EE5valueEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15call_assignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_NSt9enable_ifIXntsr25evaluator_assume_aliasingISH_EE5valueEPvE4typeE
  ------------------
  802|       |
  803|       |// by-pass "assume-aliasing"
  804|       |// When there is no aliasing, we require that 'dst' has been properly resized
  805|       |template <typename Dst, template <typename> class StorageBase, typename Src, typename Func>
  806|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void call_assignment(NoAlias<Dst, StorageBase>& dst,
  807|       |                                                                           const Src& src, const Func& func) {
  808|       |  call_assignment_no_alias(dst.expression(), src, func);
  809|       |}
  810|       |
  811|       |template <typename Dst, typename Src, typename Func>
  812|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void call_assignment_no_alias(Dst& dst, const Src& src,
  813|      4|                                                                                    const Func& func) {
  814|      4|  enum {
  815|      4|    NeedToTranspose = ((int(Dst::RowsAtCompileTime) == 1 && int(Src::ColsAtCompileTime) == 1) ||
  816|      4|                       (int(Dst::ColsAtCompileTime) == 1 && int(Src::RowsAtCompileTime) == 1)) &&
  817|      4|                      int(Dst::SizeAtCompileTime) != 1
  818|      4|  };
  819|       |
  820|      4|  typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst> ActualDstTypeCleaned;
  821|      4|  typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst&> ActualDstType;
  822|      4|  ActualDstType actualDst(dst);
  823|       |
  824|       |  // TODO check whether this is the right place to perform these checks:
  825|      4|  EIGEN_STATIC_ASSERT_LVALUE(Dst)
  826|      4|  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(ActualDstTypeCleaned, Src)
  827|      4|  EIGEN_CHECK_BINARY_COMPATIBILIY(Func, typename ActualDstTypeCleaned::Scalar, typename Src::Scalar);
  828|       |
  829|      4|  Assignment<ActualDstTypeCleaned, Src, Func>::run(actualDst, src, func);
  830|      4|}
  ------------------
  | _ZN5Eigen8internal24call_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_7ProductINS5_INS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES6_Li0EEES4_Li0EEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_:
  |  813|      1|                                                                                    const Func& func) {
  |  814|      1|  enum {
  |  815|      1|    NeedToTranspose = ((int(Dst::RowsAtCompileTime) == 1 && int(Src::ColsAtCompileTime) == 1) ||
  |  816|      1|                       (int(Dst::ColsAtCompileTime) == 1 && int(Src::RowsAtCompileTime) == 1)) &&
  |  817|      1|                      int(Dst::SizeAtCompileTime) != 1
  |  818|      1|  };
  |  819|       |
  |  820|      1|  typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst> ActualDstTypeCleaned;
  |  821|      1|  typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst&> ActualDstType;
  |  822|      1|  ActualDstType actualDst(dst);
  |  823|       |
  |  824|       |  // TODO check whether this is the right place to perform these checks:
  |  825|      1|  EIGEN_STATIC_ASSERT_LVALUE(Dst)
  |  826|      1|  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(ActualDstTypeCleaned, Src)
  |  827|      1|  EIGEN_CHECK_BINARY_COMPATIBILIY(Func, typename ActualDstTypeCleaned::Scalar, typename Src::Scalar);
  |  828|       |
  |  829|      1|  Assignment<ActualDstTypeCleaned, Src, Func>::run(actualDst, src, func);
  |  830|      1|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS_5BlockIKNS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | _ZN5Eigen8internal24call_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductIS4_S4_Li0EEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_:
  |  813|      2|                                                                                    const Func& func) {
  |  814|      2|  enum {
  |  815|      2|    NeedToTranspose = ((int(Dst::RowsAtCompileTime) == 1 && int(Src::ColsAtCompileTime) == 1) ||
  |  816|      2|                       (int(Dst::ColsAtCompileTime) == 1 && int(Src::RowsAtCompileTime) == 1)) &&
  |  817|      2|                      int(Dst::SizeAtCompileTime) != 1
  |  818|      2|  };
  |  819|       |
  |  820|      2|  typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst> ActualDstTypeCleaned;
  |  821|      2|  typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst&> ActualDstType;
  |  822|      2|  ActualDstType actualDst(dst);
  |  823|       |
  |  824|       |  // TODO check whether this is the right place to perform these checks:
  |  825|      2|  EIGEN_STATIC_ASSERT_LVALUE(Dst)
  |  826|      2|  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(ActualDstTypeCleaned, Src)
  |  827|      2|  EIGEN_CHECK_BINARY_COMPATIBILIY(Func, typename ActualDstTypeCleaned::Scalar, typename Src::Scalar);
  |  828|       |
  |  829|      2|  Assignment<ActualDstTypeCleaned, Src, Func>::run(actualDst, src, func);
  |  830|      2|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEES4_NS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | _ZN5Eigen8internal24call_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductINS5_IS4_S4_Li0EEES4_Li0EEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_:
  |  813|      1|                                                                                    const Func& func) {
  |  814|      1|  enum {
  |  815|      1|    NeedToTranspose = ((int(Dst::RowsAtCompileTime) == 1 && int(Src::ColsAtCompileTime) == 1) ||
  |  816|      1|                       (int(Dst::ColsAtCompileTime) == 1 && int(Src::RowsAtCompileTime) == 1)) &&
  |  817|      1|                      int(Dst::SizeAtCompileTime) != 1
  |  818|      1|  };
  |  819|       |
  |  820|      1|  typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst> ActualDstTypeCleaned;
  |  821|      1|  typedef std::conditional_t<NeedToTranspose, Transpose<Dst>, Dst&> ActualDstType;
  |  822|      1|  ActualDstType actualDst(dst);
  |  823|       |
  |  824|       |  // TODO check whether this is the right place to perform these checks:
  |  825|      1|  EIGEN_STATIC_ASSERT_LVALUE(Dst)
  |  826|      1|  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(ActualDstTypeCleaned, Src)
  |  827|      1|  EIGEN_CHECK_BINARY_COMPATIBILIY(Func, typename ActualDstTypeCleaned::Scalar, typename Src::Scalar);
  |  828|       |
  |  829|      1|  Assignment<ActualDstTypeCleaned, Src, Func>::run(actualDst, src, func);
  |  830|      1|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS_5BlockIKNS_7ProductINS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_NS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_5BlockINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS4_S4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKNS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISD_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_3MapINS3_IS4_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_NS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS3_S3_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS3_EEKS4_EEKNS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal24call_assignment_no_aliasINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEENS0_9assign_opIS4_S4_EEEEvRT_RKT0_RKT1_
  ------------------
  831|       |
  832|       |template <typename Dst, typename Src, typename Func>
  833|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_restricted_packet_assignment_no_alias(Dst& dst, const Src& src,
  834|      0|                                                                                      const Func& func) {
  835|      0|  typedef evaluator<Dst> DstEvaluatorType;
  836|      0|  typedef evaluator<Src> SrcEvaluatorType;
  837|      0|  typedef restricted_packet_dense_assignment_kernel<DstEvaluatorType, SrcEvaluatorType, Func> Kernel;
  838|       |
  839|      0|  EIGEN_STATIC_ASSERT_LVALUE(Dst)
  840|      0|  EIGEN_CHECK_BINARY_COMPATIBILIY(Func, typename Dst::Scalar, typename Src::Scalar);
  841|       |
  842|      0|  SrcEvaluatorType srcEvaluator(src);
  843|      0|  resize_if_allowed(dst, src, func);
  844|       |
  845|      0|  DstEvaluatorType dstEvaluator(dst);
  846|      0|  Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
  847|       |
  848|      0|  dense_assignment_loop<Kernel>::run(kernel);
  849|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal42call_restricted_packet_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductIS4_S4_Li1EEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal42call_restricted_packet_assignment_no_aliasINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductINS5_IS4_S4_Li0EEES4_Li1EEENS0_9assign_opIS3_S3_EEEEvRT_RKT0_RKT1_
  ------------------
  850|       |
  851|       |template <typename Dst, typename Src>
  852|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void call_assignment_no_alias(Dst& dst, const Src& src) {
  853|       |  call_assignment_no_alias(dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
  854|       |}
  855|       |
  856|       |template <typename Dst, typename Src, typename Func>
  857|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void call_assignment_no_alias_no_transpose(Dst& dst,
  858|       |                                                                                                 const Src& src,
  859|       |                                                                                                 const Func& func) {
  860|       |  // TODO check whether this is the right place to perform these checks:
  861|       |  EIGEN_STATIC_ASSERT_LVALUE(Dst)
  862|       |  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(Dst, Src)
  863|       |  EIGEN_CHECK_BINARY_COMPATIBILIY(Func, typename Dst::Scalar, typename Src::Scalar);
  864|       |
  865|       |  Assignment<Dst, Src, Func>::run(dst, src, func);
  866|       |}
  867|       |template <typename Dst, typename Src>
  868|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void call_assignment_no_alias_no_transpose(Dst& dst,
  869|       |                                                                                                 const Src& src) {
  870|       |  call_assignment_no_alias_no_transpose(dst, src, internal::assign_op<typename Dst::Scalar, typename Src::Scalar>());
  871|       |}
  872|       |
  873|       |// forward declaration
  874|       |template <typename Dst, typename Src>
  875|       |EIGEN_DEVICE_FUNC void check_for_aliasing(const Dst& dst, const Src& src);
  876|       |
  877|       |// Generic Dense to Dense assignment
  878|       |// Note that the last template argument "Weak" is needed to make it possible to perform
  879|       |// both partial specialization+SFINAE without ambiguous specialization
  880|       |template <typename DstXprType, typename SrcXprType, typename Functor, typename Weak>
  881|       |struct Assignment<DstXprType, SrcXprType, Functor, Dense2Dense, Weak> {
  882|      0|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(DstXprType& dst, const SrcXprType& src, const Functor& func) {
  883|      0|#ifndef EIGEN_NO_DEBUG
  884|      0|    internal::check_for_aliasing(dst, src);
  885|      0|#endif
  886|       |
  887|      0|    call_dense_assignment_loop(dst, src, func);
  888|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS_5BlockIKNS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEENS0_9assign_opIS4_S4_EENS0_11Dense2DenseEvE3runERS8_RKSF_RKSH_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEES4_NS0_9assign_opIS3_S3_EENS0_11Dense2DenseEvE3runERS4_RKS4_RKS6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS_5BlockIKNS_7ProductINS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEENS0_9assign_opIS3_S3_EENS0_11Dense2DenseEvE3runERS4_RKSA_RKSC_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_NS0_9assign_opIS3_S3_EENS0_11Dense2DenseEvE3runERS4_RKS4_RKS6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_5BlockINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS0_9assign_opIS4_S4_EENS0_11Dense2DenseEvE3runERS8_RKSB_RKSD_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS4_S4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKNS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISD_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS4_S4_EENS0_11Dense2DenseEvE3runERS6_RKSM_RKSO_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_3MapINS3_IS4_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS0_9assign_opIS4_S4_EENS0_11Dense2DenseEvE3runERS6_RKSB_RKSD_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_NS0_9assign_opIS4_S4_EENS0_11Dense2DenseEvE3runERS8_RKS5_RKSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS3_S3_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS3_EEKS4_EEKNS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEEEENS0_13add_assign_opIS3_S3_EENS0_11Dense2DenseEvE3runERS4_RKSJ_RKSL_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEENS0_9assign_opIS3_S3_EENS0_11Dense2DenseEvE3runERS4_RKS8_RKSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10AssignmentINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEENS0_9assign_opIS4_S4_EENS0_11Dense2DenseEvE3runERS8_RKSC_RKSE_
  ------------------
  889|       |};
  890|       |
  891|       |template <typename DstXprType, typename SrcPlainObject, typename Weak>
  892|       |struct Assignment<DstXprType, CwiseNullaryOp<scalar_constant_op<typename DstXprType::Scalar>, SrcPlainObject>,
  893|       |                  assign_op<typename DstXprType::Scalar, typename DstXprType::Scalar>, Dense2Dense, Weak> {
  894|       |  using Scalar = typename DstXprType::Scalar;
  895|       |  using NullaryOp = scalar_constant_op<Scalar>;
  896|       |  using SrcXprType = CwiseNullaryOp<NullaryOp, SrcPlainObject>;
  897|       |  using Functor = assign_op<Scalar, Scalar>;
  898|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(DstXprType& dst, const SrcXprType& src,
  899|       |                                                        const Functor& /*func*/) {
  900|       |    eigen_fill_impl<DstXprType>::run(dst, src);
  901|       |  }
  902|       |};
  903|       |
  904|       |template <typename DstXprType, typename SrcPlainObject, typename Weak>
  905|       |struct Assignment<DstXprType, CwiseNullaryOp<scalar_zero_op<typename DstXprType::Scalar>, SrcPlainObject>,
  906|       |                  assign_op<typename DstXprType::Scalar, typename DstXprType::Scalar>, Dense2Dense, Weak> {
  907|       |  using Scalar = typename DstXprType::Scalar;
  908|       |  using NullaryOp = scalar_zero_op<Scalar>;
  909|       |  using SrcXprType = CwiseNullaryOp<NullaryOp, SrcPlainObject>;
  910|       |  using Functor = assign_op<Scalar, Scalar>;
  911|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(DstXprType& dst, const SrcXprType& src,
  912|       |                                                        const Functor& /*func*/) {
  913|       |    eigen_zero_impl<DstXprType>::run(dst, src);
  914|       |  }
  915|       |};
  916|       |
  917|       |// Generic assignment through evalTo.
  918|       |// TODO: not sure we have to keep that one, but it helps porting current code to new evaluator mechanism.
  919|       |// Note that the last template argument "Weak" is needed to make it possible to perform
  920|       |// both partial specialization+SFINAE without ambiguous specialization
  921|       |template <typename DstXprType, typename SrcXprType, typename Functor, typename Weak>
  922|       |struct Assignment<DstXprType, SrcXprType, Functor, EigenBase2EigenBase, Weak> {
  923|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(
  924|       |      DstXprType& dst, const SrcXprType& src,
  925|       |      const internal::assign_op<typename DstXprType::Scalar, typename SrcXprType::Scalar>& /*func*/) {
  926|       |    Index dstRows = src.rows();
  927|       |    Index dstCols = src.cols();
  928|       |    if ((dst.rows() != dstRows) || (dst.cols() != dstCols)) dst.resize(dstRows, dstCols);
  929|       |
  930|       |    eigen_assert(dst.rows() == src.rows() && dst.cols() == src.cols());
  931|       |    src.evalTo(dst);
  932|       |  }
  933|       |
  934|       |  // NOTE The following two functions are templated to avoid their instantiation if not needed
  935|       |  //      This is needed because some expressions supports evalTo only and/or have 'void' as scalar type.
  936|       |  template <typename SrcScalarType>
  937|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(
  938|       |      DstXprType& dst, const SrcXprType& src,
  939|       |      const internal::add_assign_op<typename DstXprType::Scalar, SrcScalarType>& /*func*/) {
  940|       |    Index dstRows = src.rows();
  941|       |    Index dstCols = src.cols();
  942|       |    if ((dst.rows() != dstRows) || (dst.cols() != dstCols)) dst.resize(dstRows, dstCols);
  943|       |
  944|       |    eigen_assert(dst.rows() == src.rows() && dst.cols() == src.cols());
  945|       |    src.addTo(dst);
  946|       |  }
  947|       |
  948|       |  template <typename SrcScalarType>
  949|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(
  950|       |      DstXprType& dst, const SrcXprType& src,
  951|       |      const internal::sub_assign_op<typename DstXprType::Scalar, SrcScalarType>& /*func*/) {
  952|       |    Index dstRows = src.rows();
  953|       |    Index dstCols = src.cols();
  954|       |    if ((dst.rows() != dstRows) || (dst.cols() != dstCols)) dst.resize(dstRows, dstCols);
  955|       |
  956|       |    eigen_assert(dst.rows() == src.rows() && dst.cols() == src.cols());
  957|       |    src.subTo(dst);
  958|       |  }
  959|       |};
  960|       |
  961|       |}  // namespace internal
  962|       |
  963|       |}  // end namespace Eigen
  964|       |
  965|       |#endif  // EIGEN_ASSIGN_EVALUATOR_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Block.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_BLOCK_H
   12|       |#define EIGEN_BLOCK_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |template <typename XprType_, int BlockRows, int BlockCols, bool InnerPanel_>
   21|       |struct traits<Block<XprType_, BlockRows, BlockCols, InnerPanel_>> : traits<XprType_> {
   22|       |  typedef typename traits<XprType_>::Scalar Scalar;
   23|       |  typedef typename traits<XprType_>::StorageKind StorageKind;
   24|       |  typedef typename traits<XprType_>::XprKind XprKind;
   25|       |  typedef typename ref_selector<XprType_>::type XprTypeNested;
   26|       |  typedef std::remove_reference_t<XprTypeNested> XprTypeNested_;
   27|       |  enum {
   28|       |    MatrixRows = traits<XprType_>::RowsAtCompileTime,
   29|       |    MatrixCols = traits<XprType_>::ColsAtCompileTime,
   30|       |    RowsAtCompileTime = MatrixRows == 0 ? 0 : BlockRows,
   31|       |    ColsAtCompileTime = MatrixCols == 0 ? 0 : BlockCols,
   32|       |    MaxRowsAtCompileTime = BlockRows == 0                 ? 0
   33|       |                           : RowsAtCompileTime != Dynamic ? int(RowsAtCompileTime)
   34|       |                                                          : int(traits<XprType_>::MaxRowsAtCompileTime),
   35|       |    MaxColsAtCompileTime = BlockCols == 0                 ? 0
   36|       |                           : ColsAtCompileTime != Dynamic ? int(ColsAtCompileTime)
   37|       |                                                          : int(traits<XprType_>::MaxColsAtCompileTime),
   38|       |
   39|       |    XprTypeIsRowMajor = (int(traits<XprType_>::Flags) & RowMajorBit) != 0,
   40|       |    IsRowMajor = (MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1)   ? 1
   41|       |                 : (MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1) ? 0
   42|       |                                                                            : XprTypeIsRowMajor,
   43|       |    HasSameStorageOrderAsXprType = (IsRowMajor == XprTypeIsRowMajor),
   44|       |    InnerSize = IsRowMajor ? int(ColsAtCompileTime) : int(RowsAtCompileTime),
   45|       |    InnerStrideAtCompileTime = HasSameStorageOrderAsXprType ? int(inner_stride_at_compile_time<XprType_>::ret)
   46|       |                                                            : int(outer_stride_at_compile_time<XprType_>::ret),
   47|       |    OuterStrideAtCompileTime = HasSameStorageOrderAsXprType ? int(outer_stride_at_compile_time<XprType_>::ret)
   48|       |                                                            : int(inner_stride_at_compile_time<XprType_>::ret),
   49|       |
   50|       |    // FIXME, this traits is rather specialized for dense object and it needs to be cleaned further
   51|       |    FlagsLvalueBit = is_lvalue<XprType_>::value ? LvalueBit : 0,
   52|       |    FlagsRowMajorBit = IsRowMajor ? RowMajorBit : 0,
   53|       |    Flags = (traits<XprType_>::Flags & (DirectAccessBit | (InnerPanel_ ? CompressedAccessBit : 0))) | FlagsLvalueBit |
   54|       |            FlagsRowMajorBit,
   55|       |    // FIXME DirectAccessBit should not be handled by expressions
   56|       |    //
   57|       |    // Alignment is needed by MapBase's assertions
   58|       |    // We can sefely set it to false here. Internal alignment errors will be detected by an eigen_internal_assert in the
   59|       |    // respective evaluator
   60|       |    Alignment = 0,
   61|       |    InnerPanel = InnerPanel_ ? 1 : 0
   62|       |  };
   63|       |};
   64|       |
   65|       |template <typename XprType, int BlockRows = Dynamic, int BlockCols = Dynamic, bool InnerPanel = false,
   66|       |          bool HasDirectAccess = internal::has_direct_access<XprType>::ret>
   67|       |class BlockImpl_dense;
   68|       |
   69|       |}  // end namespace internal
   70|       |
   71|       |template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel, typename StorageKind>
   72|       |class BlockImpl;
   73|       |
   74|       |/** \class Block
   75|       | * \ingroup Core_Module
   76|       | *
   77|       | * \brief Expression of a fixed-size or dynamic-size block
   78|       | *
   79|       | * \tparam XprType the type of the expression in which we are taking a block
   80|       | * \tparam BlockRows the number of rows of the block we are taking at compile time (optional)
   81|       | * \tparam BlockCols the number of columns of the block we are taking at compile time (optional)
   82|       | * \tparam InnerPanel is true, if the block maps to a set of rows of a row major matrix or
   83|       | *         to set of columns of a column major matrix (optional). The parameter allows to determine
   84|       | *         at compile time whether aligned access is possible on the block expression.
   85|       | *
   86|       | * This class represents an expression of either a fixed-size or dynamic-size block. It is the return
   87|       | * type of DenseBase::block(Index,Index,Index,Index) and DenseBase::block<int,int>(Index,Index) and
   88|       | * most of the time this is the only way it is used.
   89|       | *
   90|       | * However, if you want to directly manipulate block expressions,
   91|       | * for instance if you want to write a function returning such an expression, you
   92|       | * will need to use this class.
   93|       | *
   94|       | * Here is an example illustrating the dynamic case:
   95|       | * \include class_Block.cpp
   96|       | * Output: \verbinclude class_Block.out
   97|       | *
   98|       | * \note Even though this expression has dynamic size, in the case where \a XprType
   99|       | * has fixed size, this expression inherits a fixed maximal size which means that evaluating
  100|       | * it does not cause a dynamic memory allocation.
  101|       | *
  102|       | * Here is an example illustrating the fixed-size case:
  103|       | * \include class_FixedBlock.cpp
  104|       | * Output: \verbinclude class_FixedBlock.out
  105|       | *
  106|       | * \sa DenseBase::block(Index,Index,Index,Index), DenseBase::block(Index,Index), class VectorBlock
  107|       | */
  108|       |template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
  109|       |class Block
  110|       |    : public BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, typename internal::traits<XprType>::StorageKind> {
  111|       |  typedef BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, typename internal::traits<XprType>::StorageKind> Impl;
  112|       |  using BlockHelper = internal::block_xpr_helper<Block>;
  113|       |
  114|       | public:
  115|       |  // typedef typename Impl::Base Base;
  116|       |  typedef Impl Base;
  117|       |  EIGEN_GENERIC_PUBLIC_INTERFACE(Block)
  118|       |  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Block)
  119|       |
  120|       |  typedef internal::remove_all_t<XprType> NestedExpression;
  121|       |
  122|       |  /** Column or Row constructor
  123|       |   */
  124|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Block(XprType& xpr, Index i) : Impl(xpr, i) {
  125|      0|    eigen_assert((i >= 0) && (((BlockRows == 1) && (BlockCols == XprType::ColsAtCompileTime) && i < xpr.rows()) ||
  126|      0|                              ((BlockRows == XprType::RowsAtCompileTime) && (BlockCols == 1) && i < xpr.cols())));
  127|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEELi1ELin1ELb0EEC2ERS6_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEC2ERS4_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEC2ERS4_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEC2ERS3_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockIKNS0_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEC2ERS6_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEC2ERS3_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockIKNS0_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEC2ERS6_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockINS_9TransposeINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1EEC2ERS6_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEC2ERS4_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockIKNS0_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEC2ERS8_l
  ------------------
  128|       |
  129|       |  /** Fixed-size constructor
  130|       |   */
  131|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Block(XprType& xpr, Index startRow, Index startCol)
  132|       |      : Impl(xpr, startRow, startCol) {
  133|       |    EIGEN_STATIC_ASSERT(RowsAtCompileTime != Dynamic && ColsAtCompileTime != Dynamic,
  134|       |                        THIS_METHOD_IS_ONLY_FOR_FIXED_SIZE)
  135|       |    eigen_assert(startRow >= 0 && BlockRows >= 0 && startRow + BlockRows <= xpr.rows() && startCol >= 0 &&
  136|       |                 BlockCols >= 0 && startCol + BlockCols <= xpr.cols());
  137|       |  }
  138|       |
  139|       |  /** Dynamic-size constructor
  140|       |   */
  141|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Block(XprType& xpr, Index startRow, Index startCol, Index blockRows,
  142|       |                                              Index blockCols)
  143|       |      : Impl(xpr, startRow, startCol, blockRows, blockCols) {
  144|       |    eigen_assert((RowsAtCompileTime == Dynamic || RowsAtCompileTime == blockRows) &&
  145|       |                 (ColsAtCompileTime == Dynamic || ColsAtCompileTime == blockCols));
  146|       |    eigen_assert(startRow >= 0 && blockRows >= 0 && startRow <= xpr.rows() - blockRows && startCol >= 0 &&
  147|       |                 blockCols >= 0 && startCol <= xpr.cols() - blockCols);
  148|       |  }
  149|       |
  150|       |  // convert nested blocks (e.g. Block<Block<MatrixType>>) to a simple block expression (Block<MatrixType>)
  151|       |
  152|       |  using ConstUnwindReturnType = Block<const typename BlockHelper::BaseType, BlockRows, BlockCols, InnerPanel>;
  153|       |  using UnwindReturnType = Block<typename BlockHelper::BaseType, BlockRows, BlockCols, InnerPanel>;
  154|       |
  155|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ConstUnwindReturnType unwind() const {
  156|       |    return ConstUnwindReturnType(BlockHelper::base(*this), BlockHelper::row(*this, 0), BlockHelper::col(*this, 0),
  157|       |                                 this->rows(), this->cols());
  158|       |  }
  159|       |
  160|       |  template <typename T = Block, typename EnableIf = std::enable_if_t<!std::is_const<T>::value>>
  161|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE UnwindReturnType unwind() {
  162|       |    return UnwindReturnType(BlockHelper::base(*this), BlockHelper::row(*this, 0), BlockHelper::col(*this, 0),
  163|       |                            this->rows(), this->cols());
  164|       |  }
  165|       |};
  166|       |
  167|       |// The generic default implementation for dense block simply forward to the internal::BlockImpl_dense
  168|       |// that must be specialized for direct and non-direct access...
  169|       |template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
  170|       |class BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, Dense>
  171|       |    : public internal::BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel> {
  172|       |  typedef internal::BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel> Impl;
  173|       |  typedef typename XprType::StorageIndex StorageIndex;
  174|       |
  175|       | public:
  176|       |  typedef Impl Base;
  177|       |  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(BlockImpl)
  178|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE BlockImpl(XprType& xpr, Index i) : Impl(xpr, i) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEELi1ELin1ELb0ENS_5DenseEEC2ERS6_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ENS_5DenseEEC2ERS4_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ENS_5DenseEEC2ERS4_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ENS_5DenseEEC2ERS3_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1ENS_5DenseEEC2ERS7_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ENS_5DenseEEC2ERS3_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1ENS_5DenseEEC2ERS7_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1ENS_5DenseEEC2ERS7_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1ENS_5DenseEEC2ERS4_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1ENS_5DenseEEC2ERS9_l
  ------------------
  179|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE BlockImpl(XprType& xpr, Index startRow, Index startCol)
  180|       |      : Impl(xpr, startRow, startCol) {}
  181|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE BlockImpl(XprType& xpr, Index startRow, Index startCol, Index blockRows,
  182|       |                                                  Index blockCols)
  183|       |      : Impl(xpr, startRow, startCol, blockRows, blockCols) {}
  184|       |};
  185|       |
  186|       |namespace internal {
  187|       |
  188|       |/** \internal Internal implementation of dense Blocks in the general case. */
  189|       |template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel, bool HasDirectAccess>
  190|       |class BlockImpl_dense : public internal::dense_xpr_base<Block<XprType, BlockRows, BlockCols, InnerPanel>>::type {
  191|       |  typedef Block<XprType, BlockRows, BlockCols, InnerPanel> BlockType;
  192|       |  typedef typename internal::ref_selector<XprType>::non_const_type XprTypeNested;
  193|       |
  194|       | public:
  195|       |  typedef typename internal::dense_xpr_base<BlockType>::type Base;
  196|       |  EIGEN_DENSE_PUBLIC_INTERFACE(BlockType)
  197|       |  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(BlockImpl_dense)
  198|       |
  199|       |  // class InnerIterator; // FIXME apparently never used
  200|       |
  201|       |  /** Column or Row constructor
  202|       |   */
  203|       |  EIGEN_DEVICE_FUNC inline BlockImpl_dense(XprType& xpr, Index i)
  204|       |      : m_xpr(xpr),
  205|       |        // It is a row if and only if BlockRows==1 and BlockCols==XprType::ColsAtCompileTime,
  206|       |        // and it is a column if and only if BlockRows==XprType::RowsAtCompileTime and BlockCols==1,
  207|       |        // all other cases are invalid.
  208|       |        // The case a 1x1 matrix seems ambiguous, but the result is the same anyway.
  209|       |        m_startRow((BlockRows == 1) && (BlockCols == XprType::ColsAtCompileTime) ? i : 0),
  210|       |        m_startCol((BlockRows == XprType::RowsAtCompileTime) && (BlockCols == 1) ? i : 0),
  211|       |        m_blockRows(BlockRows == 1 ? 1 : xpr.rows()),
  212|      0|        m_blockCols(BlockCols == 1 ? 1 : xpr.cols()) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0ELb0EEC2ERS7_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1ELb0EEC2ERSA_l
  ------------------
  213|       |
  214|       |  /** Fixed-size constructor
  215|       |   */
  216|       |  EIGEN_DEVICE_FUNC inline BlockImpl_dense(XprType& xpr, Index startRow, Index startCol)
  217|       |      : m_xpr(xpr), m_startRow(startRow), m_startCol(startCol), m_blockRows(BlockRows), m_blockCols(BlockCols) {}
  218|       |
  219|       |  /** Dynamic-size constructor
  220|       |   */
  221|       |  EIGEN_DEVICE_FUNC inline BlockImpl_dense(XprType& xpr, Index startRow, Index startCol, Index blockRows,
  222|       |                                           Index blockCols)
  223|       |      : m_xpr(xpr), m_startRow(startRow), m_startCol(startCol), m_blockRows(blockRows), m_blockCols(blockCols) {}
  224|       |
  225|      0|  EIGEN_DEVICE_FUNC inline Index rows() const { return m_blockRows.value(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0ELb0EE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1ELb0EE4rowsEv
  ------------------
  226|      0|  EIGEN_DEVICE_FUNC inline Index cols() const { return m_blockCols.value(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0ELb0EE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1ELb0EE4colsEv
  ------------------
  227|       |
  228|       |  EIGEN_DEVICE_FUNC inline Scalar& coeffRef(Index rowId, Index colId) {
  229|       |    EIGEN_STATIC_ASSERT_LVALUE(XprType)
  230|       |    return m_xpr.coeffRef(rowId + m_startRow.value(), colId + m_startCol.value());
  231|       |  }
  232|       |
  233|       |  EIGEN_DEVICE_FUNC inline const Scalar& coeffRef(Index rowId, Index colId) const {
  234|       |    return m_xpr.derived().coeffRef(rowId + m_startRow.value(), colId + m_startCol.value());
  235|       |  }
  236|       |
  237|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CoeffReturnType coeff(Index rowId, Index colId) const {
  238|       |    return m_xpr.coeff(rowId + m_startRow.value(), colId + m_startCol.value());
  239|       |  }
  240|       |
  241|       |  EIGEN_DEVICE_FUNC inline Scalar& coeffRef(Index index) {
  242|       |    EIGEN_STATIC_ASSERT_LVALUE(XprType)
  243|       |    return m_xpr.coeffRef(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
  244|       |                          m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
  245|       |  }
  246|       |
  247|       |  EIGEN_DEVICE_FUNC inline const Scalar& coeffRef(Index index) const {
  248|       |    return m_xpr.coeffRef(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
  249|       |                          m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
  250|       |  }
  251|       |
  252|       |  EIGEN_DEVICE_FUNC inline const CoeffReturnType coeff(Index index) const {
  253|       |    return m_xpr.coeff(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
  254|       |                       m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
  255|       |  }
  256|       |
  257|       |  template <int LoadMode>
  258|       |  EIGEN_DEVICE_FUNC inline PacketScalar packet(Index rowId, Index colId) const {
  259|       |    return m_xpr.template packet<Unaligned>(rowId + m_startRow.value(), colId + m_startCol.value());
  260|       |  }
  261|       |
  262|       |  template <int LoadMode>
  263|       |  EIGEN_DEVICE_FUNC inline void writePacket(Index rowId, Index colId, const PacketScalar& val) {
  264|       |    m_xpr.template writePacket<Unaligned>(rowId + m_startRow.value(), colId + m_startCol.value(), val);
  265|       |  }
  266|       |
  267|       |  template <int LoadMode>
  268|       |  EIGEN_DEVICE_FUNC inline PacketScalar packet(Index index) const {
  269|       |    return m_xpr.template packet<Unaligned>(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
  270|       |                                            m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
  271|       |  }
  272|       |
  273|       |  template <int LoadMode>
  274|       |  EIGEN_DEVICE_FUNC inline void writePacket(Index index, const PacketScalar& val) {
  275|       |    m_xpr.template writePacket<Unaligned>(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
  276|       |                                          m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0), val);
  277|       |  }
  278|       |
  279|       |#ifdef EIGEN_PARSED_BY_DOXYGEN
  280|       |  /** \sa MapBase::data() */
  281|       |  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const;
  282|       |  EIGEN_DEVICE_FUNC inline Index innerStride() const;
  283|       |  EIGEN_DEVICE_FUNC inline Index outerStride() const;
  284|       |#endif
  285|       |
  286|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const internal::remove_all_t<XprTypeNested>& nestedExpression() const {
  287|      0|    return m_xpr;
  288|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0ELb0EE16nestedExpressionEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1ELb0EE16nestedExpressionEv
  ------------------
  289|       |
  290|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE XprType& nestedExpression() { return m_xpr; }
  291|       |
  292|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR StorageIndex startRow() const EIGEN_NOEXCEPT {
  293|      0|    return m_startRow.value();
  294|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0ELb0EE8startRowEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1ELb0EE8startRowEv
  ------------------
  295|       |
  296|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR StorageIndex startCol() const EIGEN_NOEXCEPT {
  297|      0|    return m_startCol.value();
  298|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0ELb0EE8startColEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1ELb0EE8startColEv
  ------------------
  299|       |
  300|       | protected:
  301|       |  XprTypeNested m_xpr;
  302|       |  const internal::variable_if_dynamic<StorageIndex, (XprType::RowsAtCompileTime == 1 && BlockRows == 1) ? 0 : Dynamic>
  303|       |      m_startRow;
  304|       |  const internal::variable_if_dynamic<StorageIndex, (XprType::ColsAtCompileTime == 1 && BlockCols == 1) ? 0 : Dynamic>
  305|       |      m_startCol;
  306|       |  const internal::variable_if_dynamic<StorageIndex, RowsAtCompileTime> m_blockRows;
  307|       |  const internal::variable_if_dynamic<StorageIndex, ColsAtCompileTime> m_blockCols;
  308|       |};
  309|       |
  310|       |/** \internal Internal implementation of dense Blocks in the direct access case.*/
  311|       |template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
  312|       |class BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel, true>
  313|       |    : public MapBase<Block<XprType, BlockRows, BlockCols, InnerPanel>> {
  314|       |  typedef Block<XprType, BlockRows, BlockCols, InnerPanel> BlockType;
  315|       |  typedef typename internal::ref_selector<XprType>::non_const_type XprTypeNested;
  316|       |  enum { XprTypeIsRowMajor = (int(traits<XprType>::Flags) & RowMajorBit) != 0 };
  317|       |
  318|       |  /** \internal Returns base+offset (unless base is null, in which case returns null).
  319|       |   * Adding an offset to nullptr is undefined behavior, so we must avoid it.
  320|       |   */
  321|       |  template <typename Scalar>
  322|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE static Scalar* add_to_nullable_pointer(Scalar* base,
  323|      0|                                                                                               Index offset) {
  324|      0|    return base != nullptr ? base + offset : nullptr;
  325|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EE23add_to_nullable_pointerIKS3_EEPT_SA_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EE23add_to_nullable_pointerIKS3_EEPT_SA_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EE23add_to_nullable_pointerIS3_EEPT_S8_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1ELb1EE23add_to_nullable_pointerIKS4_EEPT_SD_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EE23add_to_nullable_pointerIS3_EEPT_S8_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1ELb1EE23add_to_nullable_pointerIKS4_EEPT_SD_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1ELb1EE23add_to_nullable_pointerIS5_EEPT_SC_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1ELb1EE23add_to_nullable_pointerIKS3_EEPT_SA_l
  ------------------
  326|       |
  327|       | public:
  328|       |  typedef MapBase<BlockType> Base;
  329|       |  EIGEN_DENSE_PUBLIC_INTERFACE(BlockType)
  330|       |  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(BlockImpl_dense)
  331|       |
  332|       |  /** Column or Row constructor
  333|       |   */
  334|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE BlockImpl_dense(XprType& xpr, Index i)
  335|       |      : Base((BlockRows == 0 || BlockCols == 0)
  336|       |                 ? nullptr
  337|       |                 : add_to_nullable_pointer(
  338|       |                       xpr.data(),
  339|       |                       i * (((BlockRows == 1) && (BlockCols == XprType::ColsAtCompileTime) && (!XprTypeIsRowMajor)) ||
  340|       |                                    ((BlockRows == XprType::RowsAtCompileTime) && (BlockCols == 1) &&
  341|       |                                     (XprTypeIsRowMajor))
  342|       |                                ? xpr.innerStride()
  343|       |                                : xpr.outerStride())),
  344|       |             BlockRows == 1 ? 1 : xpr.rows(), BlockCols == 1 ? 1 : xpr.cols()),
  345|       |        m_xpr(xpr),
  346|       |        m_startRow((BlockRows == 1) && (BlockCols == XprType::ColsAtCompileTime) ? i : 0),
  347|      0|        m_startCol((BlockRows == XprType::RowsAtCompileTime) && (BlockCols == 1) ? i : 0) {
  348|      0|    init();
  349|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EEC2ERS5_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EEC2ERS5_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EEC2ERS4_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1ELb1EEC2ERS8_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EEC2ERS4_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1ELb1EEC2ERS8_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1ELb1EEC2ERS8_l
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1ELb1EEC2ERS5_l
  ------------------
  350|       |
  351|       |  /** Fixed-size constructor
  352|       |   */
  353|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE BlockImpl_dense(XprType& xpr, Index startRow, Index startCol)
  354|       |      : Base((BlockRows == 0 || BlockCols == 0)
  355|       |                 ? nullptr
  356|       |                 : add_to_nullable_pointer(xpr.data(),
  357|       |                                           xpr.innerStride() * (XprTypeIsRowMajor ? startCol : startRow) +
  358|       |                                               xpr.outerStride() * (XprTypeIsRowMajor ? startRow : startCol))),
  359|       |        m_xpr(xpr),
  360|       |        m_startRow(startRow),
  361|       |        m_startCol(startCol) {
  362|       |    init();
  363|       |  }
  364|       |
  365|       |  /** Dynamic-size constructor
  366|       |   */
  367|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE BlockImpl_dense(XprType& xpr, Index startRow, Index startCol, Index blockRows,
  368|       |                                                        Index blockCols)
  369|       |      : Base((blockRows == 0 || blockCols == 0)
  370|       |                 ? nullptr
  371|       |                 : add_to_nullable_pointer(xpr.data(),
  372|       |                                           xpr.innerStride() * (XprTypeIsRowMajor ? startCol : startRow) +
  373|       |                                               xpr.outerStride() * (XprTypeIsRowMajor ? startRow : startCol)),
  374|       |             blockRows, blockCols),
  375|       |        m_xpr(xpr),
  376|       |        m_startRow(startRow),
  377|       |        m_startCol(startCol) {
  378|       |    init();
  379|       |  }
  380|       |
  381|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const internal::remove_all_t<XprTypeNested>& nestedExpression() const
  382|       |      EIGEN_NOEXCEPT {
  383|       |    return m_xpr;
  384|       |  }
  385|       |
  386|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE XprType& nestedExpression() { return m_xpr; }
  387|       |
  388|       |  /** \sa MapBase::innerStride() */
  389|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index innerStride() const EIGEN_NOEXCEPT {
  390|      0|    return internal::traits<BlockType>::HasSameStorageOrderAsXprType ? m_xpr.innerStride() : m_xpr.outerStride();
  391|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EE11innerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EE11innerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1ELb1EE11innerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EE11innerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1ELb1EE11innerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EE11innerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1ELb1EE11innerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1ELb1EE11innerStrideEv
  ------------------
  392|       |
  393|       |  /** \sa MapBase::outerStride() */
  394|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index outerStride() const EIGEN_NOEXCEPT {
  395|      0|    return internal::traits<BlockType>::HasSameStorageOrderAsXprType ? m_xpr.outerStride() : m_xpr.innerStride();
  396|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1ELb1EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1ELb1EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1ELb1EE11outerStrideEv
  ------------------
  397|       |
  398|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR StorageIndex startRow() const EIGEN_NOEXCEPT {
  399|       |    return m_startRow.value();
  400|       |  }
  401|       |
  402|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR StorageIndex startCol() const EIGEN_NOEXCEPT {
  403|       |    return m_startCol.value();
  404|       |  }
  405|       |
  406|       |#ifndef __SUNPRO_CC
  407|       |  // FIXME sunstudio is not friendly with the above friend...
  408|       |  // META-FIXME there is no 'friend' keyword around here. Is this obsolete?
  409|       | protected:
  410|       |#endif
  411|       |
  412|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  413|       |  /** \internal used by allowAligned() */
  414|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE BlockImpl_dense(XprType& xpr, const Scalar* data, Index blockRows,
  415|       |                                                        Index blockCols)
  416|       |      : Base(data, blockRows, blockCols), m_xpr(xpr) {
  417|       |    init();
  418|       |  }
  419|       |#endif
  420|       |
  421|       | protected:
  422|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void init() {
  423|      0|    m_outerStride =
  424|      0|        internal::traits<BlockType>::HasSameStorageOrderAsXprType ? m_xpr.outerStride() : m_xpr.innerStride();
  425|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EE4initEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EE4initEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EE4initEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1ELb1EE4initEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EE4initEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1ELb1EE4initEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1ELb1EE4initEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1ELb1EE4initEv
  ------------------
  426|       |
  427|       |  XprTypeNested m_xpr;
  428|       |  const internal::variable_if_dynamic<StorageIndex, (XprType::RowsAtCompileTime == 1 && BlockRows == 1) ? 0 : Dynamic>
  429|       |      m_startRow;
  430|       |  const internal::variable_if_dynamic<StorageIndex, (XprType::ColsAtCompileTime == 1 && BlockCols == 1) ? 0 : Dynamic>
  431|       |      m_startCol;
  432|       |  Index m_outerStride;
  433|       |};
  434|       |
  435|       |}  // end namespace internal
  436|       |
  437|       |}  // end namespace Eigen
  438|       |
  439|       |#endif  // EIGEN_BLOCK_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/CoreEvaluators.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2011 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2011-2014 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |// Copyright (C) 2011-2012 Jitse Niesen <jitse@maths.leeds.ac.uk>
    7|       |//
    8|       |// This Source Code Form is subject to the terms of the Mozilla
    9|       |// Public License v. 2.0. If a copy of the MPL was not distributed
   10|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   11|       |
   12|       |#ifndef EIGEN_COREEVALUATORS_H
   13|       |#define EIGEN_COREEVALUATORS_H
   14|       |
   15|       |// IWYU pragma: private
   16|       |#include "./InternalHeaderCheck.h"
   17|       |
   18|       |namespace Eigen {
   19|       |
   20|       |namespace internal {
   21|       |
   22|       |// This class returns the evaluator kind from the expression storage kind.
   23|       |// Default assumes index based accessors
   24|       |template <typename StorageKind>
   25|       |struct storage_kind_to_evaluator_kind {
   26|       |  typedef IndexBased Kind;
   27|       |};
   28|       |
   29|       |// This class returns the evaluator shape from the expression storage kind.
   30|       |// It can be Dense, Sparse, Triangular, Diagonal, SelfAdjoint, Band, etc.
   31|       |template <typename StorageKind>
   32|       |struct storage_kind_to_shape;
   33|       |
   34|       |template <>
   35|       |struct storage_kind_to_shape<Dense> {
   36|       |  typedef DenseShape Shape;
   37|       |};
   38|       |template <>
   39|       |struct storage_kind_to_shape<SolverStorage> {
   40|       |  typedef SolverShape Shape;
   41|       |};
   42|       |template <>
   43|       |struct storage_kind_to_shape<PermutationStorage> {
   44|       |  typedef PermutationShape Shape;
   45|       |};
   46|       |template <>
   47|       |struct storage_kind_to_shape<TranspositionsStorage> {
   48|       |  typedef TranspositionsShape Shape;
   49|       |};
   50|       |
   51|       |// Evaluators have to be specialized with respect to various criteria such as:
   52|       |//  - storage/structure/shape
   53|       |//  - scalar type
   54|       |//  - etc.
   55|       |// Therefore, we need specialization of evaluator providing additional template arguments for each kind of evaluators.
   56|       |// We currently distinguish the following kind of evaluators:
   57|       |// - unary_evaluator    for expressions taking only one arguments (CwiseUnaryOp, CwiseUnaryView, Transpose,
   58|       |// MatrixWrapper, ArrayWrapper, Reverse, Replicate)
   59|       |// - binary_evaluator   for expression taking two arguments (CwiseBinaryOp)
   60|       |// - ternary_evaluator   for expression taking three arguments (CwiseTernaryOp)
   61|       |// - product_evaluator  for linear algebra products (Product); special case of binary_evaluator because it requires
   62|       |// additional tags for dispatching.
   63|       |// - mapbase_evaluator  for Map, Block, Ref
   64|       |// - block_evaluator    for Block (special dispatching to a mapbase_evaluator or unary_evaluator)
   65|       |
   66|       |template <typename T, typename Arg1Kind = typename evaluator_traits<typename T::Arg1>::Kind,
   67|       |          typename Arg2Kind = typename evaluator_traits<typename T::Arg2>::Kind,
   68|       |          typename Arg3Kind = typename evaluator_traits<typename T::Arg3>::Kind,
   69|       |          typename Arg1Scalar = typename traits<typename T::Arg1>::Scalar,
   70|       |          typename Arg2Scalar = typename traits<typename T::Arg2>::Scalar,
   71|       |          typename Arg3Scalar = typename traits<typename T::Arg3>::Scalar>
   72|       |struct ternary_evaluator;
   73|       |
   74|       |template <typename T, typename LhsKind = typename evaluator_traits<typename T::Lhs>::Kind,
   75|       |          typename RhsKind = typename evaluator_traits<typename T::Rhs>::Kind,
   76|       |          typename LhsScalar = typename traits<typename T::Lhs>::Scalar,
   77|       |          typename RhsScalar = typename traits<typename T::Rhs>::Scalar>
   78|       |struct binary_evaluator;
   79|       |
   80|       |template <typename T, typename Kind = typename evaluator_traits<typename T::NestedExpression>::Kind,
   81|       |          typename Scalar = typename T::Scalar>
   82|       |struct unary_evaluator;
   83|       |
   84|       |// evaluator_traits<T> contains traits for evaluator<T>
   85|       |
   86|       |template <typename T>
   87|       |struct evaluator_traits_base {
   88|       |  // by default, get evaluator kind and shape from storage
   89|       |  typedef typename storage_kind_to_evaluator_kind<typename traits<T>::StorageKind>::Kind Kind;
   90|       |  typedef typename storage_kind_to_shape<typename traits<T>::StorageKind>::Shape Shape;
   91|       |};
   92|       |
   93|       |// Default evaluator traits
   94|       |template <typename T>
   95|       |struct evaluator_traits : public evaluator_traits_base<T> {};
   96|       |
   97|       |template <typename T, typename Shape = typename evaluator_traits<T>::Shape>
   98|       |struct evaluator_assume_aliasing {
   99|       |  static const bool value = false;
  100|       |};
  101|       |
  102|       |// By default, we assume a unary expression:
  103|       |template <typename T>
  104|       |struct evaluator : public unary_evaluator<T> {
  105|       |  typedef unary_evaluator<T> Base;
  106|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const T& xpr) : Base(xpr) {}
  107|       |};
  108|       |
  109|       |// TODO: Think about const-correctness
  110|       |template <typename T>
  111|       |struct evaluator<const T> : evaluator<T> {
  112|      4|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const T& xpr) : evaluator<T>(xpr) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEEEC2ERS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorIKNS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEC2ERSB_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEC2ERS8_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEC2ERS8_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEEEC2ERSA_
  ------------------
  | _ZN5Eigen8internal9evaluatorIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEC2ERS5_:
  |  112|      4|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const T& xpr) : evaluator<T>(xpr) {}
  ------------------
  113|       |};
  114|       |
  115|       |// ---------- base class for all evaluators ----------
  116|       |
  117|       |template <typename ExpressionType>
  118|       |struct evaluator_base {
  119|       |  // TODO that's not very nice to have to propagate all these traits. They are currently only needed to handle
  120|       |  // outer,inner indices.
  121|       |  typedef traits<ExpressionType> ExpressionTraits;
  122|       |
  123|       |  enum { Alignment = 0 };
  124|       |  // noncopyable:
  125|       |  // Don't make this class inherit noncopyable as this kills EBO (Empty Base Optimization)
  126|       |  // and make complex evaluator much larger than then should do.
  127|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr evaluator_base() = default;
  128|       |
  129|       | private:
  130|       |  EIGEN_DEVICE_FUNC evaluator_base(const evaluator_base&);
  131|       |  EIGEN_DEVICE_FUNC const evaluator_base& operator=(const evaluator_base&);
  132|       |};
  133|       |
  134|       |// -------------------- Matrix and Array --------------------
  135|       |//
  136|       |// evaluator<PlainObjectBase> is a common base class for the
  137|       |// Matrix and Array evaluators.
  138|       |// Here we directly specialize evaluator. This is not really a unary expression, and it is, by definition, dense,
  139|       |// so no need for more sophisticated dispatching.
  140|       |
  141|       |// this helper permits to completely eliminate m_outerStride if it is known at compiletime.
  142|       |template <typename Scalar, int OuterStride>
  143|       |class plainobjectbase_evaluator_data {
  144|       | public:
  145|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plainobjectbase_evaluator_data(const Scalar* ptr, Index outerStride)
  146|      5|      : data(ptr) {
  147|       |#ifndef EIGEN_INTERNAL_DEBUGGING
  148|       |    EIGEN_UNUSED_VARIABLE(outerStride);
  149|       |#endif
  150|      5|    eigen_internal_assert(outerStride == OuterStride);
  151|      5|  }
  152|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index outerStride() const EIGEN_NOEXCEPT { return OuterStride; }
  153|       |  const Scalar* data;
  154|       |};
  155|       |
  156|       |template <typename Scalar>
  157|       |class plainobjectbase_evaluator_data<Scalar, Dynamic> {
  158|       | public:
  159|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plainobjectbase_evaluator_data(const Scalar* ptr, Index outerStride)
  160|      3|      : data(ptr), m_outerStride(outerStride) {}
  161|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index outerStride() const { return m_outerStride; }
  162|       |  const Scalar* data;
  163|       |
  164|       | protected:
  165|       |  Index m_outerStride;
  166|       |};
  167|       |
  168|       |template <typename Derived>
  169|       |struct evaluator<PlainObjectBase<Derived>> : evaluator_base<Derived> {
  170|       |  typedef PlainObjectBase<Derived> PlainObjectType;
  171|       |  typedef typename PlainObjectType::Scalar Scalar;
  172|       |  typedef typename PlainObjectType::CoeffReturnType CoeffReturnType;
  173|       |
  174|       |  enum {
  175|       |    IsRowMajor = PlainObjectType::IsRowMajor,
  176|       |    IsVectorAtCompileTime = PlainObjectType::IsVectorAtCompileTime,
  177|       |    RowsAtCompileTime = PlainObjectType::RowsAtCompileTime,
  178|       |    ColsAtCompileTime = PlainObjectType::ColsAtCompileTime,
  179|       |
  180|       |    CoeffReadCost = NumTraits<Scalar>::ReadCost,
  181|       |    Flags = traits<Derived>::EvaluatorFlags,
  182|       |    Alignment = traits<Derived>::Alignment
  183|       |  };
  184|       |  enum {
  185|       |    // We do not need to know the outer stride for vectors
  186|       |    OuterStrideAtCompileTime = IsVectorAtCompileTime ? 0
  187|       |                               : int(IsRowMajor)     ? ColsAtCompileTime
  188|       |                                                     : RowsAtCompileTime
  189|       |  };
  190|       |
  191|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr evaluator() : m_d(0, OuterStrideAtCompileTime) {
  192|      0|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  193|      0|  }
  194|       |
  195|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr explicit evaluator(const PlainObjectType& m)
  196|      8|      : m_d(m.data(), IsVectorAtCompileTime ? 0 : m.outerStride()) {
  197|      8|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  198|      8|  }
  ------------------
  | _ZN5Eigen8internal9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEC2ERKS6_:
  |  196|      5|      : m_d(m.data(), IsVectorAtCompileTime ? 0 : m.outerStride()) {
  |  197|      5|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  |  198|      5|  }
  ------------------
  | _ZN5Eigen8internal9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEC2ERKS6_:
  |  196|      3|      : m_d(m.data(), IsVectorAtCompileTime ? 0 : m.outerStride()) {
  |  197|      3|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  |  198|      3|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEEC2ERKS6_
  ------------------
  199|       |
  200|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr CoeffReturnType coeff(Index row, Index col) const {
  201|      0|    if (IsRowMajor)
  202|      0|      return m_d.data[row * m_d.outerStride() + col];
  203|      0|    else
  204|      0|      return m_d.data[row + col * m_d.outerStride()];
  205|      0|  }
  206|       |
  207|    136|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr CoeffReturnType coeff(Index index) const { return m_d.data[index]; }
  ------------------
  | _ZNK5Eigen8internal9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEE5coeffEl:
  |  207|    136|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr CoeffReturnType coeff(Index index) const { return m_d.data[index]; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEE5coeffEl
  ------------------
  208|       |
  209|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& coeffRef(Index row, Index col) {
  210|      0|    if (IsRowMajor)
  211|      0|      return const_cast<Scalar*>(m_d.data)[row * m_d.outerStride() + col];
  212|      0|    else
  213|      0|      return const_cast<Scalar*>(m_d.data)[row + col * m_d.outerStride()];
  214|      0|  }
  215|       |
  216|  7.55k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& coeffRef(Index index) {
  217|  7.55k|    return const_cast<Scalar*>(m_d.data)[index];
  218|  7.55k|  }
  ------------------
  | _ZN5Eigen8internal9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEE8coeffRefEl:
  |  216|     50|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& coeffRef(Index index) {
  |  217|     50|    return const_cast<Scalar*>(m_d.data)[index];
  |  218|     50|  }
  ------------------
  | _ZN5Eigen8internal9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEE8coeffRefEl:
  |  216|  7.50k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& coeffRef(Index index) {
  |  217|  7.50k|    return const_cast<Scalar*>(m_d.data)[index];
  |  218|  7.50k|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEE8coeffRefEl
  ------------------
  219|       |
  220|       |  template <int LoadMode, typename PacketType>
  221|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
  222|       |    if (IsRowMajor)
  223|       |      return ploadt<PacketType, LoadMode>(m_d.data + row * m_d.outerStride() + col);
  224|       |    else
  225|       |      return ploadt<PacketType, LoadMode>(m_d.data + row + col * m_d.outerStride());
  226|       |  }
  227|       |
  228|       |  template <int LoadMode, typename PacketType>
  229|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
  230|       |    return ploadt<PacketType, LoadMode>(m_d.data + index);
  231|       |  }
  232|       |
  233|       |  template <int StoreMode, typename PacketType>
  234|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index row, Index col, const PacketType& x) {
  235|       |    if (IsRowMajor)
  236|       |      return pstoret<Scalar, PacketType, StoreMode>(const_cast<Scalar*>(m_d.data) + row * m_d.outerStride() + col, x);
  237|       |    else
  238|       |      return pstoret<Scalar, PacketType, StoreMode>(const_cast<Scalar*>(m_d.data) + row + col * m_d.outerStride(), x);
  239|       |  }
  240|       |
  241|       |  template <int StoreMode, typename PacketType>
  242|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index index, const PacketType& x) {
  243|       |    return pstoret<Scalar, PacketType, StoreMode>(const_cast<Scalar*>(m_d.data) + index, x);
  244|       |  }
  245|       |
  246|       | protected:
  247|       |  plainobjectbase_evaluator_data<Scalar, OuterStrideAtCompileTime> m_d;
  248|       |};
  249|       |
  250|       |template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  251|       |struct evaluator<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>
  252|       |    : evaluator<PlainObjectBase<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>> {
  253|       |  typedef Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols> XprType;
  254|       |
  255|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr evaluator() = default;
  256|       |
  257|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr explicit evaluator(const XprType& m)
  258|      8|      : evaluator<PlainObjectBase<XprType>>(m) {}
  ------------------
  | _ZN5Eigen8internal9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEC2ERKS4_:
  |  258|      5|      : evaluator<PlainObjectBase<XprType>>(m) {}
  ------------------
  | _ZN5Eigen8internal9evaluatorINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEC2ERKS4_:
  |  258|      3|      : evaluator<PlainObjectBase<XprType>>(m) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEC2ERKS4_
  ------------------
  259|       |};
  260|       |
  261|       |template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  262|       |struct evaluator<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>
  263|       |    : evaluator<PlainObjectBase<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>> {
  264|       |  typedef Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> XprType;
  265|       |
  266|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr evaluator() = default;
  267|       |
  268|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr explicit evaluator(const XprType& m)
  269|       |      : evaluator<PlainObjectBase<XprType>>(m) {}
  270|       |};
  271|       |
  272|       |// -------------------- Transpose --------------------
  273|       |
  274|       |template <typename ArgType>
  275|       |struct unary_evaluator<Transpose<ArgType>, IndexBased> : evaluator_base<Transpose<ArgType>> {
  276|       |  typedef Transpose<ArgType> XprType;
  277|       |
  278|       |  enum {
  279|       |    CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
  280|       |    Flags = evaluator<ArgType>::Flags ^ RowMajorBit,
  281|       |    Alignment = evaluator<ArgType>::Alignment
  282|       |  };
  283|       |
  284|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit unary_evaluator(const XprType& t) : m_argImpl(t.nestedExpression()) {}
  285|       |
  286|       |  typedef typename XprType::Scalar Scalar;
  287|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
  288|       |
  289|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
  290|       |    return m_argImpl.coeff(col, row);
  291|       |  }
  292|       |
  293|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const { return m_argImpl.coeff(index); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15unary_evaluatorINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEENS0_10IndexBasedES5_E5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15unary_evaluatorINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEENS0_10IndexBasedES4_E5coeffEl
  ------------------
  294|       |
  295|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index row, Index col) { return m_argImpl.coeffRef(col, row); }
  296|       |
  297|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename XprType::Scalar& coeffRef(Index index) {
  298|       |    return m_argImpl.coeffRef(index);
  299|       |  }
  300|       |
  301|       |  template <int LoadMode, typename PacketType>
  302|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
  303|       |    return m_argImpl.template packet<LoadMode, PacketType>(col, row);
  304|       |  }
  305|       |
  306|       |  template <int LoadMode, typename PacketType>
  307|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
  308|       |    return m_argImpl.template packet<LoadMode, PacketType>(index);
  309|       |  }
  310|       |
  311|       |  template <int StoreMode, typename PacketType>
  312|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index row, Index col, const PacketType& x) {
  313|       |    m_argImpl.template writePacket<StoreMode, PacketType>(col, row, x);
  314|       |  }
  315|       |
  316|       |  template <int StoreMode, typename PacketType>
  317|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index index, const PacketType& x) {
  318|       |    m_argImpl.template writePacket<StoreMode, PacketType>(index, x);
  319|       |  }
  320|       |
  321|       | protected:
  322|       |  evaluator<ArgType> m_argImpl;
  323|       |};
  324|       |
  325|       |// -------------------- CwiseNullaryOp --------------------
  326|       |// Like Matrix and Array, this is not really a unary expression, so we directly specialize evaluator.
  327|       |// Likewise, there is not need to more sophisticated dispatching here.
  328|       |
  329|       |template <typename Scalar, typename NullaryOp, bool has_nullary = has_nullary_operator<NullaryOp>::value,
  330|       |          bool has_unary = has_unary_operator<NullaryOp>::value,
  331|       |          bool has_binary = has_binary_operator<NullaryOp>::value>
  332|       |struct nullary_wrapper {
  333|       |  template <typename IndexType>
  334|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const NullaryOp& op, IndexType i, IndexType j) const {
  335|       |    return op(i, j);
  336|       |  }
  337|       |  template <typename IndexType>
  338|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const NullaryOp& op, IndexType i) const {
  339|       |    return op(i);
  340|       |  }
  341|       |
  342|       |  template <typename T, typename IndexType>
  343|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T packetOp(const NullaryOp& op, IndexType i, IndexType j) const {
  344|       |    return op.template packetOp<T>(i, j);
  345|       |  }
  346|       |  template <typename T, typename IndexType>
  347|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T packetOp(const NullaryOp& op, IndexType i) const {
  348|       |    return op.template packetOp<T>(i);
  349|       |  }
  350|       |};
  351|       |
  352|       |template <typename Scalar, typename NullaryOp>
  353|       |struct nullary_wrapper<Scalar, NullaryOp, true, false, false> {
  354|       |  template <typename IndexType>
  355|  7.55k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const NullaryOp& op, IndexType = 0, IndexType = 0) const {
  356|  7.55k|    return op();
  357|  7.55k|  }
  ------------------
  | _ZNK5Eigen8internal15nullary_wrapperIK14AnnoyingScalarNS0_14scalar_zero_opIS2_EELb1ELb0ELb0EEclIlEES3_RKS5_T_SA_:
  |  355|  7.55k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const NullaryOp& op, IndexType = 0, IndexType = 0) const {
  |  356|  7.55k|    return op();
  |  357|  7.55k|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15nullary_wrapperIK14AnnoyingScalarNS0_18scalar_constant_opIS2_EELb1ELb0ELb0EEclIlEES3_RKS5_T_SA_
  ------------------
  358|       |  template <typename T, typename IndexType>
  359|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T packetOp(const NullaryOp& op, IndexType = 0, IndexType = 0) const {
  360|       |    return op.template packetOp<T>();
  361|       |  }
  362|       |};
  363|       |
  364|       |template <typename Scalar, typename NullaryOp>
  365|       |struct nullary_wrapper<Scalar, NullaryOp, false, false, true> {
  366|       |  template <typename IndexType>
  367|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const NullaryOp& op, IndexType i, IndexType j = 0) const {
  368|       |    return op(i, j);
  369|       |  }
  370|       |  template <typename T, typename IndexType>
  371|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T packetOp(const NullaryOp& op, IndexType i, IndexType j = 0) const {
  372|       |    return op.template packetOp<T>(i, j);
  373|       |  }
  374|       |};
  375|       |
  376|       |// We need the following specialization for vector-only functors assigned to a runtime vector,
  377|       |// for instance, using linspace and assigning a RowVectorXd to a MatrixXd or even a row of a MatrixXd.
  378|       |// In this case, i==0 and j is used for the actual iteration.
  379|       |template <typename Scalar, typename NullaryOp>
  380|       |struct nullary_wrapper<Scalar, NullaryOp, false, true, false> {
  381|       |  template <typename IndexType>
  382|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const NullaryOp& op, IndexType i, IndexType j) const {
  383|       |    eigen_assert(i == 0 || j == 0);
  384|       |    return op(i + j);
  385|       |  }
  386|       |  template <typename T, typename IndexType>
  387|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T packetOp(const NullaryOp& op, IndexType i, IndexType j) const {
  388|       |    eigen_assert(i == 0 || j == 0);
  389|       |    return op.template packetOp<T>(i + j);
  390|       |  }
  391|       |
  392|       |  template <typename IndexType>
  393|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const NullaryOp& op, IndexType i) const {
  394|       |    return op(i);
  395|       |  }
  396|       |  template <typename T, typename IndexType>
  397|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T packetOp(const NullaryOp& op, IndexType i) const {
  398|       |    return op.template packetOp<T>(i);
  399|       |  }
  400|       |};
  401|       |
  402|       |template <typename Scalar, typename NullaryOp>
  403|       |struct nullary_wrapper<Scalar, NullaryOp, false, false, false> {};
  404|       |
  405|       |#if 0 && EIGEN_COMP_MSVC > 0
  406|       |// Disable this ugly workaround. This is now handled in traits<Ref>::match,
  407|       |// but this piece of code might still become handly if some other weird compilation
  408|       |// errors pop up again.
  409|       |
  410|       |// MSVC exhibits a weird compilation error when
  411|       |// compiling:
  412|       |//    Eigen::MatrixXf A = MatrixXf::Random(3,3);
  413|       |//    Ref<const MatrixXf> R = 2.f*A;
  414|       |// and that has_*ary_operator<scalar_constant_op<float>> have not been instantiated yet.
  415|       |// The "problem" is that evaluator<2.f*A> is instantiated by traits<Ref>::match<2.f*A>
  416|       |// and at that time has_*ary_operator<T> returns true regardless of T.
  417|       |// Then nullary_wrapper is badly instantiated as nullary_wrapper<.,.,true,true,true>.
  418|       |// The trick is thus to defer the proper instantiation of nullary_wrapper when coeff(),
  419|       |// and packet() are really instantiated as implemented below:
  420|       |
  421|       |// This is a simple wrapper around Index to enforce the re-instantiation of
  422|       |// has_*ary_operator when needed.
  423|       |template<typename T> struct nullary_wrapper_workaround_msvc {
  424|       |  nullary_wrapper_workaround_msvc(const T&);
  425|       |  operator T()const;
  426|       |};
  427|       |
  428|       |template<typename Scalar,typename NullaryOp>
  429|       |struct nullary_wrapper<Scalar,NullaryOp,true,true,true>
  430|       |{
  431|       |  template <typename IndexType>
  432|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const NullaryOp& op, IndexType i, IndexType j) const {
  433|       |    return nullary_wrapper<Scalar,NullaryOp,
  434|       |    has_nullary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value,
  435|       |    has_unary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value,
  436|       |    has_binary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value>().operator()(op,i,j);
  437|       |  }
  438|       |  template <typename IndexType>
  439|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const NullaryOp& op, IndexType i) const {
  440|       |    return nullary_wrapper<Scalar,NullaryOp,
  441|       |    has_nullary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value,
  442|       |    has_unary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value,
  443|       |    has_binary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value>().operator()(op,i);
  444|       |  }
  445|       |
  446|       |  template <typename T, typename IndexType>
  447|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T packetOp(const NullaryOp& op, IndexType i, IndexType j) const {
  448|       |    return nullary_wrapper<Scalar,NullaryOp,
  449|       |    has_nullary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value,
  450|       |    has_unary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value,
  451|       |    has_binary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value>().template packetOp<T>(op,i,j);
  452|       |  }
  453|       |  template <typename T, typename IndexType>
  454|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T packetOp(const NullaryOp& op, IndexType i) const {
  455|       |    return nullary_wrapper<Scalar,NullaryOp,
  456|       |    has_nullary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value,
  457|       |    has_unary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value,
  458|       |    has_binary_operator<NullaryOp,nullary_wrapper_workaround_msvc<IndexType> >::value>().template packetOp<T>(op,i);
  459|       |  }
  460|       |};
  461|       |#endif  // MSVC workaround
  462|       |
  463|       |template <typename NullaryOp, typename PlainObjectType>
  464|       |struct evaluator<CwiseNullaryOp<NullaryOp, PlainObjectType>>
  465|       |    : evaluator_base<CwiseNullaryOp<NullaryOp, PlainObjectType>> {
  466|       |  typedef CwiseNullaryOp<NullaryOp, PlainObjectType> XprType;
  467|       |  typedef internal::remove_all_t<PlainObjectType> PlainObjectTypeCleaned;
  468|       |
  469|       |  enum {
  470|       |    CoeffReadCost = internal::functor_traits<NullaryOp>::Cost,
  471|       |
  472|       |    Flags = (evaluator<PlainObjectTypeCleaned>::Flags &
  473|       |             (HereditaryBits | (functor_has_linear_access<NullaryOp>::ret ? LinearAccessBit : 0) |
  474|       |              (functor_traits<NullaryOp>::PacketAccess ? PacketAccessBit : 0))) |
  475|       |            (functor_traits<NullaryOp>::IsRepeatable ? 0 : EvalBeforeNestingBit),
  476|       |    Alignment = AlignedMax
  477|       |  };
  478|       |
  479|      4|  EIGEN_DEVICE_FUNC explicit evaluator(const XprType& n) : m_functor(n.functor()), m_wrapper() {
  480|      4|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  481|      4|  }
  ------------------
  | _ZN5Eigen8internal9evaluatorINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEEEEEC2ERKS8_:
  |  479|      1|  EIGEN_DEVICE_FUNC explicit evaluator(const XprType& n) : m_functor(n.functor()), m_wrapper() {
  |  480|      1|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  |  481|      1|  }
  ------------------
  | _ZN5Eigen8internal9evaluatorINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEEEEEC2ERKS8_:
  |  479|      3|  EIGEN_DEVICE_FUNC explicit evaluator(const XprType& n) : m_functor(n.functor()), m_wrapper() {
  |  480|      3|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  |  481|      3|  }
  ------------------
  482|       |
  483|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
  484|       |
  485|       |  template <typename IndexType>
  486|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(IndexType row, IndexType col) const {
  487|       |    return m_wrapper(m_functor, row, col);
  488|       |  }
  489|       |
  490|       |  template <typename IndexType>
  491|  7.55k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(IndexType index) const {
  492|  7.55k|    return m_wrapper(m_functor, index);
  493|  7.55k|  }
  ------------------
  | _ZNK5Eigen8internal9evaluatorINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEEEEE5coeffIlEEKS4_T_:
  |  491|     50|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(IndexType index) const {
  |  492|     50|    return m_wrapper(m_functor, index);
  |  493|     50|  }
  ------------------
  | _ZNK5Eigen8internal9evaluatorINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEEEEE5coeffIlEEKS4_T_:
  |  491|  7.50k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(IndexType index) const {
  |  492|  7.50k|    return m_wrapper(m_functor, index);
  |  493|  7.50k|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal9evaluatorINS_14CwiseNullaryOpINS0_18scalar_constant_opI14AnnoyingScalarEEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEEEEE5coeffIlEEKS4_T_
  ------------------
  494|       |
  495|       |  template <int LoadMode, typename PacketType, typename IndexType>
  496|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(IndexType row, IndexType col) const {
  497|       |    return m_wrapper.template packetOp<PacketType>(m_functor, row, col);
  498|       |  }
  499|       |
  500|       |  template <int LoadMode, typename PacketType, typename IndexType>
  501|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(IndexType index) const {
  502|       |    return m_wrapper.template packetOp<PacketType>(m_functor, index);
  503|       |  }
  504|       |
  505|       | protected:
  506|       |  const NullaryOp m_functor;
  507|       |  const internal::nullary_wrapper<CoeffReturnType, NullaryOp> m_wrapper;
  508|       |};
  509|       |
  510|       |// -------------------- CwiseUnaryOp --------------------
  511|       |
  512|       |template <typename UnaryOp, typename ArgType>
  513|       |struct unary_evaluator<CwiseUnaryOp<UnaryOp, ArgType>, IndexBased> : evaluator_base<CwiseUnaryOp<UnaryOp, ArgType>> {
  514|       |  typedef CwiseUnaryOp<UnaryOp, ArgType> XprType;
  515|       |
  516|       |  enum {
  517|       |    CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<UnaryOp>::Cost),
  518|       |
  519|       |    Flags = evaluator<ArgType>::Flags &
  520|       |            (HereditaryBits | LinearAccessBit | (functor_traits<UnaryOp>::PacketAccess ? PacketAccessBit : 0)),
  521|       |    Alignment = evaluator<ArgType>::Alignment
  522|       |  };
  523|       |
  524|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit unary_evaluator(const XprType& op) : m_d(op) {
  525|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<UnaryOp>::Cost);
  526|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  527|       |  }
  528|       |
  529|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
  530|       |
  531|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
  532|       |    return m_d.func()(m_d.argImpl.coeff(row, col));
  533|       |  }
  534|       |
  535|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
  536|       |    return m_d.func()(m_d.argImpl.coeff(index));
  537|       |  }
  538|       |
  539|       |  template <int LoadMode, typename PacketType>
  540|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
  541|       |    return m_d.func().packetOp(m_d.argImpl.template packet<LoadMode, PacketType>(row, col));
  542|       |  }
  543|       |
  544|       |  template <int LoadMode, typename PacketType>
  545|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
  546|       |    return m_d.func().packetOp(m_d.argImpl.template packet<LoadMode, PacketType>(index));
  547|       |  }
  548|       |
  549|       | protected:
  550|       |  // this helper permits to completely eliminate the functor if it is empty
  551|       |  struct Data {
  552|       |    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Data(const XprType& xpr)
  553|       |        : op(xpr.functor()), argImpl(xpr.nestedExpression()) {}
  554|       |    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const UnaryOp& func() const { return op; }
  555|       |    UnaryOp op;
  556|       |    evaluator<ArgType> argImpl;
  557|       |  };
  558|       |
  559|       |  Data m_d;
  560|       |};
  561|       |
  562|       |// ----------------------- Casting ---------------------
  563|       |
  564|       |template <typename SrcType, typename DstType, typename ArgType>
  565|       |struct unary_evaluator<CwiseUnaryOp<core_cast_op<SrcType, DstType>, ArgType>, IndexBased> {
  566|       |  using CastOp = core_cast_op<SrcType, DstType>;
  567|       |  using XprType = CwiseUnaryOp<CastOp, ArgType>;
  568|       |
  569|       |  // Use the largest packet type by default
  570|       |  using SrcPacketType = typename packet_traits<SrcType>::type;
  571|       |  static constexpr int SrcPacketSize = unpacket_traits<SrcPacketType>::size;
  572|       |  static constexpr int SrcPacketBytes = SrcPacketSize * sizeof(SrcType);
  573|       |
  574|       |  enum {
  575|       |    CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<CastOp>::Cost),
  576|       |    PacketAccess = functor_traits<CastOp>::PacketAccess,
  577|       |    ActualPacketAccessBit = PacketAccess ? PacketAccessBit : 0,
  578|       |    Flags = evaluator<ArgType>::Flags & (HereditaryBits | LinearAccessBit | ActualPacketAccessBit),
  579|       |    IsRowMajor = (evaluator<ArgType>::Flags & RowMajorBit),
  580|       |    Alignment = evaluator<ArgType>::Alignment
  581|       |  };
  582|       |
  583|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit unary_evaluator(const XprType& xpr)
  584|       |      : m_argImpl(xpr.nestedExpression()), m_rows(xpr.rows()), m_cols(xpr.cols()) {
  585|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<CastOp>::Cost);
  586|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  587|       |  }
  588|       |
  589|       |  template <typename DstPacketType>
  590|       |  using AltSrcScalarOp = std::enable_if_t<(unpacket_traits<DstPacketType>::size < SrcPacketSize &&
  591|       |                                           !find_packet_by_size<SrcType, unpacket_traits<DstPacketType>::size>::value),
  592|       |                                          bool>;
  593|       |  template <typename DstPacketType>
  594|       |  using SrcPacketArgs1 =
  595|       |      std::enable_if_t<(find_packet_by_size<SrcType, unpacket_traits<DstPacketType>::size>::value), bool>;
  596|       |  template <typename DstPacketType>
  597|       |  using SrcPacketArgs2 = std::enable_if_t<(unpacket_traits<DstPacketType>::size) == (2 * SrcPacketSize), bool>;
  598|       |  template <typename DstPacketType>
  599|       |  using SrcPacketArgs4 = std::enable_if_t<(unpacket_traits<DstPacketType>::size) == (4 * SrcPacketSize), bool>;
  600|       |  template <typename DstPacketType>
  601|       |  using SrcPacketArgs8 = std::enable_if_t<(unpacket_traits<DstPacketType>::size) == (8 * SrcPacketSize), bool>;
  602|       |
  603|       |  template <bool UseRowMajor = IsRowMajor, std::enable_if_t<UseRowMajor, bool> = true>
  604|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool check_array_bounds(Index, Index col, Index packetSize) const {
  605|       |    return col + packetSize <= cols();
  606|       |  }
  607|       |  template <bool UseRowMajor = IsRowMajor, std::enable_if_t<!UseRowMajor, bool> = true>
  608|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool check_array_bounds(Index row, Index, Index packetSize) const {
  609|       |    return row + packetSize <= rows();
  610|       |  }
  611|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool check_array_bounds(Index index, Index packetSize) const {
  612|       |    return index + packetSize <= size();
  613|       |  }
  614|       |
  615|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE SrcType srcCoeff(Index row, Index col, Index offset) const {
  616|       |    Index actualRow = IsRowMajor ? row : row + offset;
  617|       |    Index actualCol = IsRowMajor ? col + offset : col;
  618|       |    return m_argImpl.coeff(actualRow, actualCol);
  619|       |  }
  620|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE SrcType srcCoeff(Index index, Index offset) const {
  621|       |    Index actualIndex = index + offset;
  622|       |    return m_argImpl.coeff(actualIndex);
  623|       |  }
  624|       |
  625|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstType coeff(Index row, Index col) const {
  626|       |    return cast<SrcType, DstType>(srcCoeff(row, col, 0));
  627|       |  }
  628|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstType coeff(Index index) const {
  629|       |    return cast<SrcType, DstType>(srcCoeff(index, 0));
  630|       |  }
  631|       |
  632|       |  template <int LoadMode, typename PacketType = SrcPacketType>
  633|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType srcPacket(Index row, Index col, Index offset) const {
  634|       |    constexpr int PacketSize = unpacket_traits<PacketType>::size;
  635|       |    Index actualRow = IsRowMajor ? row : row + (offset * PacketSize);
  636|       |    Index actualCol = IsRowMajor ? col + (offset * PacketSize) : col;
  637|       |    eigen_assert(check_array_bounds(actualRow, actualCol, PacketSize) && "Array index out of bounds");
  638|       |    return m_argImpl.template packet<LoadMode, PacketType>(actualRow, actualCol);
  639|       |  }
  640|       |  template <int LoadMode, typename PacketType = SrcPacketType>
  641|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType srcPacket(Index index, Index offset) const {
  642|       |    constexpr int PacketSize = unpacket_traits<PacketType>::size;
  643|       |    Index actualIndex = index + (offset * PacketSize);
  644|       |    eigen_assert(check_array_bounds(actualIndex, PacketSize) && "Array index out of bounds");
  645|       |    return m_argImpl.template packet<LoadMode, PacketType>(actualIndex);
  646|       |  }
  647|       |
  648|       |  // There is no source packet type with equal or fewer elements than DstPacketType.
  649|       |  // This is problematic as the evaluation loop may attempt to access data outside the bounds of the array.
  650|       |  // For example, consider the cast utilizing pcast<Packet4f,Packet2d> with an array of size 4: {0.0f,1.0f,2.0f,3.0f}.
  651|       |  // The first iteration of the evaluation loop will load 16 bytes: {0.0f,1.0f,2.0f,3.0f} and cast to {0.0,1.0}, which
  652|       |  // is acceptable. The second iteration will load 16 bytes: {2.0f,3.0f,?,?}, which is outside the bounds of the array.
  653|       |
  654|       |  // Instead, perform runtime check to determine if the load would access data outside the bounds of the array.
  655|       |  // If not, perform full load. Otherwise, revert to a scalar loop to perform a partial load.
  656|       |  // In either case, perform a vectorized cast of the source packet.
  657|       |  template <int LoadMode, typename DstPacketType, AltSrcScalarOp<DstPacketType> = true>
  658|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index row, Index col) const {
  659|       |    constexpr int DstPacketSize = unpacket_traits<DstPacketType>::size;
  660|       |    constexpr int SrcBytesIncrement = DstPacketSize * sizeof(SrcType);
  661|       |    constexpr int SrcLoadMode = plain_enum_min(SrcBytesIncrement, LoadMode);
  662|       |    SrcPacketType src;
  663|       |    if (EIGEN_PREDICT_TRUE(check_array_bounds(row, col, SrcPacketSize))) {
  664|       |      src = srcPacket<SrcLoadMode>(row, col, 0);
  665|       |    } else {
  666|       |      Array<SrcType, SrcPacketSize, 1> srcArray;
  667|       |      for (size_t k = 0; k < DstPacketSize; k++) srcArray[k] = srcCoeff(row, col, k);
  668|       |      for (size_t k = DstPacketSize; k < SrcPacketSize; k++) srcArray[k] = SrcType(0);
  669|       |      src = pload<SrcPacketType>(srcArray.data());
  670|       |    }
  671|       |    return pcast<SrcPacketType, DstPacketType>(src);
  672|       |  }
  673|       |  // Use the source packet type with the same size as DstPacketType, if it exists
  674|       |  template <int LoadMode, typename DstPacketType, SrcPacketArgs1<DstPacketType> = true>
  675|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index row, Index col) const {
  676|       |    constexpr int DstPacketSize = unpacket_traits<DstPacketType>::size;
  677|       |    using SizedSrcPacketType = typename find_packet_by_size<SrcType, DstPacketSize>::type;
  678|       |    constexpr int SrcBytesIncrement = DstPacketSize * sizeof(SrcType);
  679|       |    constexpr int SrcLoadMode = plain_enum_min(SrcBytesIncrement, LoadMode);
  680|       |    return pcast<SizedSrcPacketType, DstPacketType>(srcPacket<SrcLoadMode, SizedSrcPacketType>(row, col, 0));
  681|       |  }
  682|       |  // unpacket_traits<DstPacketType>::size == 2 * SrcPacketSize
  683|       |  template <int LoadMode, typename DstPacketType, SrcPacketArgs2<DstPacketType> = true>
  684|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index row, Index col) const {
  685|       |    constexpr int SrcLoadMode = plain_enum_min(SrcPacketBytes, LoadMode);
  686|       |    return pcast<SrcPacketType, DstPacketType>(srcPacket<SrcLoadMode>(row, col, 0),
  687|       |                                               srcPacket<SrcLoadMode>(row, col, 1));
  688|       |  }
  689|       |  // unpacket_traits<DstPacketType>::size == 4 * SrcPacketSize
  690|       |  template <int LoadMode, typename DstPacketType, SrcPacketArgs4<DstPacketType> = true>
  691|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index row, Index col) const {
  692|       |    constexpr int SrcLoadMode = plain_enum_min(SrcPacketBytes, LoadMode);
  693|       |    return pcast<SrcPacketType, DstPacketType>(srcPacket<SrcLoadMode>(row, col, 0), srcPacket<SrcLoadMode>(row, col, 1),
  694|       |                                               srcPacket<SrcLoadMode>(row, col, 2),
  695|       |                                               srcPacket<SrcLoadMode>(row, col, 3));
  696|       |  }
  697|       |  // unpacket_traits<DstPacketType>::size == 8 * SrcPacketSize
  698|       |  template <int LoadMode, typename DstPacketType, SrcPacketArgs8<DstPacketType> = true>
  699|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index row, Index col) const {
  700|       |    constexpr int SrcLoadMode = plain_enum_min(SrcPacketBytes, LoadMode);
  701|       |    return pcast<SrcPacketType, DstPacketType>(
  702|       |        srcPacket<SrcLoadMode>(row, col, 0), srcPacket<SrcLoadMode>(row, col, 1), srcPacket<SrcLoadMode>(row, col, 2),
  703|       |        srcPacket<SrcLoadMode>(row, col, 3), srcPacket<SrcLoadMode>(row, col, 4), srcPacket<SrcLoadMode>(row, col, 5),
  704|       |        srcPacket<SrcLoadMode>(row, col, 6), srcPacket<SrcLoadMode>(row, col, 7));
  705|       |  }
  706|       |
  707|       |  // Analogous routines for linear access.
  708|       |  template <int LoadMode, typename DstPacketType, AltSrcScalarOp<DstPacketType> = true>
  709|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index index) const {
  710|       |    constexpr int DstPacketSize = unpacket_traits<DstPacketType>::size;
  711|       |    constexpr int SrcBytesIncrement = DstPacketSize * sizeof(SrcType);
  712|       |    constexpr int SrcLoadMode = plain_enum_min(SrcBytesIncrement, LoadMode);
  713|       |    SrcPacketType src;
  714|       |    if (EIGEN_PREDICT_TRUE(check_array_bounds(index, SrcPacketSize))) {
  715|       |      src = srcPacket<SrcLoadMode>(index, 0);
  716|       |    } else {
  717|       |      Array<SrcType, SrcPacketSize, 1> srcArray;
  718|       |      for (size_t k = 0; k < DstPacketSize; k++) srcArray[k] = srcCoeff(index, k);
  719|       |      for (size_t k = DstPacketSize; k < SrcPacketSize; k++) srcArray[k] = SrcType(0);
  720|       |      src = pload<SrcPacketType>(srcArray.data());
  721|       |    }
  722|       |    return pcast<SrcPacketType, DstPacketType>(src);
  723|       |  }
  724|       |  template <int LoadMode, typename DstPacketType, SrcPacketArgs1<DstPacketType> = true>
  725|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index index) const {
  726|       |    constexpr int DstPacketSize = unpacket_traits<DstPacketType>::size;
  727|       |    using SizedSrcPacketType = typename find_packet_by_size<SrcType, DstPacketSize>::type;
  728|       |    constexpr int SrcBytesIncrement = DstPacketSize * sizeof(SrcType);
  729|       |    constexpr int SrcLoadMode = plain_enum_min(SrcBytesIncrement, LoadMode);
  730|       |    return pcast<SizedSrcPacketType, DstPacketType>(srcPacket<SrcLoadMode, SizedSrcPacketType>(index, 0));
  731|       |  }
  732|       |  template <int LoadMode, typename DstPacketType, SrcPacketArgs2<DstPacketType> = true>
  733|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index index) const {
  734|       |    constexpr int SrcLoadMode = plain_enum_min(SrcPacketBytes, LoadMode);
  735|       |    return pcast<SrcPacketType, DstPacketType>(srcPacket<SrcLoadMode>(index, 0), srcPacket<SrcLoadMode>(index, 1));
  736|       |  }
  737|       |  template <int LoadMode, typename DstPacketType, SrcPacketArgs4<DstPacketType> = true>
  738|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index index) const {
  739|       |    constexpr int SrcLoadMode = plain_enum_min(SrcPacketBytes, LoadMode);
  740|       |    return pcast<SrcPacketType, DstPacketType>(srcPacket<SrcLoadMode>(index, 0), srcPacket<SrcLoadMode>(index, 1),
  741|       |                                               srcPacket<SrcLoadMode>(index, 2), srcPacket<SrcLoadMode>(index, 3));
  742|       |  }
  743|       |  template <int LoadMode, typename DstPacketType, SrcPacketArgs8<DstPacketType> = true>
  744|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DstPacketType packet(Index index) const {
  745|       |    constexpr int SrcLoadMode = plain_enum_min(SrcPacketBytes, LoadMode);
  746|       |    return pcast<SrcPacketType, DstPacketType>(srcPacket<SrcLoadMode>(index, 0), srcPacket<SrcLoadMode>(index, 1),
  747|       |                                               srcPacket<SrcLoadMode>(index, 2), srcPacket<SrcLoadMode>(index, 3),
  748|       |                                               srcPacket<SrcLoadMode>(index, 4), srcPacket<SrcLoadMode>(index, 5),
  749|       |                                               srcPacket<SrcLoadMode>(index, 6), srcPacket<SrcLoadMode>(index, 7));
  750|       |  }
  751|       |
  752|       |  constexpr EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index rows() const { return m_rows; }
  753|       |  constexpr EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index cols() const { return m_cols; }
  754|       |  constexpr EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index size() const { return m_rows * m_cols; }
  755|       |
  756|       | protected:
  757|       |  const evaluator<ArgType> m_argImpl;
  758|       |  const variable_if_dynamic<Index, XprType::RowsAtCompileTime> m_rows;
  759|       |  const variable_if_dynamic<Index, XprType::ColsAtCompileTime> m_cols;
  760|       |};
  761|       |
  762|       |// -------------------- CwiseTernaryOp --------------------
  763|       |
  764|       |// this is a ternary expression
  765|       |template <typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
  766|       |struct evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>>
  767|       |    : public ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>> {
  768|       |  typedef CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> XprType;
  769|       |  typedef ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>> Base;
  770|       |
  771|       |  EIGEN_DEVICE_FUNC explicit evaluator(const XprType& xpr) : Base(xpr) {}
  772|       |};
  773|       |
  774|       |template <typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
  775|       |struct ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>, IndexBased, IndexBased>
  776|       |    : evaluator_base<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>> {
  777|       |  typedef CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> XprType;
  778|       |
  779|       |  enum {
  780|       |    CoeffReadCost = int(evaluator<Arg1>::CoeffReadCost) + int(evaluator<Arg2>::CoeffReadCost) +
  781|       |                    int(evaluator<Arg3>::CoeffReadCost) + int(functor_traits<TernaryOp>::Cost),
  782|       |
  783|       |    Arg1Flags = evaluator<Arg1>::Flags,
  784|       |    Arg2Flags = evaluator<Arg2>::Flags,
  785|       |    Arg3Flags = evaluator<Arg3>::Flags,
  786|       |    SameType = is_same<typename Arg1::Scalar, typename Arg2::Scalar>::value &&
  787|       |               is_same<typename Arg1::Scalar, typename Arg3::Scalar>::value,
  788|       |    StorageOrdersAgree = (int(Arg1Flags) & RowMajorBit) == (int(Arg2Flags) & RowMajorBit) &&
  789|       |                         (int(Arg1Flags) & RowMajorBit) == (int(Arg3Flags) & RowMajorBit),
  790|       |    Flags0 = (int(Arg1Flags) | int(Arg2Flags) | int(Arg3Flags)) &
  791|       |             (HereditaryBits |
  792|       |              (int(Arg1Flags) & int(Arg2Flags) & int(Arg3Flags) &
  793|       |               ((StorageOrdersAgree ? LinearAccessBit : 0) |
  794|       |                (functor_traits<TernaryOp>::PacketAccess && StorageOrdersAgree && SameType ? PacketAccessBit : 0)))),
  795|       |    Flags = (Flags0 & ~RowMajorBit) | (Arg1Flags & RowMajorBit),
  796|       |    Alignment = plain_enum_min(plain_enum_min(evaluator<Arg1>::Alignment, evaluator<Arg2>::Alignment),
  797|       |                               evaluator<Arg3>::Alignment)
  798|       |  };
  799|       |
  800|       |  EIGEN_DEVICE_FUNC explicit ternary_evaluator(const XprType& xpr) : m_d(xpr) {
  801|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<TernaryOp>::Cost);
  802|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  803|       |  }
  804|       |
  805|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
  806|       |
  807|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
  808|       |    return m_d.func()(m_d.arg1Impl.coeff(row, col), m_d.arg2Impl.coeff(row, col), m_d.arg3Impl.coeff(row, col));
  809|       |  }
  810|       |
  811|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
  812|       |    return m_d.func()(m_d.arg1Impl.coeff(index), m_d.arg2Impl.coeff(index), m_d.arg3Impl.coeff(index));
  813|       |  }
  814|       |
  815|       |  template <int LoadMode, typename PacketType>
  816|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
  817|       |    return m_d.func().packetOp(m_d.arg1Impl.template packet<LoadMode, PacketType>(row, col),
  818|       |                               m_d.arg2Impl.template packet<LoadMode, PacketType>(row, col),
  819|       |                               m_d.arg3Impl.template packet<LoadMode, PacketType>(row, col));
  820|       |  }
  821|       |
  822|       |  template <int LoadMode, typename PacketType>
  823|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
  824|       |    return m_d.func().packetOp(m_d.arg1Impl.template packet<LoadMode, PacketType>(index),
  825|       |                               m_d.arg2Impl.template packet<LoadMode, PacketType>(index),
  826|       |                               m_d.arg3Impl.template packet<LoadMode, PacketType>(index));
  827|       |  }
  828|       |
  829|       | protected:
  830|       |  // this helper permits to completely eliminate the functor if it is empty
  831|       |  struct Data {
  832|       |    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Data(const XprType& xpr)
  833|       |        : op(xpr.functor()), arg1Impl(xpr.arg1()), arg2Impl(xpr.arg2()), arg3Impl(xpr.arg3()) {}
  834|       |    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const TernaryOp& func() const { return op; }
  835|       |    TernaryOp op;
  836|       |    evaluator<Arg1> arg1Impl;
  837|       |    evaluator<Arg2> arg2Impl;
  838|       |    evaluator<Arg3> arg3Impl;
  839|       |  };
  840|       |
  841|       |  Data m_d;
  842|       |};
  843|       |
  844|       |// specialization for expressions like (a < b).select(c, d) to enable full vectorization
  845|       |template <typename Arg1, typename Arg2, typename Scalar, typename CmpLhsType, typename CmpRhsType, ComparisonName cmp>
  846|       |struct evaluator<CwiseTernaryOp<scalar_boolean_select_op<Scalar, Scalar, bool>, Arg1, Arg2,
  847|       |                                CwiseBinaryOp<scalar_cmp_op<Scalar, Scalar, cmp, false>, CmpLhsType, CmpRhsType>>>
  848|       |    : public ternary_evaluator<
  849|       |          CwiseTernaryOp<scalar_boolean_select_op<Scalar, Scalar, Scalar>, Arg1, Arg2,
  850|       |                         CwiseBinaryOp<scalar_cmp_op<Scalar, Scalar, cmp, true>, CmpLhsType, CmpRhsType>>> {
  851|       |  using DummyTernaryOp = scalar_boolean_select_op<Scalar, Scalar, bool>;
  852|       |  using DummyArg3 = CwiseBinaryOp<scalar_cmp_op<Scalar, Scalar, cmp, false>, CmpLhsType, CmpRhsType>;
  853|       |  using DummyXprType = CwiseTernaryOp<DummyTernaryOp, Arg1, Arg2, DummyArg3>;
  854|       |
  855|       |  using TernaryOp = scalar_boolean_select_op<Scalar, Scalar, Scalar>;
  856|       |  using Arg3 = CwiseBinaryOp<scalar_cmp_op<Scalar, Scalar, cmp, true>, CmpLhsType, CmpRhsType>;
  857|       |  using XprType = CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>;
  858|       |
  859|       |  using Base = ternary_evaluator<XprType>;
  860|       |
  861|       |  EIGEN_DEVICE_FUNC explicit evaluator(const DummyXprType& xpr)
  862|       |      : Base(XprType(xpr.arg1(), xpr.arg2(), Arg3(xpr.arg3().lhs(), xpr.arg3().rhs()))) {}
  863|       |};
  864|       |
  865|       |// -------------------- CwiseBinaryOp --------------------
  866|       |
  867|       |// this is a binary expression
  868|       |template <typename BinaryOp, typename Lhs, typename Rhs>
  869|       |struct evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> : public binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> {
  870|       |  typedef CwiseBinaryOp<BinaryOp, Lhs, Rhs> XprType;
  871|       |  typedef binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> Base;
  872|       |
  873|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr) : Base(xpr) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEEEC2ERKSH_
  ------------------
  | _ZN5Eigen8internal9evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EEEC2ERKS9_:
  |  873|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr) : Base(xpr) {}
  ------------------
  874|       |};
  875|       |
  876|       |template <typename BinaryOp, typename Lhs, typename Rhs>
  877|       |struct binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>, IndexBased, IndexBased>
  878|       |    : evaluator_base<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> {
  879|       |  typedef CwiseBinaryOp<BinaryOp, Lhs, Rhs> XprType;
  880|       |
  881|       |  enum {
  882|       |    CoeffReadCost =
  883|       |        int(evaluator<Lhs>::CoeffReadCost) + int(evaluator<Rhs>::CoeffReadCost) + int(functor_traits<BinaryOp>::Cost),
  884|       |
  885|       |    LhsFlags = evaluator<Lhs>::Flags,
  886|       |    RhsFlags = evaluator<Rhs>::Flags,
  887|       |    SameType = is_same<typename Lhs::Scalar, typename Rhs::Scalar>::value,
  888|       |    StorageOrdersAgree = (int(LhsFlags) & RowMajorBit) == (int(RhsFlags) & RowMajorBit),
  889|       |    Flags0 = (int(LhsFlags) | int(RhsFlags)) &
  890|       |             (HereditaryBits |
  891|       |              (int(LhsFlags) & int(RhsFlags) &
  892|       |               ((StorageOrdersAgree ? LinearAccessBit : 0) |
  893|       |                (functor_traits<BinaryOp>::PacketAccess && StorageOrdersAgree && SameType ? PacketAccessBit : 0)))),
  894|       |    Flags = (Flags0 & ~RowMajorBit) | (LhsFlags & RowMajorBit),
  895|       |    Alignment = plain_enum_min(evaluator<Lhs>::Alignment, evaluator<Rhs>::Alignment)
  896|       |  };
  897|       |
  898|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit binary_evaluator(const XprType& xpr) : m_d(xpr) {
  899|      2|    EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<BinaryOp>::Cost);
  900|      2|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  901|      2|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEENS0_10IndexBasedESI_S4_S4_EC2ERKSH_
  ------------------
  | _ZN5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EENS0_10IndexBasedESA_S4_S4_EC2ERKS9_:
  |  898|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit binary_evaluator(const XprType& xpr) : m_d(xpr) {
  |  899|      2|    EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<BinaryOp>::Cost);
  |  900|      2|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  |  901|      2|  }
  ------------------
  902|       |
  903|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
  904|       |
  905|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
  906|       |    return m_d.func()(m_d.lhsImpl.coeff(row, col), m_d.rhsImpl.coeff(row, col));
  907|       |  }
  908|       |
  909|     68|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
  910|     68|    return m_d.func()(m_d.lhsImpl.coeff(index), m_d.rhsImpl.coeff(index));
  911|     68|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEENS0_10IndexBasedESI_S4_S4_E5coeffEl
  ------------------
  | _ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EENS0_10IndexBasedESA_S4_S4_E5coeffEl:
  |  909|     68|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
  |  910|     68|    return m_d.func()(m_d.lhsImpl.coeff(index), m_d.rhsImpl.coeff(index));
  |  911|     68|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISA_Li1ENS_6StrideILi0ELi0EEEEEEENS0_10IndexBasedESK_S4_S4_E5coeffEl
  ------------------
  912|       |
  913|       |  template <int LoadMode, typename PacketType>
  914|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
  915|       |    return m_d.func().packetOp(m_d.lhsImpl.template packet<LoadMode, PacketType>(row, col),
  916|       |                               m_d.rhsImpl.template packet<LoadMode, PacketType>(row, col));
  917|       |  }
  918|       |
  919|       |  template <int LoadMode, typename PacketType>
  920|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
  921|       |    return m_d.func().packetOp(m_d.lhsImpl.template packet<LoadMode, PacketType>(index),
  922|       |                               m_d.rhsImpl.template packet<LoadMode, PacketType>(index));
  923|       |  }
  924|       |
  925|       | protected:
  926|       |  // this helper permits to completely eliminate the functor if it is empty
  927|       |  struct Data {
  928|       |    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Data(const XprType& xpr)
  929|      2|        : op(xpr.functor()), lhsImpl(xpr.lhs()), rhsImpl(xpr.rhs()) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEENS0_10IndexBasedESI_S4_S4_E4DataC2ERKSH_
  ------------------
  | _ZN5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EENS0_10IndexBasedESA_S4_S4_E4DataC2ERKS9_:
  |  929|      2|        : op(xpr.functor()), lhsImpl(xpr.lhs()), rhsImpl(xpr.rhs()) {}
  ------------------
  930|     68|    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const BinaryOp& func() const { return op; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEENS0_10IndexBasedESI_S4_S4_E4Data4funcEv
  ------------------
  | _ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EENS0_10IndexBasedESA_S4_S4_E4Data4funcEv:
  |  930|     68|    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const BinaryOp& func() const { return op; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISA_Li1ENS_6StrideILi0ELi0EEEEEEENS0_10IndexBasedESK_S4_S4_E4Data4funcEv
  ------------------
  931|       |    BinaryOp op;
  932|       |    evaluator<Lhs> lhsImpl;
  933|       |    evaluator<Rhs> rhsImpl;
  934|       |  };
  935|       |
  936|       |  Data m_d;
  937|       |};
  938|       |
  939|       |// -------------------- CwiseUnaryView --------------------
  940|       |
  941|       |template <typename UnaryOp, typename ArgType, typename StrideType>
  942|       |struct unary_evaluator<CwiseUnaryView<UnaryOp, ArgType, StrideType>, IndexBased>
  943|       |    : evaluator_base<CwiseUnaryView<UnaryOp, ArgType, StrideType>> {
  944|       |  typedef CwiseUnaryView<UnaryOp, ArgType, StrideType> XprType;
  945|       |
  946|       |  enum {
  947|       |    CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<UnaryOp>::Cost),
  948|       |
  949|       |    Flags = (evaluator<ArgType>::Flags & (HereditaryBits | LinearAccessBit | DirectAccessBit)),
  950|       |
  951|       |    Alignment = 0  // FIXME it is not very clear why alignment is necessarily lost...
  952|       |  };
  953|       |
  954|       |  EIGEN_DEVICE_FUNC explicit unary_evaluator(const XprType& op) : m_d(op) {
  955|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<UnaryOp>::Cost);
  956|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  957|       |  }
  958|       |
  959|       |  typedef typename XprType::Scalar Scalar;
  960|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
  961|       |
  962|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
  963|       |    return m_d.func()(m_d.argImpl.coeff(row, col));
  964|       |  }
  965|       |
  966|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
  967|       |    return m_d.func()(m_d.argImpl.coeff(index));
  968|       |  }
  969|       |
  970|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index row, Index col) {
  971|       |    return m_d.func()(m_d.argImpl.coeffRef(row, col));
  972|       |  }
  973|       |
  974|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index index) {
  975|       |    return m_d.func()(m_d.argImpl.coeffRef(index));
  976|       |  }
  977|       |
  978|       | protected:
  979|       |  // this helper permits to completely eliminate the functor if it is empty
  980|       |  struct Data {
  981|       |    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Data(const XprType& xpr)
  982|       |        : op(xpr.functor()), argImpl(xpr.nestedExpression()) {}
  983|       |    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const UnaryOp& func() const { return op; }
  984|       |    UnaryOp op;
  985|       |    evaluator<ArgType> argImpl;
  986|       |  };
  987|       |
  988|       |  Data m_d;
  989|       |};
  990|       |
  991|       |// -------------------- Map --------------------
  992|       |
  993|       |// FIXME perhaps the PlainObjectType could be provided by Derived::PlainObject ?
  994|       |// but that might complicate template specialization
  995|       |template <typename Derived, typename PlainObjectType>
  996|       |struct mapbase_evaluator;
  997|       |
  998|       |template <typename Derived, typename PlainObjectType>
  999|       |struct mapbase_evaluator : evaluator_base<Derived> {
 1000|       |  typedef Derived XprType;
 1001|       |  typedef typename XprType::PointerType PointerType;
 1002|       |  typedef typename XprType::Scalar Scalar;
 1003|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
 1004|       |
 1005|       |  enum {
 1006|       |    IsRowMajor = XprType::RowsAtCompileTime,
 1007|       |    ColsAtCompileTime = XprType::ColsAtCompileTime,
 1008|       |    CoeffReadCost = NumTraits<Scalar>::ReadCost
 1009|       |  };
 1010|       |
 1011|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit mapbase_evaluator(const XprType& map)
 1012|       |      : m_data(const_cast<PointerType>(map.data())),
 1013|       |        m_innerStride(map.innerStride()),
 1014|      0|        m_outerStride(map.outerStride()) {
 1015|      0|    EIGEN_STATIC_ASSERT(check_implication((evaluator<Derived>::Flags & PacketAccessBit) != 0,
 1016|      0|                                          internal::inner_stride_at_compile_time<Derived>::ret == 1),
 1017|      0|                        PACKET_ACCESS_REQUIRES_TO_HAVE_INNER_STRIDE_FIXED_TO_1);
 1018|      0|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
 1019|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEC2ERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEEC2ERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEENS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEEC2ERKS9_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEC2ERKS9_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17mapbase_evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEES5_EC2ERKS8_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEES5_EC2ERKS7_
  ------------------
 1020|       |
 1021|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
 1022|       |    return m_data[col * colStride() + row * rowStride()];
 1023|       |  }
 1024|       |
 1025|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
 1026|      0|    return m_data[index * m_innerStride.value()];
 1027|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS3_IS4_Li1ELin1ELi1ELi1ELin1EEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEENS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS3_IS4_Li1ELin1ELi1ELi1ELin1EEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal17mapbase_evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEES5_E5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal17mapbase_evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal17mapbase_evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_E5coeffEl
  ------------------
 1028|       |
 1029|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index row, Index col) {
 1030|       |    return m_data[col * colStride() + row * rowStride()];
 1031|       |  }
 1032|       |
 1033|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index index) { return m_data[index * m_innerStride.value()]; }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17mapbase_evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEES5_E8coeffRefEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17mapbase_evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_E8coeffRefEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17mapbase_evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEE8coeffRefEl
  ------------------
 1034|       |
 1035|       |  template <int LoadMode, typename PacketType>
 1036|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
 1037|       |    PointerType ptr = m_data + row * rowStride() + col * colStride();
 1038|       |    return internal::ploadt<PacketType, LoadMode>(ptr);
 1039|       |  }
 1040|       |
 1041|       |  template <int LoadMode, typename PacketType>
 1042|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
 1043|       |    return internal::ploadt<PacketType, LoadMode>(m_data + index * m_innerStride.value());
 1044|       |  }
 1045|       |
 1046|       |  template <int StoreMode, typename PacketType>
 1047|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index row, Index col, const PacketType& x) {
 1048|       |    PointerType ptr = m_data + row * rowStride() + col * colStride();
 1049|       |    return internal::pstoret<Scalar, PacketType, StoreMode>(ptr, x);
 1050|       |  }
 1051|       |
 1052|       |  template <int StoreMode, typename PacketType>
 1053|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index index, const PacketType& x) {
 1054|       |    internal::pstoret<Scalar, PacketType, StoreMode>(m_data + index * m_innerStride.value(), x);
 1055|       |  }
 1056|       |
 1057|       | protected:
 1058|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rowStride() const EIGEN_NOEXCEPT {
 1059|       |    return XprType::IsRowMajor ? m_outerStride.value() : m_innerStride.value();
 1060|       |  }
 1061|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index colStride() const EIGEN_NOEXCEPT {
 1062|       |    return XprType::IsRowMajor ? m_innerStride.value() : m_outerStride.value();
 1063|       |  }
 1064|       |
 1065|       |  PointerType m_data;
 1066|       |  const internal::variable_if_dynamic<Index, XprType::InnerStrideAtCompileTime> m_innerStride;
 1067|       |  const internal::variable_if_dynamic<Index, XprType::OuterStrideAtCompileTime> m_outerStride;
 1068|       |};
 1069|       |
 1070|       |template <typename PlainObjectType, int MapOptions, typename StrideType>
 1071|       |struct evaluator<Map<PlainObjectType, MapOptions, StrideType>>
 1072|       |    : public mapbase_evaluator<Map<PlainObjectType, MapOptions, StrideType>, PlainObjectType> {
 1073|       |  typedef Map<PlainObjectType, MapOptions, StrideType> XprType;
 1074|       |  typedef typename XprType::Scalar Scalar;
 1075|       |  // TODO: should check for smaller packet types once we can handle multi-sized packet types
 1076|       |  typedef typename packet_traits<Scalar>::type PacketScalar;
 1077|       |
 1078|       |  enum {
 1079|       |    InnerStrideAtCompileTime = StrideType::InnerStrideAtCompileTime == 0
 1080|       |                                   ? int(PlainObjectType::InnerStrideAtCompileTime)
 1081|       |                                   : int(StrideType::InnerStrideAtCompileTime),
 1082|       |    OuterStrideAtCompileTime = StrideType::OuterStrideAtCompileTime == 0
 1083|       |                                   ? int(PlainObjectType::OuterStrideAtCompileTime)
 1084|       |                                   : int(StrideType::OuterStrideAtCompileTime),
 1085|       |    HasNoInnerStride = InnerStrideAtCompileTime == 1,
 1086|       |    HasNoOuterStride = StrideType::OuterStrideAtCompileTime == 0,
 1087|       |    HasNoStride = HasNoInnerStride && HasNoOuterStride,
 1088|       |    IsDynamicSize = PlainObjectType::SizeAtCompileTime == Dynamic,
 1089|       |
 1090|       |    PacketAccessMask = bool(HasNoInnerStride) ? ~int(0) : ~int(PacketAccessBit),
 1091|       |    LinearAccessMask =
 1092|       |        bool(HasNoStride) || bool(PlainObjectType::IsVectorAtCompileTime) ? ~int(0) : ~int(LinearAccessBit),
 1093|       |    Flags = int(evaluator<PlainObjectType>::Flags) & (LinearAccessMask & PacketAccessMask),
 1094|       |
 1095|       |    Alignment = int(MapOptions) & int(AlignedMask)
 1096|       |  };
 1097|       |
 1098|      0|  EIGEN_DEVICE_FUNC explicit evaluator(const XprType& map) : mapbase_evaluator<XprType, PlainObjectType>(map) {}
 1099|       |};
 1100|       |
 1101|       |// -------------------- Ref --------------------
 1102|       |
 1103|       |template <typename PlainObjectType, int RefOptions, typename StrideType>
 1104|       |struct evaluator<Ref<PlainObjectType, RefOptions, StrideType>>
 1105|       |    : public mapbase_evaluator<Ref<PlainObjectType, RefOptions, StrideType>, PlainObjectType> {
 1106|       |  typedef Ref<PlainObjectType, RefOptions, StrideType> XprType;
 1107|       |
 1108|       |  enum {
 1109|       |    Flags = evaluator<Map<PlainObjectType, RefOptions, StrideType>>::Flags,
 1110|       |    Alignment = evaluator<Map<PlainObjectType, RefOptions, StrideType>>::Alignment
 1111|       |  };
 1112|       |
 1113|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& ref)
 1114|       |      : mapbase_evaluator<XprType, PlainObjectType>(ref) {}
 1115|       |};
 1116|       |
 1117|       |// -------------------- Block --------------------
 1118|       |
 1119|       |template <typename ArgType, int BlockRows, int BlockCols, bool InnerPanel,
 1120|       |          bool HasDirectAccess = internal::has_direct_access<ArgType>::ret>
 1121|       |struct block_evaluator;
 1122|       |
 1123|       |template <typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 1124|       |struct evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>>
 1125|       |    : block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel> {
 1126|       |  typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
 1127|       |  typedef typename XprType::Scalar Scalar;
 1128|       |  // TODO: should check for smaller packet types once we can handle multi-sized packet types
 1129|       |  typedef typename packet_traits<Scalar>::type PacketScalar;
 1130|       |
 1131|       |  enum {
 1132|       |    CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
 1133|       |
 1134|       |    RowsAtCompileTime = traits<XprType>::RowsAtCompileTime,
 1135|       |    ColsAtCompileTime = traits<XprType>::ColsAtCompileTime,
 1136|       |    MaxRowsAtCompileTime = traits<XprType>::MaxRowsAtCompileTime,
 1137|       |    MaxColsAtCompileTime = traits<XprType>::MaxColsAtCompileTime,
 1138|       |
 1139|       |    ArgTypeIsRowMajor = (int(evaluator<ArgType>::Flags) & RowMajorBit) != 0,
 1140|       |    IsRowMajor = (MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1)   ? 1
 1141|       |                 : (MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1) ? 0
 1142|       |                                                                            : ArgTypeIsRowMajor,
 1143|       |    HasSameStorageOrderAsArgType = (IsRowMajor == ArgTypeIsRowMajor),
 1144|       |    InnerSize = IsRowMajor ? int(ColsAtCompileTime) : int(RowsAtCompileTime),
 1145|       |    InnerStrideAtCompileTime = HasSameStorageOrderAsArgType ? int(inner_stride_at_compile_time<ArgType>::ret)
 1146|       |                                                            : int(outer_stride_at_compile_time<ArgType>::ret),
 1147|       |    OuterStrideAtCompileTime = HasSameStorageOrderAsArgType ? int(outer_stride_at_compile_time<ArgType>::ret)
 1148|       |                                                            : int(inner_stride_at_compile_time<ArgType>::ret),
 1149|       |    MaskPacketAccessBit = (InnerStrideAtCompileTime == 1 || HasSameStorageOrderAsArgType) ? PacketAccessBit : 0,
 1150|       |
 1151|       |    FlagsLinearAccessBit = (RowsAtCompileTime == 1 || ColsAtCompileTime == 1 ||
 1152|       |                            (InnerPanel && (evaluator<ArgType>::Flags & LinearAccessBit)))
 1153|       |                               ? LinearAccessBit
 1154|       |                               : 0,
 1155|       |    FlagsRowMajorBit = XprType::Flags & RowMajorBit,
 1156|       |    Flags0 = evaluator<ArgType>::Flags & ((HereditaryBits & ~RowMajorBit) | DirectAccessBit | MaskPacketAccessBit),
 1157|       |    Flags = Flags0 | FlagsLinearAccessBit | FlagsRowMajorBit,
 1158|       |
 1159|       |    PacketAlignment = unpacket_traits<PacketScalar>::alignment,
 1160|       |    Alignment0 = (InnerPanel && (OuterStrideAtCompileTime != Dynamic) && (OuterStrideAtCompileTime != 0) &&
 1161|       |                  (((OuterStrideAtCompileTime * int(sizeof(Scalar))) % int(PacketAlignment)) == 0))
 1162|       |                     ? int(PacketAlignment)
 1163|       |                     : 0,
 1164|       |    Alignment = plain_enum_min(evaluator<ArgType>::Alignment, Alignment0)
 1165|       |  };
 1166|       |  typedef block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel> block_evaluator_type;
 1167|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& block) : block_evaluator_type(block) {
 1168|      0|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
 1169|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEEEC2ERKS9_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEC2ERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEC2ERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEEC2ERKS9_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEC2ERKS9_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEC2ERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_5BlockIKNS2_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEC2ERKSB_
  ------------------
 1170|       |};
 1171|       |
 1172|       |// no direct-access => dispatch to a unary evaluator
 1173|       |template <typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 1174|       |struct block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel, /*HasDirectAccess*/ false>
 1175|       |    : unary_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>> {
 1176|       |  typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
 1177|       |
 1178|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit block_evaluator(const XprType& block)
 1179|      0|      : unary_evaluator<XprType>(block) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15block_evaluatorIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0ELb0EEC2ERKNS_5BlockIS7_Li1ELin1ELb0EEE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15block_evaluatorIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1ELb0EEC2ERKNS2_ISA_Li1ELin1ELb1EEE
  ------------------
 1180|       |};
 1181|       |
 1182|       |template <typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 1183|       |struct unary_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>, IndexBased>
 1184|       |    : evaluator_base<Block<ArgType, BlockRows, BlockCols, InnerPanel>> {
 1185|       |  typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
 1186|       |
 1187|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit unary_evaluator(const XprType& block)
 1188|       |      : m_argImpl(block.nestedExpression()),
 1189|       |        m_startRow(block.startRow()),
 1190|       |        m_startCol(block.startCol()),
 1191|       |        m_linear_offset(ForwardLinearAccess
 1192|       |                            ? (ArgType::IsRowMajor
 1193|       |                                   ? block.startRow() * block.nestedExpression().cols() + block.startCol()
 1194|       |                                   : block.startCol() * block.nestedExpression().rows() + block.startRow())
 1195|      0|                            : 0) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15unary_evaluatorINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEENS0_10IndexBasedES5_EC2ERKS9_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15unary_evaluatorINS_5BlockIKNS2_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS0_10IndexBasedES5_EC2ERKSB_
  ------------------
 1196|       |
 1197|       |  typedef typename XprType::Scalar Scalar;
 1198|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
 1199|       |
 1200|       |  enum {
 1201|       |    RowsAtCompileTime = XprType::RowsAtCompileTime,
 1202|       |    ForwardLinearAccess = (InnerPanel || int(XprType::IsRowMajor) == int(ArgType::IsRowMajor)) &&
 1203|       |                          bool(evaluator<ArgType>::Flags & LinearAccessBit)
 1204|       |  };
 1205|       |
 1206|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
 1207|      0|    return m_argImpl.coeff(m_startRow.value() + row, m_startCol.value() + col);
 1208|      0|  }
 1209|       |
 1210|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
 1211|      0|    return linear_coeff_impl(index, bool_constant<ForwardLinearAccess>());
 1212|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15unary_evaluatorINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEENS0_10IndexBasedES5_E5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal15unary_evaluatorINS_5BlockIKNS2_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS0_10IndexBasedES5_E5coeffEl
  ------------------
 1213|       |
 1214|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index row, Index col) {
 1215|       |    return m_argImpl.coeffRef(m_startRow.value() + row, m_startCol.value() + col);
 1216|       |  }
 1217|       |
 1218|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index index) {
 1219|       |    return linear_coeffRef_impl(index, bool_constant<ForwardLinearAccess>());
 1220|       |  }
 1221|       |
 1222|       |  template <int LoadMode, typename PacketType>
 1223|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
 1224|       |    return m_argImpl.template packet<LoadMode, PacketType>(m_startRow.value() + row, m_startCol.value() + col);
 1225|       |  }
 1226|       |
 1227|       |  template <int LoadMode, typename PacketType>
 1228|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
 1229|       |    if (ForwardLinearAccess)
 1230|       |      return m_argImpl.template packet<LoadMode, PacketType>(m_linear_offset.value() + index);
 1231|       |    else
 1232|       |      return packet<LoadMode, PacketType>(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
 1233|       |  }
 1234|       |
 1235|       |  template <int StoreMode, typename PacketType>
 1236|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index row, Index col, const PacketType& x) {
 1237|       |    return m_argImpl.template writePacket<StoreMode, PacketType>(m_startRow.value() + row, m_startCol.value() + col, x);
 1238|       |  }
 1239|       |
 1240|       |  template <int StoreMode, typename PacketType>
 1241|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index index, const PacketType& x) {
 1242|       |    if (ForwardLinearAccess)
 1243|       |      return m_argImpl.template writePacket<StoreMode, PacketType>(m_linear_offset.value() + index, x);
 1244|       |    else
 1245|       |      return writePacket<StoreMode, PacketType>(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0,
 1246|       |                                                x);
 1247|       |  }
 1248|       |
 1249|       | protected:
 1250|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType
 1251|      0|  linear_coeff_impl(Index index, internal::true_type /* ForwardLinearAccess */) const {
 1252|      0|    return m_argImpl.coeff(m_linear_offset.value() + index);
 1253|      0|  }
 1254|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType
 1255|      0|  linear_coeff_impl(Index index, internal::false_type /* not ForwardLinearAccess */) const {
 1256|      0|    return coeff(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
 1257|      0|  }
 1258|       |
 1259|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& linear_coeffRef_impl(Index index,
 1260|       |                                                                     internal::true_type /* ForwardLinearAccess */) {
 1261|       |    return m_argImpl.coeffRef(m_linear_offset.value() + index);
 1262|       |  }
 1263|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& linear_coeffRef_impl(
 1264|       |      Index index, internal::false_type /* not ForwardLinearAccess */) {
 1265|       |    return coeffRef(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
 1266|       |  }
 1267|       |
 1268|       |  evaluator<ArgType> m_argImpl;
 1269|       |  const variable_if_dynamic<Index, (ArgType::RowsAtCompileTime == 1 && BlockRows == 1) ? 0 : Dynamic> m_startRow;
 1270|       |  const variable_if_dynamic<Index, (ArgType::ColsAtCompileTime == 1 && BlockCols == 1) ? 0 : Dynamic> m_startCol;
 1271|       |  const variable_if_dynamic<Index, ForwardLinearAccess ? Dynamic : 0> m_linear_offset;
 1272|       |};
 1273|       |
 1274|       |// TODO: This evaluator does not actually use the child evaluator;
 1275|       |// all action is via the data() as returned by the Block expression.
 1276|       |
 1277|       |template <typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 1278|       |struct block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel, /* HasDirectAccess */ true>
 1279|       |    : mapbase_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>,
 1280|       |                        typename Block<ArgType, BlockRows, BlockCols, InnerPanel>::PlainObject> {
 1281|       |  typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
 1282|       |  typedef typename XprType::Scalar Scalar;
 1283|       |
 1284|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit block_evaluator(const XprType& block)
 1285|      0|      : mapbase_evaluator<XprType, typename XprType::PlainObject>(block) {
 1286|      0|    eigen_internal_assert((internal::is_constant_evaluated() ||
 1287|      0|                           (std::uintptr_t(block.data()) % plain_enum_max(1, evaluator<XprType>::Alignment)) == 0) &&
 1288|      0|                          "data is not aligned");
 1289|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15block_evaluatorIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0ELb1EEC2ERKNS_5BlockIS5_Li1ELin1ELb0EEE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15block_evaluatorIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EEC2ERKNS_5BlockIS5_Lin1ELi1ELb1EEE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15block_evaluatorIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1ELb1EEC2ERKNS2_IS8_Lin1ELi1ELb1EEE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15block_evaluatorIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1ELb1EEC2ERKNS2_IS8_Li1ELin1ELb1EEE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15block_evaluatorIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1ELb1EEC2ERKNS_5BlockIS5_Lin1ELi1ELb1EEE
  ------------------
 1290|       |};
 1291|       |
 1292|       |// -------------------- Select --------------------
 1293|       |// NOTE shall we introduce a ternary_evaluator?
 1294|       |
 1295|       |// TODO enable vectorization for Select
 1296|       |template <typename ConditionMatrixType, typename ThenMatrixType, typename ElseMatrixType>
 1297|       |struct evaluator<Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType>>
 1298|       |    : evaluator_base<Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType>> {
 1299|       |  typedef Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType> XprType;
 1300|       |  enum {
 1301|       |    CoeffReadCost = evaluator<ConditionMatrixType>::CoeffReadCost +
 1302|       |                    plain_enum_max(evaluator<ThenMatrixType>::CoeffReadCost, evaluator<ElseMatrixType>::CoeffReadCost),
 1303|       |
 1304|       |    Flags = (unsigned int)evaluator<ThenMatrixType>::Flags & evaluator<ElseMatrixType>::Flags & HereditaryBits,
 1305|       |
 1306|       |    Alignment = plain_enum_min(evaluator<ThenMatrixType>::Alignment, evaluator<ElseMatrixType>::Alignment)
 1307|       |  };
 1308|       |
 1309|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& select)
 1310|       |      : m_conditionImpl(select.conditionMatrix()), m_thenImpl(select.thenMatrix()), m_elseImpl(select.elseMatrix()) {
 1311|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
 1312|       |  }
 1313|       |
 1314|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
 1315|       |
 1316|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
 1317|       |    if (m_conditionImpl.coeff(row, col))
 1318|       |      return m_thenImpl.coeff(row, col);
 1319|       |    else
 1320|       |      return m_elseImpl.coeff(row, col);
 1321|       |  }
 1322|       |
 1323|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
 1324|       |    if (m_conditionImpl.coeff(index))
 1325|       |      return m_thenImpl.coeff(index);
 1326|       |    else
 1327|       |      return m_elseImpl.coeff(index);
 1328|       |  }
 1329|       |
 1330|       | protected:
 1331|       |  evaluator<ConditionMatrixType> m_conditionImpl;
 1332|       |  evaluator<ThenMatrixType> m_thenImpl;
 1333|       |  evaluator<ElseMatrixType> m_elseImpl;
 1334|       |};
 1335|       |
 1336|       |// -------------------- Replicate --------------------
 1337|       |
 1338|       |template <typename ArgType, int RowFactor, int ColFactor>
 1339|       |struct unary_evaluator<Replicate<ArgType, RowFactor, ColFactor>>
 1340|       |    : evaluator_base<Replicate<ArgType, RowFactor, ColFactor>> {
 1341|       |  typedef Replicate<ArgType, RowFactor, ColFactor> XprType;
 1342|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
 1343|       |  enum { Factor = (RowFactor == Dynamic || ColFactor == Dynamic) ? Dynamic : RowFactor * ColFactor };
 1344|       |  typedef typename internal::nested_eval<ArgType, Factor>::type ArgTypeNested;
 1345|       |  typedef internal::remove_all_t<ArgTypeNested> ArgTypeNestedCleaned;
 1346|       |
 1347|       |  enum {
 1348|       |    CoeffReadCost = evaluator<ArgTypeNestedCleaned>::CoeffReadCost,
 1349|       |    LinearAccessMask = XprType::IsVectorAtCompileTime ? LinearAccessBit : 0,
 1350|       |    Flags = (evaluator<ArgTypeNestedCleaned>::Flags & (HereditaryBits | LinearAccessMask) & ~RowMajorBit) |
 1351|       |            (traits<XprType>::Flags & RowMajorBit),
 1352|       |
 1353|       |    Alignment = evaluator<ArgTypeNestedCleaned>::Alignment
 1354|       |  };
 1355|       |
 1356|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit unary_evaluator(const XprType& replicate)
 1357|       |      : m_arg(replicate.nestedExpression()),
 1358|       |        m_argImpl(m_arg),
 1359|       |        m_rows(replicate.nestedExpression().rows()),
 1360|       |        m_cols(replicate.nestedExpression().cols()) {}
 1361|       |
 1362|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
 1363|       |    // try to avoid using modulo; this is a pure optimization strategy
 1364|       |    const Index actual_row = internal::traits<XprType>::RowsAtCompileTime == 1 ? 0
 1365|       |                             : RowFactor == 1                                  ? row
 1366|       |                                                                               : row % m_rows.value();
 1367|       |    const Index actual_col = internal::traits<XprType>::ColsAtCompileTime == 1 ? 0
 1368|       |                             : ColFactor == 1                                  ? col
 1369|       |                                                                               : col % m_cols.value();
 1370|       |
 1371|       |    return m_argImpl.coeff(actual_row, actual_col);
 1372|       |  }
 1373|       |
 1374|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
 1375|       |    // try to avoid using modulo; this is a pure optimization strategy
 1376|       |    const Index actual_index = internal::traits<XprType>::RowsAtCompileTime == 1
 1377|       |                                   ? (ColFactor == 1 ? index : index % m_cols.value())
 1378|       |                                   : (RowFactor == 1 ? index : index % m_rows.value());
 1379|       |
 1380|       |    return m_argImpl.coeff(actual_index);
 1381|       |  }
 1382|       |
 1383|       |  template <int LoadMode, typename PacketType>
 1384|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
 1385|       |    const Index actual_row = internal::traits<XprType>::RowsAtCompileTime == 1 ? 0
 1386|       |                             : RowFactor == 1                                  ? row
 1387|       |                                                                               : row % m_rows.value();
 1388|       |    const Index actual_col = internal::traits<XprType>::ColsAtCompileTime == 1 ? 0
 1389|       |                             : ColFactor == 1                                  ? col
 1390|       |                                                                               : col % m_cols.value();
 1391|       |
 1392|       |    return m_argImpl.template packet<LoadMode, PacketType>(actual_row, actual_col);
 1393|       |  }
 1394|       |
 1395|       |  template <int LoadMode, typename PacketType>
 1396|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
 1397|       |    const Index actual_index = internal::traits<XprType>::RowsAtCompileTime == 1
 1398|       |                                   ? (ColFactor == 1 ? index : index % m_cols.value())
 1399|       |                                   : (RowFactor == 1 ? index : index % m_rows.value());
 1400|       |
 1401|       |    return m_argImpl.template packet<LoadMode, PacketType>(actual_index);
 1402|       |  }
 1403|       |
 1404|       | protected:
 1405|       |  const ArgTypeNested m_arg;
 1406|       |  evaluator<ArgTypeNestedCleaned> m_argImpl;
 1407|       |  const variable_if_dynamic<Index, ArgType::RowsAtCompileTime> m_rows;
 1408|       |  const variable_if_dynamic<Index, ArgType::ColsAtCompileTime> m_cols;
 1409|       |};
 1410|       |
 1411|       |// -------------------- MatrixWrapper and ArrayWrapper --------------------
 1412|       |//
 1413|       |// evaluator_wrapper_base<T> is a common base class for the
 1414|       |// MatrixWrapper and ArrayWrapper evaluators.
 1415|       |
 1416|       |template <typename XprType>
 1417|       |struct evaluator_wrapper_base : evaluator_base<XprType> {
 1418|       |  typedef remove_all_t<typename XprType::NestedExpressionType> ArgType;
 1419|       |  enum {
 1420|       |    CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
 1421|       |    Flags = evaluator<ArgType>::Flags,
 1422|       |    Alignment = evaluator<ArgType>::Alignment
 1423|       |  };
 1424|       |
 1425|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator_wrapper_base(const ArgType& arg) : m_argImpl(arg) {}
 1426|       |
 1427|       |  typedef typename ArgType::Scalar Scalar;
 1428|       |  typedef typename ArgType::CoeffReturnType CoeffReturnType;
 1429|       |
 1430|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
 1431|       |    return m_argImpl.coeff(row, col);
 1432|       |  }
 1433|       |
 1434|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const { return m_argImpl.coeff(index); }
 1435|       |
 1436|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index row, Index col) { return m_argImpl.coeffRef(row, col); }
 1437|       |
 1438|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index index) { return m_argImpl.coeffRef(index); }
 1439|       |
 1440|       |  template <int LoadMode, typename PacketType>
 1441|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
 1442|       |    return m_argImpl.template packet<LoadMode, PacketType>(row, col);
 1443|       |  }
 1444|       |
 1445|       |  template <int LoadMode, typename PacketType>
 1446|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
 1447|       |    return m_argImpl.template packet<LoadMode, PacketType>(index);
 1448|       |  }
 1449|       |
 1450|       |  template <int StoreMode, typename PacketType>
 1451|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index row, Index col, const PacketType& x) {
 1452|       |    m_argImpl.template writePacket<StoreMode>(row, col, x);
 1453|       |  }
 1454|       |
 1455|       |  template <int StoreMode, typename PacketType>
 1456|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index index, const PacketType& x) {
 1457|       |    m_argImpl.template writePacket<StoreMode>(index, x);
 1458|       |  }
 1459|       |
 1460|       | protected:
 1461|       |  evaluator<ArgType> m_argImpl;
 1462|       |};
 1463|       |
 1464|       |template <typename TArgType>
 1465|       |struct unary_evaluator<MatrixWrapper<TArgType>> : evaluator_wrapper_base<MatrixWrapper<TArgType>> {
 1466|       |  typedef MatrixWrapper<TArgType> XprType;
 1467|       |
 1468|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit unary_evaluator(const XprType& wrapper)
 1469|       |      : evaluator_wrapper_base<MatrixWrapper<TArgType>>(wrapper.nestedExpression()) {}
 1470|       |};
 1471|       |
 1472|       |template <typename TArgType>
 1473|       |struct unary_evaluator<ArrayWrapper<TArgType>> : evaluator_wrapper_base<ArrayWrapper<TArgType>> {
 1474|       |  typedef ArrayWrapper<TArgType> XprType;
 1475|       |
 1476|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit unary_evaluator(const XprType& wrapper)
 1477|       |      : evaluator_wrapper_base<ArrayWrapper<TArgType>>(wrapper.nestedExpression()) {}
 1478|       |};
 1479|       |
 1480|       |// -------------------- Reverse --------------------
 1481|       |
 1482|       |// defined in Reverse.h:
 1483|       |template <typename PacketType, bool ReversePacket>
 1484|       |struct reverse_packet_cond;
 1485|       |
 1486|       |template <typename ArgType, int Direction>
 1487|       |struct unary_evaluator<Reverse<ArgType, Direction>> : evaluator_base<Reverse<ArgType, Direction>> {
 1488|       |  typedef Reverse<ArgType, Direction> XprType;
 1489|       |  typedef typename XprType::Scalar Scalar;
 1490|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
 1491|       |
 1492|       |  enum {
 1493|       |    IsRowMajor = XprType::IsRowMajor,
 1494|       |    IsColMajor = !IsRowMajor,
 1495|       |    ReverseRow = (Direction == Vertical) || (Direction == BothDirections),
 1496|       |    ReverseCol = (Direction == Horizontal) || (Direction == BothDirections),
 1497|       |    ReversePacket = (Direction == BothDirections) || ((Direction == Vertical) && IsColMajor) ||
 1498|       |                    ((Direction == Horizontal) && IsRowMajor),
 1499|       |
 1500|       |    CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
 1501|       |
 1502|       |    // let's enable LinearAccess only with vectorization because of the product overhead
 1503|       |    // FIXME enable DirectAccess with negative strides?
 1504|       |    Flags0 = evaluator<ArgType>::Flags,
 1505|       |    LinearAccess =
 1506|       |        ((Direction == BothDirections) && (int(Flags0) & PacketAccessBit)) ||
 1507|       |                ((ReverseRow && XprType::ColsAtCompileTime == 1) || (ReverseCol && XprType::RowsAtCompileTime == 1))
 1508|       |            ? LinearAccessBit
 1509|       |            : 0,
 1510|       |
 1511|       |    Flags = int(Flags0) & (HereditaryBits | PacketAccessBit | LinearAccess),
 1512|       |
 1513|       |    Alignment = 0  // FIXME in some rare cases, Alignment could be preserved, like a Vector4f.
 1514|       |  };
 1515|       |
 1516|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit unary_evaluator(const XprType& reverse)
 1517|       |      : m_argImpl(reverse.nestedExpression()),
 1518|       |        m_rows(ReverseRow ? reverse.nestedExpression().rows() : 1),
 1519|       |        m_cols(ReverseCol ? reverse.nestedExpression().cols() : 1) {}
 1520|       |
 1521|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index col) const {
 1522|       |    return m_argImpl.coeff(ReverseRow ? m_rows.value() - row - 1 : row, ReverseCol ? m_cols.value() - col - 1 : col);
 1523|       |  }
 1524|       |
 1525|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
 1526|       |    return m_argImpl.coeff(m_rows.value() * m_cols.value() - index - 1);
 1527|       |  }
 1528|       |
 1529|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index row, Index col) {
 1530|       |    return m_argImpl.coeffRef(ReverseRow ? m_rows.value() - row - 1 : row, ReverseCol ? m_cols.value() - col - 1 : col);
 1531|       |  }
 1532|       |
 1533|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index index) {
 1534|       |    return m_argImpl.coeffRef(m_rows.value() * m_cols.value() - index - 1);
 1535|       |  }
 1536|       |
 1537|       |  template <int LoadMode, typename PacketType>
 1538|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
 1539|       |    enum {
 1540|       |      PacketSize = unpacket_traits<PacketType>::size,
 1541|       |      OffsetRow = ReverseRow && IsColMajor ? PacketSize : 1,
 1542|       |      OffsetCol = ReverseCol && IsRowMajor ? PacketSize : 1
 1543|       |    };
 1544|       |    typedef internal::reverse_packet_cond<PacketType, ReversePacket> reverse_packet;
 1545|       |    return reverse_packet::run(m_argImpl.template packet<LoadMode, PacketType>(
 1546|       |        ReverseRow ? m_rows.value() - row - OffsetRow : row, ReverseCol ? m_cols.value() - col - OffsetCol : col));
 1547|       |  }
 1548|       |
 1549|       |  template <int LoadMode, typename PacketType>
 1550|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
 1551|       |    enum { PacketSize = unpacket_traits<PacketType>::size };
 1552|       |    return preverse(
 1553|       |        m_argImpl.template packet<LoadMode, PacketType>(m_rows.value() * m_cols.value() - index - PacketSize));
 1554|       |  }
 1555|       |
 1556|       |  template <int LoadMode, typename PacketType>
 1557|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index row, Index col, const PacketType& x) {
 1558|       |    // FIXME we could factorize some code with packet(i,j)
 1559|       |    enum {
 1560|       |      PacketSize = unpacket_traits<PacketType>::size,
 1561|       |      OffsetRow = ReverseRow && IsColMajor ? PacketSize : 1,
 1562|       |      OffsetCol = ReverseCol && IsRowMajor ? PacketSize : 1
 1563|       |    };
 1564|       |    typedef internal::reverse_packet_cond<PacketType, ReversePacket> reverse_packet;
 1565|       |    m_argImpl.template writePacket<LoadMode>(ReverseRow ? m_rows.value() - row - OffsetRow : row,
 1566|       |                                             ReverseCol ? m_cols.value() - col - OffsetCol : col,
 1567|       |                                             reverse_packet::run(x));
 1568|       |  }
 1569|       |
 1570|       |  template <int LoadMode, typename PacketType>
 1571|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void writePacket(Index index, const PacketType& x) {
 1572|       |    enum { PacketSize = unpacket_traits<PacketType>::size };
 1573|       |    m_argImpl.template writePacket<LoadMode>(m_rows.value() * m_cols.value() - index - PacketSize, preverse(x));
 1574|       |  }
 1575|       |
 1576|       | protected:
 1577|       |  evaluator<ArgType> m_argImpl;
 1578|       |
 1579|       |  // If we do not reverse rows, then we do not need to know the number of rows; same for columns
 1580|       |  // Nonetheless, in this case it is important to set to 1 such that the coeff(index) method works fine for vectors.
 1581|       |  const variable_if_dynamic<Index, ReverseRow ? ArgType::RowsAtCompileTime : 1> m_rows;
 1582|       |  const variable_if_dynamic<Index, ReverseCol ? ArgType::ColsAtCompileTime : 1> m_cols;
 1583|       |};
 1584|       |
 1585|       |// -------------------- Diagonal --------------------
 1586|       |
 1587|       |template <typename ArgType, int DiagIndex>
 1588|       |struct evaluator<Diagonal<ArgType, DiagIndex>> : evaluator_base<Diagonal<ArgType, DiagIndex>> {
 1589|       |  typedef Diagonal<ArgType, DiagIndex> XprType;
 1590|       |
 1591|       |  enum {
 1592|       |    CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
 1593|       |
 1594|       |    Flags =
 1595|       |        (unsigned int)(evaluator<ArgType>::Flags & (HereditaryBits | DirectAccessBit) & ~RowMajorBit) | LinearAccessBit,
 1596|       |
 1597|       |    Alignment = 0
 1598|       |  };
 1599|       |
 1600|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& diagonal)
 1601|       |      : m_argImpl(diagonal.nestedExpression()), m_index(diagonal.index()) {}
 1602|       |
 1603|       |  typedef typename XprType::Scalar Scalar;
 1604|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
 1605|       |
 1606|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index row, Index) const {
 1607|       |    return m_argImpl.coeff(row + rowOffset(), row + colOffset());
 1608|       |  }
 1609|       |
 1610|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeff(Index index) const {
 1611|       |    return m_argImpl.coeff(index + rowOffset(), index + colOffset());
 1612|       |  }
 1613|       |
 1614|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index row, Index) {
 1615|       |    return m_argImpl.coeffRef(row + rowOffset(), row + colOffset());
 1616|       |  }
 1617|       |
 1618|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRef(Index index) {
 1619|       |    return m_argImpl.coeffRef(index + rowOffset(), index + colOffset());
 1620|       |  }
 1621|       |
 1622|       | protected:
 1623|       |  evaluator<ArgType> m_argImpl;
 1624|       |  const internal::variable_if_dynamicindex<Index, XprType::DiagIndex> m_index;
 1625|       |
 1626|       | private:
 1627|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rowOffset() const {
 1628|       |    return m_index.value() > 0 ? 0 : -m_index.value();
 1629|       |  }
 1630|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index colOffset() const {
 1631|       |    return m_index.value() > 0 ? m_index.value() : 0;
 1632|       |  }
 1633|       |};
 1634|       |
 1635|       |//----------------------------------------------------------------------
 1636|       |// deprecated code
 1637|       |//----------------------------------------------------------------------
 1638|       |
 1639|       |// -------------------- EvalToTemp --------------------
 1640|       |
 1641|       |// expression class for evaluating nested expression to a temporary
 1642|       |
 1643|       |template <typename ArgType>
 1644|       |class EvalToTemp;
 1645|       |
 1646|       |template <typename ArgType>
 1647|       |struct traits<EvalToTemp<ArgType>> : public traits<ArgType> {};
 1648|       |
 1649|       |template <typename ArgType>
 1650|       |class EvalToTemp : public dense_xpr_base<EvalToTemp<ArgType>>::type {
 1651|       | public:
 1652|       |  typedef typename dense_xpr_base<EvalToTemp>::type Base;
 1653|       |  EIGEN_GENERIC_PUBLIC_INTERFACE(EvalToTemp)
 1654|       |
 1655|       |  explicit EvalToTemp(const ArgType& arg) : m_arg(arg) {}
 1656|       |
 1657|       |  const ArgType& arg() const { return m_arg; }
 1658|       |
 1659|       |  EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_arg.rows(); }
 1660|       |
 1661|       |  EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_arg.cols(); }
 1662|       |
 1663|       | private:
 1664|       |  const ArgType& m_arg;
 1665|       |};
 1666|       |
 1667|       |template <typename ArgType>
 1668|       |struct evaluator<EvalToTemp<ArgType>> : public evaluator<typename ArgType::PlainObject> {
 1669|       |  typedef EvalToTemp<ArgType> XprType;
 1670|       |  typedef typename ArgType::PlainObject PlainObject;
 1671|       |  typedef evaluator<PlainObject> Base;
 1672|       |
 1673|       |  EIGEN_DEVICE_FUNC explicit evaluator(const XprType& xpr) : m_result(xpr.arg()) {
 1674|       |    internal::construct_at<Base>(this, m_result);
 1675|       |  }
 1676|       |
 1677|       |  // This constructor is used when nesting an EvalTo evaluator in another evaluator
 1678|       |  EIGEN_DEVICE_FUNC evaluator(const ArgType& arg) : m_result(arg) { internal::construct_at<Base>(this, m_result); }
 1679|       |
 1680|       | protected:
 1681|       |  PlainObject m_result;
 1682|       |};
 1683|       |
 1684|       |}  // namespace internal
 1685|       |
 1686|       |}  // end namespace Eigen
 1687|       |
 1688|       |#endif  // EIGEN_COREEVALUATORS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/CwiseBinaryOp.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2014 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_CWISE_BINARY_OP_H
   12|       |#define EIGEN_CWISE_BINARY_OP_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |template <typename BinaryOp, typename Lhs, typename Rhs>
   21|       |struct traits<CwiseBinaryOp<BinaryOp, Lhs, Rhs>> {
   22|       |  // we must not inherit from traits<Lhs> since it has
   23|       |  // the potential to cause problems with MSVC
   24|       |  typedef remove_all_t<Lhs> Ancestor;
   25|       |  typedef typename traits<Ancestor>::XprKind XprKind;
   26|       |  enum {
   27|       |    RowsAtCompileTime = traits<Ancestor>::RowsAtCompileTime,
   28|       |    ColsAtCompileTime = traits<Ancestor>::ColsAtCompileTime,
   29|       |    MaxRowsAtCompileTime = traits<Ancestor>::MaxRowsAtCompileTime,
   30|       |    MaxColsAtCompileTime = traits<Ancestor>::MaxColsAtCompileTime
   31|       |  };
   32|       |
   33|       |  // even though we require Lhs and Rhs to have the same scalar type (see CwiseBinaryOp constructor),
   34|       |  // we still want to handle the case when the result type is different.
   35|       |  typedef typename result_of<BinaryOp(const typename Lhs::Scalar&, const typename Rhs::Scalar&)>::type Scalar;
   36|       |  typedef typename cwise_promote_storage_type<typename traits<Lhs>::StorageKind, typename traits<Rhs>::StorageKind,
   37|       |                                              BinaryOp>::ret StorageKind;
   38|       |  typedef typename promote_index_type<typename traits<Lhs>::StorageIndex, typename traits<Rhs>::StorageIndex>::type
   39|       |      StorageIndex;
   40|       |  typedef typename Lhs::Nested LhsNested;
   41|       |  typedef typename Rhs::Nested RhsNested;
   42|       |  typedef std::remove_reference_t<LhsNested> LhsNested_;
   43|       |  typedef std::remove_reference_t<RhsNested> RhsNested_;
   44|       |  enum {
   45|       |    Flags = cwise_promote_storage_order<typename traits<Lhs>::StorageKind, typename traits<Rhs>::StorageKind,
   46|       |                                        LhsNested_::Flags & RowMajorBit, RhsNested_::Flags & RowMajorBit>::value
   47|       |  };
   48|       |};
   49|       |}  // end namespace internal
   50|       |
   51|       |template <typename BinaryOp, typename Lhs, typename Rhs, typename StorageKind>
   52|       |class CwiseBinaryOpImpl;
   53|       |
   54|       |/** \class CwiseBinaryOp
   55|       | * \ingroup Core_Module
   56|       | *
   57|       | * \brief Generic expression where a coefficient-wise binary operator is applied to two expressions
   58|       | *
   59|       | * \tparam BinaryOp template functor implementing the operator
   60|       | * \tparam LhsType the type of the left-hand side
   61|       | * \tparam RhsType the type of the right-hand side
   62|       | *
   63|       | * This class represents an expression  where a coefficient-wise binary operator is applied to two expressions.
   64|       | * It is the return type of binary operators, by which we mean only those binary operators where
   65|       | * both the left-hand side and the right-hand side are Eigen expressions.
   66|       | * For example, the return type of matrix1+matrix2 is a CwiseBinaryOp.
   67|       | *
   68|       | * Most of the time, this is the only way that it is used, so you typically don't have to name
   69|       | * CwiseBinaryOp types explicitly.
   70|       | *
   71|       | * \sa MatrixBase::binaryExpr(const MatrixBase<OtherDerived> &,const CustomBinaryOp &) const, class CwiseUnaryOp, class
   72|       | * CwiseNullaryOp
   73|       | */
   74|       |template <typename BinaryOp, typename LhsType, typename RhsType>
   75|       |class CwiseBinaryOp : public CwiseBinaryOpImpl<BinaryOp, LhsType, RhsType,
   76|       |                                               typename internal::cwise_promote_storage_type<
   77|       |                                                   typename internal::traits<LhsType>::StorageKind,
   78|       |                                                   typename internal::traits<RhsType>::StorageKind, BinaryOp>::ret>,
   79|       |                      internal::no_assignment_operator {
   80|       | public:
   81|       |  typedef internal::remove_all_t<BinaryOp> Functor;
   82|       |  typedef internal::remove_all_t<LhsType> Lhs;
   83|       |  typedef internal::remove_all_t<RhsType> Rhs;
   84|       |
   85|       |  typedef typename CwiseBinaryOpImpl<
   86|       |      BinaryOp, LhsType, RhsType,
   87|       |      typename internal::cwise_promote_storage_type<typename internal::traits<LhsType>::StorageKind,
   88|       |                                                    typename internal::traits<Rhs>::StorageKind, BinaryOp>::ret>::Base
   89|       |      Base;
   90|       |  EIGEN_GENERIC_PUBLIC_INTERFACE(CwiseBinaryOp)
   91|       |
   92|       |  EIGEN_CHECK_BINARY_COMPATIBILIY(BinaryOp, typename Lhs::Scalar, typename Rhs::Scalar)
   93|       |  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(Lhs, Rhs)
   94|       |
   95|       |  typedef typename internal::ref_selector<LhsType>::type LhsNested;
   96|       |  typedef typename internal::ref_selector<RhsType>::type RhsNested;
   97|       |  typedef std::remove_reference_t<LhsNested> LhsNested_;
   98|       |  typedef std::remove_reference_t<RhsNested> RhsNested_;
   99|       |
  100|       |#if EIGEN_COMP_MSVC
  101|       |  // Required for Visual Studio or the Copy constructor will probably not get inlined!
  102|       |  EIGEN_STRONG_INLINE CwiseBinaryOp(const CwiseBinaryOp<BinaryOp, LhsType, RhsType>&) = default;
  103|       |#endif
  104|       |
  105|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CwiseBinaryOp(const Lhs& aLhs, const Rhs& aRhs,
  106|       |                                                      const BinaryOp& func = BinaryOp())
  107|      2|      : m_lhs(aLhs), m_rhs(aRhs), m_functor(func) {
  108|      2|    eigen_assert(aLhs.rows() == aRhs.rows() && aLhs.cols() == aRhs.cols());
  109|      2|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS6_IS9_Lin1ELi1ELb1EEEEC2ERSD_RSF_RKS4_
  ------------------
  | _ZN5Eigen13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEES7_EC2ERS7_S9_RKS4_:
  |  107|      2|      : m_lhs(aLhs), m_rhs(aRhs), m_functor(func) {
  |  108|      2|    eigen_assert(aLhs.rows() == aRhs.rows() && aLhs.cols() == aRhs.cols());
  |  109|      2|  }
  ------------------
  110|       |
  111|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT {
  112|       |    // return the fixed size type if available to enable compile time optimizations
  113|      3|    return internal::traits<internal::remove_all_t<LhsNested>>::RowsAtCompileTime == Dynamic ? m_rhs.rows()
  114|      3|                                                                                             : m_lhs.rows();
  115|      3|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS6_IS9_Lin1ELi1ELb1EEEE4rowsEv
  ------------------
  | _ZNK5Eigen13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEES7_E4rowsEv:
  |  111|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT {
  |  112|       |    // return the fixed size type if available to enable compile time optimizations
  |  113|      3|    return internal::traits<internal::remove_all_t<LhsNested>>::RowsAtCompileTime == Dynamic ? m_rhs.rows()
  |  114|      3|                                                                                             : m_lhs.rows();
  |  115|      3|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_14CwiseNullaryOpINS1_18scalar_constant_opIS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapIS9_Li1ENS_6StrideILi0ELi0EEEEEE4rowsEv
  ------------------
  116|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT {
  117|       |    // return the fixed size type if available to enable compile time optimizations
  118|      3|    return internal::traits<internal::remove_all_t<LhsNested>>::ColsAtCompileTime == Dynamic ? m_rhs.cols()
  119|      3|                                                                                             : m_lhs.cols();
  120|      3|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS6_IS9_Lin1ELi1ELb1EEEE4colsEv
  ------------------
  | _ZNK5Eigen13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEES7_E4colsEv:
  |  116|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT {
  |  117|       |    // return the fixed size type if available to enable compile time optimizations
  |  118|      3|    return internal::traits<internal::remove_all_t<LhsNested>>::ColsAtCompileTime == Dynamic ? m_rhs.cols()
  |  119|      3|                                                                                             : m_lhs.cols();
  |  120|      3|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_14CwiseNullaryOpINS1_18scalar_constant_opIS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapIS9_Li1ENS_6StrideILi0ELi0EEEEEE4colsEv
  ------------------
  121|       |
  122|       |  /** \returns the left hand side nested expression */
  123|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const LhsNested_& lhs() const { return m_lhs; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS6_IS9_Lin1ELi1ELb1EEEE3lhsEv
  ------------------
  | _ZNK5Eigen13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEES7_E3lhsEv:
  |  123|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const LhsNested_& lhs() const { return m_lhs; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_14CwiseNullaryOpINS1_18scalar_constant_opIS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapIS9_Li1ENS_6StrideILi0ELi0EEEEEE3lhsEv
  ------------------
  124|       |  /** \returns the right hand side nested expression */
  125|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const RhsNested_& rhs() const { return m_rhs; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS6_IS9_Lin1ELi1ELb1EEEE3rhsEv
  ------------------
  | _ZNK5Eigen13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEES7_E3rhsEv:
  |  125|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const RhsNested_& rhs() const { return m_rhs; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_14CwiseNullaryOpINS1_18scalar_constant_opIS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapIS9_Li1ENS_6StrideILi0ELi0EEEEEE3rhsEv
  ------------------
  126|       |  /** \returns the functor representing the binary operation */
  127|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const BinaryOp& functor() const { return m_functor; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS6_IS9_Lin1ELi1ELb1EEEE7functorEv
  ------------------
  | _ZNK5Eigen13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEES7_E7functorEv:
  |  127|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const BinaryOp& functor() const { return m_functor; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS3_EEKNS_14CwiseNullaryOpINS1_18scalar_constant_opIS3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapIS9_Li1ENS_6StrideILi0ELi0EEEEEE7functorEv
  ------------------
  128|       |
  129|       | protected:
  130|       |  LhsNested m_lhs;
  131|       |  RhsNested m_rhs;
  132|       |  const BinaryOp m_functor;
  133|       |};
  134|       |
  135|       |// Generic API dispatcher
  136|       |template <typename BinaryOp, typename Lhs, typename Rhs, typename StorageKind>
  137|       |class CwiseBinaryOpImpl : public internal::generic_xpr_base<CwiseBinaryOp<BinaryOp, Lhs, Rhs>>::type {
  138|       | public:
  139|       |  typedef typename internal::generic_xpr_base<CwiseBinaryOp<BinaryOp, Lhs, Rhs>>::type Base;
  140|       |};
  141|       |
  142|       |/** replaces \c *this by \c *this - \a other.
  143|       | *
  144|       | * \returns a reference to \c *this
  145|       | */
  146|       |template <typename Derived>
  147|       |template <typename OtherDerived>
  148|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::operator-=(const MatrixBase<OtherDerived>& other) {
  149|       |  call_assignment(derived(), other.derived(), internal::sub_assign_op<Scalar, typename OtherDerived::Scalar>());
  150|       |  return derived();
  151|       |}
  152|       |
  153|       |/** replaces \c *this by \c *this + \a other.
  154|       | *
  155|       | * \returns a reference to \c *this
  156|       | */
  157|       |template <typename Derived>
  158|       |template <typename OtherDerived>
  159|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::operator+=(const MatrixBase<OtherDerived>& other) {
  160|      0|  call_assignment(derived(), other.derived(), internal::add_assign_op<Scalar, typename OtherDerived::Scalar>());
  161|      0|  return derived();
  162|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEpLINS_13CwiseBinaryOpINS_8internal17scalar_product_opIS3_S3_EEKNS_14CwiseNullaryOpINS9_18scalar_constant_opIS3_EEKNS2_IS3_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISF_Li1ENS_6StrideILi0ELi0EEEEEEEEERS5_RKNS0_IT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEpLINS_13CwiseBinaryOpINS_8internal17scalar_product_opIS2_S2_EEKNS_14CwiseNullaryOpINS7_18scalar_constant_opIS2_EEKS3_EEKNS_3MapIS3_Li1ENS_6StrideILi0ELi0EEEEEEEEERS3_RKNS0_IT_EE
  ------------------
  163|       |
  164|       |}  // end namespace Eigen
  165|       |
  166|       |#endif  // EIGEN_CWISE_BINARY_OP_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/CwiseNullaryOp.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_CWISE_NULLARY_OP_H
   11|       |#define EIGEN_CWISE_NULLARY_OP_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "./InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |template <typename NullaryOp, typename PlainObjectType>
   20|       |struct traits<CwiseNullaryOp<NullaryOp, PlainObjectType> > : traits<PlainObjectType> {
   21|       |  enum { Flags = traits<PlainObjectType>::Flags & RowMajorBit };
   22|       |};
   23|       |
   24|       |}  // namespace internal
   25|       |
   26|       |/** \class CwiseNullaryOp
   27|       |  * \ingroup Core_Module
   28|       |  *
   29|       |  * \brief Generic expression of a matrix where all coefficients are defined by a functor
   30|       |  *
   31|       |  * \tparam NullaryOp template functor implementing the operator
   32|       |  * \tparam PlainObjectType the underlying plain matrix/array type
   33|       |  *
   34|       |  * This class represents an expression of a generic nullary operator.
   35|       |  * It is the return type of the Ones(), Zero(), Constant(), Identity() and Random() methods,
   36|       |  * and most of the time this is the only way it is used.
   37|       |  *
   38|       |  * However, if you want to write a function returning such an expression, you
   39|       |  * will need to use this class.
   40|       |  *
   41|       |  * The functor NullaryOp must expose one of the following method:
   42|       |    <table class="manual">
   43|       |    <tr            ><td>\c operator()() </td><td>if the procedural generation does not depend on the coefficient entries
   44|       |  (e.g., random numbers)</td></tr> <tr class="alt"><td>\c operator()(Index i)</td><td>if the procedural generation makes
   45|       |  sense for vectors only and that it depends on the coefficient index \c i (e.g., linspace) </td></tr> <tr ><td>\c
   46|       |  operator()(Index i,Index j)</td><td>if the procedural generation depends on the matrix coordinates \c i, \c j (e.g.,
   47|       |  to generate a checkerboard with 0 and 1)</td></tr>
   48|       |    </table>
   49|       |  * It is also possible to expose the last two operators if the generation makes sense for matrices but can be optimized
   50|       |  for vectors.
   51|       |  *
   52|       |  * See DenseBase::NullaryExpr(Index,const CustomNullaryOp&) for an example binding
   53|       |  * C++11 random number generators.
   54|       |  *
   55|       |  * A nullary expression can also be used to implement custom sophisticated matrix manipulations
   56|       |  * that cannot be covered by the existing set of natively supported matrix manipulations.
   57|       |  * See this \ref TopicCustomizing_NullaryExpr "page" for some examples and additional explanations
   58|       |  * on the behavior of CwiseNullaryOp.
   59|       |  *
   60|       |  * \sa class CwiseUnaryOp, class CwiseBinaryOp, DenseBase::NullaryExpr
   61|       |  */
   62|       |template <typename NullaryOp, typename PlainObjectType>
   63|       |class CwiseNullaryOp : public internal::dense_xpr_base<CwiseNullaryOp<NullaryOp, PlainObjectType> >::type,
   64|       |                       internal::no_assignment_operator {
   65|       | public:
   66|       |  typedef typename internal::dense_xpr_base<CwiseNullaryOp>::type Base;
   67|       |  EIGEN_DENSE_PUBLIC_INTERFACE(CwiseNullaryOp)
   68|       |
   69|       |  EIGEN_DEVICE_FUNC CwiseNullaryOp(Index rows, Index cols, const NullaryOp& func = NullaryOp())
   70|      4|      : m_rows(rows), m_cols(cols), m_functor(func) {
   71|      4|    eigen_assert(rows >= 0 && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows) && cols >= 0 &&
   72|      4|                 (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols));
   73|      4|  }
  ------------------
  | _ZN5Eigen14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEEC2EllRKS4_:
  |   70|      1|      : m_rows(rows), m_cols(cols), m_functor(func) {
  |   71|      1|    eigen_assert(rows >= 0 && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows) && cols >= 0 &&
  |   72|      1|                 (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols));
  |   73|      1|  }
  ------------------
  | _ZN5Eigen14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEEEC2EllRKS4_:
  |   70|      3|      : m_rows(rows), m_cols(cols), m_functor(func) {
  |   71|      3|    eigen_assert(rows >= 0 && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows) && cols >= 0 &&
  |   72|      3|                 (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols));
  |   73|      3|  }
  ------------------
   74|       |  EIGEN_DEVICE_FUNC CwiseNullaryOp(Index size, const NullaryOp& func = NullaryOp())
   75|       |      : CwiseNullaryOp(RowsAtCompileTime == 1 ? 1 : size, RowsAtCompileTime == 1 ? size : 1, func) {
   76|       |    EIGEN_STATIC_ASSERT(CwiseNullaryOp::IsVectorAtCompileTime, YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX);
   77|       |  }
   78|       |
   79|      4|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const { return m_rows.value(); }
  ------------------
  | _ZNK5Eigen14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEE4rowsEv:
  |   79|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const { return m_rows.value(); }
  ------------------
  | _ZNK5Eigen14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEEE4rowsEv:
  |   79|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const { return m_rows.value(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen14CwiseNullaryOpINS_8internal18scalar_constant_opI14AnnoyingScalarEEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEE4rowsEv
  ------------------
   80|      4|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const { return m_cols.value(); }
  ------------------
  | _ZNK5Eigen14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEE4colsEv:
  |   80|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const { return m_cols.value(); }
  ------------------
  | _ZNK5Eigen14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEEE4colsEv:
  |   80|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const { return m_cols.value(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen14CwiseNullaryOpINS_8internal18scalar_constant_opI14AnnoyingScalarEEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEE4colsEv
  ------------------
   81|       |
   82|       |  /** \returns the functor representing the nullary operation */
   83|      4|  EIGEN_DEVICE_FUNC const NullaryOp& functor() const { return m_functor; }
  ------------------
  | _ZNK5Eigen14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEE7functorEv:
  |   83|      1|  EIGEN_DEVICE_FUNC const NullaryOp& functor() const { return m_functor; }
  ------------------
  | _ZNK5Eigen14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEEE7functorEv:
  |   83|      3|  EIGEN_DEVICE_FUNC const NullaryOp& functor() const { return m_functor; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen14CwiseNullaryOpINS_8internal18scalar_constant_opI14AnnoyingScalarEEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEEE7functorEv
  ------------------
   84|       |
   85|       | protected:
   86|       |  const internal::variable_if_dynamic<Index, RowsAtCompileTime> m_rows;
   87|       |  const internal::variable_if_dynamic<Index, ColsAtCompileTime> m_cols;
   88|       |  const NullaryOp m_functor;
   89|       |};
   90|       |
   91|       |/** \returns an expression of a matrix defined by a custom functor \a func
   92|       | *
   93|       | * The parameters \a rows and \a cols are the number of rows and of columns of
   94|       | * the returned matrix. Must be compatible with this MatrixBase type.
   95|       | *
   96|       | * This variant is meant to be used for dynamic-size matrix types. For fixed-size types,
   97|       | * it is redundant to pass \a rows and \a cols as arguments, so Zero() should be used
   98|       | * instead.
   99|       | *
  100|       | * The template parameter \a CustomNullaryOp is the type of the functor.
  101|       | *
  102|       | * \sa class CwiseNullaryOp
  103|       | */
  104|       |template <typename Derived>
  105|       |template <typename CustomNullaryOp>
  106|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  107|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  108|       |    const CwiseNullaryOp<CustomNullaryOp, typename DenseBase<Derived>::PlainObject>
  109|       |#else
  110|       |    const CwiseNullaryOp<CustomNullaryOp, PlainObject>
  111|       |#endif
  112|       |    DenseBase<Derived>::NullaryExpr(Index rows, Index cols, const CustomNullaryOp& func) {
  113|       |  return CwiseNullaryOp<CustomNullaryOp, PlainObject>(rows, cols, func);
  114|       |}
  115|       |
  116|       |/** \returns an expression of a matrix defined by a custom functor \a func
  117|       | *
  118|       | * The parameter \a size is the size of the returned vector.
  119|       | * Must be compatible with this MatrixBase type.
  120|       | *
  121|       | * \only_for_vectors
  122|       | *
  123|       | * This variant is meant to be used for dynamic-size vector types. For fixed-size types,
  124|       | * it is redundant to pass \a size as argument, so Zero() should be used
  125|       | * instead.
  126|       | *
  127|       | * The template parameter \a CustomNullaryOp is the type of the functor.
  128|       | *
  129|       | * Here is an example with C++11 random generators: \include random_cpp11.cpp
  130|       | * Output: \verbinclude random_cpp11.out
  131|       | *
  132|       | * \sa class CwiseNullaryOp
  133|       | */
  134|       |template <typename Derived>
  135|       |template <typename CustomNullaryOp>
  136|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  137|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  138|       |    const CwiseNullaryOp<CustomNullaryOp, typename DenseBase<Derived>::PlainObject>
  139|       |#else
  140|       |    const CwiseNullaryOp<CustomNullaryOp, PlainObject>
  141|       |#endif
  142|       |    DenseBase<Derived>::NullaryExpr(Index size, const CustomNullaryOp& func) {
  143|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  144|       |  if (RowsAtCompileTime == 1)
  145|       |    return CwiseNullaryOp<CustomNullaryOp, PlainObject>(1, size, func);
  146|       |  else
  147|       |    return CwiseNullaryOp<CustomNullaryOp, PlainObject>(size, 1, func);
  148|       |}
  149|       |
  150|       |/** \returns an expression of a matrix defined by a custom functor \a func
  151|       | *
  152|       | * This variant is only for fixed-size DenseBase types. For dynamic-size types, you
  153|       | * need to use the variants taking size arguments.
  154|       | *
  155|       | * The template parameter \a CustomNullaryOp is the type of the functor.
  156|       | *
  157|       | * \sa class CwiseNullaryOp
  158|       | */
  159|       |template <typename Derived>
  160|       |template <typename CustomNullaryOp>
  161|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  162|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  163|       |    const CwiseNullaryOp<CustomNullaryOp, typename DenseBase<Derived>::PlainObject>
  164|       |#else
  165|       |    const CwiseNullaryOp<CustomNullaryOp, PlainObject>
  166|       |#endif
  167|       |    DenseBase<Derived>::NullaryExpr(const CustomNullaryOp& func) {
  168|       |  return CwiseNullaryOp<CustomNullaryOp, PlainObject>(RowsAtCompileTime, ColsAtCompileTime, func);
  169|       |}
  170|       |
  171|       |/** \returns an expression of a constant matrix of value \a value
  172|       | *
  173|       | * The parameters \a rows and \a cols are the number of rows and of columns of
  174|       | * the returned matrix. Must be compatible with this DenseBase type.
  175|       | *
  176|       | * This variant is meant to be used for dynamic-size matrix types. For fixed-size types,
  177|       | * it is redundant to pass \a rows and \a cols as arguments, so Zero() should be used
  178|       | * instead.
  179|       | *
  180|       | * The template parameter \a CustomNullaryOp is the type of the functor.
  181|       | *
  182|       | * \sa class CwiseNullaryOp
  183|       | */
  184|       |template <typename Derived>
  185|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ConstantReturnType
  186|       |DenseBase<Derived>::Constant(Index rows, Index cols, const Scalar& value) {
  187|       |  return DenseBase<Derived>::NullaryExpr(rows, cols, internal::scalar_constant_op<Scalar>(value));
  188|       |}
  189|       |
  190|       |/** \returns an expression of a constant matrix of value \a value
  191|       | *
  192|       | * The parameter \a size is the size of the returned vector.
  193|       | * Must be compatible with this DenseBase type.
  194|       | *
  195|       | * \only_for_vectors
  196|       | *
  197|       | * This variant is meant to be used for dynamic-size vector types. For fixed-size types,
  198|       | * it is redundant to pass \a size as argument, so Zero() should be used
  199|       | * instead.
  200|       | *
  201|       | * The template parameter \a CustomNullaryOp is the type of the functor.
  202|       | *
  203|       | * \sa class CwiseNullaryOp
  204|       | */
  205|       |template <typename Derived>
  206|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ConstantReturnType
  207|       |DenseBase<Derived>::Constant(Index size, const Scalar& value) {
  208|       |  return DenseBase<Derived>::NullaryExpr(size, internal::scalar_constant_op<Scalar>(value));
  209|       |}
  210|       |
  211|       |/** \returns an expression of a constant matrix of value \a value
  212|       | *
  213|       | * This variant is only for fixed-size DenseBase types. For dynamic-size types, you
  214|       | * need to use the variants taking size arguments.
  215|       | *
  216|       | * The template parameter \a CustomNullaryOp is the type of the functor.
  217|       | *
  218|       | * \sa class CwiseNullaryOp
  219|       | */
  220|       |template <typename Derived>
  221|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ConstantReturnType
  222|       |DenseBase<Derived>::Constant(const Scalar& value) {
  223|       |  EIGEN_STATIC_ASSERT_FIXED_SIZE(Derived)
  224|       |  return DenseBase<Derived>::NullaryExpr(RowsAtCompileTime, ColsAtCompileTime,
  225|       |                                         internal::scalar_constant_op<Scalar>(value));
  226|       |}
  227|       |
  228|       |/** \deprecated because of accuracy loss. In Eigen 3.3, it is an alias for LinSpaced(Index,const Scalar&,const Scalar&)
  229|       | *
  230|       | * \only_for_vectors
  231|       | *
  232|       | * Example: \include DenseBase_LinSpaced_seq_deprecated.cpp
  233|       | * Output: \verbinclude DenseBase_LinSpaced_seq_deprecated.out
  234|       | *
  235|       | * \sa LinSpaced(Index,const Scalar&, const Scalar&), setLinSpaced(Index,const Scalar&,const Scalar&)
  236|       | */
  237|       |template <typename Derived>
  238|       |EIGEN_DEPRECATED EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<
  239|       |    Derived>::RandomAccessLinSpacedReturnType
  240|       |DenseBase<Derived>::LinSpaced(Sequential_t, Index size, const Scalar& low, const Scalar& high) {
  241|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  242|       |  return DenseBase<Derived>::NullaryExpr(size, internal::linspaced_op<Scalar>(low, high, size));
  243|       |}
  244|       |
  245|       |/** \deprecated because of accuracy loss. In Eigen 3.3, it is an alias for LinSpaced(const Scalar&,const Scalar&)
  246|       | *
  247|       | * \sa LinSpaced(const Scalar&, const Scalar&)
  248|       | */
  249|       |template <typename Derived>
  250|       |EIGEN_DEPRECATED EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<
  251|       |    Derived>::RandomAccessLinSpacedReturnType
  252|       |DenseBase<Derived>::LinSpaced(Sequential_t, const Scalar& low, const Scalar& high) {
  253|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  254|       |  EIGEN_STATIC_ASSERT_FIXED_SIZE(Derived)
  255|       |  return DenseBase<Derived>::NullaryExpr(Derived::SizeAtCompileTime,
  256|       |                                         internal::linspaced_op<Scalar>(low, high, Derived::SizeAtCompileTime));
  257|       |}
  258|       |
  259|       |/**
  260|       | * \brief Sets a linearly spaced vector.
  261|       | *
  262|       | * The function generates 'size' equally spaced values in the closed interval [low,high].
  263|       | * When size is set to 1, a vector of length 1 containing 'high' is returned.
  264|       | *
  265|       | * \only_for_vectors
  266|       | *
  267|       | * Example: \include DenseBase_LinSpaced.cpp
  268|       | * Output: \verbinclude DenseBase_LinSpaced.out
  269|       | *
  270|       | * For integer scalar types, an even spacing is possible if and only if the length of the range,
  271|       | * i.e., \c high-low is a scalar multiple of \c size-1, or if \c size is a scalar multiple of the
  272|       | * number of values \c high-low+1 (meaning each value can be repeated the same number of time).
  273|       | * If one of these two considions is not satisfied, then \c high is lowered to the largest value
  274|       | * satisfying one of this constraint.
  275|       | * Here are some examples:
  276|       | *
  277|       | * Example: \include DenseBase_LinSpacedInt.cpp
  278|       | * Output: \verbinclude DenseBase_LinSpacedInt.out
  279|       | *
  280|       | * \sa setLinSpaced(Index,const Scalar&,const Scalar&), CwiseNullaryOp
  281|       | */
  282|       |template <typename Derived>
  283|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::RandomAccessLinSpacedReturnType
  284|       |DenseBase<Derived>::LinSpaced(Index size, const Scalar& low, const Scalar& high) {
  285|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  286|       |  return DenseBase<Derived>::NullaryExpr(size, internal::linspaced_op<Scalar>(low, high, size));
  287|       |}
  288|       |
  289|       |/**
  290|       | * \copydoc DenseBase::LinSpaced(Index, const Scalar&, const Scalar&)
  291|       | * Special version for fixed size types which does not require the size parameter.
  292|       | */
  293|       |template <typename Derived>
  294|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::RandomAccessLinSpacedReturnType
  295|       |DenseBase<Derived>::LinSpaced(const Scalar& low, const Scalar& high) {
  296|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  297|       |  EIGEN_STATIC_ASSERT_FIXED_SIZE(Derived)
  298|       |  return DenseBase<Derived>::NullaryExpr(Derived::SizeAtCompileTime,
  299|       |                                         internal::linspaced_op<Scalar>(low, high, Derived::SizeAtCompileTime));
  300|       |}
  301|       |
  302|       |template <typename Derived>
  303|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::RandomAccessEqualSpacedReturnType
  304|       |DenseBase<Derived>::EqualSpaced(Index size, const Scalar& low, const Scalar& step) {
  305|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  306|       |  return DenseBase<Derived>::NullaryExpr(size, internal::equalspaced_op<Scalar>(low, step));
  307|       |}
  308|       |
  309|       |template <typename Derived>
  310|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::RandomAccessEqualSpacedReturnType
  311|       |DenseBase<Derived>::EqualSpaced(const Scalar& low, const Scalar& step) {
  312|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  313|       |  return DenseBase<Derived>::NullaryExpr(Derived::SizeAtCompileTime, internal::equalspaced_op<Scalar>(low, step));
  314|       |}
  315|       |
  316|       |/** \returns true if all coefficients in this matrix are approximately equal to \a val, to within precision \a prec */
  317|       |template <typename Derived>
  318|       |EIGEN_DEVICE_FUNC bool DenseBase<Derived>::isApproxToConstant(const Scalar& val, const RealScalar& prec) const {
  319|       |  typename internal::nested_eval<Derived, 1>::type self(derived());
  320|       |  for (Index j = 0; j < cols(); ++j)
  321|       |    for (Index i = 0; i < rows(); ++i)
  322|       |      if (!internal::isApprox(self.coeff(i, j), val, prec)) return false;
  323|       |  return true;
  324|       |}
  325|       |
  326|       |/** This is just an alias for isApproxToConstant().
  327|       | *
  328|       | * \returns true if all coefficients in this matrix are approximately equal to \a value, to within precision \a prec */
  329|       |template <typename Derived>
  330|       |EIGEN_DEVICE_FUNC bool DenseBase<Derived>::isConstant(const Scalar& val, const RealScalar& prec) const {
  331|       |  return isApproxToConstant(val, prec);
  332|       |}
  333|       |
  334|       |/** Alias for setConstant(): sets all coefficients in this expression to \a val.
  335|       | *
  336|       | * \sa setConstant(), Constant(), class CwiseNullaryOp
  337|       | */
  338|       |template <typename Derived>
  339|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void DenseBase<Derived>::fill(const Scalar& val) {
  340|       |  setConstant(val);
  341|       |}
  342|       |
  343|       |/** Sets all coefficients in this expression to value \a val.
  344|       | *
  345|       | * \sa fill(), setConstant(Index,const Scalar&), setConstant(Index,Index,const Scalar&), setZero(), setOnes(),
  346|       | * Constant(), class CwiseNullaryOp, setZero(), setOnes()
  347|       | */
  348|       |template <typename Derived>
  349|      5|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setConstant(const Scalar& val) {
  350|      5|  internal::eigen_fill_impl<Derived>::run(derived(), val);
  351|      5|  return derived();
  352|      5|}
  ------------------
  | _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE11setConstantERKS2_:
  |  349|      2|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setConstant(const Scalar& val) {
  |  350|      2|  internal::eigen_fill_impl<Derived>::run(derived(), val);
  |  351|      2|  return derived();
  |  352|      2|}
  ------------------
  | _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE11setConstantERKS2_:
  |  349|      3|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setConstant(const Scalar& val) {
  |  350|      3|  internal::eigen_fill_impl<Derived>::run(derived(), val);
  |  351|      3|  return derived();
  |  352|      3|}
  ------------------
  353|       |
  354|       |/** Resizes to the given \a size, and sets all coefficients in this expression to the given value \a val.
  355|       | *
  356|       | * \only_for_vectors
  357|       | *
  358|       | * Example: \include Matrix_setConstant_int.cpp
  359|       | * Output: \verbinclude Matrix_setConstant_int.out
  360|       | *
  361|       | * \sa MatrixBase::setConstant(const Scalar&), setConstant(Index,Index,const Scalar&), class CwiseNullaryOp,
  362|       | * MatrixBase::Constant(const Scalar&)
  363|       | */
  364|       |template <typename Derived>
  365|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setConstant(Index size, const Scalar& val) {
  366|       |  resize(size);
  367|       |  return setConstant(val);
  368|       |}
  369|       |
  370|       |/** Resizes to the given size, and sets all coefficients in this expression to the given value \a val.
  371|       | *
  372|       | * \param rows the new number of rows
  373|       | * \param cols the new number of columns
  374|       | * \param val the value to which all coefficients are set
  375|       | *
  376|       | * Example: \include Matrix_setConstant_int_int.cpp
  377|       | * Output: \verbinclude Matrix_setConstant_int_int.out
  378|       | *
  379|       | * \sa MatrixBase::setConstant(const Scalar&), setConstant(Index,const Scalar&), class CwiseNullaryOp,
  380|       | * MatrixBase::Constant(const Scalar&)
  381|       | */
  382|       |template <typename Derived>
  383|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setConstant(Index rows, Index cols,
  384|       |                                                                                     const Scalar& val) {
  385|       |  resize(rows, cols);
  386|       |  return setConstant(val);
  387|       |}
  388|       |
  389|       |/** Resizes to the given size, changing only the number of columns, and sets all
  390|       | * coefficients in this expression to the given value \a val. For the parameter
  391|       | * of type NoChange_t, just pass the special value \c NoChange.
  392|       | *
  393|       | * \sa MatrixBase::setConstant(const Scalar&), setConstant(Index,const Scalar&), class CwiseNullaryOp,
  394|       | * MatrixBase::Constant(const Scalar&)
  395|       | */
  396|       |template <typename Derived>
  397|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setConstant(NoChange_t, Index cols,
  398|       |                                                                                     const Scalar& val) {
  399|       |  return setConstant(rows(), cols, val);
  400|       |}
  401|       |
  402|       |/** Resizes to the given size, changing only the number of rows, and sets all
  403|       | * coefficients in this expression to the given value \a val. For the parameter
  404|       | * of type NoChange_t, just pass the special value \c NoChange.
  405|       | *
  406|       | * \sa MatrixBase::setConstant(const Scalar&), setConstant(Index,const Scalar&), class CwiseNullaryOp,
  407|       | * MatrixBase::Constant(const Scalar&)
  408|       | */
  409|       |template <typename Derived>
  410|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setConstant(Index rows, NoChange_t,
  411|       |                                                                                     const Scalar& val) {
  412|       |  return setConstant(rows, cols(), val);
  413|       |}
  414|       |
  415|       |/**
  416|       | * \brief Sets a linearly spaced vector.
  417|       | *
  418|       | * The function generates 'size' equally spaced values in the closed interval [low,high].
  419|       | * When size is set to 1, a vector of length 1 containing 'high' is returned.
  420|       | *
  421|       | * \only_for_vectors
  422|       | *
  423|       | * Example: \include DenseBase_setLinSpaced.cpp
  424|       | * Output: \verbinclude DenseBase_setLinSpaced.out
  425|       | *
  426|       | * For integer scalar types, do not miss the explanations on the definition
  427|       | * of \link LinSpaced(Index,const Scalar&,const Scalar&) even spacing \endlink.
  428|       | *
  429|       | * \sa LinSpaced(Index,const Scalar&,const Scalar&), CwiseNullaryOp
  430|       | */
  431|       |template <typename Derived>
  432|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setLinSpaced(Index newSize, const Scalar& low,
  433|       |                                                                                const Scalar& high) {
  434|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  435|       |  return derived() = Derived::NullaryExpr(newSize, internal::linspaced_op<Scalar>(low, high, newSize));
  436|       |}
  437|       |
  438|       |/**
  439|       | * \brief Sets a linearly spaced vector.
  440|       | *
  441|       | * The function fills \c *this with equally spaced values in the closed interval [low,high].
  442|       | * When size is set to 1, a vector of length 1 containing 'high' is returned.
  443|       | *
  444|       | * \only_for_vectors
  445|       | *
  446|       | * For integer scalar types, do not miss the explanations on the definition
  447|       | * of \link LinSpaced(Index,const Scalar&,const Scalar&) even spacing \endlink.
  448|       | *
  449|       | * \sa LinSpaced(Index,const Scalar&,const Scalar&), setLinSpaced(Index, const Scalar&, const Scalar&), CwiseNullaryOp
  450|       | */
  451|       |template <typename Derived>
  452|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setLinSpaced(const Scalar& low, const Scalar& high) {
  453|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  454|       |  return setLinSpaced(size(), low, high);
  455|       |}
  456|       |
  457|       |template <typename Derived>
  458|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setEqualSpaced(Index newSize, const Scalar& low,
  459|       |                                                                                  const Scalar& step) {
  460|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  461|       |  return derived() = Derived::NullaryExpr(newSize, internal::equalspaced_op<Scalar>(low, step));
  462|       |}
  463|       |template <typename Derived>
  464|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setEqualSpaced(const Scalar& low,
  465|       |                                                                                  const Scalar& step) {
  466|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  467|       |  return setEqualSpaced(size(), low, step);
  468|       |}
  469|       |
  470|       |// zero:
  471|       |
  472|       |/** \returns an expression of a zero matrix.
  473|       | *
  474|       | * The parameters \a rows and \a cols are the number of rows and of columns of
  475|       | * the returned matrix. Must be compatible with this MatrixBase type.
  476|       | *
  477|       | * This variant is meant to be used for dynamic-size matrix types. For fixed-size types,
  478|       | * it is redundant to pass \a rows and \a cols as arguments, so Zero() should be used
  479|       | * instead.
  480|       | *
  481|       | * Example: \include MatrixBase_zero_int_int.cpp
  482|       | * Output: \verbinclude MatrixBase_zero_int_int.out
  483|       | *
  484|       | * \sa Zero(), Zero(Index)
  485|       | */
  486|       |template <typename Derived>
  487|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ZeroReturnType DenseBase<Derived>::Zero(
  488|       |    Index rows, Index cols) {
  489|       |  return ZeroReturnType(rows, cols);
  490|       |}
  491|       |
  492|       |/** \returns an expression of a zero vector.
  493|       | *
  494|       | * The parameter \a size is the size of the returned vector.
  495|       | * Must be compatible with this MatrixBase type.
  496|       | *
  497|       | * \only_for_vectors
  498|       | *
  499|       | * This variant is meant to be used for dynamic-size vector types. For fixed-size types,
  500|       | * it is redundant to pass \a size as argument, so Zero() should be used
  501|       | * instead.
  502|       | *
  503|       | * Example: \include MatrixBase_zero_int.cpp
  504|       | * Output: \verbinclude MatrixBase_zero_int.out
  505|       | *
  506|       | * \sa Zero(), Zero(Index,Index)
  507|       | */
  508|       |template <typename Derived>
  509|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ZeroReturnType DenseBase<Derived>::Zero(
  510|       |    Index size) {
  511|       |  return ZeroReturnType(size);
  512|       |}
  513|       |
  514|       |/** \returns an expression of a fixed-size zero matrix or vector.
  515|       | *
  516|       | * This variant is only for fixed-size MatrixBase types. For dynamic-size types, you
  517|       | * need to use the variants taking size arguments.
  518|       | *
  519|       | * Example: \include MatrixBase_zero.cpp
  520|       | * Output: \verbinclude MatrixBase_zero.out
  521|       | *
  522|       | * \sa Zero(Index), Zero(Index,Index)
  523|       | */
  524|       |template <typename Derived>
  525|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ZeroReturnType DenseBase<Derived>::Zero() {
  526|       |  return ZeroReturnType(RowsAtCompileTime, ColsAtCompileTime);
  527|       |}
  528|       |
  529|       |/** \returns true if *this is approximately equal to the zero matrix,
  530|       | *          within the precision given by \a prec.
  531|       | *
  532|       | * Example: \include MatrixBase_isZero.cpp
  533|       | * Output: \verbinclude MatrixBase_isZero.out
  534|       | *
  535|       | * \sa class CwiseNullaryOp, Zero()
  536|       | */
  537|       |template <typename Derived>
  538|       |EIGEN_DEVICE_FUNC bool DenseBase<Derived>::isZero(const RealScalar& prec) const {
  539|       |  typename internal::nested_eval<Derived, 1>::type self(derived());
  540|       |  for (Index j = 0; j < cols(); ++j)
  541|       |    for (Index i = 0; i < rows(); ++i)
  542|       |      if (!internal::isMuchSmallerThan(self.coeff(i, j), static_cast<Scalar>(1), prec)) return false;
  543|       |  return true;
  544|       |}
  545|       |
  546|       |/** Sets all coefficients in this expression to zero.
  547|       | *
  548|       | * Example: \include MatrixBase_setZero.cpp
  549|       | * Output: \verbinclude MatrixBase_setZero.out
  550|       | *
  551|       | * \sa class CwiseNullaryOp, Zero()
  552|       | */
  553|       |template <typename Derived>
  554|      4|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setZero() {
  555|      4|  internal::eigen_zero_impl<Derived>::run(derived());
  556|      4|  return derived();
  557|      4|}
  ------------------
  | _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE7setZeroEv:
  |  554|      1|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setZero() {
  |  555|      1|  internal::eigen_zero_impl<Derived>::run(derived());
  |  556|      1|  return derived();
  |  557|      1|}
  ------------------
  | _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE7setZeroEv:
  |  554|      3|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setZero() {
  |  555|      3|  internal::eigen_zero_impl<Derived>::run(derived());
  |  556|      3|  return derived();
  |  557|      3|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEE7setZeroEv
  ------------------
  558|       |
  559|       |/** Resizes to the given \a size, and sets all coefficients in this expression to zero.
  560|       | *
  561|       | * \only_for_vectors
  562|       | *
  563|       | * Example: \include Matrix_setZero_int.cpp
  564|       | * Output: \verbinclude Matrix_setZero_int.out
  565|       | *
  566|       | * \sa DenseBase::setZero(), setZero(Index,Index), class CwiseNullaryOp, DenseBase::Zero()
  567|       | */
  568|       |template <typename Derived>
  569|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setZero(Index newSize) {
  570|       |  resize(newSize);
  571|       |  return setZero();
  572|       |}
  573|       |
  574|       |/** Resizes to the given size, and sets all coefficients in this expression to zero.
  575|       | *
  576|       | * \param rows the new number of rows
  577|       | * \param cols the new number of columns
  578|       | *
  579|       | * Example: \include Matrix_setZero_int_int.cpp
  580|       | * Output: \verbinclude Matrix_setZero_int_int.out
  581|       | *
  582|       | * \sa DenseBase::setZero(), setZero(Index), class CwiseNullaryOp, DenseBase::Zero()
  583|       | */
  584|       |template <typename Derived>
  585|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setZero(Index rows, Index cols) {
  586|       |  resize(rows, cols);
  587|       |  return setZero();
  588|       |}
  589|       |
  590|       |/** Resizes to the given size, changing only the number of columns, and sets all
  591|       | * coefficients in this expression to zero. For the parameter of type NoChange_t,
  592|       | * just pass the special value \c NoChange.
  593|       | *
  594|       | * \sa DenseBase::setZero(), setZero(Index), setZero(Index, Index), setZero(Index, NoChange_t), class CwiseNullaryOp,
  595|       | * DenseBase::Zero()
  596|       | */
  597|       |template <typename Derived>
  598|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setZero(NoChange_t, Index cols) {
  599|       |  return setZero(rows(), cols);
  600|       |}
  601|       |
  602|       |/** Resizes to the given size, changing only the number of rows, and sets all
  603|       | * coefficients in this expression to zero. For the parameter of type NoChange_t,
  604|       | * just pass the special value \c NoChange.
  605|       | *
  606|       | * \sa DenseBase::setZero(), setZero(Index), setZero(Index, Index), setZero(NoChange_t, Index), class CwiseNullaryOp,
  607|       | * DenseBase::Zero()
  608|       | */
  609|       |template <typename Derived>
  610|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setZero(Index rows, NoChange_t) {
  611|       |  return setZero(rows, cols());
  612|       |}
  613|       |
  614|       |// ones:
  615|       |
  616|       |/** \returns an expression of a matrix where all coefficients equal one.
  617|       | *
  618|       | * The parameters \a rows and \a cols are the number of rows and of columns of
  619|       | * the returned matrix. Must be compatible with this MatrixBase type.
  620|       | *
  621|       | * This variant is meant to be used for dynamic-size matrix types. For fixed-size types,
  622|       | * it is redundant to pass \a rows and \a cols as arguments, so Ones() should be used
  623|       | * instead.
  624|       | *
  625|       | * Example: \include MatrixBase_ones_int_int.cpp
  626|       | * Output: \verbinclude MatrixBase_ones_int_int.out
  627|       | *
  628|       | * \sa Ones(), Ones(Index), isOnes(), class Ones
  629|       | */
  630|       |template <typename Derived>
  631|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Ones(
  632|       |    Index rows, Index cols) {
  633|       |  return Constant(rows, cols, Scalar(1));
  634|       |}
  635|       |
  636|       |/** \returns an expression of a vector where all coefficients equal one.
  637|       | *
  638|       | * The parameter \a newSize is the size of the returned vector.
  639|       | * Must be compatible with this MatrixBase type.
  640|       | *
  641|       | * \only_for_vectors
  642|       | *
  643|       | * This variant is meant to be used for dynamic-size vector types. For fixed-size types,
  644|       | * it is redundant to pass \a size as argument, so Ones() should be used
  645|       | * instead.
  646|       | *
  647|       | * Example: \include MatrixBase_ones_int.cpp
  648|       | * Output: \verbinclude MatrixBase_ones_int.out
  649|       | *
  650|       | * \sa Ones(), Ones(Index,Index), isOnes(), class Ones
  651|       | */
  652|       |template <typename Derived>
  653|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Ones(
  654|       |    Index newSize) {
  655|       |  return Constant(newSize, Scalar(1));
  656|       |}
  657|       |
  658|       |/** \returns an expression of a fixed-size matrix or vector where all coefficients equal one.
  659|       | *
  660|       | * This variant is only for fixed-size MatrixBase types. For dynamic-size types, you
  661|       | * need to use the variants taking size arguments.
  662|       | *
  663|       | * Example: \include MatrixBase_ones.cpp
  664|       | * Output: \verbinclude MatrixBase_ones.out
  665|       | *
  666|       | * \sa Ones(Index), Ones(Index,Index), isOnes(), class Ones
  667|       | */
  668|       |template <typename Derived>
  669|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ConstantReturnType DenseBase<Derived>::Ones() {
  670|       |  return Constant(Scalar(1));
  671|       |}
  672|       |
  673|       |/** \returns true if *this is approximately equal to the matrix where all coefficients
  674|       | *          are equal to 1, within the precision given by \a prec.
  675|       | *
  676|       | * Example: \include MatrixBase_isOnes.cpp
  677|       | * Output: \verbinclude MatrixBase_isOnes.out
  678|       | *
  679|       | * \sa class CwiseNullaryOp, Ones()
  680|       | */
  681|       |template <typename Derived>
  682|       |EIGEN_DEVICE_FUNC bool DenseBase<Derived>::isOnes(const RealScalar& prec) const {
  683|       |  return isApproxToConstant(Scalar(1), prec);
  684|       |}
  685|       |
  686|       |/** Sets all coefficients in this expression to one.
  687|       | *
  688|       | * Example: \include MatrixBase_setOnes.cpp
  689|       | * Output: \verbinclude MatrixBase_setOnes.out
  690|       | *
  691|       | * \sa class CwiseNullaryOp, Ones()
  692|       | */
  693|       |template <typename Derived>
  694|      5|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setOnes() {
  695|      5|  return setConstant(Scalar(1));
  696|      5|}
  ------------------
  | _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE7setOnesEv:
  |  694|      2|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setOnes() {
  |  695|      2|  return setConstant(Scalar(1));
  |  696|      2|}
  ------------------
  | _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE7setOnesEv:
  |  694|      3|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& DenseBase<Derived>::setOnes() {
  |  695|      3|  return setConstant(Scalar(1));
  |  696|      3|}
  ------------------
  697|       |
  698|       |/** Resizes to the given \a newSize, and sets all coefficients in this expression to one.
  699|       | *
  700|       | * \only_for_vectors
  701|       | *
  702|       | * Example: \include Matrix_setOnes_int.cpp
  703|       | * Output: \verbinclude Matrix_setOnes_int.out
  704|       | *
  705|       | * \sa MatrixBase::setOnes(), setOnes(Index,Index), class CwiseNullaryOp, MatrixBase::Ones()
  706|       | */
  707|       |template <typename Derived>
  708|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setOnes(Index newSize) {
  709|       |  resize(newSize);
  710|       |  return setConstant(Scalar(1));
  711|       |}
  712|       |
  713|       |/** Resizes to the given size, and sets all coefficients in this expression to one.
  714|       | *
  715|       | * \param rows the new number of rows
  716|       | * \param cols the new number of columns
  717|       | *
  718|       | * Example: \include Matrix_setOnes_int_int.cpp
  719|       | * Output: \verbinclude Matrix_setOnes_int_int.out
  720|       | *
  721|       | * \sa MatrixBase::setOnes(), setOnes(Index), class CwiseNullaryOp, MatrixBase::Ones()
  722|       | */
  723|       |template <typename Derived>
  724|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setOnes(Index rows, Index cols) {
  725|       |  resize(rows, cols);
  726|       |  return setConstant(Scalar(1));
  727|       |}
  728|       |
  729|       |/** Resizes to the given size, changing only the number of rows, and sets all
  730|       | * coefficients in this expression to one. For the parameter of type NoChange_t,
  731|       | * just pass the special value \c NoChange.
  732|       | *
  733|       | * \sa MatrixBase::setOnes(), setOnes(Index), setOnes(Index, Index), setOnes(NoChange_t, Index), class CwiseNullaryOp,
  734|       | * MatrixBase::Ones()
  735|       | */
  736|       |template <typename Derived>
  737|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setOnes(Index rows, NoChange_t) {
  738|       |  return setOnes(rows, cols());
  739|       |}
  740|       |
  741|       |/** Resizes to the given size, changing only the number of columns, and sets all
  742|       | * coefficients in this expression to one. For the parameter of type NoChange_t,
  743|       | * just pass the special value \c NoChange.
  744|       | *
  745|       | * \sa MatrixBase::setOnes(), setOnes(Index), setOnes(Index, Index), setOnes(Index, NoChange_t) class CwiseNullaryOp,
  746|       | * MatrixBase::Ones()
  747|       | */
  748|       |template <typename Derived>
  749|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& PlainObjectBase<Derived>::setOnes(NoChange_t, Index cols) {
  750|       |  return setOnes(rows(), cols);
  751|       |}
  752|       |
  753|       |// Identity:
  754|       |
  755|       |/** \returns an expression of the identity matrix (not necessarily square).
  756|       | *
  757|       | * The parameters \a rows and \a cols are the number of rows and of columns of
  758|       | * the returned matrix. Must be compatible with this MatrixBase type.
  759|       | *
  760|       | * This variant is meant to be used for dynamic-size matrix types. For fixed-size types,
  761|       | * it is redundant to pass \a rows and \a cols as arguments, so Identity() should be used
  762|       | * instead.
  763|       | *
  764|       | * Example: \include MatrixBase_identity_int_int.cpp
  765|       | * Output: \verbinclude MatrixBase_identity_int_int.out
  766|       | *
  767|       | * \sa Identity(), setIdentity(), isIdentity()
  768|       | */
  769|       |template <typename Derived>
  770|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::IdentityReturnType
  771|       |MatrixBase<Derived>::Identity(Index rows, Index cols) {
  772|       |  return DenseBase<Derived>::NullaryExpr(rows, cols, internal::scalar_identity_op<Scalar>());
  773|       |}
  774|       |
  775|       |/** \returns an expression of the identity matrix (not necessarily square).
  776|       | *
  777|       | * This variant is only for fixed-size MatrixBase types. For dynamic-size types, you
  778|       | * need to use the variant taking size arguments.
  779|       | *
  780|       | * Example: \include MatrixBase_identity.cpp
  781|       | * Output: \verbinclude MatrixBase_identity.out
  782|       | *
  783|       | * \sa Identity(Index,Index), setIdentity(), isIdentity()
  784|       | */
  785|       |template <typename Derived>
  786|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::IdentityReturnType
  787|       |MatrixBase<Derived>::Identity() {
  788|       |  EIGEN_STATIC_ASSERT_FIXED_SIZE(Derived)
  789|       |  return MatrixBase<Derived>::NullaryExpr(RowsAtCompileTime, ColsAtCompileTime, internal::scalar_identity_op<Scalar>());
  790|       |}
  791|       |
  792|       |/** \returns true if *this is approximately equal to the identity matrix
  793|       | *          (not necessarily square),
  794|       | *          within the precision given by \a prec.
  795|       | *
  796|       | * Example: \include MatrixBase_isIdentity.cpp
  797|       | * Output: \verbinclude MatrixBase_isIdentity.out
  798|       | *
  799|       | * \sa class CwiseNullaryOp, Identity(), Identity(Index,Index), setIdentity()
  800|       | */
  801|       |template <typename Derived>
  802|       |bool MatrixBase<Derived>::isIdentity(const RealScalar& prec) const {
  803|       |  typename internal::nested_eval<Derived, 1>::type self(derived());
  804|       |  for (Index j = 0; j < cols(); ++j) {
  805|       |    for (Index i = 0; i < rows(); ++i) {
  806|       |      if (i == j) {
  807|       |        if (!internal::isApprox(self.coeff(i, j), static_cast<Scalar>(1), prec)) return false;
  808|       |      } else {
  809|       |        if (!internal::isMuchSmallerThan(self.coeff(i, j), static_cast<RealScalar>(1), prec)) return false;
  810|       |      }
  811|       |    }
  812|       |  }
  813|       |  return true;
  814|       |}
  815|       |
  816|       |namespace internal {
  817|       |
  818|       |template <typename Derived, bool Big = (Derived::SizeAtCompileTime >= 16)>
  819|       |struct setIdentity_impl {
  820|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Derived& run(Derived& m) {
  821|       |    return m = Derived::Identity(m.rows(), m.cols());
  822|       |  }
  823|       |};
  824|       |
  825|       |template <typename Derived>
  826|       |struct setIdentity_impl<Derived, true> {
  827|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Derived& run(Derived& m) {
  828|       |    m.setZero();
  829|       |    const Index size = numext::mini(m.rows(), m.cols());
  830|       |    for (Index i = 0; i < size; ++i) m.coeffRef(i, i) = typename Derived::Scalar(1);
  831|       |    return m;
  832|       |  }
  833|       |};
  834|       |
  835|       |}  // end namespace internal
  836|       |
  837|       |/** Writes the identity expression (not necessarily square) into *this.
  838|       | *
  839|       | * Example: \include MatrixBase_setIdentity.cpp
  840|       | * Output: \verbinclude MatrixBase_setIdentity.out
  841|       | *
  842|       | * \sa class CwiseNullaryOp, Identity(), Identity(Index,Index), isIdentity()
  843|       | */
  844|       |template <typename Derived>
  845|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::setIdentity() {
  846|       |  return internal::setIdentity_impl<Derived>::run(derived());
  847|       |}
  848|       |
  849|       |/** \brief Resizes to the given size, and writes the identity expression (not necessarily square) into *this.
  850|       | *
  851|       | * \param rows the new number of rows
  852|       | * \param cols the new number of columns
  853|       | *
  854|       | * Example: \include Matrix_setIdentity_int_int.cpp
  855|       | * Output: \verbinclude Matrix_setIdentity_int_int.out
  856|       | *
  857|       | * \sa MatrixBase::setIdentity(), class CwiseNullaryOp, MatrixBase::Identity()
  858|       | */
  859|       |template <typename Derived>
  860|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::setIdentity(Index rows, Index cols) {
  861|       |  derived().resize(rows, cols);
  862|       |  return setIdentity();
  863|       |}
  864|       |
  865|       |/** \returns an expression of the i-th unit (basis) vector.
  866|       | *
  867|       | * \only_for_vectors
  868|       | *
  869|       | * \sa MatrixBase::Unit(Index), MatrixBase::UnitX(), MatrixBase::UnitY(), MatrixBase::UnitZ(), MatrixBase::UnitW()
  870|       | */
  871|       |template <typename Derived>
  872|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::Unit(
  873|       |    Index newSize, Index i) {
  874|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  875|       |  return BasisReturnType(SquareMatrixType::Identity(newSize, newSize), i);
  876|       |}
  877|       |
  878|       |/** \returns an expression of the i-th unit (basis) vector.
  879|       | *
  880|       | * \only_for_vectors
  881|       | *
  882|       | * This variant is for fixed-size vector only.
  883|       | *
  884|       | * \sa MatrixBase::Unit(Index,Index), MatrixBase::UnitX(), MatrixBase::UnitY(), MatrixBase::UnitZ(), MatrixBase::UnitW()
  885|       | */
  886|       |template <typename Derived>
  887|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::Unit(
  888|       |    Index i) {
  889|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  890|       |  return BasisReturnType(SquareMatrixType::Identity(), i);
  891|       |}
  892|       |
  893|       |/** \returns an expression of the X axis unit vector (1{,0}^*)
  894|       | *
  895|       | * \only_for_vectors
  896|       | *
  897|       | * \sa MatrixBase::Unit(Index,Index), MatrixBase::Unit(Index), MatrixBase::UnitY(), MatrixBase::UnitZ(),
  898|       | * MatrixBase::UnitW()
  899|       | */
  900|       |template <typename Derived>
  901|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::UnitX() {
  902|       |  return Derived::Unit(0);
  903|       |}
  904|       |
  905|       |/** \returns an expression of the Y axis unit vector (0,1{,0}^*)
  906|       | *
  907|       | * \only_for_vectors
  908|       | *
  909|       | * \sa MatrixBase::Unit(Index,Index), MatrixBase::Unit(Index), MatrixBase::UnitY(), MatrixBase::UnitZ(),
  910|       | * MatrixBase::UnitW()
  911|       | */
  912|       |template <typename Derived>
  913|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::UnitY() {
  914|       |  return Derived::Unit(1);
  915|       |}
  916|       |
  917|       |/** \returns an expression of the Z axis unit vector (0,0,1{,0}^*)
  918|       | *
  919|       | * \only_for_vectors
  920|       | *
  921|       | * \sa MatrixBase::Unit(Index,Index), MatrixBase::Unit(Index), MatrixBase::UnitY(), MatrixBase::UnitZ(),
  922|       | * MatrixBase::UnitW()
  923|       | */
  924|       |template <typename Derived>
  925|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::UnitZ() {
  926|       |  return Derived::Unit(2);
  927|       |}
  928|       |
  929|       |/** \returns an expression of the W axis unit vector (0,0,0,1)
  930|       | *
  931|       | * \only_for_vectors
  932|       | *
  933|       | * \sa MatrixBase::Unit(Index,Index), MatrixBase::Unit(Index), MatrixBase::UnitY(), MatrixBase::UnitZ(),
  934|       | * MatrixBase::UnitW()
  935|       | */
  936|       |template <typename Derived>
  937|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::BasisReturnType MatrixBase<Derived>::UnitW() {
  938|       |  return Derived::Unit(3);
  939|       |}
  940|       |
  941|       |/** \brief Set the coefficients of \c *this to the i-th unit (basis) vector
  942|       | *
  943|       | * \param i index of the unique coefficient to be set to 1
  944|       | *
  945|       | * \only_for_vectors
  946|       | *
  947|       | * \sa MatrixBase::setIdentity(), class CwiseNullaryOp, MatrixBase::Unit(Index,Index)
  948|       | */
  949|       |template <typename Derived>
  950|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::setUnit(Index i) {
  951|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived);
  952|       |  eigen_assert(i < size());
  953|       |  derived().setZero();
  954|       |  derived().coeffRef(i) = Scalar(1);
  955|       |  return derived();
  956|       |}
  957|       |
  958|       |/** \brief Resizes to the given \a newSize, and writes the i-th unit (basis) vector into *this.
  959|       | *
  960|       | * \param newSize the new size of the vector
  961|       | * \param i index of the unique coefficient to be set to 1
  962|       | *
  963|       | * \only_for_vectors
  964|       | *
  965|       | * \sa MatrixBase::setIdentity(), class CwiseNullaryOp, MatrixBase::Unit(Index,Index)
  966|       | */
  967|       |template <typename Derived>
  968|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& MatrixBase<Derived>::setUnit(Index newSize, Index i) {
  969|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived);
  970|       |  eigen_assert(i < newSize);
  971|       |  derived().resize(newSize);
  972|       |  return setUnit(i);
  973|       |}
  974|       |
  975|       |}  // end namespace Eigen
  976|       |
  977|       |#endif  // EIGEN_CWISE_NULLARY_OP_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/DenseBase.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2007-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2008-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_DENSEBASE_H
   12|       |#define EIGEN_DENSEBASE_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |// The index type defined by EIGEN_DEFAULT_DENSE_INDEX_TYPE must be a signed type.
   20|       |EIGEN_STATIC_ASSERT(NumTraits<DenseIndex>::IsSigned, THE_INDEX_TYPE_MUST_BE_A_SIGNED_TYPE)
   21|       |
   22|       |/** \class DenseBase
   23|       | * \ingroup Core_Module
   24|       | *
   25|       | * \brief Base class for all dense matrices, vectors, and arrays
   26|       | *
   27|       | * This class is the base that is inherited by all dense objects (matrix, vector, arrays,
   28|       | * and related expression types). The common Eigen API for dense objects is contained in this class.
   29|       | *
   30|       | * \tparam Derived is the derived type, e.g., a matrix type or an expression.
   31|       | *
   32|       | * This class can be extended with the help of the plugin mechanism described on the page
   33|       | * \ref TopicCustomizing_Plugins by defining the preprocessor symbol \c EIGEN_DENSEBASE_PLUGIN.
   34|       | *
   35|       | * \sa \blank \ref TopicClassHierarchy
   36|       | */
   37|       |template <typename Derived>
   38|       |class DenseBase
   39|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
   40|       |    : public DenseCoeffsBase<Derived, internal::accessors_level<Derived>::value>
   41|       |#else
   42|       |    : public DenseCoeffsBase<Derived, DirectWriteAccessors>
   43|       |#endif  // not EIGEN_PARSED_BY_DOXYGEN
   44|       |{
   45|       | public:
   46|       |  /** Inner iterator type to iterate over the coefficients of a row or column.
   47|       |   * \sa class InnerIterator
   48|       |   */
   49|       |  typedef Eigen::InnerIterator<Derived> InnerIterator;
   50|       |
   51|       |  typedef typename internal::traits<Derived>::StorageKind StorageKind;
   52|       |
   53|       |  /**
   54|       |   * \brief The type used to store indices
   55|       |   * \details This typedef is relevant for types that store multiple indices such as
   56|       |   *          PermutationMatrix or Transpositions, otherwise it defaults to Eigen::Index
   57|       |   * \sa \blank \ref TopicPreprocessorDirectives, Eigen::Index, SparseMatrixBase.
   58|       |   */
   59|       |  typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
   60|       |
   61|       |  /** The numeric type of the expression' coefficients, e.g. float, double, int or std::complex<float>, etc. */
   62|       |  typedef typename internal::traits<Derived>::Scalar Scalar;
   63|       |
   64|       |  /** The numeric type of the expression' coefficients, e.g. float, double, int or std::complex<float>, etc.
   65|       |   *
   66|       |   * It is an alias for the Scalar type */
   67|       |  typedef Scalar value_type;
   68|       |
   69|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
   70|       |  typedef DenseCoeffsBase<Derived, internal::accessors_level<Derived>::value> Base;
   71|       |
   72|       |  using Base::coeff;
   73|       |  using Base::coeffByOuterInner;
   74|       |  using Base::colIndexByOuterInner;
   75|       |  using Base::cols;
   76|       |  using Base::const_cast_derived;
   77|       |  using Base::derived;
   78|       |  using Base::rowIndexByOuterInner;
   79|       |  using Base::rows;
   80|       |  using Base::size;
   81|       |  using Base::operator();
   82|       |  using Base::operator[];
   83|       |  using Base::colStride;
   84|       |  using Base::innerStride;
   85|       |  using Base::outerStride;
   86|       |  using Base::rowStride;
   87|       |  using Base::stride;
   88|       |  using Base::w;
   89|       |  using Base::x;
   90|       |  using Base::y;
   91|       |  using Base::z;
   92|       |  typedef typename Base::CoeffReturnType CoeffReturnType;
   93|       |
   94|       |  enum {
   95|       |
   96|       |    RowsAtCompileTime = internal::traits<Derived>::RowsAtCompileTime,
   97|       |    /**< The number of rows at compile-time. This is just a copy of the value provided
   98|       |     * by the \a Derived type. If a value is not known at compile-time,
   99|       |     * it is set to the \a Dynamic constant.
  100|       |     * \sa MatrixBase::rows(), MatrixBase::cols(), ColsAtCompileTime, SizeAtCompileTime */
  101|       |
  102|       |    ColsAtCompileTime = internal::traits<Derived>::ColsAtCompileTime,
  103|       |    /**< The number of columns at compile-time. This is just a copy of the value provided
  104|       |     * by the \a Derived type. If a value is not known at compile-time,
  105|       |     * it is set to the \a Dynamic constant.
  106|       |     * \sa MatrixBase::rows(), MatrixBase::cols(), RowsAtCompileTime, SizeAtCompileTime */
  107|       |
  108|       |    SizeAtCompileTime = (internal::size_of_xpr_at_compile_time<Derived>::ret),
  109|       |    /**< This is equal to the number of coefficients, i.e. the number of
  110|       |     * rows times the number of columns, or to \a Dynamic if this is not
  111|       |     * known at compile-time. \sa RowsAtCompileTime, ColsAtCompileTime */
  112|       |
  113|       |    MaxRowsAtCompileTime = internal::traits<Derived>::MaxRowsAtCompileTime,
  114|       |    /**< This value is equal to the maximum possible number of rows that this expression
  115|       |     * might have. If this expression might have an arbitrarily high number of rows,
  116|       |     * this value is set to \a Dynamic.
  117|       |     *
  118|       |     * This value is useful to know when evaluating an expression, in order to determine
  119|       |     * whether it is possible to avoid doing a dynamic memory allocation.
  120|       |     *
  121|       |     * \sa RowsAtCompileTime, MaxColsAtCompileTime, MaxSizeAtCompileTime
  122|       |     */
  123|       |
  124|       |    MaxColsAtCompileTime = internal::traits<Derived>::MaxColsAtCompileTime,
  125|       |    /**< This value is equal to the maximum possible number of columns that this expression
  126|       |     * might have. If this expression might have an arbitrarily high number of columns,
  127|       |     * this value is set to \a Dynamic.
  128|       |     *
  129|       |     * This value is useful to know when evaluating an expression, in order to determine
  130|       |     * whether it is possible to avoid doing a dynamic memory allocation.
  131|       |     *
  132|       |     * \sa ColsAtCompileTime, MaxRowsAtCompileTime, MaxSizeAtCompileTime
  133|       |     */
  134|       |
  135|       |    MaxSizeAtCompileTime = internal::size_at_compile_time(internal::traits<Derived>::MaxRowsAtCompileTime,
  136|       |                                                          internal::traits<Derived>::MaxColsAtCompileTime),
  137|       |    /**< This value is equal to the maximum possible number of coefficients that this expression
  138|       |     * might have. If this expression might have an arbitrarily high number of coefficients,
  139|       |     * this value is set to \a Dynamic.
  140|       |     *
  141|       |     * This value is useful to know when evaluating an expression, in order to determine
  142|       |     * whether it is possible to avoid doing a dynamic memory allocation.
  143|       |     *
  144|       |     * \sa SizeAtCompileTime, MaxRowsAtCompileTime, MaxColsAtCompileTime
  145|       |     */
  146|       |
  147|       |    IsVectorAtCompileTime =
  148|       |        internal::traits<Derived>::RowsAtCompileTime == 1 || internal::traits<Derived>::ColsAtCompileTime == 1,
  149|       |    /**< This is set to true if either the number of rows or the number of
  150|       |     * columns is known at compile-time to be equal to 1. Indeed, in that case,
  151|       |     * we are dealing with a column-vector (if there is only one column) or with
  152|       |     * a row-vector (if there is only one row). */
  153|       |
  154|       |    NumDimensions = int(MaxSizeAtCompileTime) == 1 ? 0
  155|       |                    : bool(IsVectorAtCompileTime)  ? 1
  156|       |                                                   : 2,
  157|       |    /**< This value is equal to Tensor::NumDimensions, i.e. 0 for scalars, 1 for vectors,
  158|       |     * and 2 for matrices.
  159|       |     */
  160|       |
  161|       |    Flags = internal::traits<Derived>::Flags,
  162|       |    /**< This stores expression \ref flags flags which may or may not be inherited by new expressions
  163|       |     * constructed from this one. See the \ref flags "list of flags".
  164|       |     */
  165|       |
  166|       |    IsRowMajor = int(Flags) & RowMajorBit, /**< True if this expression has row-major storage order. */
  167|       |
  168|       |    InnerSizeAtCompileTime = int(IsVectorAtCompileTime) ? int(SizeAtCompileTime)
  169|       |                             : int(IsRowMajor)          ? int(ColsAtCompileTime)
  170|       |                                                        : int(RowsAtCompileTime),
  171|       |
  172|       |    InnerStrideAtCompileTime = internal::inner_stride_at_compile_time<Derived>::ret,
  173|       |    OuterStrideAtCompileTime = internal::outer_stride_at_compile_time<Derived>::ret
  174|       |  };
  175|       |
  176|       |  typedef typename internal::find_best_packet<Scalar, SizeAtCompileTime>::type PacketScalar;
  177|       |
  178|       |  enum { IsPlainObjectBase = 0 };
  179|       |
  180|       |  /** The plain matrix type corresponding to this expression.
  181|       |   * \sa PlainObject */
  182|       |  typedef Matrix<typename internal::traits<Derived>::Scalar, internal::traits<Derived>::RowsAtCompileTime,
  183|       |                 internal::traits<Derived>::ColsAtCompileTime,
  184|       |                 AutoAlign | (internal::traits<Derived>::Flags & RowMajorBit ? RowMajor : ColMajor),
  185|       |                 internal::traits<Derived>::MaxRowsAtCompileTime, internal::traits<Derived>::MaxColsAtCompileTime>
  186|       |      PlainMatrix;
  187|       |
  188|       |  /** The plain array type corresponding to this expression.
  189|       |   * \sa PlainObject */
  190|       |  typedef Array<typename internal::traits<Derived>::Scalar, internal::traits<Derived>::RowsAtCompileTime,
  191|       |                internal::traits<Derived>::ColsAtCompileTime,
  192|       |                AutoAlign | (internal::traits<Derived>::Flags & RowMajorBit ? RowMajor : ColMajor),
  193|       |                internal::traits<Derived>::MaxRowsAtCompileTime, internal::traits<Derived>::MaxColsAtCompileTime>
  194|       |      PlainArray;
  195|       |
  196|       |  /** \brief The plain matrix or array type corresponding to this expression.
  197|       |   *
  198|       |   * This is not necessarily exactly the return type of eval(). In the case of plain matrices,
  199|       |   * the return type of eval() is a const reference to a matrix, not a matrix! It is however guaranteed
  200|       |   * that the return type of eval() is either PlainObject or const PlainObject&.
  201|       |   */
  202|       |  typedef std::conditional_t<internal::is_same<typename internal::traits<Derived>::XprKind, MatrixXpr>::value,
  203|       |                             PlainMatrix, PlainArray>
  204|       |      PlainObject;
  205|       |
  206|       |  /** \returns the outer size.
  207|       |   *
  208|       |   * \note For a vector, this returns just 1. For a matrix (non-vector), this is the major dimension
  209|       |   * with respect to the \ref TopicStorageOrders "storage order", i.e., the number of columns for a
  210|       |   * column-major matrix, and the number of rows for a row-major matrix. */
  211|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index outerSize() const {
  212|      0|    return IsVectorAtCompileTime ? 1 : int(IsRowMajor) ? this->rows() : this->cols();
  213|      0|  }
  214|       |
  215|       |  /** \returns the inner size.
  216|       |   *
  217|       |   * \note For a vector, this is just the size. For a matrix (non-vector), this is the minor dimension
  218|       |   * with respect to the \ref TopicStorageOrders "storage order", i.e., the number of rows for a
  219|       |   * column-major matrix, and the number of columns for a row-major matrix. */
  220|      9|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index innerSize() const {
  221|      9|    return IsVectorAtCompileTime ? this->size() : int(IsRowMajor) ? this->cols() : this->rows();
  222|      9|  }
  ------------------
  | _ZNK5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE9innerSizeEv:
  |  220|      9|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index innerSize() const {
  |  221|      9|    return IsVectorAtCompileTime ? this->size() : int(IsRowMajor) ? this->cols() : this->rows();
  |  222|      9|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE9innerSizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE9innerSizeEv
  ------------------
  223|       |
  224|       |  /** Only plain matrices/arrays, not expressions, may be resized; therefore the only useful resize methods are
  225|       |   * Matrix::resize() and Array::resize(). The present method only asserts that the new size equals the old size, and
  226|       |   * does nothing else.
  227|       |   */
  228|       |  EIGEN_DEVICE_FUNC void resize(Index newSize) {
  229|       |    EIGEN_ONLY_USED_FOR_DEBUG(newSize);
  230|       |    eigen_assert(newSize == this->size() && "DenseBase::resize() does not actually allow to resize.");
  231|       |  }
  232|       |  /** Only plain matrices/arrays, not expressions, may be resized; therefore the only useful resize methods are
  233|       |   * Matrix::resize() and Array::resize(). The present method only asserts that the new size equals the old size, and
  234|       |   * does nothing else.
  235|       |   */
  236|      0|  EIGEN_DEVICE_FUNC void resize(Index rows, Index cols) {
  237|      0|    EIGEN_ONLY_USED_FOR_DEBUG(rows);
  238|      0|    EIGEN_ONLY_USED_FOR_DEBUG(cols);
  239|      0|    eigen_assert(rows == this->rows() && cols == this->cols() &&
  240|      0|                 "DenseBase::resize() does not actually allow to resize.");
  241|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEE6resizeEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEE6resizeEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE6resizeEll
  ------------------
  242|       |
  243|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  244|       |  /** \internal Represents a matrix with all coefficients equal to one another*/
  245|       |  typedef CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> ConstantReturnType;
  246|       |  /** \internal Represents a matrix with all coefficients equal to zero*/
  247|       |  typedef CwiseNullaryOp<internal::scalar_zero_op<Scalar>, PlainObject> ZeroReturnType;
  248|       |  /** \internal \deprecated Represents a vector with linearly spaced coefficients that allows sequential access only. */
  249|       |  EIGEN_DEPRECATED typedef CwiseNullaryOp<internal::linspaced_op<Scalar>, PlainObject> SequentialLinSpacedReturnType;
  250|       |  /** \internal Represents a vector with linearly spaced coefficients that allows random access. */
  251|       |  typedef CwiseNullaryOp<internal::linspaced_op<Scalar>, PlainObject> RandomAccessLinSpacedReturnType;
  252|       |  /** \internal Represents a vector with equally spaced coefficients that allows random access. */
  253|       |  typedef CwiseNullaryOp<internal::equalspaced_op<Scalar>, PlainObject> RandomAccessEqualSpacedReturnType;
  254|       |  /** \internal the return type of MatrixBase::eigenvalues() */
  255|       |  typedef Matrix<typename NumTraits<typename internal::traits<Derived>::Scalar>::Real,
  256|       |                 internal::traits<Derived>::ColsAtCompileTime, 1>
  257|       |      EigenvaluesReturnType;
  258|       |
  259|       |#endif  // not EIGEN_PARSED_BY_DOXYGEN
  260|       |
  261|       |  /** Copies \a other into *this. \returns a reference to *this. */
  262|       |  template <typename OtherDerived>
  263|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const DenseBase<OtherDerived>& other);
  264|       |
  265|       |  /** Special case of the template operator=, in order to prevent the compiler
  266|       |   * from generating a default operator= (issue hit with g++ 4.1)
  267|       |   */
  268|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const DenseBase& other);
  269|       |
  270|       |  template <typename OtherDerived>
  271|       |  EIGEN_DEVICE_FUNC Derived& operator=(const EigenBase<OtherDerived>& other);
  272|       |
  273|       |  template <typename OtherDerived>
  274|       |  EIGEN_DEVICE_FUNC Derived& operator+=(const EigenBase<OtherDerived>& other);
  275|       |
  276|       |  template <typename OtherDerived>
  277|       |  EIGEN_DEVICE_FUNC Derived& operator-=(const EigenBase<OtherDerived>& other);
  278|       |
  279|       |  template <typename OtherDerived>
  280|       |  EIGEN_DEVICE_FUNC Derived& operator=(const ReturnByValue<OtherDerived>& func);
  281|       |
  282|       |  /** \internal
  283|       |   * Copies \a other into *this without evaluating other. \returns a reference to *this. */
  284|       |  template <typename OtherDerived>
  285|       |  /** \deprecated */
  286|       |  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC Derived& lazyAssign(const DenseBase<OtherDerived>& other);
  287|       |
  288|       |  EIGEN_DEVICE_FUNC CommaInitializer<Derived> operator<<(const Scalar& s);
  289|       |
  290|       |  template <unsigned int Added, unsigned int Removed>
  291|       |  /** \deprecated it now returns \c *this */
  292|       |  EIGEN_DEPRECATED const Derived& flagged() const {
  293|       |    return derived();
  294|       |  }
  295|       |
  296|       |  template <typename OtherDerived>
  297|       |  EIGEN_DEVICE_FUNC CommaInitializer<Derived> operator<<(const DenseBase<OtherDerived>& other);
  298|       |
  299|       |  typedef Transpose<Derived> TransposeReturnType;
  300|       |  EIGEN_DEVICE_FUNC TransposeReturnType transpose();
  301|       |  typedef Transpose<const Derived> ConstTransposeReturnType;
  302|       |  EIGEN_DEVICE_FUNC const ConstTransposeReturnType transpose() const;
  303|       |  EIGEN_DEVICE_FUNC void transposeInPlace();
  304|       |
  305|       |  EIGEN_DEVICE_FUNC static const ConstantReturnType Constant(Index rows, Index cols, const Scalar& value);
  306|       |  EIGEN_DEVICE_FUNC static const ConstantReturnType Constant(Index size, const Scalar& value);
  307|       |  EIGEN_DEVICE_FUNC static const ConstantReturnType Constant(const Scalar& value);
  308|       |
  309|       |  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC static const RandomAccessLinSpacedReturnType LinSpaced(Sequential_t, Index size,
  310|       |                                                                                            const Scalar& low,
  311|       |                                                                                            const Scalar& high);
  312|       |  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC static const RandomAccessLinSpacedReturnType LinSpaced(Sequential_t,
  313|       |                                                                                            const Scalar& low,
  314|       |                                                                                            const Scalar& high);
  315|       |
  316|       |  EIGEN_DEVICE_FUNC static const RandomAccessLinSpacedReturnType LinSpaced(Index size, const Scalar& low,
  317|       |                                                                           const Scalar& high);
  318|       |  EIGEN_DEVICE_FUNC static const RandomAccessLinSpacedReturnType LinSpaced(const Scalar& low, const Scalar& high);
  319|       |
  320|       |  EIGEN_DEVICE_FUNC static const RandomAccessEqualSpacedReturnType EqualSpaced(Index size, const Scalar& low,
  321|       |                                                                               const Scalar& step);
  322|       |  EIGEN_DEVICE_FUNC static const RandomAccessEqualSpacedReturnType EqualSpaced(const Scalar& low, const Scalar& step);
  323|       |
  324|       |  template <typename CustomNullaryOp>
  325|       |  EIGEN_DEVICE_FUNC static const CwiseNullaryOp<CustomNullaryOp, PlainObject> NullaryExpr(Index rows, Index cols,
  326|       |                                                                                          const CustomNullaryOp& func);
  327|       |  template <typename CustomNullaryOp>
  328|       |  EIGEN_DEVICE_FUNC static const CwiseNullaryOp<CustomNullaryOp, PlainObject> NullaryExpr(Index size,
  329|       |                                                                                          const CustomNullaryOp& func);
  330|       |  template <typename CustomNullaryOp>
  331|       |  EIGEN_DEVICE_FUNC static const CwiseNullaryOp<CustomNullaryOp, PlainObject> NullaryExpr(const CustomNullaryOp& func);
  332|       |
  333|       |  EIGEN_DEVICE_FUNC static const ZeroReturnType Zero(Index rows, Index cols);
  334|       |  EIGEN_DEVICE_FUNC static const ZeroReturnType Zero(Index size);
  335|       |  EIGEN_DEVICE_FUNC static const ZeroReturnType Zero();
  336|       |  EIGEN_DEVICE_FUNC static const ConstantReturnType Ones(Index rows, Index cols);
  337|       |  EIGEN_DEVICE_FUNC static const ConstantReturnType Ones(Index size);
  338|       |  EIGEN_DEVICE_FUNC static const ConstantReturnType Ones();
  339|       |
  340|       |  EIGEN_DEVICE_FUNC void fill(const Scalar& value);
  341|       |  EIGEN_DEVICE_FUNC Derived& setConstant(const Scalar& value);
  342|       |  EIGEN_DEVICE_FUNC Derived& setLinSpaced(Index size, const Scalar& low, const Scalar& high);
  343|       |  EIGEN_DEVICE_FUNC Derived& setLinSpaced(const Scalar& low, const Scalar& high);
  344|       |  EIGEN_DEVICE_FUNC Derived& setEqualSpaced(Index size, const Scalar& low, const Scalar& step);
  345|       |  EIGEN_DEVICE_FUNC Derived& setEqualSpaced(const Scalar& low, const Scalar& step);
  346|       |  EIGEN_DEVICE_FUNC Derived& setZero();
  347|       |  EIGEN_DEVICE_FUNC Derived& setOnes();
  348|       |  EIGEN_DEVICE_FUNC Derived& setRandom();
  349|       |
  350|       |  template <typename OtherDerived>
  351|       |  EIGEN_DEVICE_FUNC bool isApprox(const DenseBase<OtherDerived>& other,
  352|       |                                  const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  353|       |  EIGEN_DEVICE_FUNC bool isMuchSmallerThan(const RealScalar& other,
  354|       |                                           const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  355|       |  template <typename OtherDerived>
  356|       |  EIGEN_DEVICE_FUNC bool isMuchSmallerThan(const DenseBase<OtherDerived>& other,
  357|       |                                           const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  358|       |
  359|       |  EIGEN_DEVICE_FUNC bool isApproxToConstant(const Scalar& value,
  360|       |                                            const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  361|       |  EIGEN_DEVICE_FUNC bool isConstant(const Scalar& value,
  362|       |                                    const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  363|       |  EIGEN_DEVICE_FUNC bool isZero(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  364|       |  EIGEN_DEVICE_FUNC bool isOnes(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  365|       |
  366|       |  EIGEN_DEVICE_FUNC inline bool hasNaN() const;
  367|       |  EIGEN_DEVICE_FUNC inline bool allFinite() const;
  368|       |
  369|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator*=(const Scalar& other);
  370|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator/=(const Scalar& other);
  371|       |
  372|       |  typedef internal::add_const_on_value_type_t<typename internal::eval<Derived>::type> EvalReturnType;
  373|       |  /** \returns the matrix or vector obtained by evaluating this expression.
  374|       |   *
  375|       |   * Notice that in the case of a plain matrix or vector (not an expression) this function just returns
  376|       |   * a const reference, in order to avoid a useless copy.
  377|       |   *
  378|       |   * \warning Be careful with eval() and the auto C++ keyword, as detailed in this \link TopicPitfalls_auto_keyword page
  379|       |   * \endlink.
  380|       |   */
  381|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EvalReturnType eval() const {
  382|       |    // Even though MSVC does not honor strong inlining when the return type
  383|       |    // is a dynamic matrix, we desperately need strong inlining for fixed
  384|       |    // size types on MSVC.
  385|       |    return typename internal::eval<Derived>::type(derived());
  386|       |  }
  387|       |
  388|       |  /** swaps *this with the expression \a other.
  389|       |   *
  390|       |   */
  391|       |  template <typename OtherDerived>
  392|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void swap(const DenseBase<OtherDerived>& other) {
  393|       |    EIGEN_STATIC_ASSERT(!OtherDerived::IsPlainObjectBase, THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY);
  394|       |    eigen_assert(rows() == other.rows() && cols() == other.cols());
  395|       |    call_assignment(derived(), other.const_cast_derived(), internal::swap_assign_op<Scalar>());
  396|       |  }
  397|       |
  398|       |  /** swaps *this with the matrix or array \a other.
  399|       |   *
  400|       |   */
  401|       |  template <typename OtherDerived>
  402|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void swap(PlainObjectBase<OtherDerived>& other) {
  403|       |    eigen_assert(rows() == other.rows() && cols() == other.cols());
  404|       |    call_assignment(derived(), other.derived(), internal::swap_assign_op<Scalar>());
  405|       |  }
  406|       |
  407|       |  EIGEN_DEVICE_FUNC inline const NestByValue<Derived> nestByValue() const;
  408|       |  EIGEN_DEVICE_FUNC inline const ForceAlignedAccess<Derived> forceAlignedAccess() const;
  409|       |  EIGEN_DEVICE_FUNC inline ForceAlignedAccess<Derived> forceAlignedAccess();
  410|       |  template <bool Enable>
  411|       |  EIGEN_DEVICE_FUNC inline const std::conditional_t<Enable, ForceAlignedAccess<Derived>, Derived&>
  412|       |  forceAlignedAccessIf() const;
  413|       |  template <bool Enable>
  414|       |  EIGEN_DEVICE_FUNC inline std::conditional_t<Enable, ForceAlignedAccess<Derived>, Derived&> forceAlignedAccessIf();
  415|       |
  416|       |  EIGEN_DEVICE_FUNC Scalar sum() const;
  417|       |  EIGEN_DEVICE_FUNC Scalar mean() const;
  418|       |  EIGEN_DEVICE_FUNC Scalar trace() const;
  419|       |
  420|       |  EIGEN_DEVICE_FUNC Scalar prod() const;
  421|       |
  422|       |  template <int NaNPropagation>
  423|       |  EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar minCoeff() const;
  424|       |  template <int NaNPropagation>
  425|       |  EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar maxCoeff() const;
  426|       |
  427|       |  // By default, the fastest version with undefined NaN propagation semantics is
  428|       |  // used.
  429|       |  // TODO(rmlarsen): Replace with default template argument when we move to
  430|       |  // c++11 or beyond.
  431|       |  EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar minCoeff() const {
  432|       |    return minCoeff<PropagateFast>();
  433|       |  }
  434|       |  EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar maxCoeff() const {
  435|       |    return maxCoeff<PropagateFast>();
  436|       |  }
  437|       |
  438|       |  template <int NaNPropagation, typename IndexType>
  439|       |  EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar minCoeff(IndexType* row, IndexType* col) const;
  440|       |  template <int NaNPropagation, typename IndexType>
  441|       |  EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar maxCoeff(IndexType* row, IndexType* col) const;
  442|       |  template <int NaNPropagation, typename IndexType>
  443|       |  EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar minCoeff(IndexType* index) const;
  444|       |  template <int NaNPropagation, typename IndexType>
  445|       |  EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar maxCoeff(IndexType* index) const;
  446|       |
  447|       |  // TODO(rmlarsen): Replace these methods with a default template argument.
  448|       |  template <typename IndexType>
  449|       |  EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar minCoeff(IndexType* row, IndexType* col) const {
  450|       |    return minCoeff<PropagateFast>(row, col);
  451|       |  }
  452|       |  template <typename IndexType>
  453|       |  EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar maxCoeff(IndexType* row, IndexType* col) const {
  454|       |    return maxCoeff<PropagateFast>(row, col);
  455|       |  }
  456|       |  template <typename IndexType>
  457|       |  EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar minCoeff(IndexType* index) const {
  458|       |    return minCoeff<PropagateFast>(index);
  459|       |  }
  460|       |  template <typename IndexType>
  461|       |  EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar maxCoeff(IndexType* index) const {
  462|       |    return maxCoeff<PropagateFast>(index);
  463|       |  }
  464|       |
  465|       |  template <typename BinaryOp>
  466|       |  EIGEN_DEVICE_FUNC Scalar redux(const BinaryOp& func) const;
  467|       |
  468|       |  template <typename Visitor>
  469|       |  EIGEN_DEVICE_FUNC void visit(Visitor& func) const;
  470|       |
  471|       |  /** \returns a WithFormat proxy object allowing to print a matrix the with given
  472|       |   * format \a fmt.
  473|       |   *
  474|       |   * See class IOFormat for some examples.
  475|       |   *
  476|       |   * \sa class IOFormat, class WithFormat
  477|       |   */
  478|       |  inline const WithFormat<Derived> format(const IOFormat& fmt) const { return WithFormat<Derived>(derived(), fmt); }
  479|       |
  480|       |  /** \returns the unique coefficient of a 1x1 expression */
  481|       |  EIGEN_DEVICE_FUNC CoeffReturnType value() const {
  482|       |    EIGEN_STATIC_ASSERT_SIZE_1x1(Derived) eigen_assert(this->rows() == 1 && this->cols() == 1);
  483|       |    return derived().coeff(0, 0);
  484|       |  }
  485|       |
  486|       |  EIGEN_DEVICE_FUNC bool all() const;
  487|       |  EIGEN_DEVICE_FUNC bool any() const;
  488|       |  EIGEN_DEVICE_FUNC Index count() const;
  489|       |
  490|       |  typedef VectorwiseOp<Derived, Horizontal> RowwiseReturnType;
  491|       |  typedef const VectorwiseOp<const Derived, Horizontal> ConstRowwiseReturnType;
  492|       |  typedef VectorwiseOp<Derived, Vertical> ColwiseReturnType;
  493|       |  typedef const VectorwiseOp<const Derived, Vertical> ConstColwiseReturnType;
  494|       |
  495|       |  /** \returns a VectorwiseOp wrapper of *this for broadcasting and partial reductions
  496|       |   *
  497|       |   * Example: \include MatrixBase_rowwise.cpp
  498|       |   * Output: \verbinclude MatrixBase_rowwise.out
  499|       |   *
  500|       |   * \sa colwise(), class VectorwiseOp, \ref TutorialReductionsVisitorsBroadcasting
  501|       |   */
  502|       |  // Code moved here due to a CUDA compiler bug
  503|       |  EIGEN_DEVICE_FUNC inline ConstRowwiseReturnType rowwise() const { return ConstRowwiseReturnType(derived()); }
  504|       |  EIGEN_DEVICE_FUNC RowwiseReturnType rowwise();
  505|       |
  506|       |  /** \returns a VectorwiseOp wrapper of *this broadcasting and partial reductions
  507|       |   *
  508|       |   * Example: \include MatrixBase_colwise.cpp
  509|       |   * Output: \verbinclude MatrixBase_colwise.out
  510|       |   *
  511|       |   * \sa rowwise(), class VectorwiseOp, \ref TutorialReductionsVisitorsBroadcasting
  512|       |   */
  513|       |  EIGEN_DEVICE_FUNC inline ConstColwiseReturnType colwise() const { return ConstColwiseReturnType(derived()); }
  514|       |  EIGEN_DEVICE_FUNC ColwiseReturnType colwise();
  515|       |
  516|       |  typedef CwiseNullaryOp<internal::scalar_random_op<Scalar>, PlainObject> RandomReturnType;
  517|       |  static const RandomReturnType Random(Index rows, Index cols);
  518|       |  static const RandomReturnType Random(Index size);
  519|       |  static const RandomReturnType Random();
  520|       |
  521|       |  template <typename ThenDerived, typename ElseDerived>
  522|       |  inline EIGEN_DEVICE_FUNC
  523|       |      CwiseTernaryOp<internal::scalar_boolean_select_op<typename DenseBase<ThenDerived>::Scalar,
  524|       |                                                        typename DenseBase<ElseDerived>::Scalar, Scalar>,
  525|       |                     ThenDerived, ElseDerived, Derived>
  526|       |      select(const DenseBase<ThenDerived>& thenMatrix, const DenseBase<ElseDerived>& elseMatrix) const;
  527|       |
  528|       |  template <typename ThenDerived>
  529|       |  inline EIGEN_DEVICE_FUNC
  530|       |      CwiseTernaryOp<internal::scalar_boolean_select_op<typename DenseBase<ThenDerived>::Scalar,
  531|       |                                                        typename DenseBase<ThenDerived>::Scalar, Scalar>,
  532|       |                     ThenDerived, typename DenseBase<ThenDerived>::ConstantReturnType, Derived>
  533|       |      select(const DenseBase<ThenDerived>& thenMatrix, const typename DenseBase<ThenDerived>::Scalar& elseScalar) const;
  534|       |
  535|       |  template <typename ElseDerived>
  536|       |  inline EIGEN_DEVICE_FUNC
  537|       |      CwiseTernaryOp<internal::scalar_boolean_select_op<typename DenseBase<ElseDerived>::Scalar,
  538|       |                                                        typename DenseBase<ElseDerived>::Scalar, Scalar>,
  539|       |                     typename DenseBase<ElseDerived>::ConstantReturnType, ElseDerived, Derived>
  540|       |      select(const typename DenseBase<ElseDerived>::Scalar& thenScalar, const DenseBase<ElseDerived>& elseMatrix) const;
  541|       |
  542|       |  template <int p>
  543|       |  RealScalar lpNorm() const;
  544|       |
  545|       |  template <int RowFactor, int ColFactor>
  546|       |  EIGEN_DEVICE_FUNC const Replicate<Derived, RowFactor, ColFactor> replicate() const;
  547|       |  /**
  548|       |   * \return an expression of the replication of \c *this
  549|       |   *
  550|       |   * Example: \include MatrixBase_replicate_int_int.cpp
  551|       |   * Output: \verbinclude MatrixBase_replicate_int_int.out
  552|       |   *
  553|       |   * \sa VectorwiseOp::replicate(), DenseBase::replicate<int,int>(), class Replicate
  554|       |   */
  555|       |  // Code moved here due to a CUDA compiler bug
  556|       |  EIGEN_DEVICE_FUNC const Replicate<Derived, Dynamic, Dynamic> replicate(Index rowFactor, Index colFactor) const {
  557|       |    return Replicate<Derived, Dynamic, Dynamic>(derived(), rowFactor, colFactor);
  558|       |  }
  559|       |
  560|       |  typedef Reverse<Derived, BothDirections> ReverseReturnType;
  561|       |  typedef const Reverse<const Derived, BothDirections> ConstReverseReturnType;
  562|       |  EIGEN_DEVICE_FUNC ReverseReturnType reverse();
  563|       |  /** This is the const version of reverse(). */
  564|       |  // Code moved here due to a CUDA compiler bug
  565|       |  EIGEN_DEVICE_FUNC ConstReverseReturnType reverse() const { return ConstReverseReturnType(derived()); }
  566|       |  EIGEN_DEVICE_FUNC void reverseInPlace();
  567|       |
  568|       |#ifdef EIGEN_PARSED_BY_DOXYGEN
  569|       |  /** STL-like <a href="https://en.cppreference.com/w/cpp/named_req/RandomAccessIterator">RandomAccessIterator</a>
  570|       |   * iterator type as returned by the begin() and end() methods.
  571|       |   */
  572|       |  typedef random_access_iterator_type iterator;
  573|       |  /** This is the const version of iterator (aka read-only) */
  574|       |  typedef random_access_iterator_type const_iterator;
  575|       |#else
  576|       |  typedef std::conditional_t<(Flags & DirectAccessBit) == DirectAccessBit,
  577|       |                             internal::pointer_based_stl_iterator<Derived>,
  578|       |                             internal::generic_randaccess_stl_iterator<Derived> >
  579|       |      iterator_type;
  580|       |
  581|       |  typedef std::conditional_t<(Flags & DirectAccessBit) == DirectAccessBit,
  582|       |                             internal::pointer_based_stl_iterator<const Derived>,
  583|       |                             internal::generic_randaccess_stl_iterator<const Derived> >
  584|       |      const_iterator_type;
  585|       |
  586|       |  // Stl-style iterators are supported only for vectors.
  587|       |
  588|       |  typedef std::conditional_t<IsVectorAtCompileTime, iterator_type, void> iterator;
  589|       |
  590|       |  typedef std::conditional_t<IsVectorAtCompileTime, const_iterator_type, void> const_iterator;
  591|       |#endif
  592|       |
  593|       |  inline iterator begin();
  594|       |  inline const_iterator begin() const;
  595|       |  inline const_iterator cbegin() const;
  596|       |  inline iterator end();
  597|       |  inline const_iterator end() const;
  598|       |  inline const_iterator cend() const;
  599|       |
  600|       |#define EIGEN_CURRENT_STORAGE_BASE_CLASS Eigen::DenseBase
  601|       |#define EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  602|       |#define EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(COND)
  603|       |#define EIGEN_DOC_UNARY_ADDONS(X, Y)
  604|       |#include "../plugins/CommonCwiseUnaryOps.inc"
  605|       |#include "../plugins/BlockMethods.inc"
  606|       |#include "../plugins/IndexedViewMethods.inc"
  607|       |#include "../plugins/ReshapedMethods.inc"
  608|       |#ifdef EIGEN_DENSEBASE_PLUGIN
  609|       |#include EIGEN_DENSEBASE_PLUGIN
  610|       |#endif
  611|       |#undef EIGEN_CURRENT_STORAGE_BASE_CLASS
  612|       |#undef EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  613|       |#undef EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF
  614|       |#undef EIGEN_DOC_UNARY_ADDONS
  615|       |
  616|       |  // disable the use of evalTo for dense objects with a nice compilation error
  617|       |  template <typename Dest>
  618|       |  EIGEN_DEVICE_FUNC inline void evalTo(Dest&) const {
  619|       |    EIGEN_STATIC_ASSERT((internal::is_same<Dest, void>::value),
  620|       |                        THE_EVAL_EVALTO_FUNCTION_SHOULD_NEVER_BE_CALLED_FOR_DENSE_OBJECTS);
  621|       |  }
  622|       |
  623|       | protected:
  624|       |  EIGEN_DEFAULT_COPY_CONSTRUCTOR(DenseBase)
  625|       |  /** Default constructor. Do nothing. */
  626|       |#ifdef EIGEN_INTERNAL_DEBUGGING
  627|     19|  EIGEN_DEVICE_FUNC constexpr DenseBase() {
  628|       |    /* Just checks for self-consistency of the flags.
  629|       |     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
  630|       |     */
  631|     19|    EIGEN_STATIC_ASSERT(
  632|     19|        (internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1, int(IsRowMajor)) &&
  633|     19|         internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1, int(!IsRowMajor))),
  634|     19|        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
  635|     19|  }
  ------------------
  | _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEC2Ev:
  |  627|      3|  EIGEN_DEVICE_FUNC constexpr DenseBase() {
  |  628|       |    /* Just checks for self-consistency of the flags.
  |  629|       |     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
  |  630|       |     */
  |  631|      3|    EIGEN_STATIC_ASSERT(
  |  632|      3|        (internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1, int(IsRowMajor)) &&
  |  633|      3|         internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1, int(!IsRowMajor))),
  |  634|      3|        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
  |  635|      3|  }
  ------------------
  | _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEC2Ev:
  |  627|      6|  EIGEN_DEVICE_FUNC constexpr DenseBase() {
  |  628|       |    /* Just checks for self-consistency of the flags.
  |  629|       |     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
  |  630|       |     */
  |  631|      6|    EIGEN_STATIC_ASSERT(
  |  632|      6|        (internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1, int(IsRowMajor)) &&
  |  633|      6|         internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1, int(!IsRowMajor))),
  |  634|      6|        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
  |  635|      6|  }
  ------------------
  | _ZN5Eigen9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEEEC2Ev:
  |  627|      2|  EIGEN_DEVICE_FUNC constexpr DenseBase() {
  |  628|       |    /* Just checks for self-consistency of the flags.
  |  629|       |     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
  |  630|       |     */
  |  631|      2|    EIGEN_STATIC_ASSERT(
  |  632|      2|        (internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1, int(IsRowMajor)) &&
  |  633|      2|         internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1, int(!IsRowMajor))),
  |  634|      2|        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
  |  635|      2|  }
  ------------------
  | _ZN5Eigen9DenseBaseINS_7ProductINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEENS2_IS3_Lin1ELi1ELi0ELin1ELi1EEELi0EEEEC2Ev:
  |  627|      1|  EIGEN_DEVICE_FUNC constexpr DenseBase() {
  |  628|       |    /* Just checks for self-consistency of the flags.
  |  629|       |     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
  |  630|       |     */
  |  631|      1|    EIGEN_STATIC_ASSERT(
  |  632|      1|        (internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1, int(IsRowMajor)) &&
  |  633|      1|         internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1, int(!IsRowMajor))),
  |  634|      1|        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
  |  635|      1|  }
  ------------------
  | _ZN5Eigen9DenseBaseINS_14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEEEEEC2Ev:
  |  627|      1|  EIGEN_DEVICE_FUNC constexpr DenseBase() {
  |  628|       |    /* Just checks for self-consistency of the flags.
  |  629|       |     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
  |  630|       |     */
  |  631|      1|    EIGEN_STATIC_ASSERT(
  |  632|      1|        (internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1, int(IsRowMajor)) &&
  |  633|      1|         internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1, int(!IsRowMajor))),
  |  634|      1|        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
  |  635|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li1EEEEC2Ev
  ------------------
  | _ZN5Eigen9DenseBaseINS_14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEEEEEC2Ev:
  |  627|      3|  EIGEN_DEVICE_FUNC constexpr DenseBase() {
  |  628|       |    /* Just checks for self-consistency of the flags.
  |  629|       |     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
  |  630|       |     */
  |  631|      3|    EIGEN_STATIC_ASSERT(
  |  632|      3|        (internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1, int(IsRowMajor)) &&
  |  633|      3|         internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1, int(!IsRowMajor))),
  |  634|      3|        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
  |  635|      3|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockINS_9TransposeINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | _ZN5Eigen9DenseBaseINS_7ProductINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEES4_Li0EEEEC2Ev:
  |  627|      1|  EIGEN_DEVICE_FUNC constexpr DenseBase() {
  |  628|       |    /* Just checks for self-consistency of the flags.
  |  629|       |     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
  |  630|       |     */
  |  631|      1|    EIGEN_STATIC_ASSERT(
  |  632|      1|        (internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1, int(IsRowMajor)) &&
  |  633|      1|         internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1, int(!IsRowMajor))),
  |  634|      1|        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
  |  635|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_7ProductINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEES4_Li1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_5BlockIKNS1_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEEC2Ev
  ------------------
  | _ZN5Eigen9DenseBaseINS_13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EEEC2Ev:
  |  627|      2|  EIGEN_DEVICE_FUNC constexpr DenseBase() {
  |  628|       |    /* Just checks for self-consistency of the flags.
  |  629|       |     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
  |  630|       |     */
  |  631|      2|    EIGEN_STATIC_ASSERT(
  |  632|      2|        (internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1, int(IsRowMajor)) &&
  |  633|      2|         internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1, int(!IsRowMajor))),
  |  634|      2|        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
  |  635|      2|  }
  ------------------
  636|       |#else
  637|       |  EIGEN_DEVICE_FUNC constexpr DenseBase() = default;
  638|       |#endif
  639|       |
  640|       | private:
  641|       |  EIGEN_DEVICE_FUNC explicit DenseBase(int);
  642|       |  EIGEN_DEVICE_FUNC DenseBase(int, int);
  643|       |  template <typename OtherDerived>
  644|       |  EIGEN_DEVICE_FUNC explicit DenseBase(const DenseBase<OtherDerived>&);
  645|       |};
  646|       |
  647|       |/** Free-function swap.
  648|       | */
  649|       |template <typename DerivedA, typename DerivedB>
  650|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  651|       |    // Use forwarding references to capture all combinations of cv-qualified l+r-value cases.
  652|       |    std::enable_if_t<std::is_base_of<DenseBase<std::decay_t<DerivedA>>, std::decay_t<DerivedA>>::value &&
  653|       |                         std::is_base_of<DenseBase<std::decay_t<DerivedB>>, std::decay_t<DerivedB>>::value,
  654|       |                     void>
  655|       |    swap(DerivedA&& a, DerivedB&& b) {
  656|       |  a.swap(b);
  657|       |}
  658|       |
  659|       |}  // end namespace Eigen
  660|       |
  661|       |#endif  // EIGEN_DENSEBASE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/DenseCoeffsBase.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_DENSECOEFFSBASE_H
   11|       |#define EIGEN_DENSECOEFFSBASE_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "./InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |template <typename T>
   20|       |struct add_const_on_value_type_if_arithmetic {
   21|       |  typedef std::conditional_t<is_arithmetic<T>::value, T, add_const_on_value_type_t<T>> type;
   22|       |};
   23|       |}  // namespace internal
   24|       |
   25|       |/** \brief Base class providing read-only coefficient access to matrices and arrays.
   26|       | * \ingroup Core_Module
   27|       | * \tparam Derived Type of the derived class
   28|       | *
   29|       | * \note #ReadOnlyAccessors Constant indicating read-only access
   30|       | *
   31|       | * This class defines the \c operator() \c const function and friends, which can be used to read specific
   32|       | * entries of a matrix or array.
   33|       | *
   34|       | * \sa DenseCoeffsBase<Derived, WriteAccessors>, DenseCoeffsBase<Derived, DirectAccessors>,
   35|       | *     \ref TopicClassHierarchy
   36|       | */
   37|       |template <typename Derived>
   38|       |class DenseCoeffsBase<Derived, ReadOnlyAccessors> : public EigenBase<Derived> {
   39|       | public:
   40|       |  typedef typename internal::traits<Derived>::StorageKind StorageKind;
   41|       |  typedef typename internal::traits<Derived>::Scalar Scalar;
   42|       |  typedef typename internal::packet_traits<Scalar>::type PacketScalar;
   43|       |
   44|       |  // Explanation for this CoeffReturnType typedef.
   45|       |  // - This is the return type of the coeff() method.
   46|       |  // - The LvalueBit means exactly that we can offer a coeffRef() method, which means exactly that we can get references
   47|       |  // to coeffs, which means exactly that we can have coeff() return a const reference (as opposed to returning a value).
   48|       |  // - The is_arithmetic check is required since "const int", "const double", etc. will cause warnings on some systems
   49|       |  // while the declaration of "const T", where T is a non arithmetic type does not. Always returning "const Scalar&" is
   50|       |  // not possible, since the underlying expressions might not offer a valid address the reference could be referring to.
   51|       |  typedef std::conditional_t<bool(internal::traits<Derived>::Flags& LvalueBit), const Scalar&,
   52|       |                             std::conditional_t<internal::is_arithmetic<Scalar>::value, Scalar, const Scalar>>
   53|       |      CoeffReturnType;
   54|       |
   55|       |  typedef typename internal::add_const_on_value_type_if_arithmetic<typename internal::packet_traits<Scalar>::type>::type
   56|       |      PacketReturnType;
   57|       |
   58|       |  typedef EigenBase<Derived> Base;
   59|       |  using Base::cols;
   60|       |  using Base::derived;
   61|       |  using Base::rows;
   62|       |  using Base::size;
   63|       |
   64|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index rowIndexByOuterInner(Index outer, Index inner) const {
   65|       |    return int(Derived::RowsAtCompileTime) == 1   ? 0
   66|       |           : int(Derived::ColsAtCompileTime) == 1 ? inner
   67|       |           : int(Derived::Flags) & RowMajorBit    ? outer
   68|       |                                                  : inner;
   69|       |  }
   70|       |
   71|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index colIndexByOuterInner(Index outer, Index inner) const {
   72|       |    return int(Derived::ColsAtCompileTime) == 1   ? 0
   73|       |           : int(Derived::RowsAtCompileTime) == 1 ? inner
   74|       |           : int(Derived::Flags) & RowMajorBit    ? inner
   75|       |                                                  : outer;
   76|       |  }
   77|       |
   78|       |  /** Short version: don't use this function, use
   79|       |   * \link operator()(Index,Index) const \endlink instead.
   80|       |   *
   81|       |   * Long version: this function is similar to
   82|       |   * \link operator()(Index,Index) const \endlink, but without the assertion.
   83|       |   * Use this for limiting the performance cost of debugging code when doing
   84|       |   * repeated coefficient access. Only use this when it is guaranteed that the
   85|       |   * parameters \a row and \a col are in range.
   86|       |   *
   87|       |   * If EIGEN_INTERNAL_DEBUGGING is defined, an assertion will be made, making this
   88|       |   * function equivalent to \link operator()(Index,Index) const \endlink.
   89|       |   *
   90|       |   * \sa operator()(Index,Index) const, coeffRef(Index,Index), coeff(Index) const
   91|       |   */
   92|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType coeff(Index row, Index col) const {
   93|       |    eigen_internal_assert(row >= 0 && row < rows() && col >= 0 && col < cols());
   94|       |    return internal::evaluator<Derived>(derived()).coeff(row, col);
   95|       |  }
   96|       |
   97|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType coeffByOuterInner(Index outer,
   98|       |                                                                                          Index inner) const {
   99|       |    return coeff(rowIndexByOuterInner(outer, inner), colIndexByOuterInner(outer, inner));
  100|       |  }
  101|       |
  102|       |  /** \returns the coefficient at given the given row and column.
  103|       |   *
  104|       |   * \sa operator()(Index,Index), operator[](Index)
  105|       |   */
  106|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType operator()(Index row, Index col) const {
  107|       |    eigen_assert(row >= 0 && row < rows() && col >= 0 && col < cols());
  108|       |    return coeff(row, col);
  109|       |  }
  110|       |
  111|       |  /** Short version: don't use this function, use
  112|       |   * \link operator[](Index) const \endlink instead.
  113|       |   *
  114|       |   * Long version: this function is similar to
  115|       |   * \link operator[](Index) const \endlink, but without the assertion.
  116|       |   * Use this for limiting the performance cost of debugging code when doing
  117|       |   * repeated coefficient access. Only use this when it is guaranteed that the
  118|       |   * parameter \a index is in range.
  119|       |   *
  120|       |   * If EIGEN_INTERNAL_DEBUGGING is defined, an assertion will be made, making this
  121|       |   * function equivalent to \link operator[](Index) const \endlink.
  122|       |   *
  123|       |   * \sa operator[](Index) const, coeffRef(Index), coeff(Index,Index) const
  124|       |   */
  125|       |
  126|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType coeff(Index index) const {
  127|       |    EIGEN_STATIC_ASSERT(internal::evaluator<Derived>::Flags & LinearAccessBit,
  128|       |                        THIS_COEFFICIENT_ACCESSOR_TAKING_ONE_ACCESS_IS_ONLY_FOR_EXPRESSIONS_ALLOWING_LINEAR_ACCESS)
  129|       |    eigen_internal_assert(index >= 0 && index < size());
  130|       |    return internal::evaluator<Derived>(derived()).coeff(index);
  131|       |  }
  132|       |
  133|       |  /** \returns the coefficient at given index.
  134|       |   *
  135|       |   * This method is allowed only for vector expressions, and for matrix expressions having the LinearAccessBit.
  136|       |   *
  137|       |   * \sa operator[](Index), operator()(Index,Index) const, x() const, y() const,
  138|       |   * z() const, w() const
  139|       |   */
  140|       |
  141|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType operator[](Index index) const {
  142|       |    EIGEN_STATIC_ASSERT(Derived::IsVectorAtCompileTime,
  143|       |                        THE_BRACKET_OPERATOR_IS_ONLY_FOR_VECTORS__USE_THE_PARENTHESIS_OPERATOR_INSTEAD)
  144|       |    eigen_assert(index >= 0 && index < size());
  145|       |    return coeff(index);
  146|       |  }
  147|       |
  148|       |  /** \returns the coefficient at given index.
  149|       |   *
  150|       |   * This is synonymous to operator[](Index) const.
  151|       |   *
  152|       |   * This method is allowed only for vector expressions, and for matrix expressions having the LinearAccessBit.
  153|       |   *
  154|       |   * \sa operator[](Index), operator()(Index,Index) const, x() const, y() const,
  155|       |   * z() const, w() const
  156|       |   */
  157|       |
  158|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType operator()(Index index) const {
  159|       |    eigen_assert(index >= 0 && index < size());
  160|       |    return coeff(index);
  161|       |  }
  162|       |
  163|       |  /** equivalent to operator[](0).  */
  164|       |
  165|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType x() const { return (*this)[0]; }
  166|       |
  167|       |  /** equivalent to operator[](1).  */
  168|       |
  169|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType y() const {
  170|       |    EIGEN_STATIC_ASSERT(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 2, OUT_OF_RANGE_ACCESS);
  171|       |    return (*this)[1];
  172|       |  }
  173|       |
  174|       |  /** equivalent to operator[](2).  */
  175|       |
  176|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType z() const {
  177|       |    EIGEN_STATIC_ASSERT(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 3, OUT_OF_RANGE_ACCESS);
  178|       |    return (*this)[2];
  179|       |  }
  180|       |
  181|       |  /** equivalent to operator[](3).  */
  182|       |
  183|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR CoeffReturnType w() const {
  184|       |    EIGEN_STATIC_ASSERT(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 4, OUT_OF_RANGE_ACCESS);
  185|       |    return (*this)[3];
  186|       |  }
  187|       |
  188|       |  /** \internal
  189|       |   * \returns the packet of coefficients starting at the given row and column. It is your responsibility
  190|       |   * to ensure that a packet really starts there. This method is only available on expressions having the
  191|       |   * PacketAccessBit.
  192|       |   *
  193|       |   * The \a LoadMode parameter may have the value \a #Aligned or \a #Unaligned. Its effect is to select
  194|       |   * the appropriate vectorization instruction. Aligned access is faster, but is only possible for packets
  195|       |   * starting at an address which is a multiple of the packet size.
  196|       |   */
  197|       |
  198|       |  template <int LoadMode>
  199|       |  EIGEN_STRONG_INLINE PacketReturnType packet(Index row, Index col) const {
  200|       |    typedef typename internal::packet_traits<Scalar>::type DefaultPacketType;
  201|       |    eigen_internal_assert(row >= 0 && row < rows() && col >= 0 && col < cols());
  202|       |    return internal::evaluator<Derived>(derived()).template packet<LoadMode, DefaultPacketType>(row, col);
  203|       |  }
  204|       |
  205|       |  /** \internal */
  206|       |  template <int LoadMode>
  207|       |  EIGEN_STRONG_INLINE PacketReturnType packetByOuterInner(Index outer, Index inner) const {
  208|       |    return packet<LoadMode>(rowIndexByOuterInner(outer, inner), colIndexByOuterInner(outer, inner));
  209|       |  }
  210|       |
  211|       |  /** \internal
  212|       |   * \returns the packet of coefficients starting at the given index. It is your responsibility
  213|       |   * to ensure that a packet really starts there. This method is only available on expressions having the
  214|       |   * PacketAccessBit and the LinearAccessBit.
  215|       |   *
  216|       |   * The \a LoadMode parameter may have the value \a #Aligned or \a #Unaligned. Its effect is to select
  217|       |   * the appropriate vectorization instruction. Aligned access is faster, but is only possible for packets
  218|       |   * starting at an address which is a multiple of the packet size.
  219|       |   */
  220|       |
  221|       |  template <int LoadMode>
  222|       |  EIGEN_STRONG_INLINE PacketReturnType packet(Index index) const {
  223|       |    EIGEN_STATIC_ASSERT(internal::evaluator<Derived>::Flags & LinearAccessBit,
  224|       |                        THIS_COEFFICIENT_ACCESSOR_TAKING_ONE_ACCESS_IS_ONLY_FOR_EXPRESSIONS_ALLOWING_LINEAR_ACCESS)
  225|       |    typedef typename internal::packet_traits<Scalar>::type DefaultPacketType;
  226|       |    eigen_internal_assert(index >= 0 && index < size());
  227|       |    return internal::evaluator<Derived>(derived()).template packet<LoadMode, DefaultPacketType>(index);
  228|       |  }
  229|       |
  230|       | protected:
  231|       |  // explanation: DenseBase is doing "using ..." on the methods from DenseCoeffsBase.
  232|       |  // But some methods are only available in the DirectAccess case.
  233|       |  // So we add dummy methods here with these names, so that "using... " doesn't fail.
  234|       |  // It's not private so that the child class DenseBase can access them, and it's not public
  235|       |  // either since it's an implementation detail, so has to be protected.
  236|       |  void coeffRef();
  237|       |  void coeffRefByOuterInner();
  238|       |  void writePacket();
  239|       |  void writePacketByOuterInner();
  240|       |  void copyCoeff();
  241|       |  void copyCoeffByOuterInner();
  242|       |  void copyPacket();
  243|       |  void copyPacketByOuterInner();
  244|       |  void stride();
  245|       |  void innerStride();
  246|       |  void outerStride();
  247|       |  void rowStride();
  248|       |  void colStride();
  249|       |};
  250|       |
  251|       |/** \brief Base class providing read/write coefficient access to matrices and arrays.
  252|       | * \ingroup Core_Module
  253|       | * \tparam Derived Type of the derived class
  254|       | *
  255|       | * \note #WriteAccessors Constant indicating read/write access
  256|       | *
  257|       | * This class defines the non-const \c operator() function and friends, which can be used to write specific
  258|       | * entries of a matrix or array. This class inherits DenseCoeffsBase<Derived, ReadOnlyAccessors> which
  259|       | * defines the const variant for reading specific entries.
  260|       | *
  261|       | * \sa DenseCoeffsBase<Derived, DirectAccessors>, \ref TopicClassHierarchy
  262|       | */
  263|       |template <typename Derived>
  264|       |class DenseCoeffsBase<Derived, WriteAccessors> : public DenseCoeffsBase<Derived, ReadOnlyAccessors> {
  265|       | public:
  266|       |  typedef DenseCoeffsBase<Derived, ReadOnlyAccessors> Base;
  267|       |
  268|       |  typedef typename internal::traits<Derived>::StorageKind StorageKind;
  269|       |  typedef typename internal::traits<Derived>::Scalar Scalar;
  270|       |  typedef typename internal::packet_traits<Scalar>::type PacketScalar;
  271|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  272|       |
  273|       |  using Base::coeff;
  274|       |  using Base::colIndexByOuterInner;
  275|       |  using Base::cols;
  276|       |  using Base::derived;
  277|       |  using Base::rowIndexByOuterInner;
  278|       |  using Base::rows;
  279|       |  using Base::size;
  280|       |  using Base::operator[];
  281|       |  using Base::operator();
  282|       |  using Base::w;
  283|       |  using Base::x;
  284|       |  using Base::y;
  285|       |  using Base::z;
  286|       |
  287|       |  /** Short version: don't use this function, use
  288|       |   * \link operator()(Index,Index) \endlink instead.
  289|       |   *
  290|       |   * Long version: this function is similar to
  291|       |   * \link operator()(Index,Index) \endlink, but without the assertion.
  292|       |   * Use this for limiting the performance cost of debugging code when doing
  293|       |   * repeated coefficient access. Only use this when it is guaranteed that the
  294|       |   * parameters \a row and \a col are in range.
  295|       |   *
  296|       |   * If EIGEN_INTERNAL_DEBUGGING is defined, an assertion will be made, making this
  297|       |   * function equivalent to \link operator()(Index,Index) \endlink.
  298|       |   *
  299|       |   * \sa operator()(Index,Index), coeff(Index, Index) const, coeffRef(Index)
  300|       |   */
  301|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& coeffRef(Index row, Index col) {
  302|       |    eigen_internal_assert(row >= 0 && row < rows() && col >= 0 && col < cols());
  303|       |    return internal::evaluator<Derived>(derived()).coeffRef(row, col);
  304|       |  }
  305|       |
  306|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar& coeffRefByOuterInner(Index outer, Index inner) {
  307|       |    return coeffRef(rowIndexByOuterInner(outer, inner), colIndexByOuterInner(outer, inner));
  308|       |  }
  309|       |
  310|       |  /** \returns a reference to the coefficient at given the given row and column.
  311|       |   *
  312|       |   * \sa operator[](Index)
  313|       |   */
  314|       |
  315|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& operator()(Index row, Index col) {
  316|       |    eigen_assert(row >= 0 && row < rows() && col >= 0 && col < cols());
  317|       |    return coeffRef(row, col);
  318|       |  }
  319|       |
  320|       |  /** Short version: don't use this function, use
  321|       |   * \link operator[](Index) \endlink instead.
  322|       |   *
  323|       |   * Long version: this function is similar to
  324|       |   * \link operator[](Index) \endlink, but without the assertion.
  325|       |   * Use this for limiting the performance cost of debugging code when doing
  326|       |   * repeated coefficient access. Only use this when it is guaranteed that the
  327|       |   * parameters \a row and \a col are in range.
  328|       |   *
  329|       |   * If EIGEN_INTERNAL_DEBUGGING is defined, an assertion will be made, making this
  330|       |   * function equivalent to \link operator[](Index) \endlink.
  331|       |   *
  332|       |   * \sa operator[](Index), coeff(Index) const, coeffRef(Index,Index)
  333|       |   */
  334|       |
  335|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& coeffRef(Index index) {
  336|       |    EIGEN_STATIC_ASSERT(internal::evaluator<Derived>::Flags & LinearAccessBit,
  337|       |                        THIS_COEFFICIENT_ACCESSOR_TAKING_ONE_ACCESS_IS_ONLY_FOR_EXPRESSIONS_ALLOWING_LINEAR_ACCESS)
  338|       |    eigen_internal_assert(index >= 0 && index < size());
  339|       |    return internal::evaluator<Derived>(derived()).coeffRef(index);
  340|       |  }
  341|       |
  342|       |  /** \returns a reference to the coefficient at given index.
  343|       |   *
  344|       |   * This method is allowed only for vector expressions, and for matrix expressions having the LinearAccessBit.
  345|       |   *
  346|       |   * \sa operator[](Index) const, operator()(Index,Index), x(), y(), z(), w()
  347|       |   */
  348|       |
  349|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& operator[](Index index) {
  350|       |    EIGEN_STATIC_ASSERT(Derived::IsVectorAtCompileTime,
  351|       |                        THE_BRACKET_OPERATOR_IS_ONLY_FOR_VECTORS__USE_THE_PARENTHESIS_OPERATOR_INSTEAD)
  352|       |    eigen_assert(index >= 0 && index < size());
  353|       |    return coeffRef(index);
  354|       |  }
  355|       |
  356|       |  /** \returns a reference to the coefficient at given index.
  357|       |   *
  358|       |   * This is synonymous to operator[](Index).
  359|       |   *
  360|       |   * This method is allowed only for vector expressions, and for matrix expressions having the LinearAccessBit.
  361|       |   *
  362|       |   * \sa operator[](Index) const, operator()(Index,Index), x(), y(), z(), w()
  363|       |   */
  364|       |
  365|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Scalar& operator()(Index index) {
  366|       |    eigen_assert(index >= 0 && index < size());
  367|       |    return coeffRef(index);
  368|       |  }
  369|       |
  370|       |  /** equivalent to operator[](0).  */
  371|       |
  372|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Scalar& x() { return (*this)[0]; }
  373|       |
  374|       |  /** equivalent to operator[](1).  */
  375|       |
  376|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Scalar& y() {
  377|       |    EIGEN_STATIC_ASSERT(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 2, OUT_OF_RANGE_ACCESS);
  378|       |    return (*this)[1];
  379|       |  }
  380|       |
  381|       |  /** equivalent to operator[](2).  */
  382|       |
  383|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Scalar& z() {
  384|       |    EIGEN_STATIC_ASSERT(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 3, OUT_OF_RANGE_ACCESS);
  385|       |    return (*this)[2];
  386|       |  }
  387|       |
  388|       |  /** equivalent to operator[](3).  */
  389|       |
  390|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Scalar& w() {
  391|       |    EIGEN_STATIC_ASSERT(Derived::SizeAtCompileTime == -1 || Derived::SizeAtCompileTime >= 4, OUT_OF_RANGE_ACCESS);
  392|       |    return (*this)[3];
  393|       |  }
  394|       |};
  395|       |
  396|       |/** \brief Base class providing direct read-only coefficient access to matrices and arrays.
  397|       | * \ingroup Core_Module
  398|       | * \tparam Derived Type of the derived class
  399|       | *
  400|       | * \note #DirectAccessors Constant indicating direct access
  401|       | *
  402|       | * This class defines functions to work with strides which can be used to access entries directly. This class
  403|       | * inherits DenseCoeffsBase<Derived, ReadOnlyAccessors> which defines functions to access entries read-only using
  404|       | * \c operator() .
  405|       | *
  406|       | * \sa \blank \ref TopicClassHierarchy
  407|       | */
  408|       |template <typename Derived>
  409|       |class DenseCoeffsBase<Derived, DirectAccessors> : public DenseCoeffsBase<Derived, ReadOnlyAccessors> {
  410|       | public:
  411|       |  typedef DenseCoeffsBase<Derived, ReadOnlyAccessors> Base;
  412|       |  typedef typename internal::traits<Derived>::Scalar Scalar;
  413|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  414|       |
  415|       |  using Base::cols;
  416|       |  using Base::derived;
  417|       |  using Base::rows;
  418|       |  using Base::size;
  419|       |
  420|       |  /** \returns the pointer increment between two consecutive elements within a slice in the inner direction.
  421|       |   *
  422|       |   * \sa outerStride(), rowStride(), colStride()
  423|       |   */
  424|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const { return derived().innerStride(); }
  425|       |
  426|       |  /** \returns the pointer increment between two consecutive inner slices (for example, between two consecutive columns
  427|       |   *          in a column-major matrix).
  428|       |   *
  429|       |   * \sa innerStride(), rowStride(), colStride()
  430|       |   */
  431|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const { return derived().outerStride(); }
  432|       |
  433|       |  // FIXME shall we remove it ?
  434|       |  EIGEN_CONSTEXPR inline Index stride() const { return Derived::IsVectorAtCompileTime ? innerStride() : outerStride(); }
  435|       |
  436|       |  /** \returns the pointer increment between two consecutive rows.
  437|       |   *
  438|       |   * \sa innerStride(), outerStride(), colStride()
  439|       |   */
  440|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rowStride() const {
  441|       |    return Derived::IsRowMajor ? outerStride() : innerStride();
  442|       |  }
  443|       |
  444|       |  /** \returns the pointer increment between two consecutive columns.
  445|       |   *
  446|       |   * \sa innerStride(), outerStride(), rowStride()
  447|       |   */
  448|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index colStride() const {
  449|       |    return Derived::IsRowMajor ? innerStride() : outerStride();
  450|       |  }
  451|       |};
  452|       |
  453|       |/** \brief Base class providing direct read/write coefficient access to matrices and arrays.
  454|       | * \ingroup Core_Module
  455|       | * \tparam Derived Type of the derived class
  456|       | *
  457|       | * \note #DirectWriteAccessors Constant indicating direct access
  458|       | *
  459|       | * This class defines functions to work with strides which can be used to access entries directly. This class
  460|       | * inherits DenseCoeffsBase<Derived, WriteAccessors> which defines functions to access entries read/write using
  461|       | * \c operator().
  462|       | *
  463|       | * \sa \blank \ref TopicClassHierarchy
  464|       | */
  465|       |template <typename Derived>
  466|       |class DenseCoeffsBase<Derived, DirectWriteAccessors> : public DenseCoeffsBase<Derived, WriteAccessors> {
  467|       | public:
  468|       |  typedef DenseCoeffsBase<Derived, WriteAccessors> Base;
  469|       |  typedef typename internal::traits<Derived>::Scalar Scalar;
  470|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  471|       |
  472|       |  using Base::cols;
  473|       |  using Base::derived;
  474|       |  using Base::rows;
  475|       |  using Base::size;
  476|       |
  477|       |  /** \returns the pointer increment between two consecutive elements within a slice in the inner direction.
  478|       |   *
  479|       |   * \sa outerStride(), rowStride(), colStride()
  480|       |   */
  481|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const EIGEN_NOEXCEPT { return derived().innerStride(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi3EE11innerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi3EE11innerStrideEv
  ------------------
  482|       |
  483|       |  /** \returns the pointer increment between two consecutive inner slices (for example, between two consecutive columns
  484|       |   *          in a column-major matrix).
  485|       |   *
  486|       |   * \sa innerStride(), rowStride(), colStride()
  487|       |   */
  488|      3|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const EIGEN_NOEXCEPT { return derived().outerStride(); }
  ------------------
  | _ZNK5Eigen15DenseCoeffsBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi3EE11outerStrideEv:
  |  488|      3|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const EIGEN_NOEXCEPT { return derived().outerStride(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi3EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi3EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi3EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEELi3EE11outerStrideEv
  ------------------
  489|       |
  490|       |  // FIXME shall we remove it ?
  491|       |  EIGEN_CONSTEXPR inline Index stride() const EIGEN_NOEXCEPT {
  492|       |    return Derived::IsVectorAtCompileTime ? innerStride() : outerStride();
  493|       |  }
  494|       |
  495|       |  /** \returns the pointer increment between two consecutive rows.
  496|       |   *
  497|       |   * \sa innerStride(), outerStride(), colStride()
  498|       |   */
  499|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rowStride() const EIGEN_NOEXCEPT {
  500|      0|    return Derived::IsRowMajor ? outerStride() : innerStride();
  501|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi3EE9rowStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi3EE9rowStrideEv
  ------------------
  502|       |
  503|       |  /** \returns the pointer increment between two consecutive columns.
  504|       |   *
  505|       |   * \sa innerStride(), outerStride(), rowStride()
  506|       |   */
  507|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index colStride() const EIGEN_NOEXCEPT {
  508|      0|    return Derived::IsRowMajor ? innerStride() : outerStride();
  509|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi3EE9colStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15DenseCoeffsBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi3EE9colStrideEv
  ------------------
  510|       |};
  511|       |
  512|       |namespace internal {
  513|       |
  514|       |template <int Alignment, typename Derived, bool JustReturnZero>
  515|       |struct first_aligned_impl {
  516|       |  static EIGEN_CONSTEXPR inline Index run(const Derived&) EIGEN_NOEXCEPT { return 0; }
  517|       |};
  518|       |
  519|       |template <int Alignment, typename Derived>
  520|       |struct first_aligned_impl<Alignment, Derived, false> {
  521|       |  static inline Index run(const Derived& m) { return internal::first_aligned<Alignment>(m.data(), m.size()); }
  522|       |};
  523|       |
  524|       |/** \internal \returns the index of the first element of the array stored by \a m that is properly aligned with respect
  525|       | * to \a Alignment for vectorization.
  526|       | *
  527|       | * \tparam Alignment requested alignment in Bytes.
  528|       | *
  529|       | * There is also the variant first_aligned(const Scalar*, Integer) defined in Memory.h. See it for more
  530|       | * documentation.
  531|       | */
  532|       |template <int Alignment, typename Derived>
  533|       |static inline Index first_aligned(const DenseBase<Derived>& m) {
  534|       |  enum { ReturnZero = (int(evaluator<Derived>::Alignment) >= Alignment) || !(Derived::Flags & DirectAccessBit) };
  535|       |  return first_aligned_impl<Alignment, Derived, ReturnZero>::run(m.derived());
  536|       |}
  537|       |
  538|       |template <typename Derived>
  539|       |static inline Index first_default_aligned(const DenseBase<Derived>& m) {
  540|       |  typedef typename Derived::Scalar Scalar;
  541|       |  typedef typename packet_traits<Scalar>::type DefaultPacketType;
  542|       |  return internal::first_aligned<int(unpacket_traits<DefaultPacketType>::alignment), Derived>(m);
  543|       |}
  544|       |
  545|       |template <typename Derived, bool HasDirectAccess = has_direct_access<Derived>::ret>
  546|       |struct inner_stride_at_compile_time {
  547|       |  enum { ret = traits<Derived>::InnerStrideAtCompileTime };
  548|       |};
  549|       |
  550|       |template <typename Derived>
  551|       |struct inner_stride_at_compile_time<Derived, false> {
  552|       |  enum { ret = 0 };
  553|       |};
  554|       |
  555|       |template <typename Derived, bool HasDirectAccess = has_direct_access<Derived>::ret>
  556|       |struct outer_stride_at_compile_time {
  557|       |  enum { ret = traits<Derived>::OuterStrideAtCompileTime };
  558|       |};
  559|       |
  560|       |template <typename Derived>
  561|       |struct outer_stride_at_compile_time<Derived, false> {
  562|       |  enum { ret = 0 };
  563|       |};
  564|       |
  565|       |}  // end namespace internal
  566|       |
  567|       |}  // end namespace Eigen
  568|       |
  569|       |#endif  // EIGEN_DENSECOEFFSBASE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/DenseStorage.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2009 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |// Copyright (C) 2010-2013 Hauke Heibel <hauke.heibel@gmail.com>
    7|       |//
    8|       |// This Source Code Form is subject to the terms of the Mozilla
    9|       |// Public License v. 2.0. If a copy of the MPL was not distributed
   10|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   11|       |
   12|       |#ifndef EIGEN_MATRIXSTORAGE_H
   13|       |#define EIGEN_MATRIXSTORAGE_H
   14|       |
   15|       |#ifdef EIGEN_DENSE_STORAGE_CTOR_PLUGIN
   16|       |#define EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(X) \
   17|       |  X;                                                \
   18|       |  EIGEN_DENSE_STORAGE_CTOR_PLUGIN;
   19|       |#else
   20|       |#define EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(X)
   21|       |#endif
   22|       |
   23|       |// IWYU pragma: private
   24|       |#include "./InternalHeaderCheck.h"
   25|       |
   26|       |namespace Eigen {
   27|       |
   28|       |namespace internal {
   29|       |
   30|       |#if defined(EIGEN_DISABLE_UNALIGNED_ARRAY_ASSERT)
   31|       |#define EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(Alignment)
   32|       |#else
   33|       |#define EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(Alignment)                                        \
   34|       |  eigen_assert((is_constant_evaluated() || (std::uintptr_t(array) % Alignment == 0)) &&     \
   35|       |               "this assertion is explained here: "                                         \
   36|       |               "http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html" \
   37|       |               " **** READ THIS WEB PAGE !!! ****");
   38|       |#endif
   39|       |
   40|       |#if EIGEN_STACK_ALLOCATION_LIMIT
   41|       |#define EIGEN_MAKE_STACK_ALLOCATION_ASSERT(X) \
   42|       |  EIGEN_STATIC_ASSERT(X <= EIGEN_STACK_ALLOCATION_LIMIT, OBJECT_ALLOCATED_ON_STACK_IS_TOO_BIG)
   43|       |#else
   44|       |#define EIGEN_MAKE_STACK_ALLOCATION_ASSERT(X)
   45|       |#endif
   46|       |
   47|       |/** \internal
   48|       | * Static array. If the MatrixOrArrayOptions require auto-alignment, the array will be automatically aligned:
   49|       | * to 16 bytes boundary if the total size is a multiple of 16 bytes.
   50|       | */
   51|       |
   52|       |template <typename T, int Size, int MatrixOrArrayOptions,
   53|       |          int Alignment = (MatrixOrArrayOptions & DontAlign) ? 0 : compute_default_alignment<T, Size>::value>
   54|       |struct plain_array {
   55|       |  EIGEN_ALIGN_TO_BOUNDARY(Alignment) T array[Size];
   56|       |#if defined(EIGEN_NO_DEBUG) || defined(EIGEN_TESTING_PLAINOBJECT_CTOR)
   57|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() = default;
   58|       |#else
   59|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() {
   60|       |    EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(Alignment)
   61|       |    EIGEN_MAKE_STACK_ALLOCATION_ASSERT(Size * sizeof(T))
   62|       |  }
   63|       |#endif
   64|       |};
   65|       |
   66|       |template <typename T, int Size, int MatrixOrArrayOptions>
   67|       |struct plain_array<T, Size, MatrixOrArrayOptions, 0> {
   68|       |  T array[Size];
   69|       |#if defined(EIGEN_NO_DEBUG) || defined(EIGEN_TESTING_PLAINOBJECT_CTOR)
   70|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() = default;
   71|       |#else
   72|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() { EIGEN_MAKE_STACK_ALLOCATION_ASSERT(Size * sizeof(T)) }
   73|       |#endif
   74|       |};
   75|       |
   76|       |template <typename T, int MatrixOrArrayOptions, int Alignment>
   77|       |struct plain_array<T, 0, MatrixOrArrayOptions, Alignment> {
   78|       |  T array[1];
   79|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() = default;
   80|       |};
   81|       |
   82|       |template <typename T, int Size, int Options, int Alignment>
   83|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap_plain_array(plain_array<T, Size, Options, Alignment>& a,
   84|       |                                                                      plain_array<T, Size, Options, Alignment>& b,
   85|       |                                                                      Index a_size, Index b_size) {
   86|       |  Index common_size = numext::mini(a_size, b_size);
   87|       |  std::swap_ranges(a.array, a.array + common_size, b.array);
   88|       |  if (a_size > b_size)
   89|       |    smart_copy(a.array + common_size, a.array + a_size, b.array + common_size);
   90|       |  else if (b_size > a_size)
   91|       |    smart_copy(b.array + common_size, b.array + b_size, a.array + common_size);
   92|       |}
   93|       |
   94|       |template <typename T, int Size, int Rows, int Cols, int Options>
   95|       |class DenseStorage_impl {
   96|       |  plain_array<T, Size, Options> m_data;
   97|       |
   98|       | public:
   99|       |#ifndef EIGEN_DENSE_STORAGE_CTOR_PLUGIN
  100|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  101|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&) = default;
  102|       |#else
  103|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() {
  104|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = Size)
  105|       |  }
  106|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl& other) {
  107|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = Size)
  108|       |    smart_copy(other.m_data.array, other.m_data.array + Size, m_data.array);
  109|       |  }
  110|       |#endif
  111|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index /*rows*/, Index /*cols*/) {}
  112|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl&) = default;
  113|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) {
  114|       |    numext::swap(m_data, other.m_data);
  115|       |  }
  116|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index /*rows*/,
  117|       |                                                                          Index /*cols*/) {}
  118|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index /*rows*/, Index /*cols*/) {}
  119|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }
  120|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }
  121|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * Cols; }
  122|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data.array; }
  123|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data.array; }
  124|       |};
  125|       |template <typename T, int Size, int Cols, int Options>
  126|       |class DenseStorage_impl<T, Size, Dynamic, Cols, Options> {
  127|       |  plain_array<T, Size, Options> m_data;
  128|       |  Index m_rows = 0;
  129|       |
  130|       | public:
  131|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  132|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl& other)
  133|       |      : m_rows(other.m_rows) {
  134|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())
  135|       |    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);
  136|       |  }
  137|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index rows, Index /*cols*/)
  138|       |      : m_rows(rows) {
  139|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
  140|       |    EIGEN_UNUSED_VARIABLE(size)
  141|       |  }
  142|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl& other) {
  143|       |    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);
  144|       |    m_rows = other.m_rows;
  145|       |    return *this;
  146|       |  }
  147|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) {
  148|       |    swap_plain_array(m_data, other.m_data, size(), other.size());
  149|       |    numext::swap(m_rows, other.m_rows);
  150|       |  }
  151|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index rows, Index /*cols*/) {
  152|       |    m_rows = rows;
  153|       |  }
  154|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index rows, Index /*cols*/) {
  155|       |    m_rows = rows;
  156|       |  }
  157|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }
  158|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }
  159|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * Cols; }
  160|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data.array; }
  161|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data.array; }
  162|       |};
  163|       |template <typename T, int Size, int Rows, int Options>
  164|       |class DenseStorage_impl<T, Size, Rows, Dynamic, Options> {
  165|       |  plain_array<T, Size, Options> m_data;
  166|       |  Index m_cols = 0;
  167|       |
  168|       | public:
  169|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  170|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl& other)
  171|       |      : m_cols(other.m_cols) {
  172|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())
  173|       |    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);
  174|       |  }
  175|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index /*rows*/, Index cols)
  176|       |      : m_cols(cols) {
  177|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
  178|       |    EIGEN_UNUSED_VARIABLE(size)
  179|       |  }
  180|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl& other) {
  181|       |    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);
  182|       |    m_cols = other.m_cols;
  183|       |    return *this;
  184|       |  }
  185|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) {
  186|       |    swap_plain_array(m_data, other.m_data, size(), other.size());
  187|       |    numext::swap(m_cols, other.m_cols);
  188|       |  }
  189|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index /*rows*/, Index cols) {
  190|       |    m_cols = cols;
  191|       |  }
  192|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index /*rows*/, Index cols) {
  193|       |    m_cols = cols;
  194|       |  }
  195|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }
  196|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }
  197|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * m_cols; }
  198|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data.array; }
  199|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data.array; }
  200|       |};
  201|       |template <typename T, int Size, int Options>
  202|       |class DenseStorage_impl<T, Size, Dynamic, Dynamic, Options> {
  203|       |  plain_array<T, Size, Options> m_data;
  204|       |  Index m_rows = 0;
  205|       |  Index m_cols = 0;
  206|       |
  207|       | public:
  208|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  209|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl& other)
  210|       |      : m_rows(other.m_rows), m_cols(other.m_cols) {
  211|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())
  212|       |    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);
  213|       |  }
  214|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index rows, Index cols)
  215|       |      : m_rows(rows), m_cols(cols) {
  216|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
  217|       |    EIGEN_UNUSED_VARIABLE(size)
  218|       |  }
  219|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl& other) {
  220|       |    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);
  221|       |    m_rows = other.m_rows;
  222|       |    m_cols = other.m_cols;
  223|       |    return *this;
  224|       |  }
  225|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) {
  226|       |    swap_plain_array(m_data, other.m_data, size(), other.size());
  227|       |    numext::swap(m_rows, other.m_rows);
  228|       |    numext::swap(m_cols, other.m_cols);
  229|       |  }
  230|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index rows, Index cols) {
  231|       |    m_rows = rows;
  232|       |    m_cols = cols;
  233|       |  }
  234|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index rows, Index cols) {
  235|       |    m_rows = rows;
  236|       |    m_cols = cols;
  237|       |  }
  238|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }
  239|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }
  240|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * m_cols; }
  241|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data.array; }
  242|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data.array; }
  243|       |};
  244|       |// null matrix variants
  245|       |template <typename T, int Rows, int Cols, int Options>
  246|       |class DenseStorage_impl<T, 0, Rows, Cols, Options> {
  247|       | public:
  248|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  249|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&) = default;
  250|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index /*rows*/, Index /*cols*/) {}
  251|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl&) = default;
  252|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&) {}
  253|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index /*rows*/,
  254|       |                                                                          Index /*cols*/) {}
  255|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index /*rows*/, Index /*cols*/) {}
  256|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }
  257|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }
  258|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * Cols; }
  259|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return nullptr; }
  260|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return nullptr; }
  261|       |};
  262|       |template <typename T, int Cols, int Options>
  263|       |class DenseStorage_impl<T, 0, Dynamic, Cols, Options> {
  264|       |  Index m_rows = 0;
  265|       |
  266|       | public:
  267|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  268|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&) = default;
  269|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index rows, Index /*cols*/)
  270|       |      : m_rows(rows) {}
  271|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl&) = default;
  272|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) noexcept {
  273|       |    numext::swap(m_rows, other.m_rows);
  274|       |  }
  275|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index rows, Index /*cols*/) {
  276|       |    m_rows = rows;
  277|       |  }
  278|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index rows, Index /*cols*/) {
  279|       |    m_rows = rows;
  280|       |  }
  281|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }
  282|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }
  283|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * Cols; }
  284|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return nullptr; }
  285|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return nullptr; }
  286|       |};
  287|       |template <typename T, int Rows, int Options>
  288|       |class DenseStorage_impl<T, 0, Rows, Dynamic, Options> {
  289|       |  Index m_cols = 0;
  290|       |
  291|       | public:
  292|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  293|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&) = default;
  294|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index /*rows*/, Index cols)
  295|       |      : m_cols(cols) {}
  296|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl&) = default;
  297|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) noexcept {
  298|       |    numext::swap(m_cols, other.m_cols);
  299|       |  }
  300|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index /*rows*/, Index cols) {
  301|       |    m_cols = cols;
  302|       |  }
  303|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index /*rows*/, Index cols) {
  304|       |    m_cols = cols;
  305|       |  }
  306|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }
  307|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }
  308|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * m_cols; }
  309|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return nullptr; }
  310|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return nullptr; }
  311|       |};
  312|       |template <typename T, int Options>
  313|       |class DenseStorage_impl<T, 0, Dynamic, Dynamic, Options> {
  314|       |  Index m_rows = 0;
  315|       |  Index m_cols = 0;
  316|       |
  317|       | public:
  318|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  319|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&) = default;
  320|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index rows, Index cols)
  321|       |      : m_rows(rows), m_cols(cols) {}
  322|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl&) = default;
  323|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) noexcept {
  324|       |    numext::swap(m_rows, other.m_rows);
  325|       |    numext::swap(m_cols, other.m_cols);
  326|       |  }
  327|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index rows, Index cols) {
  328|       |    m_rows = rows;
  329|       |    m_cols = cols;
  330|       |  }
  331|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index rows, Index cols) {
  332|       |    m_rows = rows;
  333|       |    m_cols = cols;
  334|       |  }
  335|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }
  336|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }
  337|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * m_cols; }
  338|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return nullptr; }
  339|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return nullptr; }
  340|       |};
  341|       |// fixed-size matrix with dynamic memory allocation not currently supported
  342|       |template <typename T, int Rows, int Cols, int Options>
  343|       |class DenseStorage_impl<T, Dynamic, Rows, Cols, Options> {};
  344|       |// dynamic-sized variants
  345|       |template <typename T, int Cols, int Options>
  346|       |class DenseStorage_impl<T, Dynamic, Dynamic, Cols, Options> {
  347|       |  static constexpr bool Align = (Options & DontAlign) == 0;
  348|       |  T* m_data = nullptr;
  349|       |  Index m_rows = 0;
  350|       |
  351|       | public:
  352|       |  static constexpr int Size = Dynamic;
  353|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  354|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl& other)
  355|       |      : m_data(conditional_aligned_new_auto<T, Align>(other.size())), m_rows(other.m_rows) {
  356|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())
  357|       |    smart_copy(other.m_data, other.m_data + other.size(), m_data);
  358|       |  }
  359|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index rows, Index /*cols*/)
  360|       |      : m_data(conditional_aligned_new_auto<T, Align>(size)), m_rows(rows) {
  361|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
  362|       |  }
  363|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(DenseStorage_impl&& other) noexcept
  364|       |      : m_data(other.m_data), m_rows(other.m_rows) {
  365|       |    other.m_data = nullptr;
  366|       |    other.m_rows = 0;
  367|       |  }
  368|      3|  EIGEN_DEVICE_FUNC ~DenseStorage_impl() { conditional_aligned_delete_auto<T, Align>(m_data, size()); }
  369|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl& other) {
  370|       |    resize(other.size(), other.rows(), other.cols());
  371|       |    smart_copy(other.m_data, other.m_data + other.size(), m_data);
  372|       |    return *this;
  373|       |  }
  374|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(DenseStorage_impl&& other) noexcept {
  375|       |    this->swap(other);
  376|       |    return *this;
  377|       |  }
  378|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) noexcept {
  379|       |    numext::swap(m_data, other.m_data);
  380|       |    numext::swap(m_rows, other.m_rows);
  381|       |  }
  382|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index size, Index rows, Index /*cols*/) {
  383|       |    m_data = conditional_aligned_realloc_new_auto<T, Align>(m_data, size, this->size());
  384|       |    m_rows = rows;
  385|       |  }
  386|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index size, Index rows, Index /*cols*/) {
  387|      3|    Index oldSize = this->size();
  388|      3|    if (oldSize != size) {
  389|      3|      conditional_aligned_delete_auto<T, Align>(m_data, oldSize);
  390|      3|      m_data = conditional_aligned_new_auto<T, Align>(size);
  391|      3|      EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
  392|      3|    }
  393|      3|    m_rows = rows;
  394|      3|  }
  395|     15|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }
  396|     14|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }
  397|      6|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * Cols; }
  398|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data; }
  399|      5|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data; }
  400|       |};
  401|       |template <typename T, int Rows, int Options>
  402|       |class DenseStorage_impl<T, Dynamic, Rows, Dynamic, Options> {
  403|       |  static constexpr bool Align = (Options & DontAlign) == 0;
  404|       |  T* m_data = nullptr;
  405|       |  Index m_cols = 0;
  406|       |
  407|       | public:
  408|       |  static constexpr int Size = Dynamic;
  409|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  410|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl& other)
  411|       |      : m_data(conditional_aligned_new_auto<T, Align>(other.size())), m_cols(other.m_cols) {
  412|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())
  413|       |    smart_copy(other.m_data, other.m_data + other.size(), m_data);
  414|       |  }
  415|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index /*rows*/, Index cols)
  416|       |      : m_data(conditional_aligned_new_auto<T, Align>(size)), m_cols(cols) {
  417|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
  418|       |  }
  419|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(DenseStorage_impl&& other) noexcept
  420|       |      : m_data(other.m_data), m_cols(other.m_cols) {
  421|       |    other.m_data = nullptr;
  422|       |    other.m_cols = 0;
  423|       |  }
  424|      0|  EIGEN_DEVICE_FUNC ~DenseStorage_impl() { conditional_aligned_delete_auto<T, Align>(m_data, size()); }
  425|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl& other) {
  426|       |    resize(other.size(), other.rows(), other.cols());
  427|       |    smart_copy(other.m_data, other.m_data + other.size(), m_data);
  428|       |    return *this;
  429|       |  }
  430|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(DenseStorage_impl&& other) noexcept {
  431|       |    this->swap(other);
  432|       |    return *this;
  433|       |  }
  434|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) noexcept {
  435|       |    numext::swap(m_data, other.m_data);
  436|       |    numext::swap(m_cols, other.m_cols);
  437|       |  }
  438|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index size, Index /*rows*/, Index cols) {
  439|       |    m_data = conditional_aligned_realloc_new_auto<T, Align>(m_data, size, this->size());
  440|       |    m_cols = cols;
  441|       |  }
  442|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index size, Index /*rows*/, Index cols) {
  443|      0|    Index oldSize = this->size();
  444|      0|    if (oldSize != size) {
  445|      0|      conditional_aligned_delete_auto<T, Align>(m_data, oldSize);
  446|      0|      m_data = conditional_aligned_new_auto<T, Align>(size);
  447|      0|      EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
  448|      0|    }
  449|      0|    m_cols = cols;
  450|      0|  }
  451|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }
  452|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }
  453|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * m_cols; }
  454|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data; }
  455|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data; }
  456|       |};
  457|       |template <typename T, int Options>
  458|       |class DenseStorage_impl<T, Dynamic, Dynamic, Dynamic, Options> {
  459|       |  static constexpr bool Align = (Options & DontAlign) == 0;
  460|       |  T* m_data = nullptr;
  461|       |  Index m_rows = 0;
  462|       |  Index m_cols = 0;
  463|       |
  464|       | public:
  465|       |  static constexpr int Size = Dynamic;
  466|      6|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;
  467|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl& other)
  468|       |      : m_data(conditional_aligned_new_auto<T, Align>(other.size())), m_rows(other.m_rows), m_cols(other.m_cols) {
  469|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())
  470|       |    smart_copy(other.m_data, other.m_data + other.size(), m_data);
  471|       |  }
  472|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index rows, Index cols)
  473|       |      : m_data(conditional_aligned_new_auto<T, Align>(size)), m_rows(rows), m_cols(cols) {
  474|       |    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
  475|       |  }
  476|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(DenseStorage_impl&& other) noexcept
  477|       |      : m_data(other.m_data), m_rows(other.m_rows), m_cols(other.m_cols) {
  478|       |    other.m_data = nullptr;
  479|       |    other.m_rows = 0;
  480|       |    other.m_cols = 0;
  481|       |  }
  482|      6|  EIGEN_DEVICE_FUNC ~DenseStorage_impl() { conditional_aligned_delete_auto<T, Align>(m_data, size()); }
  483|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(const DenseStorage_impl& other) {
  484|       |    resize(other.size(), other.rows(), other.cols());
  485|       |    smart_copy(other.m_data, other.m_data + other.size(), m_data);
  486|       |    return *this;
  487|       |  }
  488|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl& operator=(DenseStorage_impl&& other) noexcept {
  489|       |    this->swap(other);
  490|       |    return *this;
  491|       |  }
  492|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl& other) noexcept {
  493|       |    numext::swap(m_data, other.m_data);
  494|       |    numext::swap(m_rows, other.m_rows);
  495|       |    numext::swap(m_cols, other.m_cols);
  496|       |  }
  497|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index size, Index rows, Index cols) {
  498|       |    m_data = conditional_aligned_realloc_new_auto<T, Align>(m_data, size, this->size());
  499|       |    m_rows = rows;
  500|       |    m_cols = cols;
  501|       |  }
  502|      6|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index size, Index rows, Index cols) {
  503|      6|    Index oldSize = this->size();
  504|      6|    if (oldSize != size) {
  505|      6|      conditional_aligned_delete_auto<T, Align>(m_data, oldSize);
  506|      6|      m_data = conditional_aligned_new_auto<T, Align>(size);
  507|      6|      EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
  508|      6|    }
  509|      6|    m_rows = rows;
  510|      6|    m_cols = cols;
  511|      6|  }
  512|     66|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }
  513|     54|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }
  514|     12|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * m_cols; }
  515|      5|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data; }
  516|      7|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data; }
  517|       |};
  518|       |template <typename T, int Size, int Rows, int Cols>
  519|       |struct use_default_move {
  520|       |  static constexpr bool DynamicObject = Size == Dynamic;
  521|       |  static constexpr bool TrivialObject =
  522|       |      (!NumTraits<T>::RequireInitialization) && (Rows >= 0) && (Cols >= 0) && (Size == Rows * Cols);
  523|       |  static constexpr bool value = DynamicObject || TrivialObject;
  524|       |};
  525|       |}  // end namespace internal
  526|       |
  527|       |/** \internal
  528|       | *
  529|       | * \class DenseStorage_impl
  530|       | * \ingroup Core_Module
  531|       | *
  532|       | * \brief Stores the data of a matrix
  533|       | *
  534|       | * This class stores the data of fixed-size, dynamic-size or mixed matrices
  535|       | * in a way as compact as possible.
  536|       | *
  537|       | * \sa Matrix
  538|       | */
  539|       |template <typename T, int Size, int Rows, int Cols, int Options,
  540|       |          bool Trivial = internal::use_default_move<T, Size, Rows, Cols>::value>
  541|       |class DenseStorage : public internal::DenseStorage_impl<T, Size, Rows, Cols, Options> {
  542|       |  using Base = internal::DenseStorage_impl<T, Size, Rows, Cols, Options>;
  543|       |
  544|       | public:
  545|      9|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage() = default;
  ------------------
  | _ZN5Eigen12DenseStorageI14AnnoyingScalarLin1ELin1ELi1ELi0ELb1EEC2Ev:
  |  545|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage() = default;
  ------------------
  | _ZN5Eigen12DenseStorageI14AnnoyingScalarLin1ELin1ELin1ELi0ELb1EEC2Ev:
  |  545|      6|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage() = default;
  ------------------
  | Unexecuted instantiation: _ZN5Eigen12DenseStorageI14AnnoyingScalarLin1ELi1ELin1ELi1ELb1EEC2Ev
  ------------------
  546|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(const DenseStorage&) = default;
  547|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(Index size, Index rows, Index cols)
  548|       |      : Base(size, rows, cols) {}
  549|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage& operator=(const DenseStorage&) = default;
  550|       |  // if DenseStorage meets the requirements of use_default_move, then use the move construction and move assignment
  551|       |  // operation defined in DenseStorage_impl, or the compiler-generated version if none is defined
  552|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(DenseStorage&&) = default;
  553|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage& operator=(DenseStorage&&) = default;
  554|       |};
  555|       |template <typename T, int Size, int Rows, int Cols, int Options>
  556|       |class DenseStorage<T, Size, Rows, Cols, Options, false>
  557|       |    : public internal::DenseStorage_impl<T, Size, Rows, Cols, Options> {
  558|       |  using Base = internal::DenseStorage_impl<T, Size, Rows, Cols, Options>;
  559|       |
  560|       | public:
  561|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage() = default;
  562|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(const DenseStorage&) = default;
  563|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(Index size, Index rows, Index cols)
  564|       |      : Base(size, rows, cols) {}
  565|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage& operator=(const DenseStorage&) = default;
  566|       |  // if DenseStorage does not meet the requirements of use_default_move, then defer to the copy construction and copy
  567|       |  // assignment behavior
  568|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(DenseStorage&& other)
  569|       |      : DenseStorage(static_cast<const DenseStorage&>(other)) {}
  570|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage& operator=(DenseStorage&& other) {
  571|       |    *this = other;
  572|       |    return *this;
  573|       |  }
  574|       |};
  575|       |
  576|       |}  // end namespace Eigen
  577|       |
  578|       |#endif  // EIGEN_MATRIX_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Dot.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2008, 2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_DOT_H
   11|       |#define EIGEN_DOT_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "./InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |template <typename Derived, typename Scalar = typename traits<Derived>::Scalar>
   21|       |struct squared_norm_impl {
   22|       |  using Real = typename NumTraits<Scalar>::Real;
   23|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Real run(const Derived& a) {
   24|       |    Scalar result = a.unaryExpr(squared_norm_functor<Scalar>()).sum();
   25|       |    return numext::real(result) + numext::imag(result);
   26|       |  }
   27|       |};
   28|       |
   29|       |template <typename Derived>
   30|       |struct squared_norm_impl<Derived, bool> {
   31|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool run(const Derived& a) { return a.any(); }
   32|       |};
   33|       |
   34|       |}  // end namespace internal
   35|       |
   36|       |/** \fn MatrixBase::dot
   37|       | * \returns the dot product of *this with other.
   38|       | *
   39|       | * \only_for_vectors
   40|       | *
   41|       | * \note If the scalar type is complex numbers, then this function returns the hermitian
   42|       | * (sesquilinear) dot product, conjugate-linear in the first variable and linear in the
   43|       | * second variable.
   44|       | *
   45|       | * \sa squaredNorm(), norm()
   46|       | */
   47|       |template <typename Derived>
   48|       |template <typename OtherDerived>
   49|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   50|       |    typename ScalarBinaryOpTraits<typename internal::traits<Derived>::Scalar,
   51|       |                                  typename internal::traits<OtherDerived>::Scalar>::ReturnType
   52|      1|    MatrixBase<Derived>::dot(const MatrixBase<OtherDerived>& other) const {
   53|      1|  return internal::dot_impl<Derived, OtherDerived>::run(derived(), other.derived());
   54|      1|}
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen10MatrixBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEE3dotINS1_IKNS3_IS4_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEENS_20ScalarBinaryOpTraitsIS4_NS_8internal6traitsIT_E6ScalarENSF_17scalar_product_opIS4_SJ_EEE10ReturnTypeERKNS0_ISH_EE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen10MatrixBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE3dotINS1_IKNS1_IS5_Lin1ELi1ELb1EEELin1ELi1ELb1EEEEENS_20ScalarBinaryOpTraitsIS3_NS_8internal6traitsIT_E6ScalarENSD_17scalar_product_opIS3_SH_EEE10ReturnTypeERKNS0_ISF_EE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen10MatrixBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE3dotINS1_IS5_Lin1ELi1ELb1EEEEENS_20ScalarBinaryOpTraitsIS3_NS_8internal6traitsIT_E6ScalarENSD_17scalar_product_opIS3_SH_EEE10ReturnTypeERKNS0_ISF_EE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen10MatrixBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEE3dotINS1_IKNS1_IKS5_Lin1ELi1ELb1EEELin1ELi1ELb1EEEEENS_20ScalarBinaryOpTraitsIS4_NS_8internal6traitsIT_E6ScalarENSG_17scalar_product_opIS4_SK_EEE10ReturnTypeERKNS0_ISI_EE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen10MatrixBaseINS_5BlockIKNS1_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE3dotINS1_IKS5_Lin1ELi1ELb1EEEEENS_20ScalarBinaryOpTraitsIS4_NS_8internal6traitsIT_E6ScalarENSG_17scalar_product_opIS4_SK_EEE10ReturnTypeERKNS0_ISI_EE
  ------------------
  | _ZNK5Eigen10MatrixBaseINS_13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EEE3dotIS9_EENS_20ScalarBinaryOpTraitsIS4_NS2_6traitsIT_E6ScalarENS2_17scalar_product_opIS4_SG_EEE10ReturnTypeERKNS0_ISE_EE:
  |   52|      1|    MatrixBase<Derived>::dot(const MatrixBase<OtherDerived>& other) const {
  |   53|      1|  return internal::dot_impl<Derived, OtherDerived>::run(derived(), other.derived());
  |   54|      1|}
  ------------------
   55|       |
   56|       |//---------- implementation of L2 norm and related functions ----------
   57|       |
   58|       |/** \returns, for vectors, the squared \em l2 norm of \c *this, and for matrices the squared Frobenius norm.
   59|       | * In both cases, it consists in the sum of the square of all the matrix entries.
   60|       | * For vectors, this is also equals to the dot product of \c *this with itself.
   61|       | *
   62|       | * \sa dot(), norm(), lpNorm()
   63|       | */
   64|       |template <typename Derived>
   65|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NumTraits<typename internal::traits<Derived>::Scalar>::Real
   66|       |MatrixBase<Derived>::squaredNorm() const {
   67|       |  return internal::squared_norm_impl<Derived>::run(derived());
   68|       |}
   69|       |
   70|       |/** \returns, for vectors, the \em l2 norm of \c *this, and for matrices the Frobenius norm.
   71|       | * In both cases, it consists in the square root of the sum of the square of all the matrix entries.
   72|       | * For vectors, this is also equals to the square root of the dot product of \c *this with itself.
   73|       | *
   74|       | * \sa lpNorm(), dot(), squaredNorm()
   75|       | */
   76|       |template <typename Derived>
   77|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NumTraits<typename internal::traits<Derived>::Scalar>::Real
   78|       |MatrixBase<Derived>::norm() const {
   79|       |  return numext::sqrt(squaredNorm());
   80|       |}
   81|       |
   82|       |/** \returns an expression of the quotient of \c *this by its own norm.
   83|       | *
   84|       | * \warning If the input vector is too small (i.e., this->norm()==0),
   85|       | *          then this function returns a copy of the input.
   86|       | *
   87|       | * \only_for_vectors
   88|       | *
   89|       | * \sa norm(), normalize()
   90|       | */
   91|       |template <typename Derived>
   92|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::PlainObject MatrixBase<Derived>::normalized()
   93|       |    const {
   94|       |  typedef typename internal::nested_eval<Derived, 2>::type Nested_;
   95|       |  Nested_ n(derived());
   96|       |  RealScalar z = n.squaredNorm();
   97|       |  // NOTE: after extensive benchmarking, this conditional does not impact performance, at least on recent x86 CPU
   98|       |  if (z > RealScalar(0))
   99|       |    return n / numext::sqrt(z);
  100|       |  else
  101|       |    return n;
  102|       |}
  103|       |
  104|       |/** Normalizes the vector, i.e. divides it by its own norm.
  105|       | *
  106|       | * \only_for_vectors
  107|       | *
  108|       | * \warning If the input vector is too small (i.e., this->norm()==0), then \c *this is left unchanged.
  109|       | *
  110|       | * \sa norm(), normalized()
  111|       | */
  112|       |template <typename Derived>
  113|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void MatrixBase<Derived>::normalize() {
  114|       |  RealScalar z = squaredNorm();
  115|       |  // NOTE: after extensive benchmarking, this conditional does not impact performance, at least on recent x86 CPU
  116|       |  if (z > RealScalar(0)) derived() /= numext::sqrt(z);
  117|       |}
  118|       |
  119|       |/** \returns an expression of the quotient of \c *this by its own norm while avoiding underflow and overflow.
  120|       | *
  121|       | * \only_for_vectors
  122|       | *
  123|       | * This method is analogue to the normalized() method, but it reduces the risk of
  124|       | * underflow and overflow when computing the norm.
  125|       | *
  126|       | * \warning If the input vector is too small (i.e., this->norm()==0),
  127|       | *          then this function returns a copy of the input.
  128|       | *
  129|       | * \sa stableNorm(), stableNormalize(), normalized()
  130|       | */
  131|       |template <typename Derived>
  132|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename MatrixBase<Derived>::PlainObject
  133|       |MatrixBase<Derived>::stableNormalized() const {
  134|       |  typedef typename internal::nested_eval<Derived, 3>::type Nested_;
  135|       |  Nested_ n(derived());
  136|       |  RealScalar w = n.cwiseAbs().maxCoeff();
  137|       |  RealScalar z = (n / w).squaredNorm();
  138|       |  if (z > RealScalar(0))
  139|       |    return n / (numext::sqrt(z) * w);
  140|       |  else
  141|       |    return n;
  142|       |}
  143|       |
  144|       |/** Normalizes the vector while avoid underflow and overflow
  145|       | *
  146|       | * \only_for_vectors
  147|       | *
  148|       | * This method is analogue to the normalize() method, but it reduces the risk of
  149|       | * underflow and overflow when computing the norm.
  150|       | *
  151|       | * \warning If the input vector is too small (i.e., this->norm()==0), then \c *this is left unchanged.
  152|       | *
  153|       | * \sa stableNorm(), stableNormalized(), normalize()
  154|       | */
  155|       |template <typename Derived>
  156|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void MatrixBase<Derived>::stableNormalize() {
  157|       |  RealScalar w = cwiseAbs().maxCoeff();
  158|       |  RealScalar z = (derived() / w).squaredNorm();
  159|       |  if (z > RealScalar(0)) derived() /= numext::sqrt(z) * w;
  160|       |}
  161|       |
  162|       |//---------- implementation of other norms ----------
  163|       |
  164|       |namespace internal {
  165|       |
  166|       |template <typename Derived, int p>
  167|       |struct lpNorm_selector {
  168|       |  typedef typename NumTraits<typename traits<Derived>::Scalar>::Real RealScalar;
  169|       |  EIGEN_DEVICE_FUNC static inline RealScalar run(const MatrixBase<Derived>& m) {
  170|       |    EIGEN_USING_STD(pow)
  171|       |    return pow(m.cwiseAbs().array().pow(p).sum(), RealScalar(1) / p);
  172|       |  }
  173|       |};
  174|       |
  175|       |template <typename Derived>
  176|       |struct lpNorm_selector<Derived, 1> {
  177|       |  EIGEN_DEVICE_FUNC static inline typename NumTraits<typename traits<Derived>::Scalar>::Real run(
  178|       |      const MatrixBase<Derived>& m) {
  179|       |    return m.cwiseAbs().sum();
  180|       |  }
  181|       |};
  182|       |
  183|       |template <typename Derived>
  184|       |struct lpNorm_selector<Derived, 2> {
  185|       |  EIGEN_DEVICE_FUNC static inline typename NumTraits<typename traits<Derived>::Scalar>::Real run(
  186|       |      const MatrixBase<Derived>& m) {
  187|       |    return m.norm();
  188|       |  }
  189|       |};
  190|       |
  191|       |template <typename Derived>
  192|       |struct lpNorm_selector<Derived, Infinity> {
  193|       |  typedef typename NumTraits<typename traits<Derived>::Scalar>::Real RealScalar;
  194|       |  EIGEN_DEVICE_FUNC static inline RealScalar run(const MatrixBase<Derived>& m) {
  195|       |    if (Derived::SizeAtCompileTime == 0 || (Derived::SizeAtCompileTime == Dynamic && m.size() == 0))
  196|       |      return RealScalar(0);
  197|       |    return m.cwiseAbs().maxCoeff();
  198|       |  }
  199|       |};
  200|       |
  201|       |}  // end namespace internal
  202|       |
  203|       |/** \returns the \b coefficient-wise \f$ \ell^p \f$ norm of \c *this, that is, returns the p-th root of the sum of the
  204|       | * p-th powers of the absolute values of the coefficients of \c *this. If \a p is the special value \a Eigen::Infinity,
  205|       | * this function returns the \f$ \ell^\infty \f$ norm, that is the maximum of the absolute values of the coefficients of
  206|       | * \c *this.
  207|       | *
  208|       | * In all cases, if \c *this is empty, then the value 0 is returned.
  209|       | *
  210|       | * \note For matrices, this function does not compute the <a
  211|       | * href="https://en.wikipedia.org/wiki/Operator_norm">operator-norm</a>. That is, if \c *this is a matrix, then its
  212|       | * coefficients are interpreted as a 1D vector. Nonetheless, you can easily compute the 1-norm and \f$\infty\f$-norm
  213|       | * matrix operator norms using \link TutorialReductionsVisitorsBroadcastingReductionsNorm partial reductions \endlink.
  214|       | *
  215|       | * \sa norm()
  216|       | */
  217|       |template <typename Derived>
  218|       |template <int p>
  219|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  220|       |EIGEN_DEVICE_FUNC inline typename NumTraits<typename internal::traits<Derived>::Scalar>::Real
  221|       |#else
  222|       |EIGEN_DEVICE_FUNC MatrixBase<Derived>::RealScalar
  223|       |#endif
  224|       |MatrixBase<Derived>::lpNorm() const {
  225|       |  return internal::lpNorm_selector<Derived, p>::run(*this);
  226|       |}
  227|       |
  228|       |//---------- implementation of isOrthogonal / isUnitary ----------
  229|       |
  230|       |/** \returns true if *this is approximately orthogonal to \a other,
  231|       | *          within the precision given by \a prec.
  232|       | *
  233|       | * Example: \include MatrixBase_isOrthogonal.cpp
  234|       | * Output: \verbinclude MatrixBase_isOrthogonal.out
  235|       | */
  236|       |template <typename Derived>
  237|       |template <typename OtherDerived>
  238|       |bool MatrixBase<Derived>::isOrthogonal(const MatrixBase<OtherDerived>& other, const RealScalar& prec) const {
  239|       |  typename internal::nested_eval<Derived, 2>::type nested(derived());
  240|       |  typename internal::nested_eval<OtherDerived, 2>::type otherNested(other.derived());
  241|       |  return numext::abs2(nested.dot(otherNested)) <= prec * prec * nested.squaredNorm() * otherNested.squaredNorm();
  242|       |}
  243|       |
  244|       |/** \returns true if *this is approximately an unitary matrix,
  245|       | *          within the precision given by \a prec. In the case where the \a Scalar
  246|       | *          type is real numbers, a unitary matrix is an orthogonal matrix, whence the name.
  247|       | *
  248|       | * \note This can be used to check whether a family of vectors forms an orthonormal basis.
  249|       | *       Indeed, \c m.isUnitary() returns true if and only if the columns (equivalently, the rows) of m form an
  250|       | *       orthonormal basis.
  251|       | *
  252|       | * Example: \include MatrixBase_isUnitary.cpp
  253|       | * Output: \verbinclude MatrixBase_isUnitary.out
  254|       | */
  255|       |template <typename Derived>
  256|       |bool MatrixBase<Derived>::isUnitary(const RealScalar& prec) const {
  257|       |  typename internal::nested_eval<Derived, 1>::type self(derived());
  258|       |  for (Index i = 0; i < cols(); ++i) {
  259|       |    if (!internal::isApprox(self.col(i).squaredNorm(), static_cast<RealScalar>(1), prec)) return false;
  260|       |    for (Index j = 0; j < i; ++j)
  261|       |      if (!internal::isMuchSmallerThan(self.col(i).dot(self.col(j)), static_cast<Scalar>(1), prec)) return false;
  262|       |  }
  263|       |  return true;
  264|       |}
  265|       |
  266|       |}  // end namespace Eigen
  267|       |
  268|       |#endif  // EIGEN_DOT_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/EigenBase.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2009 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2009 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_EIGENBASE_H
   12|       |#define EIGEN_EIGENBASE_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |/** \class EigenBase
   20|       | * \ingroup Core_Module
   21|       | *
   22|       | * Common base class for all classes T such that MatrixBase has an operator=(T) and a constructor MatrixBase(T).
   23|       | *
   24|       | * In other words, an EigenBase object is an object that can be copied into a MatrixBase.
   25|       | *
   26|       | * Besides MatrixBase-derived classes, this also includes special matrix classes such as diagonal matrices, etc.
   27|       | *
   28|       | * Notice that this class is trivial, it is only used to disambiguate overloaded functions.
   29|       | *
   30|       | * \sa \blank \ref TopicClassHierarchy
   31|       | */
   32|       |template <typename Derived>
   33|       |struct EigenBase {
   34|       |  //   typedef typename internal::plain_matrix_type<Derived>::type PlainObject;
   35|       |
   36|       |  /** \brief The interface type of indices
   37|       |   * \details To change this, \c \#define the preprocessor symbol \c EIGEN_DEFAULT_DENSE_INDEX_TYPE.
   38|       |   * \sa StorageIndex, \ref TopicPreprocessorDirectives.
   39|       |   * DEPRECATED: Since Eigen 3.3, its usage is deprecated. Use Eigen::Index instead.
   40|       |   * Deprecation is not marked with a doxygen comment because there are too many existing usages to add the deprecation
   41|       |   * attribute.
   42|       |   */
   43|       |  typedef Eigen::Index Index;
   44|       |
   45|       |  // FIXME is it needed?
   46|       |  typedef typename internal::traits<Derived>::StorageKind StorageKind;
   47|       |
   48|       |  /** \returns a reference to the derived object */
   49|     24|  EIGEN_DEVICE_FUNC constexpr Derived& derived() { return *static_cast<Derived*>(this); }
  ------------------
  | _ZN5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE7derivedEv:
  |   49|      8|  EIGEN_DEVICE_FUNC constexpr Derived& derived() { return *static_cast<Derived*>(this); }
  ------------------
  | _ZN5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE7derivedEv:
  |   49|     16|  EIGEN_DEVICE_FUNC constexpr Derived& derived() { return *static_cast<Derived*>(this); }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9EigenBaseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9EigenBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9EigenBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9EigenBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEE7derivedEv
  ------------------
   50|       |  /** \returns a const reference to the derived object */
   51|     60|  EIGEN_DEVICE_FUNC constexpr const Derived& derived() const { return *static_cast<const Derived*>(this); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE7derivedEv:
  |   51|     11|  EIGEN_DEVICE_FUNC constexpr const Derived& derived() const { return *static_cast<const Derived*>(this); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE7derivedEv:
  |   51|     29|  EIGEN_DEVICE_FUNC constexpr const Derived& derived() const { return *static_cast<const Derived*>(this); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEEE7derivedEv:
  |   51|      6|  EIGEN_DEVICE_FUNC constexpr const Derived& derived() const { return *static_cast<const Derived*>(this); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEE7derivedEv
  ------------------
  | _ZNK5Eigen9EigenBaseINS_7ProductINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEENS2_IS3_Lin1ELi1ELi0ELin1ELi1EEELi0EEEE7derivedEv:
  |   51|      2|  EIGEN_DEVICE_FUNC constexpr const Derived& derived() const { return *static_cast<const Derived*>(this); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEE7derivedEv
  ------------------
  | _ZNK5Eigen9EigenBaseINS_7ProductINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEES4_Li0EEEE7derivedEv:
  |   51|      2|  EIGEN_DEVICE_FUNC constexpr const Derived& derived() const { return *static_cast<const Derived*>(this); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EEE7derivedEv:
  |   51|     10|  EIGEN_DEVICE_FUNC constexpr const Derived& derived() const { return *static_cast<const Derived*>(this); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEE7derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS4_EEKNS_14CwiseNullaryOpINS2_18scalar_constant_opIS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISA_Li1ENS_6StrideILi0ELi0EEEEEEEE7derivedEv
  ------------------
   52|       |
   53|      4|  EIGEN_DEVICE_FUNC inline Derived& const_cast_derived() const {
   54|      4|    return *static_cast<Derived*>(const_cast<EigenBase*>(this));
   55|      4|  }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE18const_cast_derivedEv:
  |   53|      1|  EIGEN_DEVICE_FUNC inline Derived& const_cast_derived() const {
  |   54|      1|    return *static_cast<Derived*>(const_cast<EigenBase*>(this));
  |   55|      1|  }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE18const_cast_derivedEv:
  |   53|      3|  EIGEN_DEVICE_FUNC inline Derived& const_cast_derived() const {
  |   54|      3|    return *static_cast<Derived*>(const_cast<EigenBase*>(this));
  |   55|      3|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEE18const_cast_derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE18const_cast_derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEE18const_cast_derivedEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE18const_cast_derivedEv
  ------------------
   56|       |  EIGEN_DEVICE_FUNC inline const Derived& const_derived() const { return *static_cast<const Derived*>(this); }
   57|       |
   58|       |  /** \returns the number of rows. \sa cols(), RowsAtCompileTime */
   59|     21|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE4rowsEv:
  |   59|      3|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4rowsEv:
  |   59|     15|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEE4rowsEv
  ------------------
  | _ZNK5Eigen9EigenBaseINS_13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EEE4rowsEv:
  |   59|      3|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEE4rowsEv
  ------------------
   60|       |  /** \returns the number of columns. \sa rows(), ColsAtCompileTime*/
   61|     12|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE4colsEv:
  |   61|      3|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4colsEv:
  |   61|      6|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEE4colsEv
  ------------------
  | _ZNK5Eigen9EigenBaseINS_13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EEE4colsEv:
  |   61|      3|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEE4colsEv
  ------------------
   62|       |  /** \returns the number of coefficients, which is rows()*cols().
   63|       |   * \sa rows(), cols(), SizeAtCompileTime. */
   64|     12|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index size() const EIGEN_NOEXCEPT { return rows() * cols(); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE4sizeEv:
  |   64|      3|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index size() const EIGEN_NOEXCEPT { return rows() * cols(); }
  ------------------
  | _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4sizeEv:
  |   64|      6|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index size() const EIGEN_NOEXCEPT { return rows() * cols(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockIKNS1_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEE4sizeEv
  ------------------
  | _ZNK5Eigen9EigenBaseINS_13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EEE4sizeEv:
  |   64|      3|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index size() const EIGEN_NOEXCEPT { return rows() * cols(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9EigenBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEE4sizeEv
  ------------------
   65|       |
   66|       |  /** \internal Don't use it, but do the equivalent: \code dst = *this; \endcode */
   67|       |  template <typename Dest>
   68|       |  EIGEN_DEVICE_FUNC inline void evalTo(Dest& dst) const {
   69|       |    derived().evalTo(dst);
   70|       |  }
   71|       |
   72|       |  /** \internal Don't use it, but do the equivalent: \code dst += *this; \endcode */
   73|       |  template <typename Dest>
   74|       |  EIGEN_DEVICE_FUNC inline void addTo(Dest& dst) const {
   75|       |    // This is the default implementation,
   76|       |    // derived class can reimplement it in a more optimized way.
   77|       |    typename Dest::PlainObject res(rows(), cols());
   78|       |    evalTo(res);
   79|       |    dst += res;
   80|       |  }
   81|       |
   82|       |  /** \internal Don't use it, but do the equivalent: \code dst -= *this; \endcode */
   83|       |  template <typename Dest>
   84|       |  EIGEN_DEVICE_FUNC inline void subTo(Dest& dst) const {
   85|       |    // This is the default implementation,
   86|       |    // derived class can reimplement it in a more optimized way.
   87|       |    typename Dest::PlainObject res(rows(), cols());
   88|       |    evalTo(res);
   89|       |    dst -= res;
   90|       |  }
   91|       |
   92|       |  /** \internal Don't use it, but do the equivalent: \code dst.applyOnTheRight(*this); \endcode */
   93|       |  template <typename Dest>
   94|       |  EIGEN_DEVICE_FUNC inline void applyThisOnTheRight(Dest& dst) const {
   95|       |    // This is the default implementation,
   96|       |    // derived class can reimplement it in a more optimized way.
   97|       |    dst = dst * this->derived();
   98|       |  }
   99|       |
  100|       |  /** \internal Don't use it, but do the equivalent: \code dst.applyOnTheLeft(*this); \endcode */
  101|       |  template <typename Dest>
  102|       |  EIGEN_DEVICE_FUNC inline void applyThisOnTheLeft(Dest& dst) const {
  103|       |    // This is the default implementation,
  104|       |    // derived class can reimplement it in a more optimized way.
  105|       |    dst = this->derived() * dst;
  106|       |  }
  107|       |
  108|       |  template <typename Device>
  109|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DeviceWrapper<Derived, Device> device(Device& device);
  110|       |  template <typename Device>
  111|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DeviceWrapper<const Derived, Device> device(Device& device) const;
  112|       |};
  113|       |
  114|       |/***************************************************************************
  115|       | * Implementation of matrix base methods
  116|       | ***************************************************************************/
  117|       |
  118|       |/** \brief Copies the generic expression \a other into *this.
  119|       | *
  120|       | * \details The expression must provide a (templated) evalTo(Derived& dst) const
  121|       | * function which does the actual job. In practice, this allows any user to write
  122|       | * its own special matrix without having to modify MatrixBase
  123|       | *
  124|       | * \returns a reference to *this.
  125|       | */
  126|       |template <typename Derived>
  127|       |template <typename OtherDerived>
  128|       |EIGEN_DEVICE_FUNC Derived& DenseBase<Derived>::operator=(const EigenBase<OtherDerived>& other) {
  129|       |  call_assignment(derived(), other.derived());
  130|       |  return derived();
  131|       |}
  132|       |
  133|       |template <typename Derived>
  134|       |template <typename OtherDerived>
  135|       |EIGEN_DEVICE_FUNC Derived& DenseBase<Derived>::operator+=(const EigenBase<OtherDerived>& other) {
  136|       |  call_assignment(derived(), other.derived(), internal::add_assign_op<Scalar, typename OtherDerived::Scalar>());
  137|       |  return derived();
  138|       |}
  139|       |
  140|       |template <typename Derived>
  141|       |template <typename OtherDerived>
  142|       |EIGEN_DEVICE_FUNC Derived& DenseBase<Derived>::operator-=(const EigenBase<OtherDerived>& other) {
  143|       |  call_assignment(derived(), other.derived(), internal::sub_assign_op<Scalar, typename OtherDerived::Scalar>());
  144|       |  return derived();
  145|       |}
  146|       |
  147|       |}  // end namespace Eigen
  148|       |
  149|       |#endif  // EIGEN_EIGENBASE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Fill.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2024 Charles Schlosser <cs.schlosser@gmail.com>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_FILL_H
   11|       |#define EIGEN_FILL_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "./InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |template <typename Xpr>
   21|       |struct eigen_fill_helper : std::false_type {};
   22|       |
   23|       |template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
   24|       |struct eigen_fill_helper<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>> : std::true_type {};
   25|       |
   26|       |template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
   27|       |struct eigen_fill_helper<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>> : std::true_type {};
   28|       |
   29|       |template <typename Xpr, int BlockRows, int BlockCols>
   30|       |struct eigen_fill_helper<Block<Xpr, BlockRows, BlockCols, /*InnerPanel*/ true>> : eigen_fill_helper<Xpr> {};
   31|       |
   32|       |template <typename Xpr, int BlockRows, int BlockCols>
   33|       |struct eigen_fill_helper<Block<Xpr, BlockRows, BlockCols, /*InnerPanel*/ false>>
   34|       |    : std::integral_constant<bool, eigen_fill_helper<Xpr>::value &&
   35|       |                                       (Xpr::IsRowMajor ? (BlockRows == 1) : (BlockCols == 1))> {};
   36|       |
   37|       |template <typename Xpr, int Options>
   38|       |struct eigen_fill_helper<Map<Xpr, Options, Stride<0, 0>>> : eigen_fill_helper<Xpr> {};
   39|       |
   40|       |template <typename Xpr, int Options, int OuterStride_>
   41|       |struct eigen_fill_helper<Map<Xpr, Options, Stride<OuterStride_, 0>>>
   42|       |    : std::integral_constant<bool, eigen_fill_helper<Xpr>::value &&
   43|       |                                       enum_eq_not_dynamic(OuterStride_, Xpr::InnerSizeAtCompileTime)> {};
   44|       |
   45|       |template <typename Xpr, int Options, int OuterStride_>
   46|       |struct eigen_fill_helper<Map<Xpr, Options, Stride<OuterStride_, 1>>>
   47|       |    : eigen_fill_helper<Map<Xpr, Options, Stride<OuterStride_, 0>>> {};
   48|       |
   49|       |template <typename Xpr, int Options, int InnerStride_>
   50|       |struct eigen_fill_helper<Map<Xpr, Options, InnerStride<InnerStride_>>>
   51|       |    : eigen_fill_helper<Map<Xpr, Options, Stride<0, InnerStride_>>> {};
   52|       |
   53|       |template <typename Xpr, int Options, int OuterStride_>
   54|       |struct eigen_fill_helper<Map<Xpr, Options, OuterStride<OuterStride_>>>
   55|       |    : eigen_fill_helper<Map<Xpr, Options, Stride<OuterStride_, 0>>> {};
   56|       |
   57|       |template <typename Xpr>
   58|       |struct eigen_fill_impl<Xpr, /*use_fill*/ false> {
   59|       |  using Scalar = typename Xpr::Scalar;
   60|       |  using Func = scalar_constant_op<Scalar>;
   61|       |  using PlainObject = typename Xpr::PlainObject;
   62|       |  using Constant = typename PlainObject::ConstantReturnType;
   63|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const Scalar& val) {
   64|       |    const Constant src(dst.rows(), dst.cols(), val);
   65|       |    run(dst, src);
   66|       |  }
   67|       |  template <typename SrcXpr>
   68|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const SrcXpr& src) {
   69|       |    call_dense_assignment_loop(dst, src, assign_op<Scalar, Scalar>());
   70|       |  }
   71|       |};
   72|       |
   73|       |#if EIGEN_COMP_MSVC || defined(EIGEN_GPU_COMPILE_PHASE)
   74|       |template <typename Xpr>
   75|       |struct eigen_fill_impl<Xpr, /*use_fill*/ true> : eigen_fill_impl<Xpr, /*use_fill*/ false> {};
   76|       |#else
   77|       |template <typename Xpr>
   78|       |struct eigen_fill_impl<Xpr, /*use_fill*/ true> {
   79|       |  using Scalar = typename Xpr::Scalar;
   80|      5|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const Scalar& val) {
   81|      5|    using std::fill_n;
   82|      5|    fill_n(dst.data(), dst.size(), val);
   83|      5|  }
  ------------------
  | _ZN5Eigen8internal15eigen_fill_implINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELb1EE3runERS4_RKS3_:
  |   80|      2|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const Scalar& val) {
  |   81|      2|    using std::fill_n;
  |   82|      2|    fill_n(dst.data(), dst.size(), val);
  |   83|      2|  }
  ------------------
  | _ZN5Eigen8internal15eigen_fill_implINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELb1EE3runERS4_RKS3_:
  |   80|      3|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const Scalar& val) {
  |   81|      3|    using std::fill_n;
  |   82|      3|    fill_n(dst.data(), dst.size(), val);
  |   83|      3|  }
  ------------------
   84|       |  template <typename SrcXpr>
   85|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const SrcXpr& src) {
   86|       |    resize_if_allowed(dst, src, assign_op<Scalar, Scalar>());
   87|       |    const Scalar& val = src.functor()();
   88|       |    run(dst, val);
   89|       |  }
   90|       |};
   91|       |#endif
   92|       |
   93|       |template <typename Xpr>
   94|       |struct eigen_memset_helper {
   95|       |  static constexpr bool value = std::is_trivial<typename Xpr::Scalar>::value && eigen_fill_helper<Xpr>::value;
   96|       |};
   97|       |
   98|       |template <typename Xpr>
   99|       |struct eigen_zero_impl<Xpr, /*use_memset*/ false> {
  100|       |  using Scalar = typename Xpr::Scalar;
  101|       |  using PlainObject = typename Xpr::PlainObject;
  102|       |  using Zero = typename PlainObject::ZeroReturnType;
  103|      4|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst) {
  104|      4|    const Zero src(dst.rows(), dst.cols());
  105|      4|    run(dst, src);
  106|      4|  }
  ------------------
  | _ZN5Eigen8internal15eigen_zero_implINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELb0EE3runERS4_:
  |  103|      1|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst) {
  |  104|      1|    const Zero src(dst.rows(), dst.cols());
  |  105|      1|    run(dst, src);
  |  106|      1|  }
  ------------------
  | _ZN5Eigen8internal15eigen_zero_implINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELb0EE3runERS4_:
  |  103|      3|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst) {
  |  104|      3|    const Zero src(dst.rows(), dst.cols());
  |  105|      3|    run(dst, src);
  |  106|      3|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15eigen_zero_implINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEELb0EE3runERS8_
  ------------------
  107|       |  template <typename SrcXpr>
  108|      4|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const SrcXpr& src) {
  109|      4|    call_dense_assignment_loop(dst, src, assign_op<Scalar, Scalar>());
  110|      4|  }
  ------------------
  | _ZN5Eigen8internal15eigen_zero_implINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELb0EE3runINS_14CwiseNullaryOpINS0_14scalar_zero_opIS3_EES4_EEEEvRS4_RKT_:
  |  108|      1|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const SrcXpr& src) {
  |  109|      1|    call_dense_assignment_loop(dst, src, assign_op<Scalar, Scalar>());
  |  110|      1|  }
  ------------------
  | _ZN5Eigen8internal15eigen_zero_implINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELb0EE3runINS_14CwiseNullaryOpINS0_14scalar_zero_opIS3_EES4_EEEEvRS4_RKT_:
  |  108|      3|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const SrcXpr& src) {
  |  109|      3|    call_dense_assignment_loop(dst, src, assign_op<Scalar, Scalar>());
  |  110|      3|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15eigen_zero_implINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEELb0EE3runINS_14CwiseNullaryOpINS0_14scalar_zero_opIS4_EES5_EEEEvRS8_RKT_
  ------------------
  111|       |};
  112|       |
  113|       |template <typename Xpr>
  114|       |struct eigen_zero_impl<Xpr, /*use_memset*/ true> {
  115|       |  using Scalar = typename Xpr::Scalar;
  116|       |  static constexpr size_t max_bytes = (std::numeric_limits<std::ptrdiff_t>::max)();
  117|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst) {
  118|       |    const size_t num_bytes = dst.size() * sizeof(Scalar);
  119|       |    if (num_bytes == 0) return;
  120|       |    void* dst_ptr = static_cast<void*>(dst.data());
  121|       |#ifndef EIGEN_NO_DEBUG
  122|       |    if (num_bytes > max_bytes) throw_std_bad_alloc();
  123|       |    eigen_assert((dst_ptr != nullptr) && "null pointer dereference error!");
  124|       |#endif
  125|       |    EIGEN_USING_STD(memset);
  126|       |    memset(dst_ptr, 0, num_bytes);
  127|       |  }
  128|       |  template <typename SrcXpr>
  129|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Xpr& dst, const SrcXpr& src) {
  130|       |    resize_if_allowed(dst, src, assign_op<Scalar, Scalar>());
  131|       |    run(dst);
  132|       |  }
  133|       |};
  134|       |
  135|       |}  // namespace internal
  136|       |}  // namespace Eigen
  137|       |
  138|       |#endif  // EIGEN_FILL_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/GeneralProduct.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2008-2011 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_GENERAL_PRODUCT_H
   12|       |#define EIGEN_GENERAL_PRODUCT_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |enum { Large = 2, Small = 3 };
   20|       |
   21|       |// Define the threshold value to fallback from the generic matrix-matrix product
   22|       |// implementation (heavy) to the lightweight coeff-based product one.
   23|       |// See generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,GemmProduct>
   24|       |// in products/GeneralMatrixMatrix.h for more details.
   25|       |// TODO This threshold should also be used in the compile-time selector below.
   26|       |#ifndef EIGEN_GEMM_TO_COEFFBASED_THRESHOLD
   27|       |// This default value has been obtained on a Haswell architecture.
   28|      6|#define EIGEN_GEMM_TO_COEFFBASED_THRESHOLD 20
   29|       |#endif
   30|       |
   31|       |namespace internal {
   32|       |
   33|       |template <int Rows, int Cols, int Depth>
   34|       |struct product_type_selector;
   35|       |
   36|       |template <int Size, int MaxSize>
   37|       |struct product_size_category {
   38|       |  enum {
   39|       |#ifndef EIGEN_GPU_COMPILE_PHASE
   40|       |    is_large = MaxSize == Dynamic || Size >= EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD ||
   41|       |               (Size == Dynamic && MaxSize >= EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD),
   42|       |#else
   43|       |    is_large = 0,
   44|       |#endif
   45|       |    value = is_large    ? Large
   46|       |            : Size == 1 ? 1
   47|       |                        : Small
   48|       |  };
   49|       |};
   50|       |
   51|       |template <typename Lhs, typename Rhs>
   52|       |struct product_type {
   53|       |  typedef remove_all_t<Lhs> Lhs_;
   54|       |  typedef remove_all_t<Rhs> Rhs_;
   55|       |  enum {
   56|       |    MaxRows = traits<Lhs_>::MaxRowsAtCompileTime,
   57|       |    Rows = traits<Lhs_>::RowsAtCompileTime,
   58|       |    MaxCols = traits<Rhs_>::MaxColsAtCompileTime,
   59|       |    Cols = traits<Rhs_>::ColsAtCompileTime,
   60|       |    MaxDepth = min_size_prefer_fixed(traits<Lhs_>::MaxColsAtCompileTime, traits<Rhs_>::MaxRowsAtCompileTime),
   61|       |    Depth = min_size_prefer_fixed(traits<Lhs_>::ColsAtCompileTime, traits<Rhs_>::RowsAtCompileTime)
   62|       |  };
   63|       |
   64|       |  // the splitting into different lines of code here, introducing the _select enums and the typedef below,
   65|       |  // is to work around an internal compiler error with gcc 4.1 and 4.2.
   66|       | private:
   67|       |  enum {
   68|       |    rows_select = product_size_category<Rows, MaxRows>::value,
   69|       |    cols_select = product_size_category<Cols, MaxCols>::value,
   70|       |    depth_select = product_size_category<Depth, MaxDepth>::value
   71|       |  };
   72|       |  typedef product_type_selector<rows_select, cols_select, depth_select> selector;
   73|       |
   74|       | public:
   75|       |  enum { value = selector::ret, ret = selector::ret };
   76|       |#ifdef EIGEN_DEBUG_PRODUCT
   77|       |  static void debug() {
   78|       |    EIGEN_DEBUG_VAR(Rows);
   79|       |    EIGEN_DEBUG_VAR(Cols);
   80|       |    EIGEN_DEBUG_VAR(Depth);
   81|       |    EIGEN_DEBUG_VAR(rows_select);
   82|       |    EIGEN_DEBUG_VAR(cols_select);
   83|       |    EIGEN_DEBUG_VAR(depth_select);
   84|       |    EIGEN_DEBUG_VAR(value);
   85|       |  }
   86|       |#endif
   87|       |};
   88|       |
   89|       |/* The following allows to select the kind of product at compile time
   90|       | * based on the three dimensions of the product.
   91|       | * This is a compile time mapping from {1,Small,Large}^3 -> {product types} */
   92|       |// FIXME I'm not sure the current mapping is the ideal one.
   93|       |template <int M, int N>
   94|       |struct product_type_selector<M, N, 1> {
   95|       |  enum { ret = OuterProduct };
   96|       |};
   97|       |template <int M>
   98|       |struct product_type_selector<M, 1, 1> {
   99|       |  enum { ret = LazyCoeffBasedProductMode };
  100|       |};
  101|       |template <int N>
  102|       |struct product_type_selector<1, N, 1> {
  103|       |  enum { ret = LazyCoeffBasedProductMode };
  104|       |};
  105|       |template <int Depth>
  106|       |struct product_type_selector<1, 1, Depth> {
  107|       |  enum { ret = InnerProduct };
  108|       |};
  109|       |template <>
  110|       |struct product_type_selector<1, 1, 1> {
  111|       |  enum { ret = InnerProduct };
  112|       |};
  113|       |template <>
  114|       |struct product_type_selector<Small, 1, Small> {
  115|       |  enum { ret = CoeffBasedProductMode };
  116|       |};
  117|       |template <>
  118|       |struct product_type_selector<1, Small, Small> {
  119|       |  enum { ret = CoeffBasedProductMode };
  120|       |};
  121|       |template <>
  122|       |struct product_type_selector<Small, Small, Small> {
  123|       |  enum { ret = CoeffBasedProductMode };
  124|       |};
  125|       |template <>
  126|       |struct product_type_selector<Small, Small, 1> {
  127|       |  enum { ret = LazyCoeffBasedProductMode };
  128|       |};
  129|       |template <>
  130|       |struct product_type_selector<Small, Large, 1> {
  131|       |  enum { ret = LazyCoeffBasedProductMode };
  132|       |};
  133|       |template <>
  134|       |struct product_type_selector<Large, Small, 1> {
  135|       |  enum { ret = LazyCoeffBasedProductMode };
  136|       |};
  137|       |template <>
  138|       |struct product_type_selector<1, Large, Small> {
  139|       |  enum { ret = CoeffBasedProductMode };
  140|       |};
  141|       |template <>
  142|       |struct product_type_selector<1, Large, Large> {
  143|       |  enum { ret = GemvProduct };
  144|       |};
  145|       |template <>
  146|       |struct product_type_selector<1, Small, Large> {
  147|       |  enum { ret = CoeffBasedProductMode };
  148|       |};
  149|       |template <>
  150|       |struct product_type_selector<Large, 1, Small> {
  151|       |  enum { ret = CoeffBasedProductMode };
  152|       |};
  153|       |template <>
  154|       |struct product_type_selector<Large, 1, Large> {
  155|       |  enum { ret = GemvProduct };
  156|       |};
  157|       |template <>
  158|       |struct product_type_selector<Small, 1, Large> {
  159|       |  enum { ret = CoeffBasedProductMode };
  160|       |};
  161|       |template <>
  162|       |struct product_type_selector<Small, Small, Large> {
  163|       |  enum { ret = GemmProduct };
  164|       |};
  165|       |template <>
  166|       |struct product_type_selector<Large, Small, Large> {
  167|       |  enum { ret = GemmProduct };
  168|       |};
  169|       |template <>
  170|       |struct product_type_selector<Small, Large, Large> {
  171|       |  enum { ret = GemmProduct };
  172|       |};
  173|       |template <>
  174|       |struct product_type_selector<Large, Large, Large> {
  175|       |  enum { ret = GemmProduct };
  176|       |};
  177|       |template <>
  178|       |struct product_type_selector<Large, Small, Small> {
  179|       |  enum { ret = CoeffBasedProductMode };
  180|       |};
  181|       |template <>
  182|       |struct product_type_selector<Small, Large, Small> {
  183|       |  enum { ret = CoeffBasedProductMode };
  184|       |};
  185|       |template <>
  186|       |struct product_type_selector<Large, Large, Small> {
  187|       |  enum { ret = GemmProduct };
  188|       |};
  189|       |
  190|       |}  // end namespace internal
  191|       |
  192|       |/***********************************************************************
  193|       | *  Implementation of Inner Vector Vector Product
  194|       | ***********************************************************************/
  195|       |
  196|       |// FIXME : maybe the "inner product" could return a Scalar
  197|       |// instead of a 1x1 matrix ??
  198|       |// Pro: more natural for the user
  199|       |// Cons: this could be a problem if in a meta unrolled algorithm a matrix-matrix
  200|       |// product ends up to a row-vector times col-vector product... To tackle this use
  201|       |// case, we could have a specialization for Block<MatrixType,1,1> with: operator=(Scalar x);
  202|       |
  203|       |/***********************************************************************
  204|       | *  Implementation of Outer Vector Vector Product
  205|       | ***********************************************************************/
  206|       |
  207|       |/***********************************************************************
  208|       | *  Implementation of General Matrix Vector Product
  209|       | ***********************************************************************/
  210|       |
  211|       |/*  According to the shape/flags of the matrix we have to distinghish 3 different cases:
  212|       | *   1 - the matrix is col-major, BLAS compatible and M is large => call fast BLAS-like colmajor routine
  213|       | *   2 - the matrix is row-major, BLAS compatible and N is large => call fast BLAS-like rowmajor routine
  214|       | *   3 - all other cases are handled using a simple loop along the outer-storage direction.
  215|       | *  Therefore we need a lower level meta selector.
  216|       | *  Furthermore, if the matrix is the rhs, then the product has to be transposed.
  217|       | */
  218|       |namespace internal {
  219|       |
  220|       |template <int Side, int StorageOrder, bool BlasCompatible>
  221|       |struct gemv_dense_selector;
  222|       |
  223|       |}  // end namespace internal
  224|       |
  225|       |namespace internal {
  226|       |
  227|       |template <typename Scalar, int Size, int MaxSize, bool Cond>
  228|       |struct gemv_static_vector_if;
  229|       |
  230|       |template <typename Scalar, int Size, int MaxSize>
  231|       |struct gemv_static_vector_if<Scalar, Size, MaxSize, false> {
  232|      0|  EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC constexpr Scalar* data() {
  233|      0|    eigen_internal_assert(false && "should never be called");
  234|      0|    return 0;
  235|      0|  }
  236|       |};
  237|       |
  238|       |template <typename Scalar, int Size>
  239|       |struct gemv_static_vector_if<Scalar, Size, Dynamic, true> {
  240|      0|  EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC constexpr Scalar* data() { return 0; }
  241|       |};
  242|       |
  243|       |template <typename Scalar, int Size, int MaxSize>
  244|       |struct gemv_static_vector_if<Scalar, Size, MaxSize, true> {
  245|       |#if EIGEN_MAX_STATIC_ALIGN_BYTES != 0
  246|       |  internal::plain_array<Scalar, internal::min_size_prefer_fixed(Size, MaxSize), 0, AlignedMax> m_data;
  247|       |  EIGEN_STRONG_INLINE constexpr Scalar* data() { return m_data.array; }
  248|       |#else
  249|       |  // Some architectures cannot align on the stack,
  250|       |  // => let's manually enforce alignment by allocating more data and return the address of the first aligned element.
  251|       |  internal::plain_array<Scalar, internal::min_size_prefer_fixed(Size, MaxSize) + EIGEN_MAX_ALIGN_BYTES, 0> m_data;
  252|       |  EIGEN_STRONG_INLINE constexpr Scalar* data() {
  253|       |    return reinterpret_cast<Scalar*>((std::uintptr_t(m_data.array) & ~(std::size_t(EIGEN_MAX_ALIGN_BYTES - 1))) +
  254|       |                                     EIGEN_MAX_ALIGN_BYTES);
  255|       |  }
  256|       |#endif
  257|       |};
  258|       |
  259|       |// The vector is on the left => transposition
  260|       |template <int StorageOrder, bool BlasCompatible>
  261|       |struct gemv_dense_selector<OnTheLeft, StorageOrder, BlasCompatible> {
  262|       |  template <typename Lhs, typename Rhs, typename Dest>
  263|      0|  static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
  264|      0|    Transpose<Dest> destT(dest);
  265|      0|    enum { OtherStorageOrder = StorageOrder == RowMajor ? ColMajor : RowMajor };
  266|      0|    gemv_dense_selector<OnTheRight, OtherStorageOrder, BlasCompatible>::run(rhs.transpose(), lhs.transpose(), destT,
  267|      0|                                                                            alpha);
  268|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19gemv_dense_selectorILi1ELi0ELb1EE3runINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEES7_NS4_IS7_Li1ELin1ELb0EEEEEvRKT_RKT0_RT1_RKNSH_6ScalarE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19gemv_dense_selectorILi1ELi0ELb1EE3runINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS4_IS5_Lin1ELin1ELi0ELin1ELin1EEENS_5BlockIS7_Li1ELin1ELb0EEEEEvRKT_RKT0_RT1_RKNSG_6ScalarE
  ------------------
  269|       |};
  270|       |
  271|       |template <>
  272|       |struct gemv_dense_selector<OnTheRight, ColMajor, true> {
  273|       |  template <typename Lhs, typename Rhs, typename Dest>
  274|      0|  static inline void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
  275|      0|    typedef typename Lhs::Scalar LhsScalar;
  276|      0|    typedef typename Rhs::Scalar RhsScalar;
  277|      0|    typedef typename Dest::Scalar ResScalar;
  278|       |
  279|      0|    typedef internal::blas_traits<Lhs> LhsBlasTraits;
  280|      0|    typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
  281|      0|    typedef internal::blas_traits<Rhs> RhsBlasTraits;
  282|      0|    typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
  283|       |
  284|      0|    typedef Map<Matrix<ResScalar, Dynamic, 1>, plain_enum_min(AlignedMax, internal::packet_traits<ResScalar>::size)>
  285|      0|        MappedDest;
  286|       |
  287|      0|    ActualLhsType actualLhs = LhsBlasTraits::extract(lhs);
  288|      0|    ActualRhsType actualRhs = RhsBlasTraits::extract(rhs);
  289|       |
  290|      0|    ResScalar actualAlpha = combine_scalar_factors(alpha, lhs, rhs);
  291|       |
  292|       |    // make sure Dest is a compile-time vector type (bug 1166)
  293|      0|    typedef std::conditional_t<Dest::IsVectorAtCompileTime, Dest, typename Dest::ColXpr> ActualDest;
  294|       |
  295|      0|    enum {
  296|       |      // FIXME find a way to allow an inner stride on the result if packet_traits<Scalar>::size==1
  297|       |      // on, the other hand it is good for the cache to pack the vector anyways...
  298|      0|      EvalToDestAtCompileTime = (ActualDest::InnerStrideAtCompileTime == 1),
  299|      0|      ComplexByReal = (NumTraits<LhsScalar>::IsComplex) && (!NumTraits<RhsScalar>::IsComplex),
  300|      0|      MightCannotUseDest = ((!EvalToDestAtCompileTime) || ComplexByReal) && (ActualDest::MaxSizeAtCompileTime != 0)
  301|      0|    };
  302|       |
  303|      0|    typedef const_blas_data_mapper<LhsScalar, Index, ColMajor> LhsMapper;
  304|      0|    typedef const_blas_data_mapper<RhsScalar, Index, RowMajor> RhsMapper;
  305|      0|    RhsScalar compatibleAlpha = get_factor<ResScalar, RhsScalar>::run(actualAlpha);
  306|       |
  307|      0|    if (!MightCannotUseDest) {
  308|       |      // shortcut if we are sure to be able to use dest directly,
  309|       |      // this ease the compiler to generate cleaner and more optimzized code for most common cases
  310|      0|      general_matrix_vector_product<Index, LhsScalar, LhsMapper, ColMajor, LhsBlasTraits::NeedToConjugate, RhsScalar,
  311|      0|                                    RhsMapper, RhsBlasTraits::NeedToConjugate>::run(actualLhs.rows(), actualLhs.cols(),
  312|      0|                                                                                    LhsMapper(actualLhs.data(),
  313|      0|                                                                                              actualLhs.outerStride()),
  314|      0|                                                                                    RhsMapper(actualRhs.data(),
  315|      0|                                                                                              actualRhs.innerStride()),
  316|      0|                                                                                    dest.data(), 1, compatibleAlpha);
  317|      0|    } else {
  318|      0|      gemv_static_vector_if<ResScalar, ActualDest::SizeAtCompileTime, ActualDest::MaxSizeAtCompileTime,
  319|      0|                            MightCannotUseDest>
  320|      0|          static_dest;
  321|       |
  322|      0|      const bool alphaIsCompatible = (!ComplexByReal) || (numext::is_exactly_zero(numext::imag(actualAlpha)));
  323|      0|      const bool evalToDest = EvalToDestAtCompileTime && alphaIsCompatible;
  324|       |
  325|      0|      ei_declare_aligned_stack_constructed_variable(ResScalar, actualDestPtr, dest.size(),
  326|      0|                                                    evalToDest ? dest.data() : static_dest.data());
  327|       |
  328|      0|      if (!evalToDest) {
  329|       |#ifdef EIGEN_DENSE_STORAGE_CTOR_PLUGIN
  330|       |        constexpr int Size = Dest::SizeAtCompileTime;
  331|       |        Index size = dest.size();
  332|       |        EIGEN_DENSE_STORAGE_CTOR_PLUGIN
  333|       |#endif
  334|      0|        if (!alphaIsCompatible) {
  335|      0|          MappedDest(actualDestPtr, dest.size()).setZero();
  336|      0|          compatibleAlpha = RhsScalar(1);
  337|      0|        } else
  338|      0|          MappedDest(actualDestPtr, dest.size()) = dest;
  339|      0|      }
  340|       |
  341|      0|      general_matrix_vector_product<Index, LhsScalar, LhsMapper, ColMajor, LhsBlasTraits::NeedToConjugate, RhsScalar,
  342|      0|                                    RhsMapper, RhsBlasTraits::NeedToConjugate>::run(actualLhs.rows(), actualLhs.cols(),
  343|      0|                                                                                    LhsMapper(actualLhs.data(),
  344|      0|                                                                                              actualLhs.outerStride()),
  345|      0|                                                                                    RhsMapper(actualRhs.data(),
  346|      0|                                                                                              actualRhs.innerStride()),
  347|      0|                                                                                    actualDestPtr, 1, compatibleAlpha);
  348|       |
  349|      0|      if (!evalToDest) {
  350|      0|        if (!alphaIsCompatible)
  351|      0|          dest.matrix() += actualAlpha * MappedDest(actualDestPtr, dest.size());
  352|      0|        else
  353|      0|          dest = MappedDest(actualDestPtr, dest.size());
  354|      0|      }
  355|      0|    }
  356|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19gemv_dense_selectorILi2ELi0ELb1EE3runINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_5BlockIKS6_Lin1ELi1ELb1EEENS7_IS6_Lin1ELi1ELb1EEEEEvRKT_RKT0_RT1_RKNSH_6ScalarE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19gemv_dense_selectorILi2ELi0ELb1EE3runINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS4_IS5_Lin1ELi1ELi0ELin1ELi1EEES7_EEvRKT_RKT0_RT1_RKNSE_6ScalarE
  ------------------
  357|       |};
  358|       |
  359|       |template <>
  360|       |struct gemv_dense_selector<OnTheRight, RowMajor, true> {
  361|       |  template <typename Lhs, typename Rhs, typename Dest>
  362|      0|  static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
  363|      0|    typedef typename Lhs::Scalar LhsScalar;
  364|      0|    typedef typename Rhs::Scalar RhsScalar;
  365|      0|    typedef typename Dest::Scalar ResScalar;
  366|       |
  367|      0|    typedef internal::blas_traits<Lhs> LhsBlasTraits;
  368|      0|    typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
  369|      0|    typedef internal::blas_traits<Rhs> RhsBlasTraits;
  370|      0|    typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
  371|      0|    typedef internal::remove_all_t<ActualRhsType> ActualRhsTypeCleaned;
  372|       |
  373|      0|    std::add_const_t<ActualLhsType> actualLhs = LhsBlasTraits::extract(lhs);
  374|      0|    std::add_const_t<ActualRhsType> actualRhs = RhsBlasTraits::extract(rhs);
  375|       |
  376|      0|    ResScalar actualAlpha = combine_scalar_factors(alpha, lhs, rhs);
  377|       |
  378|      0|    enum {
  379|       |      // FIXME find a way to allow an inner stride on the result if packet_traits<Scalar>::size==1
  380|       |      // on, the other hand it is good for the cache to pack the vector anyways...
  381|      0|      DirectlyUseRhs =
  382|      0|          ActualRhsTypeCleaned::InnerStrideAtCompileTime == 1 || ActualRhsTypeCleaned::MaxSizeAtCompileTime == 0
  383|      0|    };
  384|       |
  385|      0|    gemv_static_vector_if<RhsScalar, ActualRhsTypeCleaned::SizeAtCompileTime,
  386|      0|                          ActualRhsTypeCleaned::MaxSizeAtCompileTime, !DirectlyUseRhs>
  387|      0|        static_rhs;
  388|       |
  389|      0|    ei_declare_aligned_stack_constructed_variable(
  390|      0|        RhsScalar, actualRhsPtr, actualRhs.size(),
  391|      0|        DirectlyUseRhs ? const_cast<RhsScalar*>(actualRhs.data()) : static_rhs.data());
  392|       |
  393|      0|    if (!DirectlyUseRhs) {
  394|       |#ifdef EIGEN_DENSE_STORAGE_CTOR_PLUGIN
  395|       |      constexpr int Size = ActualRhsTypeCleaned::SizeAtCompileTime;
  396|       |      Index size = actualRhs.size();
  397|       |      EIGEN_DENSE_STORAGE_CTOR_PLUGIN
  398|       |#endif
  399|      0|      Map<typename ActualRhsTypeCleaned::PlainObject>(actualRhsPtr, actualRhs.size()) = actualRhs;
  400|      0|    }
  401|       |
  402|      0|    typedef const_blas_data_mapper<LhsScalar, Index, RowMajor> LhsMapper;
  403|      0|    typedef const_blas_data_mapper<RhsScalar, Index, ColMajor> RhsMapper;
  404|      0|    general_matrix_vector_product<Index, LhsScalar, LhsMapper, RowMajor, LhsBlasTraits::NeedToConjugate, RhsScalar,
  405|      0|                                  RhsMapper, RhsBlasTraits::NeedToConjugate>::
  406|      0|        run(actualLhs.rows(), actualLhs.cols(), LhsMapper(actualLhs.data(), actualLhs.outerStride()),
  407|      0|            RhsMapper(actualRhsPtr, 1), dest.data(),
  408|      0|            dest.col(0).innerStride(),  // NOTE  if dest is not a vector at compile-time, then dest.innerStride() might
  409|       |                                        // be wrong. (bug 1166)
  410|      0|            actualAlpha);
  411|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19gemv_dense_selectorILi2ELi1ELb1EE3runINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS4_IKNS_5BlockIS8_Li1ELin1ELb0EEEEENS4_INSA_IS7_Li1ELin1ELb0EEEEEEEvRKT_RKT0_RT1_RKNSM_6ScalarE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19gemv_dense_selectorILi2ELi1ELb1EE3runINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEENS4_IKNS5_IS6_Li1ELin1ELi1ELi1ELin1EEEEENS4_INS_5BlockIS7_Li1ELin1ELb0EEEEEEEvRKT_RKT0_RT1_RKNSM_6ScalarE
  ------------------
  412|       |};
  413|       |
  414|       |template <>
  415|       |struct gemv_dense_selector<OnTheRight, ColMajor, false> {
  416|       |  template <typename Lhs, typename Rhs, typename Dest>
  417|       |  static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
  418|       |    EIGEN_STATIC_ASSERT((!nested_eval<Lhs, 1>::Evaluate),
  419|       |                        EIGEN_INTERNAL_COMPILATION_ERROR_OR_YOU_MADE_A_PROGRAMMING_MISTAKE);
  420|       |    // TODO if rhs is large enough it might be beneficial to make sure that dest is sequentially stored in memory,
  421|       |    // otherwise use a temp
  422|       |    typename nested_eval<Rhs, 1>::type actual_rhs(rhs);
  423|       |    const Index size = rhs.rows();
  424|       |    for (Index k = 0; k < size; ++k) dest += (alpha * actual_rhs.coeff(k)) * lhs.col(k);
  425|       |  }
  426|       |};
  427|       |
  428|       |template <>
  429|       |struct gemv_dense_selector<OnTheRight, RowMajor, false> {
  430|       |  template <typename Lhs, typename Rhs, typename Dest>
  431|       |  static void run(const Lhs& lhs, const Rhs& rhs, Dest& dest, const typename Dest::Scalar& alpha) {
  432|       |    EIGEN_STATIC_ASSERT((!nested_eval<Lhs, 1>::Evaluate),
  433|       |                        EIGEN_INTERNAL_COMPILATION_ERROR_OR_YOU_MADE_A_PROGRAMMING_MISTAKE);
  434|       |    typename nested_eval<Rhs, Lhs::RowsAtCompileTime>::type actual_rhs(rhs);
  435|       |    const Index rows = dest.rows();
  436|       |    for (Index i = 0; i < rows; ++i)
  437|       |      dest.coeffRef(i) += alpha * (lhs.row(i).cwiseProduct(actual_rhs.transpose())).sum();
  438|       |  }
  439|       |};
  440|       |
  441|       |}  // end namespace internal
  442|       |
  443|       |/***************************************************************************
  444|       | * Implementation of matrix base methods
  445|       | ***************************************************************************/
  446|       |
  447|       |/** \returns the matrix product of \c *this and \a other.
  448|       | *
  449|       | * \note If instead of the matrix product you want the coefficient-wise product, see Cwise::operator*().
  450|       | *
  451|       | * \sa lazyProduct(), operator*=(const MatrixBase&), Cwise::operator*()
  452|       | */
  453|       |template <typename Derived>
  454|       |template <typename OtherDerived>
  455|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Product<Derived, OtherDerived> MatrixBase<Derived>::operator*(
  456|      4|    const MatrixBase<OtherDerived>& other) const {
  457|       |  // A note regarding the function declaration: In MSVC, this function will sometimes
  458|       |  // not be inlined since DenseStorage is an unwindable object for dynamic
  459|       |  // matrices and product types are holding a member to store the result.
  460|       |  // Thus it does not help tagging this function with EIGEN_STRONG_INLINE.
  461|      4|  enum {
  462|      4|    ProductIsValid = Derived::ColsAtCompileTime == Dynamic || OtherDerived::RowsAtCompileTime == Dynamic ||
  463|      4|                     int(Derived::ColsAtCompileTime) == int(OtherDerived::RowsAtCompileTime),
  464|      4|    AreVectors = Derived::IsVectorAtCompileTime && OtherDerived::IsVectorAtCompileTime,
  465|      4|    SameSizes = EIGEN_PREDICATE_SAME_MATRIX_SIZE(Derived, OtherDerived)
  466|      4|  };
  467|       |  // note to the lost user:
  468|       |  //    * for a dot product use: v1.dot(v2)
  469|       |  //    * for a coeff-wise product use: v1.cwiseProduct(v2)
  470|      4|  EIGEN_STATIC_ASSERT(
  471|      4|      ProductIsValid || !(AreVectors && SameSizes),
  472|      4|      INVALID_VECTOR_VECTOR_PRODUCT__IF_YOU_WANTED_A_DOT_OR_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTIONS)
  473|      4|  EIGEN_STATIC_ASSERT(ProductIsValid || !(SameSizes && !AreVectors),
  474|      4|                      INVALID_MATRIX_PRODUCT__IF_YOU_WANTED_A_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTION)
  475|      4|  EIGEN_STATIC_ASSERT(ProductIsValid || SameSizes, INVALID_MATRIX_PRODUCT)
  476|       |#ifdef EIGEN_DEBUG_PRODUCT
  477|       |  internal::product_type<Derived, OtherDerived>::debug();
  478|       |#endif
  479|       |
  480|      4|  return Product<Derived, OtherDerived>(derived(), other.derived());
  481|      4|}
  ------------------
  | _ZNK5Eigen10MatrixBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEmlIS3_EEKNS_7ProductIS3_T_Li0EEERKNS0_IS7_EE:
  |  456|      2|    const MatrixBase<OtherDerived>& other) const {
  |  457|       |  // A note regarding the function declaration: In MSVC, this function will sometimes
  |  458|       |  // not be inlined since DenseStorage is an unwindable object for dynamic
  |  459|       |  // matrices and product types are holding a member to store the result.
  |  460|       |  // Thus it does not help tagging this function with EIGEN_STRONG_INLINE.
  |  461|      2|  enum {
  |  462|      2|    ProductIsValid = Derived::ColsAtCompileTime == Dynamic || OtherDerived::RowsAtCompileTime == Dynamic ||
  |  463|      2|                     int(Derived::ColsAtCompileTime) == int(OtherDerived::RowsAtCompileTime),
  |  464|      2|    AreVectors = Derived::IsVectorAtCompileTime && OtherDerived::IsVectorAtCompileTime,
  |  465|      2|    SameSizes = EIGEN_PREDICATE_SAME_MATRIX_SIZE(Derived, OtherDerived)
  |  466|      2|  };
  |  467|       |  // note to the lost user:
  |  468|       |  //    * for a dot product use: v1.dot(v2)
  |  469|       |  //    * for a coeff-wise product use: v1.cwiseProduct(v2)
  |  470|      2|  EIGEN_STATIC_ASSERT(
  |  471|      2|      ProductIsValid || !(AreVectors && SameSizes),
  |  472|      2|      INVALID_VECTOR_VECTOR_PRODUCT__IF_YOU_WANTED_A_DOT_OR_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTIONS)
  |  473|      2|  EIGEN_STATIC_ASSERT(ProductIsValid || !(SameSizes && !AreVectors),
  |  474|      2|                      INVALID_MATRIX_PRODUCT__IF_YOU_WANTED_A_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTION)
  |  475|      2|  EIGEN_STATIC_ASSERT(ProductIsValid || SameSizes, INVALID_MATRIX_PRODUCT)
  |  476|       |#ifdef EIGEN_DEBUG_PRODUCT
  |  477|       |  internal::product_type<Derived, OtherDerived>::debug();
  |  478|       |#endif
  |  479|       |
  |  480|      2|  return Product<Derived, OtherDerived>(derived(), other.derived());
  |  481|      2|}
  ------------------
  | _ZNK5Eigen10MatrixBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEEEmlINS2_IS3_Lin1ELi1ELi0ELin1ELi1EEEEEKNS1_IS5_T_Li0EEERKNS0_IS9_EE:
  |  456|      1|    const MatrixBase<OtherDerived>& other) const {
  |  457|       |  // A note regarding the function declaration: In MSVC, this function will sometimes
  |  458|       |  // not be inlined since DenseStorage is an unwindable object for dynamic
  |  459|       |  // matrices and product types are holding a member to store the result.
  |  460|       |  // Thus it does not help tagging this function with EIGEN_STRONG_INLINE.
  |  461|      1|  enum {
  |  462|      1|    ProductIsValid = Derived::ColsAtCompileTime == Dynamic || OtherDerived::RowsAtCompileTime == Dynamic ||
  |  463|      1|                     int(Derived::ColsAtCompileTime) == int(OtherDerived::RowsAtCompileTime),
  |  464|      1|    AreVectors = Derived::IsVectorAtCompileTime && OtherDerived::IsVectorAtCompileTime,
  |  465|      1|    SameSizes = EIGEN_PREDICATE_SAME_MATRIX_SIZE(Derived, OtherDerived)
  |  466|      1|  };
  |  467|       |  // note to the lost user:
  |  468|       |  //    * for a dot product use: v1.dot(v2)
  |  469|       |  //    * for a coeff-wise product use: v1.cwiseProduct(v2)
  |  470|      1|  EIGEN_STATIC_ASSERT(
  |  471|      1|      ProductIsValid || !(AreVectors && SameSizes),
  |  472|      1|      INVALID_VECTOR_VECTOR_PRODUCT__IF_YOU_WANTED_A_DOT_OR_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTIONS)
  |  473|      1|  EIGEN_STATIC_ASSERT(ProductIsValid || !(SameSizes && !AreVectors),
  |  474|      1|                      INVALID_MATRIX_PRODUCT__IF_YOU_WANTED_A_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTION)
  |  475|      1|  EIGEN_STATIC_ASSERT(ProductIsValid || SameSizes, INVALID_MATRIX_PRODUCT)
  |  476|       |#ifdef EIGEN_DEBUG_PRODUCT
  |  477|       |  internal::product_type<Derived, OtherDerived>::debug();
  |  478|       |#endif
  |  479|       |
  |  480|      1|  return Product<Derived, OtherDerived>(derived(), other.derived());
  |  481|      1|}
  ------------------
  | _ZNK5Eigen10MatrixBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEEEmlIS4_EEKNS1_IS5_T_Li0EEERKNS0_IS8_EE:
  |  456|      1|    const MatrixBase<OtherDerived>& other) const {
  |  457|       |  // A note regarding the function declaration: In MSVC, this function will sometimes
  |  458|       |  // not be inlined since DenseStorage is an unwindable object for dynamic
  |  459|       |  // matrices and product types are holding a member to store the result.
  |  460|       |  // Thus it does not help tagging this function with EIGEN_STRONG_INLINE.
  |  461|      1|  enum {
  |  462|      1|    ProductIsValid = Derived::ColsAtCompileTime == Dynamic || OtherDerived::RowsAtCompileTime == Dynamic ||
  |  463|      1|                     int(Derived::ColsAtCompileTime) == int(OtherDerived::RowsAtCompileTime),
  |  464|      1|    AreVectors = Derived::IsVectorAtCompileTime && OtherDerived::IsVectorAtCompileTime,
  |  465|      1|    SameSizes = EIGEN_PREDICATE_SAME_MATRIX_SIZE(Derived, OtherDerived)
  |  466|      1|  };
  |  467|       |  // note to the lost user:
  |  468|       |  //    * for a dot product use: v1.dot(v2)
  |  469|       |  //    * for a coeff-wise product use: v1.cwiseProduct(v2)
  |  470|      1|  EIGEN_STATIC_ASSERT(
  |  471|      1|      ProductIsValid || !(AreVectors && SameSizes),
  |  472|      1|      INVALID_VECTOR_VECTOR_PRODUCT__IF_YOU_WANTED_A_DOT_OR_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTIONS)
  |  473|      1|  EIGEN_STATIC_ASSERT(ProductIsValid || !(SameSizes && !AreVectors),
  |  474|      1|                      INVALID_MATRIX_PRODUCT__IF_YOU_WANTED_A_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTION)
  |  475|      1|  EIGEN_STATIC_ASSERT(ProductIsValid || SameSizes, INVALID_MATRIX_PRODUCT)
  |  476|       |#ifdef EIGEN_DEBUG_PRODUCT
  |  477|       |  internal::product_type<Derived, OtherDerived>::debug();
  |  478|       |#endif
  |  479|       |
  |  480|      1|  return Product<Derived, OtherDerived>(derived(), other.derived());
  |  481|      1|}
  ------------------
  482|       |
  483|       |/** \returns an expression of the matrix product of \c *this and \a other without implicit evaluation.
  484|       | *
  485|       | * The returned product will behave like any other expressions: the coefficients of the product will be
  486|       | * computed once at a time as requested. This might be useful in some extremely rare cases when only
  487|       | * a small and no coherent fraction of the result's coefficients have to be computed.
  488|       | *
  489|       | * \warning This version of the matrix product can be much much slower. So use it only if you know
  490|       | * what you are doing and that you measured a true speed improvement.
  491|       | *
  492|       | * \sa operator*(const MatrixBase&)
  493|       | */
  494|       |template <typename Derived>
  495|       |template <typename OtherDerived>
  496|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Product<Derived, OtherDerived, LazyProduct>
  497|      0|MatrixBase<Derived>::lazyProduct(const MatrixBase<OtherDerived>& other) const {
  498|      0|  enum {
  499|      0|    ProductIsValid = Derived::ColsAtCompileTime == Dynamic || OtherDerived::RowsAtCompileTime == Dynamic ||
  500|      0|                     int(Derived::ColsAtCompileTime) == int(OtherDerived::RowsAtCompileTime),
  501|      0|    AreVectors = Derived::IsVectorAtCompileTime && OtherDerived::IsVectorAtCompileTime,
  502|      0|    SameSizes = EIGEN_PREDICATE_SAME_MATRIX_SIZE(Derived, OtherDerived)
  503|      0|  };
  504|       |  // note to the lost user:
  505|       |  //    * for a dot product use: v1.dot(v2)
  506|       |  //    * for a coeff-wise product use: v1.cwiseProduct(v2)
  507|      0|  EIGEN_STATIC_ASSERT(
  508|      0|      ProductIsValid || !(AreVectors && SameSizes),
  509|      0|      INVALID_VECTOR_VECTOR_PRODUCT__IF_YOU_WANTED_A_DOT_OR_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTIONS)
  510|      0|  EIGEN_STATIC_ASSERT(ProductIsValid || !(SameSizes && !AreVectors),
  511|      0|                      INVALID_MATRIX_PRODUCT__IF_YOU_WANTED_A_COEFF_WISE_PRODUCT_YOU_MUST_USE_THE_EXPLICIT_FUNCTION)
  512|      0|  EIGEN_STATIC_ASSERT(ProductIsValid || SameSizes, INVALID_MATRIX_PRODUCT)
  513|       |
  514|      0|  return Product<Derived, OtherDerived, LazyProduct>(derived(), other.derived());
  515|      0|}
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen10MatrixBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE11lazyProductIS3_EEKNS_7ProductIS3_T_Li1EEERKNS0_IS7_EE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen10MatrixBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEEE11lazyProductIS4_EEKNS1_IS5_T_Li1EEERKNS0_IS8_EE
  ------------------
  516|       |
  517|       |}  // end namespace Eigen
  518|       |
  519|       |#endif  // EIGEN_PRODUCT_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/GenericPacketMath.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_GENERIC_PACKET_MATH_H
   12|       |#define EIGEN_GENERIC_PACKET_MATH_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |
   21|       |/** \internal
   22|       | * \file GenericPacketMath.h
   23|       | *
   24|       | * Default implementation for types not supported by the vectorization.
   25|       | * In practice these functions are provided to make easier the writing
   26|       | * of generic vectorized code.
   27|       | */
   28|       |
   29|       |#ifndef EIGEN_DEBUG_ALIGNED_LOAD
   30|       |#define EIGEN_DEBUG_ALIGNED_LOAD
   31|       |#endif
   32|       |
   33|       |#ifndef EIGEN_DEBUG_UNALIGNED_LOAD
   34|       |#define EIGEN_DEBUG_UNALIGNED_LOAD
   35|       |#endif
   36|       |
   37|       |#ifndef EIGEN_DEBUG_ALIGNED_STORE
   38|       |#define EIGEN_DEBUG_ALIGNED_STORE
   39|       |#endif
   40|       |
   41|       |#ifndef EIGEN_DEBUG_UNALIGNED_STORE
   42|       |#define EIGEN_DEBUG_UNALIGNED_STORE
   43|       |#endif
   44|       |
   45|       |struct default_packet_traits {
   46|       |  enum {
   47|       |    // Ops that are implemented for most types.
   48|       |    HasAdd = 1,
   49|       |    HasSub = 1,
   50|       |    HasShift = 1,
   51|       |    HasMul = 1,
   52|       |    HasNegate = 1,
   53|       |    HasAbs = 1,
   54|       |    HasAbs2 = 1,
   55|       |    HasMin = 1,
   56|       |    HasMax = 1,
   57|       |    HasConj = 1,
   58|       |    HasSetLinear = 1,
   59|       |    HasSign = 1,
   60|       |    // By default, the nearest integer functions (rint, round, floor, ceil, trunc) are enabled for all scalar and packet
   61|       |    // types
   62|       |    HasRound = 1,
   63|       |
   64|       |    HasArg = 0,
   65|       |    HasAbsDiff = 0,
   66|       |    HasBlend = 0,
   67|       |    // This flag is used to indicate whether packet comparison is supported.
   68|       |    // pcmp_eq, pcmp_lt and pcmp_le should be defined for it to be true.
   69|       |    HasCmp = 0,
   70|       |
   71|       |    HasDiv = 0,
   72|       |    HasReciprocal = 0,
   73|       |    HasSqrt = 0,
   74|       |    HasRsqrt = 0,
   75|       |    HasExp = 0,
   76|       |    HasExpm1 = 0,
   77|       |    HasLog = 0,
   78|       |    HasLog1p = 0,
   79|       |    HasLog10 = 0,
   80|       |    HasPow = 0,
   81|       |    HasSin = 0,
   82|       |    HasCos = 0,
   83|       |    HasTan = 0,
   84|       |    HasASin = 0,
   85|       |    HasACos = 0,
   86|       |    HasATan = 0,
   87|       |    HasATanh = 0,
   88|       |    HasSinh = 0,
   89|       |    HasCosh = 0,
   90|       |    HasTanh = 0,
   91|       |    HasLGamma = 0,
   92|       |    HasDiGamma = 0,
   93|       |    HasZeta = 0,
   94|       |    HasPolygamma = 0,
   95|       |    HasErf = 0,
   96|       |    HasErfc = 0,
   97|       |    HasNdtri = 0,
   98|       |    HasBessel = 0,
   99|       |    HasIGamma = 0,
  100|       |    HasIGammaDerA = 0,
  101|       |    HasGammaSampleDerAlpha = 0,
  102|       |    HasIGammac = 0,
  103|       |    HasBetaInc = 0
  104|       |  };
  105|       |};
  106|       |
  107|       |template <typename T>
  108|       |struct packet_traits : default_packet_traits {
  109|       |  typedef T type;
  110|       |  typedef T half;
  111|       |  enum {
  112|       |    Vectorizable = 0,
  113|       |    size = 1,
  114|       |    AlignedOnScalar = 0,
  115|       |  };
  116|       |  enum {
  117|       |    HasAdd = 0,
  118|       |    HasSub = 0,
  119|       |    HasMul = 0,
  120|       |    HasNegate = 0,
  121|       |    HasAbs = 0,
  122|       |    HasAbs2 = 0,
  123|       |    HasMin = 0,
  124|       |    HasMax = 0,
  125|       |    HasConj = 0,
  126|       |    HasSetLinear = 0
  127|       |  };
  128|       |};
  129|       |
  130|       |template <typename T>
  131|       |struct packet_traits<const T> : packet_traits<T> {};
  132|       |
  133|       |template <typename T>
  134|       |struct unpacket_traits {
  135|       |  typedef T type;
  136|       |  typedef T half;
  137|       |  typedef typename numext::get_integer_by_size<sizeof(T)>::signed_type integer_packet;
  138|       |  enum {
  139|       |    size = 1,
  140|       |    alignment = alignof(T),
  141|       |    vectorizable = false,
  142|       |    masked_load_available = false,
  143|       |    masked_store_available = false
  144|       |  };
  145|       |};
  146|       |
  147|       |template <typename T>
  148|       |struct unpacket_traits<const T> : unpacket_traits<T> {};
  149|       |
  150|       |/** \internal A convenience utility for determining if the type is a scalar.
  151|       | * This is used to enable some generic packet implementations.
  152|       | */
  153|       |template <typename Packet>
  154|       |struct is_scalar {
  155|       |  using Scalar = typename unpacket_traits<Packet>::type;
  156|       |  enum { value = internal::is_same<Packet, Scalar>::value };
  157|       |};
  158|       |
  159|       |// automatically and succinctly define combinations of pcast<SrcPacket,TgtPacket> when
  160|       |// 1) the packets are the same type, or
  161|       |// 2) the packets differ only in sign.
  162|       |// In both of these cases, preinterpret (bit_cast) is equivalent to pcast (static_cast)
  163|       |template <typename SrcPacket, typename TgtPacket,
  164|       |          bool Scalar = is_scalar<SrcPacket>::value && is_scalar<TgtPacket>::value>
  165|       |struct is_degenerate_helper : is_same<SrcPacket, TgtPacket> {};
  166|       |template <>
  167|       |struct is_degenerate_helper<int8_t, uint8_t, true> : std::true_type {};
  168|       |template <>
  169|       |struct is_degenerate_helper<int16_t, uint16_t, true> : std::true_type {};
  170|       |template <>
  171|       |struct is_degenerate_helper<int32_t, uint32_t, true> : std::true_type {};
  172|       |template <>
  173|       |struct is_degenerate_helper<int64_t, uint64_t, true> : std::true_type {};
  174|       |
  175|       |template <typename SrcPacket, typename TgtPacket>
  176|       |struct is_degenerate_helper<SrcPacket, TgtPacket, false> {
  177|       |  using SrcScalar = typename unpacket_traits<SrcPacket>::type;
  178|       |  static constexpr int SrcSize = unpacket_traits<SrcPacket>::size;
  179|       |  using TgtScalar = typename unpacket_traits<TgtPacket>::type;
  180|       |  static constexpr int TgtSize = unpacket_traits<TgtPacket>::size;
  181|       |  static constexpr bool value = is_degenerate_helper<SrcScalar, TgtScalar, true>::value && (SrcSize == TgtSize);
  182|       |};
  183|       |
  184|       |// is_degenerate<T1,T2>::value == is_degenerate<T2,T1>::value
  185|       |template <typename SrcPacket, typename TgtPacket>
  186|       |struct is_degenerate {
  187|       |  static constexpr bool value =
  188|       |      is_degenerate_helper<SrcPacket, TgtPacket>::value || is_degenerate_helper<TgtPacket, SrcPacket>::value;
  189|       |};
  190|       |
  191|       |template <typename Packet>
  192|       |struct is_half {
  193|       |  using Scalar = typename unpacket_traits<Packet>::type;
  194|       |  static constexpr int Size = unpacket_traits<Packet>::size;
  195|       |  using DefaultPacket = typename packet_traits<Scalar>::type;
  196|       |  static constexpr int DefaultSize = unpacket_traits<DefaultPacket>::size;
  197|       |  static constexpr bool value = Size != 1 && Size < DefaultSize;
  198|       |};
  199|       |
  200|       |template <typename Src, typename Tgt>
  201|       |struct type_casting_traits {
  202|       |  enum {
  203|       |    VectorizedCast =
  204|       |        is_degenerate<Src, Tgt>::value && packet_traits<Src>::Vectorizable && packet_traits<Tgt>::Vectorizable,
  205|       |    SrcCoeffRatio = 1,
  206|       |    TgtCoeffRatio = 1
  207|       |  };
  208|       |};
  209|       |
  210|       |// provides a succinct template to define vectorized casting traits with respect to the largest accessible packet types
  211|       |template <typename Src, typename Tgt>
  212|       |struct vectorized_type_casting_traits {
  213|       |  enum : int {
  214|       |    DefaultSrcPacketSize = packet_traits<Src>::size,
  215|       |    DefaultTgtPacketSize = packet_traits<Tgt>::size,
  216|       |    VectorizedCast = 1,
  217|       |    SrcCoeffRatio = plain_enum_max(DefaultTgtPacketSize / DefaultSrcPacketSize, 1),
  218|       |    TgtCoeffRatio = plain_enum_max(DefaultSrcPacketSize / DefaultTgtPacketSize, 1)
  219|       |  };
  220|       |};
  221|       |
  222|       |/** \internal Wrapper to ensure that multiple packet types can map to the same
  223|       |    same underlying vector type. */
  224|       |template <typename T, int unique_id = 0>
  225|       |struct eigen_packet_wrapper {
  226|      0|  EIGEN_ALWAYS_INLINE operator T&() { return m_val; }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20eigen_packet_wrapperIDv2_xLi0EEcvRS2_Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20eigen_packet_wrapperIDv2_xLi5EEcvRS2_Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20eigen_packet_wrapperIDv2_xLi4EEcvRS2_Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20eigen_packet_wrapperIDv2_xLi1EEcvRS2_Ev
  ------------------
  227|      0|  EIGEN_ALWAYS_INLINE operator const T&() const { return m_val; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal20eigen_packet_wrapperIDv2_xLi5EEcvRKS2_Ev
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal20eigen_packet_wrapperIDv2_xLi0EEcvRKS2_Ev
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal20eigen_packet_wrapperIDv2_xLi4EEcvRKS2_Ev
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal20eigen_packet_wrapperIDv2_xLi1EEcvRKS2_Ev
  ------------------
  228|       |  EIGEN_ALWAYS_INLINE eigen_packet_wrapper() = default;
  229|       |  EIGEN_ALWAYS_INLINE eigen_packet_wrapper(const T& v) : m_val(v) {}
  230|      0|  EIGEN_ALWAYS_INLINE eigen_packet_wrapper& operator=(const T& v) {
  231|      0|    m_val = v;
  232|      0|    return *this;
  233|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20eigen_packet_wrapperIDv2_xLi0EEaSERKS2_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20eigen_packet_wrapperIDv2_xLi4EEaSERKS2_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20eigen_packet_wrapperIDv2_xLi1EEaSERKS2_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20eigen_packet_wrapperIDv2_xLi5EEaSERKS2_
  ------------------
  234|       |
  235|       |  T m_val;
  236|       |};
  237|       |
  238|       |template <typename Target, typename Packet, bool IsSame = is_same<Target, Packet>::value>
  239|       |struct preinterpret_generic;
  240|       |
  241|       |template <typename Target, typename Packet>
  242|       |struct preinterpret_generic<Target, Packet, false> {
  243|       |  // the packets are not the same, attempt scalar bit_cast
  244|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Target run(const Packet& a) {
  245|       |    return numext::bit_cast<Target, Packet>(a);
  246|       |  }
  247|       |};
  248|       |
  249|       |template <typename Packet>
  250|       |struct preinterpret_generic<Packet, Packet, true> {
  251|       |  // the packets are the same type: do nothing
  252|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& a) { return a; }
  253|       |};
  254|       |
  255|       |/** \internal \returns reinterpret_cast<Target>(a) */
  256|       |template <typename Target, typename Packet>
  257|       |EIGEN_DEVICE_FUNC inline Target preinterpret(const Packet& a) {
  258|       |  return preinterpret_generic<Target, Packet>::run(a);
  259|       |}
  260|       |
  261|       |template <typename SrcPacket, typename TgtPacket, bool Degenerate = is_degenerate<SrcPacket, TgtPacket>::value,
  262|       |          bool TgtIsHalf = is_half<TgtPacket>::value>
  263|       |struct pcast_generic;
  264|       |
  265|       |template <typename SrcPacket, typename TgtPacket>
  266|       |struct pcast_generic<SrcPacket, TgtPacket, false, false> {
  267|       |  // the packets are not degenerate: attempt scalar static_cast
  268|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TgtPacket run(const SrcPacket& a) {
  269|       |    return cast_impl<SrcPacket, TgtPacket>::run(a);
  270|       |  }
  271|       |};
  272|       |
  273|       |template <typename Packet>
  274|       |struct pcast_generic<Packet, Packet, true, false> {
  275|       |  // the packets are the same: do nothing
  276|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& a) { return a; }
  277|       |};
  278|       |
  279|       |template <typename SrcPacket, typename TgtPacket, bool TgtIsHalf>
  280|       |struct pcast_generic<SrcPacket, TgtPacket, true, TgtIsHalf> {
  281|       |  // the packets are degenerate: preinterpret is equivalent to pcast
  282|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TgtPacket run(const SrcPacket& a) { return preinterpret<TgtPacket>(a); }
  283|       |};
  284|       |
  285|       |/** \internal \returns static_cast<TgtType>(a) (coeff-wise) */
  286|       |template <typename SrcPacket, typename TgtPacket>
  287|       |EIGEN_DEVICE_FUNC inline TgtPacket pcast(const SrcPacket& a) {
  288|       |  return pcast_generic<SrcPacket, TgtPacket>::run(a);
  289|       |}
  290|       |template <typename SrcPacket, typename TgtPacket>
  291|       |EIGEN_DEVICE_FUNC inline TgtPacket pcast(const SrcPacket& a, const SrcPacket& b) {
  292|       |  return pcast_generic<SrcPacket, TgtPacket>::run(a, b);
  293|       |}
  294|       |template <typename SrcPacket, typename TgtPacket>
  295|       |EIGEN_DEVICE_FUNC inline TgtPacket pcast(const SrcPacket& a, const SrcPacket& b, const SrcPacket& c,
  296|       |                                         const SrcPacket& d) {
  297|       |  return pcast_generic<SrcPacket, TgtPacket>::run(a, b, c, d);
  298|       |}
  299|       |template <typename SrcPacket, typename TgtPacket>
  300|       |EIGEN_DEVICE_FUNC inline TgtPacket pcast(const SrcPacket& a, const SrcPacket& b, const SrcPacket& c, const SrcPacket& d,
  301|       |                                         const SrcPacket& e, const SrcPacket& f, const SrcPacket& g,
  302|       |                                         const SrcPacket& h) {
  303|       |  return pcast_generic<SrcPacket, TgtPacket>::run(a, b, c, d, e, f, g, h);
  304|       |}
  305|       |
  306|       |template <typename SrcPacket, typename TgtPacket>
  307|       |struct pcast_generic<SrcPacket, TgtPacket, false, true> {
  308|       |  // TgtPacket is a half packet of some other type
  309|       |  // perform cast and truncate result
  310|       |  using DefaultTgtPacket = typename is_half<TgtPacket>::DefaultPacket;
  311|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TgtPacket run(const SrcPacket& a) {
  312|       |    return preinterpret<TgtPacket>(pcast<SrcPacket, DefaultTgtPacket>(a));
  313|       |  }
  314|       |};
  315|       |
  316|       |/** \internal \returns a + b (coeff-wise) */
  317|       |template <typename Packet>
  318|    232|EIGEN_DEVICE_FUNC inline Packet padd(const Packet& a, const Packet& b) {
  319|    232|  return a + b;
  320|    232|}
  ------------------
  | _ZN5Eigen8internal4paddI14AnnoyingScalarEET_RKS3_S5_:
  |  318|    232|EIGEN_DEVICE_FUNC inline Packet padd(const Packet& a, const Packet& b) {
  |  319|    232|  return a + b;
  |  320|    232|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4paddIfEET_RKS2_S4_
  ------------------
  321|       |// Avoid compiler warning for boolean algebra.
  322|       |template <>
  323|      0|EIGEN_DEVICE_FUNC inline bool padd(const bool& a, const bool& b) {
  324|      0|  return a || b;
  325|      0|}
  326|       |
  327|       |/** \internal \returns a packet version of \a *from, (un-aligned masked add)
  328|       | * There is no generic implementation. We only have implementations for specialized
  329|       | * cases. Generic case should not be called.
  330|       | */
  331|       |template <typename Packet>
  332|       |EIGEN_DEVICE_FUNC inline std::enable_if_t<unpacket_traits<Packet>::masked_fpops_available, Packet> padd(
  333|       |    const Packet& a, const Packet& b, typename unpacket_traits<Packet>::mask_t umask);
  334|       |
  335|       |/** \internal \returns a - b (coeff-wise) */
  336|       |template <typename Packet>
  337|       |EIGEN_DEVICE_FUNC inline Packet psub(const Packet& a, const Packet& b) {
  338|       |  return a - b;
  339|       |}
  340|       |
  341|       |/** \internal \returns -a (coeff-wise) */
  342|       |template <typename Packet>
  343|       |EIGEN_DEVICE_FUNC inline Packet pnegate(const Packet& a) {
  344|       |  EIGEN_STATIC_ASSERT((!is_same<typename unpacket_traits<Packet>::type, bool>::value),
  345|       |                      NEGATE IS NOT DEFINED FOR BOOLEAN TYPES)
  346|       |  return numext::negate(a);
  347|       |}
  348|       |
  349|       |/** \internal \returns conj(a) (coeff-wise) */
  350|       |template <typename Packet>
  351|       |EIGEN_DEVICE_FUNC inline Packet pconj(const Packet& a) {
  352|       |  return numext::conj(a);
  353|       |}
  354|       |
  355|       |/** \internal \returns a * b (coeff-wise) */
  356|       |template <typename Packet>
  357|    233|EIGEN_DEVICE_FUNC inline Packet pmul(const Packet& a, const Packet& b) {
  358|    233|  return a * b;
  359|    233|}
  ------------------
  | _ZN5Eigen8internal4pmulI14AnnoyingScalarEET_RKS3_S5_:
  |  357|    233|EIGEN_DEVICE_FUNC inline Packet pmul(const Packet& a, const Packet& b) {
  |  358|    233|  return a * b;
  |  359|    233|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4pmulIfEET_RKS2_S4_
  ------------------
  360|       |// Avoid compiler warning for boolean algebra.
  361|       |template <>
  362|      0|EIGEN_DEVICE_FUNC inline bool pmul(const bool& a, const bool& b) {
  363|      0|  return a && b;
  364|      0|}
  365|       |
  366|       |/** \internal \returns a / b (coeff-wise) */
  367|       |template <typename Packet>
  368|      0|EIGEN_DEVICE_FUNC inline Packet pdiv(const Packet& a, const Packet& b) {
  369|      0|  return a / b;
  370|      0|}
  371|       |
  372|       |// In the generic case, memset to all one bits.
  373|       |template <typename Packet, typename EnableIf = void>
  374|       |struct ptrue_impl {
  375|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& /*a*/) {
  376|       |    Packet b;
  377|       |    memset(static_cast<void*>(&b), 0xff, sizeof(Packet));
  378|       |    return b;
  379|       |  }
  380|       |};
  381|       |
  382|       |// For booleans, we can only directly set a valid `bool` value to avoid UB.
  383|       |template <>
  384|       |struct ptrue_impl<bool, void> {
  385|      0|  static EIGEN_DEVICE_FUNC inline bool run(const bool& /*a*/) { return true; }
  386|       |};
  387|       |
  388|       |// For non-trivial scalars, set to Scalar(1) (i.e. a non-zero value).
  389|       |// Although this is technically not a valid bitmask, the scalar path for pselect
  390|       |// uses a comparison to zero, so this should still work in most cases. We don't
  391|       |// have another option, since the scalar type requires initialization.
  392|       |template <typename T>
  393|       |struct ptrue_impl<T, std::enable_if_t<is_scalar<T>::value && NumTraits<T>::RequireInitialization>> {
  394|       |  static EIGEN_DEVICE_FUNC inline T run(const T& /*a*/) { return T(1); }
  395|       |};
  396|       |
  397|       |/** \internal \returns one bits. */
  398|       |template <typename Packet>
  399|       |EIGEN_DEVICE_FUNC inline Packet ptrue(const Packet& a) {
  400|       |  return ptrue_impl<Packet>::run(a);
  401|       |}
  402|       |
  403|       |// In the general case, memset to zero.
  404|       |template <typename Packet, typename EnableIf = void>
  405|       |struct pzero_impl {
  406|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& /*a*/) {
  407|       |    Packet b;
  408|       |    memset(static_cast<void*>(&b), 0x00, sizeof(Packet));
  409|       |    return b;
  410|       |  }
  411|       |};
  412|       |
  413|       |// For scalars, explicitly set to Scalar(0), since the underlying representation
  414|       |// for zero may not consist of all-zero bits.
  415|       |template <typename T>
  416|       |struct pzero_impl<T, std::enable_if_t<is_scalar<T>::value>> {
  417|       |  static EIGEN_DEVICE_FUNC inline T run(const T& /*a*/) { return T(0); }
  418|       |};
  419|       |
  420|       |/** \internal \returns packet of zeros */
  421|       |template <typename Packet>
  422|       |EIGEN_DEVICE_FUNC inline Packet pzero(const Packet& a) {
  423|       |  return pzero_impl<Packet>::run(a);
  424|       |}
  425|       |
  426|       |/** \internal \returns a <= b as a bit mask */
  427|       |template <typename Packet>
  428|       |EIGEN_DEVICE_FUNC inline Packet pcmp_le(const Packet& a, const Packet& b) {
  429|       |  return a <= b ? ptrue(a) : pzero(a);
  430|       |}
  431|       |
  432|       |/** \internal \returns a < b as a bit mask */
  433|       |template <typename Packet>
  434|       |EIGEN_DEVICE_FUNC inline Packet pcmp_lt(const Packet& a, const Packet& b) {
  435|       |  return a < b ? ptrue(a) : pzero(a);
  436|       |}
  437|       |
  438|       |/** \internal \returns a == b as a bit mask */
  439|       |template <typename Packet>
  440|       |EIGEN_DEVICE_FUNC inline Packet pcmp_eq(const Packet& a, const Packet& b) {
  441|       |  return a == b ? ptrue(a) : pzero(a);
  442|       |}
  443|       |
  444|       |/** \internal \returns a < b or a==NaN or b==NaN as a bit mask */
  445|       |template <typename Packet>
  446|       |EIGEN_DEVICE_FUNC inline Packet pcmp_lt_or_nan(const Packet& a, const Packet& b) {
  447|       |  return a >= b ? pzero(a) : ptrue(a);
  448|       |}
  449|       |
  450|       |template <typename T>
  451|       |struct bit_and {
  452|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a, const T& b) const { return a & b; }
  453|       |};
  454|       |
  455|       |template <typename T>
  456|       |struct bit_or {
  457|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a, const T& b) const { return a | b; }
  458|       |};
  459|       |
  460|       |template <typename T>
  461|       |struct bit_xor {
  462|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a, const T& b) const { return a ^ b; }
  463|       |};
  464|       |
  465|       |template <typename T>
  466|       |struct bit_not {
  467|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a) const { return ~a; }
  468|       |};
  469|       |
  470|       |template <>
  471|       |struct bit_and<bool> {
  472|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE bool operator()(const bool& a, const bool& b) const {
  473|      0|    return a && b;
  474|      0|  }
  475|       |};
  476|       |
  477|       |template <>
  478|       |struct bit_or<bool> {
  479|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE bool operator()(const bool& a, const bool& b) const {
  480|      0|    return a || b;
  481|      0|  }
  482|       |};
  483|       |
  484|       |template <>
  485|       |struct bit_xor<bool> {
  486|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE bool operator()(const bool& a, const bool& b) const {
  487|      0|    return a != b;
  488|      0|  }
  489|       |};
  490|       |
  491|       |template <>
  492|       |struct bit_not<bool> {
  493|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE bool operator()(const bool& a) const { return !a; }
  494|       |};
  495|       |
  496|       |// Use operators &, |, ^, ~.
  497|       |template <typename T>
  498|       |struct operator_bitwise_helper {
  499|       |  EIGEN_DEVICE_FUNC static inline T bitwise_and(const T& a, const T& b) { return bit_and<T>()(a, b); }
  500|       |  EIGEN_DEVICE_FUNC static inline T bitwise_or(const T& a, const T& b) { return bit_or<T>()(a, b); }
  501|       |  EIGEN_DEVICE_FUNC static inline T bitwise_xor(const T& a, const T& b) { return bit_xor<T>()(a, b); }
  502|       |  EIGEN_DEVICE_FUNC static inline T bitwise_not(const T& a) { return bit_not<T>()(a); }
  503|       |};
  504|       |
  505|       |// Apply binary operations byte-by-byte
  506|       |template <typename T>
  507|       |struct bytewise_bitwise_helper {
  508|       |  EIGEN_DEVICE_FUNC static inline T bitwise_and(const T& a, const T& b) {
  509|       |    return binary(a, b, bit_and<unsigned char>());
  510|       |  }
  511|       |  EIGEN_DEVICE_FUNC static inline T bitwise_or(const T& a, const T& b) { return binary(a, b, bit_or<unsigned char>()); }
  512|       |  EIGEN_DEVICE_FUNC static inline T bitwise_xor(const T& a, const T& b) {
  513|       |    return binary(a, b, bit_xor<unsigned char>());
  514|       |  }
  515|       |  EIGEN_DEVICE_FUNC static inline T bitwise_not(const T& a) { return unary(a, bit_not<unsigned char>()); }
  516|       |
  517|       | private:
  518|       |  template <typename Op>
  519|       |  EIGEN_DEVICE_FUNC static inline T unary(const T& a, Op op) {
  520|       |    const unsigned char* a_ptr = reinterpret_cast<const unsigned char*>(&a);
  521|       |    T c;
  522|       |    unsigned char* c_ptr = reinterpret_cast<unsigned char*>(&c);
  523|       |    for (size_t i = 0; i < sizeof(T); ++i) {
  524|       |      *c_ptr++ = op(*a_ptr++);
  525|       |    }
  526|       |    return c;
  527|       |  }
  528|       |
  529|       |  template <typename Op>
  530|       |  EIGEN_DEVICE_FUNC static inline T binary(const T& a, const T& b, Op op) {
  531|       |    const unsigned char* a_ptr = reinterpret_cast<const unsigned char*>(&a);
  532|       |    const unsigned char* b_ptr = reinterpret_cast<const unsigned char*>(&b);
  533|       |    T c;
  534|       |    unsigned char* c_ptr = reinterpret_cast<unsigned char*>(&c);
  535|       |    for (size_t i = 0; i < sizeof(T); ++i) {
  536|       |      *c_ptr++ = op(*a_ptr++, *b_ptr++);
  537|       |    }
  538|       |    return c;
  539|       |  }
  540|       |};
  541|       |
  542|       |// In the general case, use byte-by-byte manipulation.
  543|       |template <typename T, typename EnableIf = void>
  544|       |struct bitwise_helper : public bytewise_bitwise_helper<T> {};
  545|       |
  546|       |// For integers or non-trivial scalars, use binary operators.
  547|       |template <typename T>
  548|       |struct bitwise_helper<T, typename std::enable_if_t<is_scalar<T>::value &&
  549|       |                                                   (NumTraits<T>::IsInteger || NumTraits<T>::RequireInitialization)>>
  550|       |    : public operator_bitwise_helper<T> {};
  551|       |
  552|       |/** \internal \returns the bitwise and of \a a and \a b */
  553|       |template <typename Packet>
  554|       |EIGEN_DEVICE_FUNC inline Packet pand(const Packet& a, const Packet& b) {
  555|       |  return bitwise_helper<Packet>::bitwise_and(a, b);
  556|       |}
  557|       |
  558|       |/** \internal \returns the bitwise or of \a a and \a b */
  559|       |template <typename Packet>
  560|       |EIGEN_DEVICE_FUNC inline Packet por(const Packet& a, const Packet& b) {
  561|       |  return bitwise_helper<Packet>::bitwise_or(a, b);
  562|       |}
  563|       |
  564|       |/** \internal \returns the bitwise xor of \a a and \a b */
  565|       |template <typename Packet>
  566|       |EIGEN_DEVICE_FUNC inline Packet pxor(const Packet& a, const Packet& b) {
  567|       |  return bitwise_helper<Packet>::bitwise_xor(a, b);
  568|       |}
  569|       |
  570|       |/** \internal \returns the bitwise not of \a a */
  571|       |template <typename Packet>
  572|       |EIGEN_DEVICE_FUNC inline Packet pnot(const Packet& a) {
  573|       |  return bitwise_helper<Packet>::bitwise_not(a);
  574|       |}
  575|       |
  576|       |/** \internal \returns the bitwise and of \a a and not \a b */
  577|       |template <typename Packet>
  578|       |EIGEN_DEVICE_FUNC inline Packet pandnot(const Packet& a, const Packet& b) {
  579|       |  return pand(a, pnot(b));
  580|       |}
  581|       |
  582|       |// In the general case, use bitwise select.
  583|       |template <typename Packet, typename EnableIf = void>
  584|       |struct pselect_impl {
  585|      0|  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& mask, const Packet& a, const Packet& b) {
  586|      0|    return por(pand(a, mask), pandnot(b, mask));
  587|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12pselect_implINS0_20eigen_packet_wrapperIDv2_xLi5EEEvE3runERKS4_S7_S7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12pselect_implINS0_20eigen_packet_wrapperIDv2_xLi0EEEvE3runERKS4_S7_S7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12pselect_implIDv4_fvE3runERKS2_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12pselect_implIDv2_dvE3runERKS2_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12pselect_implINS0_9Packet1cdEvE3runERKS2_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12pselect_implINS0_9Packet2cfEvE3runERKS2_S5_S5_
  ------------------
  588|       |};
  589|       |
  590|       |// For scalars, use ternary select.
  591|       |template <typename Packet>
  592|       |struct pselect_impl<Packet, std::enable_if_t<is_scalar<Packet>::value>> {
  593|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& mask, const Packet& a, const Packet& b) {
  594|       |    return numext::equal_strict(mask, Packet(0)) ? b : a;
  595|       |  }
  596|       |};
  597|       |
  598|       |/** \internal \returns \a or \b for each field in packet according to \mask */
  599|       |template <typename Packet>
  600|      0|EIGEN_DEVICE_FUNC inline Packet pselect(const Packet& mask, const Packet& a, const Packet& b) {
  601|      0|  return pselect_impl<Packet>::run(mask, a, b);
  602|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7pselectINS0_20eigen_packet_wrapperIDv2_xLi5EEEEET_RKS5_S7_S7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7pselectINS0_20eigen_packet_wrapperIDv2_xLi0EEEEET_RKS5_S7_S7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7pselectIDv4_fEET_RKS3_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7pselectIDv2_dEET_RKS3_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7pselectINS0_9Packet1cdEEET_RKS3_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7pselectINS0_9Packet2cfEEET_RKS3_S5_S5_
  ------------------
  603|       |
  604|       |template <>
  605|      0|EIGEN_DEVICE_FUNC inline bool pselect<bool>(const bool& cond, const bool& a, const bool& b) {
  606|      0|  return cond ? a : b;
  607|      0|}
  608|       |
  609|       |/** \internal \returns the min or of \a a and \a b (coeff-wise)
  610|       |    If either \a a or \a b are NaN, the result is implementation defined. */
  611|       |template <int NaNPropagation>
  612|       |struct pminmax_impl {
  613|       |  template <typename Packet, typename Op>
  614|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a, const Packet& b, Op op) {
  615|       |    return op(a, b);
  616|       |  }
  617|       |};
  618|       |
  619|       |/** \internal \returns the min or max of \a a and \a b (coeff-wise)
  620|       |    If either \a a or \a b are NaN, NaN is returned. */
  621|       |template <>
  622|       |struct pminmax_impl<PropagateNaN> {
  623|       |  template <typename Packet, typename Op>
  624|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a, const Packet& b, Op op) {
  625|       |    Packet not_nan_mask_a = pcmp_eq(a, a);
  626|       |    Packet not_nan_mask_b = pcmp_eq(b, b);
  627|       |    return pselect(not_nan_mask_a, pselect(not_nan_mask_b, op(a, b), b), a);
  628|       |  }
  629|       |};
  630|       |
  631|       |/** \internal \returns the min or max of \a a and \a b (coeff-wise)
  632|       |    If both \a a and \a b are NaN, NaN is returned.
  633|       |    Equivalent to std::fmin(a, b).  */
  634|       |template <>
  635|       |struct pminmax_impl<PropagateNumbers> {
  636|       |  template <typename Packet, typename Op>
  637|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a, const Packet& b, Op op) {
  638|       |    Packet not_nan_mask_a = pcmp_eq(a, a);
  639|       |    Packet not_nan_mask_b = pcmp_eq(b, b);
  640|       |    return pselect(not_nan_mask_a, pselect(not_nan_mask_b, op(a, b), a), b);
  641|       |  }
  642|       |};
  643|       |
  644|       |#define EIGEN_BINARY_OP_NAN_PROPAGATION(Type, Func) [](const Type& a, const Type& b) { return Func(a, b); }
  645|       |
  646|       |/** \internal \returns the min of \a a and \a b  (coeff-wise).
  647|       |    If \a a or \b b is NaN, the return value is implementation defined. */
  648|       |template <typename Packet>
  649|      0|EIGEN_DEVICE_FUNC inline Packet pmin(const Packet& a, const Packet& b) {
  650|      0|  return numext::mini(a, b);
  651|      0|}
  652|       |
  653|       |/** \internal \returns the min of \a a and \a b  (coeff-wise).
  654|       |    NaNPropagation determines the NaN propagation semantics. */
  655|       |template <int NaNPropagation, typename Packet>
  656|       |EIGEN_DEVICE_FUNC inline Packet pmin(const Packet& a, const Packet& b) {
  657|       |  return pminmax_impl<NaNPropagation>::run(a, b, EIGEN_BINARY_OP_NAN_PROPAGATION(Packet, (pmin<Packet>)));
  658|       |}
  659|       |
  660|       |/** \internal \returns the max of \a a and \a b  (coeff-wise)
  661|       |    If \a a or \b b is NaN, the return value is implementation defined. */
  662|       |template <typename Packet>
  663|      0|EIGEN_DEVICE_FUNC inline Packet pmax(const Packet& a, const Packet& b) {
  664|      0|  return numext::maxi(a, b);
  665|      0|}
  666|       |
  667|       |/** \internal \returns the max of \a a and \a b  (coeff-wise).
  668|       |    NaNPropagation determines the NaN propagation semantics. */
  669|       |template <int NaNPropagation, typename Packet>
  670|       |EIGEN_DEVICE_FUNC inline Packet pmax(const Packet& a, const Packet& b) {
  671|       |  return pminmax_impl<NaNPropagation>::run(a, b, EIGEN_BINARY_OP_NAN_PROPAGATION(Packet, (pmax<Packet>)));
  672|       |}
  673|       |
  674|       |/** \internal \returns the absolute value of \a a */
  675|       |template <typename Packet>
  676|       |EIGEN_DEVICE_FUNC inline Packet pabs(const Packet& a) {
  677|       |  return numext::abs(a);
  678|       |}
  679|       |template <>
  680|      0|EIGEN_DEVICE_FUNC inline unsigned int pabs(const unsigned int& a) {
  681|      0|  return a;
  682|      0|}
  683|       |template <>
  684|      0|EIGEN_DEVICE_FUNC inline unsigned long pabs(const unsigned long& a) {
  685|      0|  return a;
  686|      0|}
  687|       |template <>
  688|      0|EIGEN_DEVICE_FUNC inline unsigned long long pabs(const unsigned long long& a) {
  689|      0|  return a;
  690|      0|}
  691|       |
  692|       |/** \internal \returns the addsub value of \a a,b */
  693|       |template <typename Packet>
  694|       |EIGEN_DEVICE_FUNC inline Packet paddsub(const Packet& a, const Packet& b) {
  695|       |  return pselect(peven_mask(a), padd(a, b), psub(a, b));
  696|       |}
  697|       |
  698|       |/** \internal \returns the phase angle of \a a */
  699|       |template <typename Packet>
  700|       |EIGEN_DEVICE_FUNC inline Packet parg(const Packet& a) {
  701|       |  using numext::arg;
  702|       |  return arg(a);
  703|       |}
  704|       |
  705|       |/** \internal \returns \a a arithmetically shifted by N bits to the right */
  706|       |template <int N, typename T>
  707|       |EIGEN_DEVICE_FUNC inline T parithmetic_shift_right(const T& a) {
  708|       |  return numext::arithmetic_shift_right(a, N);
  709|       |}
  710|       |
  711|       |/** \internal \returns \a a logically shifted by N bits to the right */
  712|       |template <int N, typename T>
  713|       |EIGEN_DEVICE_FUNC inline T plogical_shift_right(const T& a) {
  714|       |  return numext::logical_shift_right(a, N);
  715|       |}
  716|       |
  717|       |/** \internal \returns \a a shifted by N bits to the left */
  718|       |template <int N, typename T>
  719|       |EIGEN_DEVICE_FUNC inline T plogical_shift_left(const T& a) {
  720|       |  return numext::logical_shift_left(a, N);
  721|       |}
  722|       |
  723|       |/** \internal \returns the significant and exponent of the underlying floating point numbers
  724|       | * See https://en.cppreference.com/w/cpp/numeric/math/frexp
  725|       | */
  726|       |template <typename Packet>
  727|       |EIGEN_DEVICE_FUNC inline Packet pfrexp(const Packet& a, Packet& exponent) {
  728|       |  int exp;
  729|       |  EIGEN_USING_STD(frexp);
  730|       |  Packet result = static_cast<Packet>(frexp(a, &exp));
  731|       |  exponent = static_cast<Packet>(exp);
  732|       |  return result;
  733|       |}
  734|       |
  735|       |/** \internal \returns a * 2^((int)exponent)
  736|       | * See https://en.cppreference.com/w/cpp/numeric/math/ldexp
  737|       | */
  738|       |template <typename Packet>
  739|       |EIGEN_DEVICE_FUNC inline Packet pldexp(const Packet& a, const Packet& exponent) {
  740|       |  EIGEN_USING_STD(ldexp)
  741|       |  return static_cast<Packet>(ldexp(a, static_cast<int>(exponent)));
  742|       |}
  743|       |
  744|       |/** \internal \returns the min of \a a and \a b  (coeff-wise) */
  745|       |template <typename Packet>
  746|       |EIGEN_DEVICE_FUNC inline Packet pabsdiff(const Packet& a, const Packet& b) {
  747|       |  return pselect(pcmp_lt(a, b), psub(b, a), psub(a, b));
  748|       |}
  749|       |
  750|       |/** \internal \returns a packet version of \a *from, from must be properly aligned */
  751|       |template <typename Packet>
  752|     52|EIGEN_DEVICE_FUNC inline Packet pload(const typename unpacket_traits<Packet>::type* from) {
  753|     52|  return *from;
  754|     52|}
  755|       |
  756|       |/** \internal \returns n elements of a packet version of \a *from, from must be properly aligned
  757|       | * offset indicates the starting element in which to load and
  758|       | * offset + n <= unpacket_traits::size
  759|       | * All elements before offset and after the last element loaded will initialized with zero */
  760|       |template <typename Packet>
  761|       |EIGEN_DEVICE_FUNC inline Packet pload_partial(const typename unpacket_traits<Packet>::type* from, const Index n,
  762|       |                                              const Index offset = 0) {
  763|       |  const Index packet_size = unpacket_traits<Packet>::size;
  764|       |  eigen_assert(n + offset <= packet_size && "number of elements plus offset will read past end of packet");
  765|       |  typedef typename unpacket_traits<Packet>::type Scalar;
  766|       |  EIGEN_ALIGN_MAX Scalar elements[packet_size] = {Scalar(0)};
  767|       |  for (Index i = offset; i < numext::mini(n + offset, packet_size); i++) {
  768|       |    elements[i] = from[i - offset];
  769|       |  }
  770|       |  return pload<Packet>(elements);
  771|       |}
  772|       |
  773|       |/** \internal \returns a packet version of \a *from, (un-aligned load) */
  774|       |template <typename Packet>
  775|  5.00k|EIGEN_DEVICE_FUNC inline Packet ploadu(const typename unpacket_traits<Packet>::type* from) {
  776|  5.00k|  return *from;
  777|  5.00k|}
  778|       |
  779|       |/** \internal \returns n elements of a packet version of \a *from, (un-aligned load)
  780|       | * All elements after the last element loaded will initialized with zero */
  781|       |template <typename Packet>
  782|       |EIGEN_DEVICE_FUNC inline Packet ploadu_partial(const typename unpacket_traits<Packet>::type* from, const Index n,
  783|       |                                               const Index offset = 0) {
  784|       |  const Index packet_size = unpacket_traits<Packet>::size;
  785|       |  eigen_assert(n + offset <= packet_size && "number of elements plus offset will read past end of packet");
  786|       |  typedef typename unpacket_traits<Packet>::type Scalar;
  787|       |  EIGEN_ALIGN_MAX Scalar elements[packet_size] = {Scalar(0)};
  788|       |  for (Index i = offset; i < numext::mini(n + offset, packet_size); i++) {
  789|       |    elements[i] = from[i - offset];
  790|       |  }
  791|       |  return pload<Packet>(elements);
  792|       |}
  793|       |
  794|       |/** \internal \returns a packet version of \a *from, (un-aligned masked load)
  795|       | * There is no generic implementation. We only have implementations for specialized
  796|       | * cases. Generic case should not be called.
  797|       | */
  798|       |template <typename Packet>
  799|       |EIGEN_DEVICE_FUNC inline std::enable_if_t<unpacket_traits<Packet>::masked_load_available, Packet> ploadu(
  800|       |    const typename unpacket_traits<Packet>::type* from, typename unpacket_traits<Packet>::mask_t umask);
  801|       |
  802|       |/** \internal \returns a packet with constant coefficients \a a, e.g.: (a,a,a,a) */
  803|       |template <typename Packet>
  804|    120|EIGEN_DEVICE_FUNC inline Packet pset1(const typename unpacket_traits<Packet>::type& a) {
  805|    120|  return a;
  806|    120|}
  ------------------
  | _ZN5Eigen8internal5pset1I14AnnoyingScalarEET_RKNS0_15unpacket_traitsIS3_E4typeE:
  |  804|    120|EIGEN_DEVICE_FUNC inline Packet pset1(const typename unpacket_traits<Packet>::type& a) {
  |  805|    120|  return a;
  |  806|    120|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5pset1IfEET_RKNS0_15unpacket_traitsIS2_E4typeE
  ------------------
  807|       |
  808|       |/** \internal \returns a packet with constant coefficients set from bits */
  809|       |template <typename Packet, typename BitsType>
  810|       |EIGEN_DEVICE_FUNC inline Packet pset1frombits(BitsType a);
  811|       |
  812|       |/** \internal \returns a packet with constant coefficients \a a[0], e.g.: (a[0],a[0],a[0],a[0]) */
  813|       |template <typename Packet>
  814|    104|EIGEN_DEVICE_FUNC inline Packet pload1(const typename unpacket_traits<Packet>::type* a) {
  815|    104|  return pset1<Packet>(*a);
  816|    104|}
  ------------------
  | _ZN5Eigen8internal6pload1I14AnnoyingScalarEET_PKNS0_15unpacket_traitsIS3_E4typeE:
  |  814|    104|EIGEN_DEVICE_FUNC inline Packet pload1(const typename unpacket_traits<Packet>::type* a) {
  |  815|    104|  return pset1<Packet>(*a);
  |  816|    104|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pload1IDv2_dEET_PKNS0_15unpacket_traitsIS3_E4typeE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pload1IDv4_fEET_PKNS0_15unpacket_traitsIS3_E4typeE
  ------------------
  817|       |
  818|       |/** \internal \returns a packet with elements of \a *from duplicated.
  819|       | * For instance, for a packet of 8 elements, 4 scalars will be read from \a *from and
  820|       | * duplicated to form: {from[0],from[0],from[1],from[1],from[2],from[2],from[3],from[3]}
  821|       | * Currently, this function is only used for scalar * complex products.
  822|       | */
  823|       |template <typename Packet>
  824|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet ploaddup(const typename unpacket_traits<Packet>::type* from) {
  825|       |  return *from;
  826|       |}
  827|       |
  828|       |/** \internal \returns a packet with elements of \a *from quadrupled.
  829|       | * For instance, for a packet of 8 elements, 2 scalars will be read from \a *from and
  830|       | * replicated to form: {from[0],from[0],from[0],from[0],from[1],from[1],from[1],from[1]}
  831|       | * Currently, this function is only used in matrix products.
  832|       | * For packet-size smaller or equal to 4, this function is equivalent to pload1
  833|       | */
  834|       |template <typename Packet>
  835|      0|EIGEN_DEVICE_FUNC inline Packet ploadquad(const typename unpacket_traits<Packet>::type* from) {
  836|      0|  return pload1<Packet>(from);
  837|      0|}
  838|       |
  839|       |/** \internal equivalent to
  840|       | * \code
  841|       | * a0 = pload1(a+0);
  842|       | * a1 = pload1(a+1);
  843|       | * a2 = pload1(a+2);
  844|       | * a3 = pload1(a+3);
  845|       | * \endcode
  846|       | * \sa pset1, pload1, ploaddup, pbroadcast2
  847|       | */
  848|       |template <typename Packet>
  849|       |EIGEN_DEVICE_FUNC inline void pbroadcast4(const typename unpacket_traits<Packet>::type* a, Packet& a0, Packet& a1,
  850|     26|                                          Packet& a2, Packet& a3) {
  851|     26|  a0 = pload1<Packet>(a + 0);
  852|     26|  a1 = pload1<Packet>(a + 1);
  853|     26|  a2 = pload1<Packet>(a + 2);
  854|     26|  a3 = pload1<Packet>(a + 3);
  855|     26|}
  856|       |
  857|       |/** \internal equivalent to
  858|       | * \code
  859|       | * a0 = pload1(a+0);
  860|       | * a1 = pload1(a+1);
  861|       | * \endcode
  862|       | * \sa pset1, pload1, ploaddup, pbroadcast4
  863|       | */
  864|       |template <typename Packet>
  865|       |EIGEN_DEVICE_FUNC inline void pbroadcast2(const typename unpacket_traits<Packet>::type* a, Packet& a0, Packet& a1) {
  866|       |  a0 = pload1<Packet>(a + 0);
  867|       |  a1 = pload1<Packet>(a + 1);
  868|       |}
  869|       |
  870|       |/** \internal \brief Returns a packet with coefficients (a,a+1,...,a+packet_size-1). */
  871|       |template <typename Packet>
  872|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet plset(const typename unpacket_traits<Packet>::type& a) {
  873|       |  return a;
  874|       |}
  875|       |
  876|       |/** \internal \returns a packet with constant coefficients \a a, e.g.: (x, 0, x, 0),
  877|       |     where x is the value of all 1-bits. */
  878|       |template <typename Packet>
  879|       |EIGEN_DEVICE_FUNC inline Packet peven_mask(const Packet& /*a*/) {
  880|       |  typedef typename unpacket_traits<Packet>::type Scalar;
  881|       |  const size_t n = unpacket_traits<Packet>::size;
  882|       |  EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Scalar elements[n];
  883|       |  for (size_t i = 0; i < n; ++i) {
  884|       |    memset(elements + i, ((i & 1) == 0 ? 0xff : 0), sizeof(Scalar));
  885|       |  }
  886|       |  return ploadu<Packet>(elements);
  887|       |}
  888|       |
  889|       |/** \internal copy the packet \a from to \a *to, \a to must be properly aligned */
  890|       |template <typename Scalar, typename Packet>
  891|  5.00k|EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from) {
  892|  5.00k|  (*to) = from;
  893|  5.00k|}
  894|       |
  895|       |/** \internal copy n elements of the packet \a from to \a *to, \a to must be properly aligned
  896|       | * offset indicates the starting element in which to store and
  897|       | * offset + n <= unpacket_traits::size */
  898|       |template <typename Scalar, typename Packet>
  899|       |EIGEN_DEVICE_FUNC inline void pstore_partial(Scalar* to, const Packet& from, const Index n, const Index offset = 0) {
  900|       |  const Index packet_size = unpacket_traits<Packet>::size;
  901|       |  eigen_assert(n + offset <= packet_size && "number of elements plus offset will write past end of packet");
  902|       |  EIGEN_ALIGN_MAX Scalar elements[packet_size];
  903|       |  pstore<Scalar>(elements, from);
  904|       |  for (Index i = 0; i < numext::mini(n, packet_size - offset); i++) {
  905|       |    to[i] = elements[i + offset];
  906|       |  }
  907|       |}
  908|       |
  909|       |/** \internal copy the packet \a from to \a *to, (un-aligned store) */
  910|       |template <typename Scalar, typename Packet>
  911|      0|EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from) {
  912|      0|  (*to) = from;
  913|      0|}
  914|       |
  915|       |/** \internal copy n elements of the packet \a from to \a *to, (un-aligned store) */
  916|       |template <typename Scalar, typename Packet>
  917|       |EIGEN_DEVICE_FUNC inline void pstoreu_partial(Scalar* to, const Packet& from, const Index n, const Index offset = 0) {
  918|       |  const Index packet_size = unpacket_traits<Packet>::size;
  919|       |  eigen_assert(n + offset <= packet_size && "number of elements plus offset will write past end of packet");
  920|       |  EIGEN_ALIGN_MAX Scalar elements[packet_size];
  921|       |  pstore<Scalar>(elements, from);
  922|       |  for (Index i = 0; i < numext::mini(n, packet_size - offset); i++) {
  923|       |    to[i] = elements[i + offset];
  924|       |  }
  925|       |}
  926|       |
  927|       |/** \internal copy the packet \a from to \a *to, (un-aligned store with a mask)
  928|       | * There is no generic implementation. We only have implementations for specialized
  929|       | * cases. Generic case should not be called.
  930|       | */
  931|       |template <typename Scalar, typename Packet>
  932|       |EIGEN_DEVICE_FUNC inline std::enable_if_t<unpacket_traits<Packet>::masked_store_available, void> pstoreu(
  933|       |    Scalar* to, const Packet& from, typename unpacket_traits<Packet>::mask_t umask);
  934|       |
  935|       |template <typename Scalar, typename Packet>
  936|      0|EIGEN_DEVICE_FUNC inline Packet pgather(const Scalar* from, Index /*stride*/) {
  937|      0|  return ploadu<Packet>(from);
  938|      0|}
  939|       |
  940|       |template <typename Scalar, typename Packet>
  941|       |EIGEN_DEVICE_FUNC inline Packet pgather_partial(const Scalar* from, Index stride, const Index n) {
  942|       |  const Index packet_size = unpacket_traits<Packet>::size;
  943|       |  EIGEN_ALIGN_MAX Scalar elements[packet_size] = {Scalar(0)};
  944|       |  for (Index i = 0; i < numext::mini(n, packet_size); i++) {
  945|       |    elements[i] = from[i * stride];
  946|       |  }
  947|       |  return pload<Packet>(elements);
  948|       |}
  949|       |
  950|       |template <typename Scalar, typename Packet>
  951|      0|EIGEN_DEVICE_FUNC inline void pscatter(Scalar* to, const Packet& from, Index /*stride*/) {
  952|      0|  pstore(to, from);
  953|      0|}
  954|       |
  955|       |template <typename Scalar, typename Packet>
  956|       |EIGEN_DEVICE_FUNC inline void pscatter_partial(Scalar* to, const Packet& from, Index stride, const Index n) {
  957|       |  const Index packet_size = unpacket_traits<Packet>::size;
  958|       |  EIGEN_ALIGN_MAX Scalar elements[packet_size];
  959|       |  pstore<Scalar>(elements, from);
  960|       |  for (Index i = 0; i < numext::mini(n, packet_size); i++) {
  961|       |    to[i * stride] = elements[i];
  962|       |  }
  963|       |}
  964|       |
  965|       |/** \internal tries to do cache prefetching of \a addr */
  966|       |template <typename Scalar>
  967|     20|EIGEN_DEVICE_FUNC inline void prefetch(const Scalar* addr) {
  968|       |#if defined(EIGEN_HIP_DEVICE_COMPILE)
  969|       |  // do nothing
  970|       |#elif defined(EIGEN_CUDA_ARCH)
  971|       |#if defined(__LP64__) || EIGEN_OS_WIN64
  972|       |  // 64-bit pointer operand constraint for inlined asm
  973|       |  asm(" prefetch.L1 [ %1 ];" : "=l"(addr) : "l"(addr));
  974|       |#else
  975|       |  // 32-bit pointer operand constraint for inlined asm
  976|       |  asm(" prefetch.L1 [ %1 ];" : "=r"(addr) : "r"(addr));
  977|       |#endif
  978|       |#elif (!EIGEN_COMP_MSVC) && (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)
  979|       |  __builtin_prefetch(addr);
  980|     20|#endif
  981|     20|}
  982|       |
  983|       |/** \internal \returns the reversed elements of \a a*/
  984|       |template <typename Packet>
  985|       |EIGEN_DEVICE_FUNC inline Packet preverse(const Packet& a) {
  986|       |  return a;
  987|       |}
  988|       |
  989|       |/** \internal \returns \a a with real and imaginary part flipped (for complex type only) */
  990|       |template <typename Packet>
  991|       |EIGEN_DEVICE_FUNC inline Packet pcplxflip(const Packet& a) {
  992|       |  return Packet(numext::imag(a), numext::real(a));
  993|       |}
  994|       |
  995|       |/**************************
  996|       | * Special math functions
  997|       | ***************************/
  998|       |
  999|       |/** \internal \returns isnan(a) */
 1000|       |template <typename Packet>
 1001|      0|EIGEN_DEVICE_FUNC inline Packet pisnan(const Packet& a) {
 1002|      0|  return pandnot(ptrue(a), pcmp_eq(a, a));
 1003|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pisnanIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pisnanINS0_9Packet1cdEEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pisnanINS0_9Packet2cfEEET_RKS3_
  ------------------
 1004|       |
 1005|       |/** \internal \returns isinf(a) */
 1006|       |template <typename Packet>
 1007|       |EIGEN_DEVICE_FUNC inline Packet pisinf(const Packet& a) {
 1008|       |  using Scalar = typename unpacket_traits<Packet>::type;
 1009|       |  constexpr Scalar inf = NumTraits<Scalar>::infinity();
 1010|       |  return pcmp_eq(pabs(a), pset1<Packet>(inf));
 1011|       |}
 1012|       |
 1013|       |/** \internal \returns the sine of \a a (coeff-wise) */
 1014|       |template <typename Packet>
 1015|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psin(const Packet& a) {
 1016|       |  EIGEN_USING_STD(sin);
 1017|       |  return sin(a);
 1018|       |}
 1019|       |
 1020|       |/** \internal \returns the cosine of \a a (coeff-wise) */
 1021|       |template <typename Packet>
 1022|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcos(const Packet& a) {
 1023|       |  EIGEN_USING_STD(cos);
 1024|       |  return cos(a);
 1025|       |}
 1026|       |
 1027|       |/** \internal \returns the tan of \a a (coeff-wise) */
 1028|       |template <typename Packet>
 1029|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet ptan(const Packet& a) {
 1030|       |  EIGEN_USING_STD(tan);
 1031|       |  return tan(a);
 1032|       |}
 1033|       |
 1034|       |/** \internal \returns the arc sine of \a a (coeff-wise) */
 1035|       |template <typename Packet>
 1036|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pasin(const Packet& a) {
 1037|       |  EIGEN_USING_STD(asin);
 1038|       |  return asin(a);
 1039|       |}
 1040|       |
 1041|       |/** \internal \returns the arc cosine of \a a (coeff-wise) */
 1042|       |template <typename Packet>
 1043|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pacos(const Packet& a) {
 1044|       |  EIGEN_USING_STD(acos);
 1045|       |  return acos(a);
 1046|       |}
 1047|       |
 1048|       |/** \internal \returns the hyperbolic sine of \a a (coeff-wise) */
 1049|       |template <typename Packet>
 1050|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psinh(const Packet& a) {
 1051|       |  EIGEN_USING_STD(sinh);
 1052|       |  return sinh(a);
 1053|       |}
 1054|       |
 1055|       |/** \internal \returns the hyperbolic cosine of \a a (coeff-wise) */
 1056|       |template <typename Packet>
 1057|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcosh(const Packet& a) {
 1058|       |  EIGEN_USING_STD(cosh);
 1059|       |  return cosh(a);
 1060|       |}
 1061|       |
 1062|       |/** \internal \returns the arc tangent of \a a (coeff-wise) */
 1063|       |template <typename Packet>
 1064|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patan(const Packet& a) {
 1065|       |  EIGEN_USING_STD(atan);
 1066|       |  return atan(a);
 1067|       |}
 1068|       |
 1069|       |/** \internal \returns the hyperbolic tan of \a a (coeff-wise) */
 1070|       |template <typename Packet>
 1071|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet ptanh(const Packet& a) {
 1072|       |  EIGEN_USING_STD(tanh);
 1073|       |  return tanh(a);
 1074|       |}
 1075|       |
 1076|       |/** \internal \returns the arc tangent of \a a (coeff-wise) */
 1077|       |template <typename Packet>
 1078|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patanh(const Packet& a) {
 1079|       |  EIGEN_USING_STD(atanh);
 1080|       |  return atanh(a);
 1081|       |}
 1082|       |
 1083|       |/** \internal \returns the exp of \a a (coeff-wise) */
 1084|       |template <typename Packet>
 1085|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp(const Packet& a) {
 1086|       |  return numext::exp(a);
 1087|       |}
 1088|       |
 1089|       |/** \internal \returns the exp2 of \a a (coeff-wise) */
 1090|       |template <typename Packet>
 1091|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp2(const Packet& a) {
 1092|       |  return numext::exp2(a);
 1093|       |}
 1094|       |
 1095|       |/** \internal \returns the expm1 of \a a (coeff-wise) */
 1096|       |template <typename Packet>
 1097|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexpm1(const Packet& a) {
 1098|       |  return numext::expm1(a);
 1099|       |}
 1100|       |
 1101|       |/** \internal \returns the log of \a a (coeff-wise) */
 1102|       |template <typename Packet>
 1103|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog(const Packet& a) {
 1104|       |  EIGEN_USING_STD(log);
 1105|       |  return log(a);
 1106|       |}
 1107|       |
 1108|       |/** \internal \returns the log1p of \a a (coeff-wise) */
 1109|       |template <typename Packet>
 1110|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog1p(const Packet& a) {
 1111|       |  return numext::log1p(a);
 1112|       |}
 1113|       |
 1114|       |/** \internal \returns the log10 of \a a (coeff-wise) */
 1115|       |template <typename Packet>
 1116|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog10(const Packet& a) {
 1117|       |  EIGEN_USING_STD(log10);
 1118|       |  return log10(a);
 1119|       |}
 1120|       |
 1121|       |/** \internal \returns the log2 of \a a (coeff-wise) */
 1122|       |template <typename Packet>
 1123|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog2(const Packet& a) {
 1124|       |  using Scalar = typename internal::unpacket_traits<Packet>::type;
 1125|       |  using RealScalar = typename NumTraits<Scalar>::Real;
 1126|       |  return pmul(pset1<Packet>(Scalar(RealScalar(EIGEN_LOG2E))), plog(a));
 1127|       |}
 1128|       |
 1129|       |/** \internal \returns the square-root of \a a (coeff-wise) */
 1130|       |template <typename Packet>
 1131|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psqrt(const Packet& a) {
 1132|       |  return numext::sqrt(a);
 1133|       |}
 1134|       |
 1135|       |/** \internal \returns the cube-root of \a a (coeff-wise) */
 1136|       |template <typename Packet>
 1137|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcbrt(const Packet& a) {
 1138|       |  return numext::cbrt(a);
 1139|       |}
 1140|       |
 1141|       |template <typename Packet, bool IsScalar = is_scalar<Packet>::value,
 1142|       |          bool IsInteger = NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>
 1143|       |struct nearest_integer_packetop_impl {
 1144|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_floor(const Packet& x) { return numext::floor(x); }
 1145|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_ceil(const Packet& x) { return numext::ceil(x); }
 1146|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_rint(const Packet& x) { return numext::rint(x); }
 1147|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_round(const Packet& x) { return numext::round(x); }
 1148|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_trunc(const Packet& x) { return numext::trunc(x); }
 1149|       |};
 1150|       |
 1151|       |/** \internal \returns the rounded value of \a a (coeff-wise) */
 1152|       |template <typename Packet>
 1153|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pround(const Packet& a) {
 1154|       |  return nearest_integer_packetop_impl<Packet>::run_round(a);
 1155|       |}
 1156|       |
 1157|       |/** \internal \returns the floor of \a a (coeff-wise) */
 1158|       |template <typename Packet>
 1159|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pfloor(const Packet& a) {
 1160|      0|  return nearest_integer_packetop_impl<Packet>::run_floor(a);
 1161|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pfloorIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pfloorIDv2_dEET_RKS3_
  ------------------
 1162|       |
 1163|       |/** \internal \returns the rounded value of \a a (coeff-wise) with current
 1164|       | * rounding mode */
 1165|       |template <typename Packet>
 1166|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet print(const Packet& a) {
 1167|       |  return nearest_integer_packetop_impl<Packet>::run_rint(a);
 1168|       |}
 1169|       |
 1170|       |/** \internal \returns the ceil of \a a (coeff-wise) */
 1171|       |template <typename Packet>
 1172|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pceil(const Packet& a) {
 1173|       |  return nearest_integer_packetop_impl<Packet>::run_ceil(a);
 1174|       |}
 1175|       |
 1176|       |/** \internal \returns the truncation of \a a (coeff-wise) */
 1177|       |template <typename Packet>
 1178|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet ptrunc(const Packet& a) {
 1179|       |  return nearest_integer_packetop_impl<Packet>::run_trunc(a);
 1180|       |}
 1181|       |
 1182|       |template <typename Packet, typename EnableIf = void>
 1183|       |struct psign_impl {
 1184|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a) { return numext::sign(a); }
 1185|       |};
 1186|       |
 1187|       |/** \internal \returns the sign of \a a (coeff-wise) */
 1188|       |template <typename Packet>
 1189|       |EIGEN_DEVICE_FUNC inline Packet psign(const Packet& a) {
 1190|       |  return psign_impl<Packet>::run(a);
 1191|       |}
 1192|       |
 1193|       |template <>
 1194|      0|EIGEN_DEVICE_FUNC inline bool psign(const bool& a) {
 1195|      0|  return a;
 1196|      0|}
 1197|       |
 1198|       |/** \internal \returns the first element of a packet */
 1199|       |template <typename Packet>
 1200|       |EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type pfirst(const Packet& a) {
 1201|       |  return a;
 1202|       |}
 1203|       |
 1204|       |/** \internal \returns the sum of the elements of upper and lower half of \a a if \a a is larger than 4.
 1205|       | * For a packet {a0, a1, a2, a3, a4, a5, a6, a7}, it returns a half packet {a0+a4, a1+a5, a2+a6, a3+a7}
 1206|       | * For packet-size smaller or equal to 4, this boils down to a noop.
 1207|       | */
 1208|       |template <typename Packet>
 1209|       |EIGEN_DEVICE_FUNC inline std::conditional_t<(unpacket_traits<Packet>::size % 8) == 0,
 1210|       |                                            typename unpacket_traits<Packet>::half, Packet>
 1211|      0|predux_half_dowto4(const Packet& a) {
 1212|      0|  return a;
 1213|      0|}
 1214|       |
 1215|       |// Slow generic implementation of Packet reduction.
 1216|       |template <typename Packet, typename Op>
 1217|       |EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_helper(const Packet& a, Op op) {
 1218|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 1219|       |  const size_t n = unpacket_traits<Packet>::size;
 1220|       |  EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Scalar elements[n];
 1221|       |  pstoreu<Scalar>(elements, a);
 1222|       |  for (size_t k = n / 2; k > 0; k /= 2) {
 1223|       |    for (size_t i = 0; i < k; ++i) {
 1224|       |      elements[i] = op(elements[i], elements[i + k]);
 1225|       |    }
 1226|       |  }
 1227|       |  return elements[0];
 1228|       |}
 1229|       |
 1230|       |/** \internal \returns the sum of the elements of \a a*/
 1231|       |template <typename Packet>
 1232|      0|EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux(const Packet& a) {
 1233|      0|  return a;
 1234|      0|}
 1235|       |
 1236|       |/** \internal \returns the product of the elements of \a a */
 1237|       |template <typename Packet>
 1238|       |EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_mul(const Packet& a) {
 1239|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 1240|       |  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmul<Scalar>)));
 1241|       |}
 1242|       |
 1243|       |/** \internal \returns the min of the elements of \a a */
 1244|       |template <typename Packet>
 1245|       |EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_min(const Packet& a) {
 1246|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 1247|       |  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmin<PropagateFast, Scalar>)));
 1248|       |}
 1249|       |
 1250|       |template <int NaNPropagation, typename Packet>
 1251|       |EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_min(const Packet& a) {
 1252|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 1253|       |  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmin<NaNPropagation, Scalar>)));
 1254|       |}
 1255|       |
 1256|       |/** \internal \returns the min of the elements of \a a */
 1257|       |template <typename Packet>
 1258|       |EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_max(const Packet& a) {
 1259|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 1260|       |  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmax<PropagateFast, Scalar>)));
 1261|       |}
 1262|       |
 1263|       |template <int NaNPropagation, typename Packet>
 1264|       |EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_max(const Packet& a) {
 1265|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 1266|       |  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmax<NaNPropagation, Scalar>)));
 1267|       |}
 1268|       |
 1269|       |#undef EIGEN_BINARY_OP_NAN_PROPAGATION
 1270|       |
 1271|       |/** \internal \returns true if all coeffs of \a a means "true"
 1272|       | * It is supposed to be called on values returned by pcmp_*.
 1273|       | */
 1274|       |// not needed yet
 1275|       |// template<typename Packet> EIGEN_DEVICE_FUNC inline bool predux_all(const Packet& a)
 1276|       |// { return bool(a); }
 1277|       |
 1278|       |/** \internal \returns true if any coeffs of \a a means "true"
 1279|       | * It is supposed to be called on values returned by pcmp_*.
 1280|       | */
 1281|       |template <typename Packet>
 1282|       |EIGEN_DEVICE_FUNC inline bool predux_any(const Packet& a) {
 1283|       |  // Dirty but generic implementation where "true" is assumed to be non 0 and all the sames.
 1284|       |  // It is expected that "true" is either:
 1285|       |  //  - Scalar(1)
 1286|       |  //  - bits full of ones (NaN for floats),
 1287|       |  //  - or first bit equals to 1 (1 for ints, smallest denormal for floats).
 1288|       |  // For all these cases, taking the sum is just fine, and this boils down to a no-op for scalars.
 1289|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 1290|       |  return numext::not_equal_strict(predux(a), Scalar(0));
 1291|       |}
 1292|       |
 1293|       |/***************************************************************************
 1294|       | * The following functions might not have to be overwritten for vectorized types
 1295|       | ***************************************************************************/
 1296|       |
 1297|       |// FMA instructions.
 1298|       |/** \internal \returns a * b + c (coeff-wise) */
 1299|       |template <typename Packet>
 1300|     32|EIGEN_DEVICE_FUNC inline Packet pmadd(const Packet& a, const Packet& b, const Packet& c) {
 1301|     32|  return padd(pmul(a, b), c);
 1302|     32|}
  ------------------
  | _ZN5Eigen8internal5pmaddI14AnnoyingScalarEET_RKS3_S5_S5_:
  | 1300|     32|EIGEN_DEVICE_FUNC inline Packet pmadd(const Packet& a, const Packet& b, const Packet& c) {
  | 1301|     32|  return padd(pmul(a, b), c);
  | 1302|     32|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5pmaddIfEET_RKS2_S4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5pmaddIDv4_fEET_RKS3_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5pmaddIDv2_dEET_RKS3_S5_S5_
  ------------------
 1303|       |
 1304|       |/** \internal \returns a * b - c (coeff-wise) */
 1305|       |template <typename Packet>
 1306|       |EIGEN_DEVICE_FUNC inline Packet pmsub(const Packet& a, const Packet& b, const Packet& c) {
 1307|       |  return psub(pmul(a, b), c);
 1308|       |}
 1309|       |
 1310|       |/** \internal \returns -(a * b) + c (coeff-wise) */
 1311|       |template <typename Packet>
 1312|      0|EIGEN_DEVICE_FUNC inline Packet pnmadd(const Packet& a, const Packet& b, const Packet& c) {
 1313|      0|  return psub(c, pmul(a, b));
 1314|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pnmaddINS0_20eigen_packet_wrapperIDv2_xLi0EEEEET_RKS5_S7_S7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pnmaddIDv4_fEET_RKS3_S5_S5_
  ------------------
 1315|       |
 1316|       |/** \internal \returns -((a * b + c) (coeff-wise) */
 1317|       |template <typename Packet>
 1318|       |EIGEN_DEVICE_FUNC inline Packet pnmsub(const Packet& a, const Packet& b, const Packet& c) {
 1319|       |  return pnegate(pmadd(a, b, c));
 1320|       |}
 1321|       |
 1322|       |/** \internal copy a packet with constant coefficient \a a (e.g., [a,a,a,a]) to \a *to. \a to must be 16 bytes aligned
 1323|       | */
 1324|       |// NOTE: this function must really be templated on the packet type (think about different packet types for the same
 1325|       |// scalar type)
 1326|       |template <typename Packet>
 1327|       |inline void pstore1(typename unpacket_traits<Packet>::type* to, const typename unpacket_traits<Packet>::type& a) {
 1328|       |  pstore(to, pset1<Packet>(a));
 1329|       |}
 1330|       |
 1331|       |/** \internal \returns a packet version of \a *from.
 1332|       | * The pointer \a from must be aligned on a \a Alignment bytes boundary. */
 1333|       |template <typename Packet, int Alignment>
 1334|  5.00k|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet ploadt(const typename unpacket_traits<Packet>::type* from) {
 1335|  5.00k|  if (Alignment >= unpacket_traits<Packet>::alignment)
 1336|      0|    return pload<Packet>(from);
 1337|  5.00k|  else
 1338|  5.00k|    return ploadu<Packet>(from);
 1339|  5.00k|}
 1340|       |
 1341|       |/** \internal \returns n elements of a packet version of \a *from.
 1342|       | * The pointer \a from must be aligned on a \a Alignment bytes boundary. */
 1343|       |template <typename Packet, int Alignment>
 1344|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet ploadt_partial(const typename unpacket_traits<Packet>::type* from,
 1345|       |                                                            const Index n, const Index offset = 0) {
 1346|       |  if (Alignment >= unpacket_traits<Packet>::alignment)
 1347|       |    return pload_partial<Packet>(from, n, offset);
 1348|       |  else
 1349|       |    return ploadu_partial<Packet>(from, n, offset);
 1350|       |}
 1351|       |
 1352|       |/** \internal copy the packet \a from to \a *to.
 1353|       | * The pointer \a from must be aligned on a \a Alignment bytes boundary. */
 1354|       |template <typename Scalar, typename Packet, int Alignment>
 1355|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void pstoret(Scalar* to, const Packet& from) {
 1356|      0|  if (Alignment >= unpacket_traits<Packet>::alignment)
 1357|      0|    pstore(to, from);
 1358|      0|  else
 1359|      0|    pstoreu(to, from);
 1360|      0|}
 1361|       |
 1362|       |/** \internal copy n elements of the packet \a from to \a *to.
 1363|       | * The pointer \a from must be aligned on a \a Alignment bytes boundary. */
 1364|       |template <typename Scalar, typename Packet, int Alignment>
 1365|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void pstoret_partial(Scalar* to, const Packet& from, const Index n,
 1366|       |                                                           const Index offset = 0) {
 1367|       |  if (Alignment >= unpacket_traits<Packet>::alignment)
 1368|       |    pstore_partial(to, from, n, offset);
 1369|       |  else
 1370|       |    pstoreu_partial(to, from, n, offset);
 1371|       |}
 1372|       |
 1373|       |/** \internal \returns a packet version of \a *from.
 1374|       | * Unlike ploadt, ploadt_ro takes advantage of the read-only memory path on the
 1375|       | * hardware if available to speedup the loading of data that won't be modified
 1376|       | * by the current computation.
 1377|       | */
 1378|       |template <typename Packet, int LoadMode>
 1379|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet ploadt_ro(const typename unpacket_traits<Packet>::type* from) {
 1380|       |  return ploadt<Packet, LoadMode>(from);
 1381|       |}
 1382|       |
 1383|       |/***************************************************************************
 1384|       | * Fast complex products (GCC generates a function call which is very slow)
 1385|       | ***************************************************************************/
 1386|       |
 1387|       |// Eigen+CUDA does not support complexes.
 1388|       |#if !defined(EIGEN_GPUCC)
 1389|       |
 1390|       |template <>
 1391|      0|inline std::complex<float> pmul(const std::complex<float>& a, const std::complex<float>& b) {
 1392|      0|  return std::complex<float>(a.real() * b.real() - a.imag() * b.imag(), a.imag() * b.real() + a.real() * b.imag());
 1393|      0|}
 1394|       |
 1395|       |template <>
 1396|      0|inline std::complex<double> pmul(const std::complex<double>& a, const std::complex<double>& b) {
 1397|      0|  return std::complex<double>(a.real() * b.real() - a.imag() * b.imag(), a.imag() * b.real() + a.real() * b.imag());
 1398|      0|}
 1399|       |
 1400|       |#endif
 1401|       |
 1402|       |/***************************************************************************
 1403|       | * PacketBlock, that is a collection of N packets where the number of words
 1404|       | * in the packet is a multiple of N.
 1405|       | ***************************************************************************/
 1406|       |template <typename Packet, int N = unpacket_traits<Packet>::size>
 1407|       |struct PacketBlock {
 1408|       |  Packet packet[N];
 1409|       |};
 1410|       |
 1411|       |template <typename Packet>
 1412|      0|EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet, 1>& /*kernel*/) {
 1413|      0|  // Nothing to do in the scalar case, i.e. a 1x1 matrix.
 1414|      0|}
 1415|       |
 1416|       |/***************************************************************************
 1417|       | * Selector, i.e. vector of N boolean values used to select (i.e. blend)
 1418|       | * words from 2 packets.
 1419|       | ***************************************************************************/
 1420|       |template <size_t N>
 1421|       |struct Selector {
 1422|       |  bool select[N];
 1423|       |};
 1424|       |
 1425|       |template <typename Packet>
 1426|       |EIGEN_DEVICE_FUNC inline Packet pblend(const Selector<unpacket_traits<Packet>::size>& ifPacket,
 1427|       |                                       const Packet& thenPacket, const Packet& elsePacket) {
 1428|       |  return ifPacket.select[0] ? thenPacket : elsePacket;
 1429|       |}
 1430|       |
 1431|       |/** \internal \returns 1 / a (coeff-wise) */
 1432|       |template <typename Packet>
 1433|      0|EIGEN_DEVICE_FUNC inline Packet preciprocal(const Packet& a) {
 1434|      0|  using Scalar = typename unpacket_traits<Packet>::type;
 1435|      0|  return pdiv(pset1<Packet>(Scalar(1)), a);
 1436|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11preciprocalIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11preciprocalIDv2_dEET_RKS3_
  ------------------
 1437|       |
 1438|       |/** \internal \returns the reciprocal square-root of \a a (coeff-wise) */
 1439|       |template <typename Packet>
 1440|       |EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet prsqrt(const Packet& a) {
 1441|       |  return preciprocal<Packet>(psqrt(a));
 1442|       |}
 1443|       |
 1444|       |template <typename Packet, bool IsScalar = is_scalar<Packet>::value,
 1445|       |          bool IsInteger = NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>
 1446|       |struct psignbit_impl;
 1447|       |template <typename Packet, bool IsInteger>
 1448|       |struct psignbit_impl<Packet, true, IsInteger> {
 1449|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static constexpr Packet run(const Packet& a) { return numext::signbit(a); }
 1450|       |};
 1451|       |template <typename Packet>
 1452|       |struct psignbit_impl<Packet, false, false> {
 1453|       |  // generic implementation if not specialized in PacketMath.h
 1454|       |  // slower than arithmetic shift
 1455|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 1456|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static Packet run(const Packet& a) {
 1457|       |    const Packet cst_pos_one = pset1<Packet>(Scalar(1));
 1458|       |    const Packet cst_neg_one = pset1<Packet>(Scalar(-1));
 1459|       |    return pcmp_eq(por(pand(a, cst_neg_one), cst_pos_one), cst_neg_one);
 1460|       |  }
 1461|       |};
 1462|       |template <typename Packet>
 1463|       |struct psignbit_impl<Packet, false, true> {
 1464|       |  // generic implementation for integer packets
 1465|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static constexpr Packet run(const Packet& a) { return pcmp_lt(a, pzero(a)); }
 1466|       |};
 1467|       |/** \internal \returns the sign bit of \a a as a bitmask*/
 1468|       |template <typename Packet>
 1469|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE constexpr Packet psignbit(const Packet& a) {
 1470|       |  return psignbit_impl<Packet>::run(a);
 1471|       |}
 1472|       |
 1473|       |/** \internal \returns the 2-argument arc tangent of \a y and \a x (coeff-wise) */
 1474|       |template <typename Packet, std::enable_if_t<is_scalar<Packet>::value, int> = 0>
 1475|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet patan2(const Packet& y, const Packet& x) {
 1476|       |  return numext::atan2(y, x);
 1477|       |}
 1478|       |
 1479|       |/** \internal \returns the 2-argument arc tangent of \a y and \a x (coeff-wise) */
 1480|       |template <typename Packet, std::enable_if_t<!is_scalar<Packet>::value, int> = 0>
 1481|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet patan2(const Packet& y, const Packet& x) {
 1482|      0|  typedef typename internal::unpacket_traits<Packet>::type Scalar;
 1483|      0|
 1484|      0|  // See https://en.cppreference.com/w/cpp/numeric/math/atan2
 1485|      0|  // for how corner cases are supposed to be handled according to the
 1486|      0|  // IEEE floating-point standard (IEC 60559).
 1487|      0|  const Packet kSignMask = pset1<Packet>(-Scalar(0));
 1488|      0|  const Packet kZero = pzero(x);
 1489|      0|  const Packet kOne = pset1<Packet>(Scalar(1));
 1490|      0|  const Packet kPi = pset1<Packet>(Scalar(EIGEN_PI));
 1491|      0|
 1492|      0|  const Packet x_has_signbit = psignbit(x);
 1493|      0|  const Packet y_signmask = pand(y, kSignMask);
 1494|      0|  const Packet x_signmask = pand(x, kSignMask);
 1495|      0|  const Packet result_signmask = pxor(y_signmask, x_signmask);
 1496|      0|  const Packet shift = por(pand(x_has_signbit, kPi), y_signmask);
 1497|      0|
 1498|      0|  const Packet x_and_y_are_same = pcmp_eq(pabs(x), pabs(y));
 1499|      0|  const Packet x_and_y_are_zero = pcmp_eq(por(x, y), kZero);
 1500|      0|
 1501|      0|  Packet arg = pdiv(y, x);
 1502|      0|  arg = pselect(x_and_y_are_same, por(kOne, result_signmask), arg);
 1503|      0|  arg = pselect(x_and_y_are_zero, result_signmask, arg);
 1504|      0|
 1505|      0|  Packet result = patan(arg);
 1506|      0|  result = padd(result, shift);
 1507|      0|  return result;
 1508|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6patan2IDv2_dLi0EEET_RKS3_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6patan2IDv4_fLi0EEET_RKS3_S5_
  ------------------
 1509|       |
 1510|       |/** \internal \returns the argument of \a a as a complex number */
 1511|       |template <typename Packet, std::enable_if_t<is_scalar<Packet>::value, int> = 0>
 1512|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet pcarg(const Packet& a) {
 1513|       |  return Packet(numext::arg(a));
 1514|       |}
 1515|       |
 1516|       |/** \internal \returns the argument of \a a as a complex number */
 1517|       |template <typename Packet, std::enable_if_t<!is_scalar<Packet>::value, int> = 0>
 1518|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet pcarg(const Packet& a) {
 1519|       |  EIGEN_STATIC_ASSERT(NumTraits<typename unpacket_traits<Packet>::type>::IsComplex,
 1520|       |                      THIS METHOD IS FOR COMPLEX TYPES ONLY)
 1521|       |  using RealPacket = typename unpacket_traits<Packet>::as_real;
 1522|       |  // a                                              // r     i    r     i    ...
 1523|       |  RealPacket aflip = pcplxflip(a).v;                // i     r    i     r    ...
 1524|       |  RealPacket result = patan2(aflip, a.v);           // atan2 crap atan2 crap ...
 1525|       |  return (Packet)pand(result, peven_mask(result));  // atan2 0    atan2 0    ...
 1526|       |}
 1527|       |
 1528|       |}  // end namespace internal
 1529|       |
 1530|       |}  // end namespace Eigen
 1531|       |
 1532|       |#endif  // EIGEN_GENERIC_PACKET_MATH_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/IO.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_IO_H
   12|       |#define EIGEN_IO_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |enum { DontAlignCols = 1 };
   20|       |enum { StreamPrecision = -1, FullPrecision = -2 };
   21|       |
   22|       |namespace internal {
   23|       |template <typename Derived>
   24|       |std::ostream& print_matrix(std::ostream& s, const Derived& _m, const IOFormat& fmt);
   25|       |}
   26|       |
   27|       |/** \class IOFormat
   28|       | * \ingroup Core_Module
   29|       | *
   30|       | * \brief Stores a set of parameters controlling the way matrices are printed
   31|       | *
   32|       | * List of available parameters:
   33|       | *  - \b precision number of digits for floating point values, or one of the special constants \c StreamPrecision and \c
   34|       | * FullPrecision. The default is the special value \c StreamPrecision which means to use the stream's own precision
   35|       | * setting, as set for instance using \c cout.precision(3). The other special value \c FullPrecision means that the
   36|       | * number of digits will be computed to match the full precision of each floating-point type.
   37|       | *  - \b flags an OR-ed combination of flags, the default value is 0, the only currently available flag is \c
   38|       | * DontAlignCols which allows to disable the alignment of columns, resulting in faster code.
   39|       | *  - \b coeffSeparator string printed between two coefficients of the same row
   40|       | *  - \b rowSeparator string printed between two rows
   41|       | *  - \b rowPrefix string printed at the beginning of each row
   42|       | *  - \b rowSuffix string printed at the end of each row
   43|       | *  - \b matPrefix string printed at the beginning of the matrix
   44|       | *  - \b matSuffix string printed at the end of the matrix
   45|       | *  - \b fill character printed to fill the empty space in aligned columns
   46|       | *
   47|       | * Example: \include IOFormat.cpp
   48|       | * Output: \verbinclude IOFormat.out
   49|       | *
   50|       | * \sa DenseBase::format(), class WithFormat
   51|       | */
   52|       |struct IOFormat {
   53|       |  /** Default constructor, see class IOFormat for the meaning of the parameters */
   54|       |  IOFormat(int _precision = StreamPrecision, int _flags = 0, const std::string& _coeffSeparator = " ",
   55|       |           const std::string& _rowSeparator = "\n", const std::string& _rowPrefix = "",
   56|       |           const std::string& _rowSuffix = "", const std::string& _matPrefix = "", const std::string& _matSuffix = "",
   57|       |           const char _fill = ' ')
   58|       |      : matPrefix(_matPrefix),
   59|       |        matSuffix(_matSuffix),
   60|       |        rowPrefix(_rowPrefix),
   61|       |        rowSuffix(_rowSuffix),
   62|       |        rowSeparator(_rowSeparator),
   63|       |        rowSpacer(""),
   64|       |        coeffSeparator(_coeffSeparator),
   65|       |        fill(_fill),
   66|       |        precision(_precision),
   67|      0|        flags(_flags) {
   68|      0|    // TODO check if rowPrefix, rowSuffix or rowSeparator contains a newline
   69|      0|    // don't add rowSpacer if columns are not to be aligned
   70|      0|    if ((flags & DontAlignCols)) return;
   71|      0|    int i = int(matPrefix.length()) - 1;
   72|      0|    while (i >= 0 && matPrefix[i] != '\n') {
   73|      0|      rowSpacer += ' ';
   74|      0|      i--;
   75|      0|    }
   76|      0|  }
   77|       |  std::string matPrefix, matSuffix;
   78|       |  std::string rowPrefix, rowSuffix, rowSeparator, rowSpacer;
   79|       |  std::string coeffSeparator;
   80|       |  char fill;
   81|       |  int precision;
   82|       |  int flags;
   83|       |};
   84|       |
   85|       |/** \class WithFormat
   86|       | * \ingroup Core_Module
   87|       | *
   88|       | * \brief Pseudo expression providing matrix output with given format
   89|       | *
   90|       | * \tparam ExpressionType the type of the object on which IO stream operations are performed
   91|       | *
   92|       | * This class represents an expression with stream operators controlled by a given IOFormat.
   93|       | * It is the return type of DenseBase::format()
   94|       | * and most of the time this is the only way it is used.
   95|       | *
   96|       | * See class IOFormat for some examples.
   97|       | *
   98|       | * \sa DenseBase::format(), class IOFormat
   99|       | */
  100|       |template <typename ExpressionType>
  101|       |class WithFormat {
  102|       | public:
  103|       |  WithFormat(const ExpressionType& matrix, const IOFormat& format) : m_matrix(matrix), m_format(format) {}
  104|       |
  105|       |  friend std::ostream& operator<<(std::ostream& s, const WithFormat& wf) {
  106|       |    return internal::print_matrix(s, wf.m_matrix.eval(), wf.m_format);
  107|       |  }
  108|       |
  109|       | protected:
  110|       |  typename ExpressionType::Nested m_matrix;
  111|       |  IOFormat m_format;
  112|       |};
  113|       |
  114|       |namespace internal {
  115|       |
  116|       |// NOTE: This helper is kept for backward compatibility with previous code specializing
  117|       |//       this internal::significant_decimals_impl structure. In the future we should directly
  118|       |//       call max_digits10().
  119|       |template <typename Scalar>
  120|       |struct significant_decimals_impl {
  121|       |  static inline int run() { return NumTraits<Scalar>::max_digits10(); }
  122|       |};
  123|       |
  124|       |/** \internal
  125|       | * print the matrix \a _m to the output stream \a s using the output format \a fmt */
  126|       |template <typename Derived>
  127|       |std::ostream& print_matrix(std::ostream& s, const Derived& _m, const IOFormat& fmt) {
  128|       |  using internal::is_same;
  129|       |
  130|       |  if (_m.size() == 0) {
  131|       |    s << fmt.matPrefix << fmt.matSuffix;
  132|       |    return s;
  133|       |  }
  134|       |
  135|       |  typename Derived::Nested m = _m;
  136|       |  typedef typename Derived::Scalar Scalar;
  137|       |  typedef std::conditional_t<is_same<Scalar, char>::value || is_same<Scalar, unsigned char>::value ||
  138|       |                                 is_same<Scalar, numext::int8_t>::value || is_same<Scalar, numext::uint8_t>::value,
  139|       |                             int,
  140|       |                             std::conditional_t<is_same<Scalar, std::complex<char> >::value ||
  141|       |                                                    is_same<Scalar, std::complex<unsigned char> >::value ||
  142|       |                                                    is_same<Scalar, std::complex<numext::int8_t> >::value ||
  143|       |                                                    is_same<Scalar, std::complex<numext::uint8_t> >::value,
  144|       |                                                std::complex<int>, const Scalar&> >
  145|       |      PrintType;
  146|       |
  147|       |  Index width = 0;
  148|       |
  149|       |  std::streamsize explicit_precision;
  150|       |  if (fmt.precision == StreamPrecision) {
  151|       |    explicit_precision = 0;
  152|       |  } else if (fmt.precision == FullPrecision) {
  153|       |    if (NumTraits<Scalar>::IsInteger) {
  154|       |      explicit_precision = 0;
  155|       |    } else {
  156|       |      explicit_precision = significant_decimals_impl<Scalar>::run();
  157|       |    }
  158|       |  } else {
  159|       |    explicit_precision = fmt.precision;
  160|       |  }
  161|       |
  162|       |  std::streamsize old_precision = 0;
  163|       |  if (explicit_precision) old_precision = s.precision(explicit_precision);
  164|       |
  165|       |  bool align_cols = !(fmt.flags & DontAlignCols);
  166|       |  if (align_cols) {
  167|       |    // compute the largest width
  168|       |    for (Index j = 0; j < m.cols(); ++j)
  169|       |      for (Index i = 0; i < m.rows(); ++i) {
  170|       |        std::stringstream sstr;
  171|       |        sstr.copyfmt(s);
  172|       |        sstr << static_cast<PrintType>(m.coeff(i, j));
  173|       |        width = std::max<Index>(width, Index(sstr.str().length()));
  174|       |      }
  175|       |  }
  176|       |  std::streamsize old_width = s.width();
  177|       |  char old_fill_character = s.fill();
  178|       |  s << fmt.matPrefix;
  179|       |  for (Index i = 0; i < m.rows(); ++i) {
  180|       |    if (i) s << fmt.rowSpacer;
  181|       |    s << fmt.rowPrefix;
  182|       |    if (width) {
  183|       |      s.fill(fmt.fill);
  184|       |      s.width(width);
  185|       |    }
  186|       |    s << static_cast<PrintType>(m.coeff(i, 0));
  187|       |    for (Index j = 1; j < m.cols(); ++j) {
  188|       |      s << fmt.coeffSeparator;
  189|       |      if (width) {
  190|       |        s.fill(fmt.fill);
  191|       |        s.width(width);
  192|       |      }
  193|       |      s << static_cast<PrintType>(m.coeff(i, j));
  194|       |    }
  195|       |    s << fmt.rowSuffix;
  196|       |    if (i < m.rows() - 1) s << fmt.rowSeparator;
  197|       |  }
  198|       |  s << fmt.matSuffix;
  199|       |  if (explicit_precision) s.precision(old_precision);
  200|       |  if (width) {
  201|       |    s.fill(old_fill_character);
  202|       |    s.width(old_width);
  203|       |  }
  204|       |  return s;
  205|       |}
  206|       |
  207|       |}  // end namespace internal
  208|       |
  209|       |/** \relates DenseBase
  210|       | *
  211|       | * Outputs the matrix, to the given stream.
  212|       | *
  213|       | * If you wish to print the matrix with a format different than the default, use DenseBase::format().
  214|       | *
  215|       | * It is also possible to change the default format by defining EIGEN_DEFAULT_IO_FORMAT before including Eigen headers.
  216|       | * If not defined, this will automatically be defined to Eigen::IOFormat(), that is the Eigen::IOFormat with default
  217|       | * parameters.
  218|       | *
  219|       | * \sa DenseBase::format()
  220|       | */
  221|       |template <typename Derived>
  222|       |std::ostream& operator<<(std::ostream& s, const DenseBase<Derived>& m) {
  223|       |  return internal::print_matrix(s, m.eval(), EIGEN_DEFAULT_IO_FORMAT);
  224|       |}
  225|       |
  226|       |template <typename Derived>
  227|       |std::ostream& operator<<(std::ostream& s, const DiagonalBase<Derived>& m) {
  228|       |  return internal::print_matrix(s, m.derived(), EIGEN_DEFAULT_IO_FORMAT);
  229|       |}
  230|       |
  231|       |}  // end namespace Eigen
  232|       |
  233|       |#endif  // EIGEN_IO_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/InnerProduct.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2024 Charlie Schlosser <cs.schlosser@gmail.com>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_INNER_PRODUCT_EVAL_H
   11|       |#define EIGEN_INNER_PRODUCT_EVAL_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "./InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |// recursively searches for the largest simd type that does not exceed Size, or the smallest if no such type exists
   21|       |template <typename Scalar, int Size, typename Packet = typename packet_traits<Scalar>::type,
   22|       |          bool Stop =
   23|       |              (unpacket_traits<Packet>::size <= Size) || is_same<Packet, typename unpacket_traits<Packet>::half>::value>
   24|       |struct find_inner_product_packet_helper;
   25|       |
   26|       |template <typename Scalar, int Size, typename Packet>
   27|       |struct find_inner_product_packet_helper<Scalar, Size, Packet, false> {
   28|       |  using type = typename find_inner_product_packet_helper<Scalar, Size, typename unpacket_traits<Packet>::half>::type;
   29|       |};
   30|       |
   31|       |template <typename Scalar, int Size, typename Packet>
   32|       |struct find_inner_product_packet_helper<Scalar, Size, Packet, true> {
   33|       |  using type = Packet;
   34|       |};
   35|       |
   36|       |template <typename Scalar, int Size>
   37|       |struct find_inner_product_packet : find_inner_product_packet_helper<Scalar, Size> {};
   38|       |
   39|       |template <typename Scalar>
   40|       |struct find_inner_product_packet<Scalar, Dynamic> {
   41|       |  using type = typename packet_traits<Scalar>::type;
   42|       |};
   43|       |
   44|       |template <typename Lhs, typename Rhs>
   45|       |struct inner_product_assert {
   46|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Lhs)
   47|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Rhs)
   48|       |  EIGEN_STATIC_ASSERT_SAME_VECTOR_SIZE(Lhs, Rhs)
   49|       |#ifndef EIGEN_NO_DEBUG
   50|      1|  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, const Rhs& rhs) {
   51|      1|    eigen_assert((lhs.size() == rhs.size()) && "Inner product: lhs and rhs vectors must have same size");
   52|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20inner_product_assertINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS2_IKNS2_IS6_Lin1ELi1ELb1EEELin1ELi1ELb1EEEE3runERKS7_RKSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20inner_product_assertINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS2_IS6_Lin1ELi1ELb1EEEE3runERKS9_RKSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20inner_product_assertINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEENS2_IKNS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEE3runERKS9_RKSC_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20inner_product_assertINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEENS2_IKNS2_IKS6_Lin1ELi1ELb1EEELin1ELi1ELb1EEEE3runERKS9_RKSD_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20inner_product_assertINS_5BlockIKNS2_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS2_IKS6_Lin1ELi1ELb1EEEE3runERKSB_RKSD_
  ------------------
  | _ZN5Eigen8internal20inner_product_assertINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EES9_E3runERKS9_SC_:
  |   50|      1|  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, const Rhs& rhs) {
  |   51|      1|    eigen_assert((lhs.size() == rhs.size()) && "Inner product: lhs and rhs vectors must have same size");
  |   52|      1|  }
  ------------------
   53|       |#else
   54|       |  static EIGEN_DEVICE_FUNC void run(const Lhs&, const Rhs&) {}
   55|       |#endif
   56|       |};
   57|       |
   58|       |template <typename Func, typename Lhs, typename Rhs>
   59|       |struct inner_product_evaluator {
   60|       |  static constexpr int LhsFlags = evaluator<Lhs>::Flags, RhsFlags = evaluator<Rhs>::Flags,
   61|       |                       SizeAtCompileTime = min_size_prefer_fixed(Lhs::SizeAtCompileTime, Rhs::SizeAtCompileTime),
   62|       |                       LhsAlignment = evaluator<Lhs>::Alignment, RhsAlignment = evaluator<Rhs>::Alignment;
   63|       |
   64|       |  using Scalar = typename Func::result_type;
   65|       |  using Packet = typename find_inner_product_packet<Scalar, SizeAtCompileTime>::type;
   66|       |
   67|       |  static constexpr bool Vectorize =
   68|       |      bool(LhsFlags & RhsFlags & PacketAccessBit) && Func::PacketAccess &&
   69|       |      ((SizeAtCompileTime == Dynamic) || (unpacket_traits<Packet>::size <= SizeAtCompileTime));
   70|       |
   71|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit inner_product_evaluator(const Lhs& lhs, const Rhs& rhs,
   72|       |                                                                         Func func = Func())
   73|      1|      : m_func(func), m_lhs(lhs), m_rhs(rhs), m_size(lhs.size()) {
   74|      1|    inner_product_assert<Lhs, Rhs>::run(lhs, rhs);
   75|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEENS5_IKNS7_IS3_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEC2ERKSB_RKSE_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS5_IKNS5_IS8_Lin1ELi1ELb1EEELin1ELi1ELb1EEEEC2ERKS9_RKSC_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS5_IKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS5_IS8_Lin1ELi1ELb1EEEEC2ERKSB_RKSC_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEENS5_IKNS5_IKS8_Lin1ELi1ELb1EEELin1ELi1ELb1EEEEC2ERKSB_RKSF_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS5_IKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS5_IKS8_Lin1ELi1ELb1EEEEC2ERKSD_RKSF_S4_
  ------------------
  | _ZN5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_13CwiseBinaryOpINS0_13scalar_sum_opIS3_S3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEESA_EESB_EC2ERKSB_SE_S4_:
  |   73|      1|      : m_func(func), m_lhs(lhs), m_rhs(rhs), m_size(lhs.size()) {
  |   74|      1|    inner_product_assert<Lhs, Rhs>::run(lhs, rhs);
  |   75|      1|  }
  ------------------
   76|       |
   77|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index size() const { return m_size.value(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS5_IKNS5_IS8_Lin1ELi1ELb1EEELin1ELi1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS5_IKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS5_IS8_Lin1ELi1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEENS5_IKNS7_IS3_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEENS5_IKNS5_IKS8_Lin1ELi1ELb1EEELin1ELi1ELb1EEEE4sizeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS5_IKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS5_IKS8_Lin1ELi1ELb1EEEE4sizeEv
  ------------------
  | _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_13CwiseBinaryOpINS0_13scalar_sum_opIS3_S3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEESA_EESB_E4sizeEv:
  |   77|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index size() const { return m_size.value(); }
  ------------------
   78|       |
   79|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(Index index) const {
   80|      1|    return m_func.coeff(m_lhs.coeff(index), m_rhs.coeff(index));
   81|      1|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS5_IKNS5_IS8_Lin1ELi1ELb1EEELin1ELi1ELb1EEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS5_IKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS5_IS8_Lin1ELi1ELb1EEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEENS5_IKNS7_IS3_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEENS5_IKNS5_IKS8_Lin1ELi1ELb1EEELin1ELi1ELb1EEEE5coeffEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS5_IKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS5_IKS8_Lin1ELi1ELb1EEEE5coeffEl
  ------------------
  | _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_13CwiseBinaryOpINS0_13scalar_sum_opIS3_S3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEESA_EESB_E5coeffEl:
  |   79|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(Index index) const {
  |   80|      1|    return m_func.coeff(m_lhs.coeff(index), m_rhs.coeff(index));
  |   81|      1|  }
  ------------------
   82|       |
   83|     33|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(const Scalar& value, Index index) const {
   84|     33|    return m_func.coeff(value, m_lhs.coeff(index), m_rhs.coeff(index));
   85|     33|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS5_IKNS5_IS8_Lin1ELi1ELb1EEELin1ELi1ELb1EEEE5coeffERKS3_l
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS5_IKNS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS5_IS8_Lin1ELi1ELb1EEEE5coeffERKS3_l
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEENS5_IKNS7_IS3_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEE5coeffERKS3_l
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEENS5_IKNS5_IKS8_Lin1ELi1ELb1EEELin1ELi1ELb1EEEE5coeffERKS3_l
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_5BlockIKNS5_IKNS_7ProductINS_6MatrixIS3_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS5_IKS8_Lin1ELi1ELb1EEEE5coeffERKS3_l
  ------------------
  | _ZNK5Eigen8internal23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS3_Lb1EEENS_13CwiseBinaryOpINS0_13scalar_sum_opIS3_S3_EEKNS_6MatrixIS3_Lin1ELi1ELi0ELin1ELi1EEESA_EESB_E5coeffERKS3_l:
  |   83|     33|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(const Scalar& value, Index index) const {
  |   84|     33|    return m_func.coeff(value, m_lhs.coeff(index), m_rhs.coeff(index));
  |   85|     33|  }
  ------------------
   86|       |
   87|       |  template <typename PacketType, int LhsMode = LhsAlignment, int RhsMode = RhsAlignment>
   88|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(Index index) const {
   89|       |    return m_func.packet(m_lhs.template packet<LhsMode, PacketType>(index),
   90|       |                         m_rhs.template packet<RhsMode, PacketType>(index));
   91|       |  }
   92|       |
   93|       |  template <typename PacketType, int LhsMode = LhsAlignment, int RhsMode = RhsAlignment>
   94|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packet(const PacketType& value, Index index) const {
   95|       |    return m_func.packet(value, m_lhs.template packet<LhsMode, PacketType>(index),
   96|       |                         m_rhs.template packet<RhsMode, PacketType>(index));
   97|       |  }
   98|       |
   99|       |  const Func m_func;
  100|       |  const evaluator<Lhs> m_lhs;
  101|       |  const evaluator<Rhs> m_rhs;
  102|       |  const variable_if_dynamic<Index, SizeAtCompileTime> m_size;
  103|       |};
  104|       |
  105|       |template <typename Evaluator, bool Vectorize = Evaluator::Vectorize>
  106|       |struct inner_product_impl;
  107|       |
  108|       |// scalar loop
  109|       |template <typename Evaluator>
  110|       |struct inner_product_impl<Evaluator, false> {
  111|       |  using Scalar = typename Evaluator::Scalar;
  112|      1|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval) {
  113|      1|    const Index size = eval.size();
  114|      1|    if (size == 0) return Scalar(0);
  115|       |
  116|      1|    Scalar result = eval.coeff(0);
  117|     34|    for (Index k = 1; k < size; k++) {
  118|     33|      result = eval.coeff(result, k);
  119|     33|    }
  120|       |
  121|      1|    return result;
  122|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18inner_product_implINS0_23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS4_Lb1EEENS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS6_IKNS6_IS9_Lin1ELi1ELb1EEELin1ELi1ELb1EEEEELb0EE3runERKSE_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18inner_product_implINS0_23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS4_Lb1EEENS_5BlockIKNS6_IKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS6_IS9_Lin1ELi1ELb1EEEEELb0EE3runERKSE_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18inner_product_implINS0_23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS4_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEES9_Li0EEELi1ELin1ELb0EEENS6_IKNS8_IS4_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEELb0EE3runERKSG_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18inner_product_implINS0_23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS4_Lb1EEENS_5BlockIKNS_7ProductINS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEES9_Li0EEELi1ELin1ELb0EEENS6_IKNS6_IKS9_Lin1ELi1ELb1EEELin1ELi1ELb1EEEEELb0EE3runERKSH_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18inner_product_implINS0_23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS4_Lb1EEENS_5BlockIKNS6_IKNS_7ProductINS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEES9_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS6_IKS9_Lin1ELi1ELb1EEEEELb0EE3runERKSH_
  ------------------
  | _ZN5Eigen8internal18inner_product_implINS0_23inner_product_evaluatorINS0_23scalar_inner_product_opI14AnnoyingScalarS4_Lb1EEENS_13CwiseBinaryOpINS0_13scalar_sum_opIS4_S4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEESB_EESC_EELb0EE3runERKSD_:
  |  112|      1|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval) {
  |  113|      1|    const Index size = eval.size();
  |  114|      1|    if (size == 0) return Scalar(0);
  |  115|       |
  |  116|      1|    Scalar result = eval.coeff(0);
  |  117|     34|    for (Index k = 1; k < size; k++) {
  |  118|     33|      result = eval.coeff(result, k);
  |  119|     33|    }
  |  120|       |
  |  121|      1|    return result;
  |  122|      1|  }
  ------------------
  123|       |};
  124|       |
  125|       |// vector loop
  126|       |template <typename Evaluator>
  127|       |struct inner_product_impl<Evaluator, true> {
  128|       |  using UnsignedIndex = std::make_unsigned_t<Index>;
  129|       |  using Scalar = typename Evaluator::Scalar;
  130|       |  using Packet = typename Evaluator::Packet;
  131|       |  static constexpr int PacketSize = unpacket_traits<Packet>::size;
  132|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval) {
  133|       |    const UnsignedIndex size = static_cast<UnsignedIndex>(eval.size());
  134|       |    if (size < PacketSize) return inner_product_impl<Evaluator, false>::run(eval);
  135|       |
  136|       |    const UnsignedIndex packetEnd = numext::round_down(size, PacketSize);
  137|       |    const UnsignedIndex quadEnd = numext::round_down(size, 4 * PacketSize);
  138|       |    const UnsignedIndex numPackets = size / PacketSize;
  139|       |    const UnsignedIndex numRemPackets = (packetEnd - quadEnd) / PacketSize;
  140|       |
  141|       |    Packet presult0, presult1, presult2, presult3;
  142|       |
  143|       |    presult0 = eval.template packet<Packet>(0 * PacketSize);
  144|       |    if (numPackets >= 2) presult1 = eval.template packet<Packet>(1 * PacketSize);
  145|       |    if (numPackets >= 3) presult2 = eval.template packet<Packet>(2 * PacketSize);
  146|       |    if (numPackets >= 4) {
  147|       |      presult3 = eval.template packet<Packet>(3 * PacketSize);
  148|       |
  149|       |      for (UnsignedIndex k = 4 * PacketSize; k < quadEnd; k += 4 * PacketSize) {
  150|       |        presult0 = eval.packet(presult0, k + 0 * PacketSize);
  151|       |        presult1 = eval.packet(presult1, k + 1 * PacketSize);
  152|       |        presult2 = eval.packet(presult2, k + 2 * PacketSize);
  153|       |        presult3 = eval.packet(presult3, k + 3 * PacketSize);
  154|       |      }
  155|       |
  156|       |      if (numRemPackets >= 1) presult0 = eval.packet(presult0, quadEnd + 0 * PacketSize);
  157|       |      if (numRemPackets >= 2) presult1 = eval.packet(presult1, quadEnd + 1 * PacketSize);
  158|       |      if (numRemPackets == 3) presult2 = eval.packet(presult2, quadEnd + 2 * PacketSize);
  159|       |
  160|       |      presult2 = padd(presult2, presult3);
  161|       |    }
  162|       |
  163|       |    if (numPackets >= 3) presult1 = padd(presult1, presult2);
  164|       |    if (numPackets >= 2) presult0 = padd(presult0, presult1);
  165|       |
  166|       |    Scalar result = predux(presult0);
  167|       |    for (UnsignedIndex k = packetEnd; k < size; k++) {
  168|       |      result = eval.coeff(result, k);
  169|       |    }
  170|       |
  171|       |    return result;
  172|       |  }
  173|       |};
  174|       |
  175|       |template <typename Scalar, bool Conj>
  176|       |struct conditional_conj;
  177|       |
  178|       |template <typename Scalar>
  179|       |struct conditional_conj<Scalar, true> {
  180|     33|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(const Scalar& a) { return numext::conj(a); }
  181|       |  template <typename Packet>
  182|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packet(const Packet& a) {
  183|       |    return pconj(a);
  184|       |  }
  185|       |};
  186|       |
  187|       |template <typename Scalar>
  188|       |struct conditional_conj<Scalar, false> {
  189|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(const Scalar& a) { return a; }
  190|       |  template <typename Packet>
  191|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packet(const Packet& a) {
  192|       |    return a;
  193|       |  }
  194|       |};
  195|       |
  196|       |template <typename LhsScalar, typename RhsScalar, bool Conj>
  197|       |struct scalar_inner_product_op {
  198|       |  using result_type = typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType;
  199|       |  using conj_helper = conditional_conj<LhsScalar, Conj>;
  200|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type coeff(const LhsScalar& a, const RhsScalar& b) const {
  201|       |    return (conj_helper::coeff(a) * b);
  202|       |  }
  203|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type coeff(const result_type& accum, const LhsScalar& a,
  204|       |                                                          const RhsScalar& b) const {
  205|       |    return (conj_helper::coeff(a) * b) + accum;
  206|       |  }
  207|       |  static constexpr bool PacketAccess = false;
  208|       |};
  209|       |
  210|       |template <typename Scalar, bool Conj>
  211|       |struct scalar_inner_product_op<Scalar, Scalar, Conj> {
  212|       |  using result_type = Scalar;
  213|       |  using conj_helper = conditional_conj<Scalar, Conj>;
  214|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(const Scalar& a, const Scalar& b) const {
  215|      1|    return pmul(conj_helper::coeff(a), b);
  216|      1|  }
  217|     32|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(const Scalar& accum, const Scalar& a, const Scalar& b) const {
  218|     32|    return pmadd(conj_helper::coeff(a), b, accum);
  219|     32|  }
  220|       |  template <typename Packet>
  221|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packet(const Packet& a, const Packet& b) const {
  222|       |    return pmul(conj_helper::packet(a), b);
  223|       |  }
  224|       |  template <typename Packet>
  225|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packet(const Packet& accum, const Packet& a, const Packet& b) const {
  226|       |    return pmadd(conj_helper::packet(a), b, accum);
  227|       |  }
  228|       |  static constexpr bool PacketAccess = packet_traits<Scalar>::HasMul && packet_traits<Scalar>::HasAdd;
  229|       |};
  230|       |
  231|       |template <typename Lhs, typename Rhs, bool Conj>
  232|       |struct default_inner_product_impl {
  233|       |  using LhsScalar = typename traits<Lhs>::Scalar;
  234|       |  using RhsScalar = typename traits<Rhs>::Scalar;
  235|       |  using Op = scalar_inner_product_op<LhsScalar, RhsScalar, Conj>;
  236|       |  using Evaluator = inner_product_evaluator<Op, Lhs, Rhs>;
  237|       |  using result_type = typename Evaluator::Scalar;
  238|      1|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type run(const MatrixBase<Lhs>& a, const MatrixBase<Rhs>& b) {
  239|      1|    Evaluator eval(a.derived(), b.derived(), Op());
  240|      1|    return inner_product_impl<Evaluator>::run(eval);
  241|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26default_inner_product_implINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEENS2_IKNS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEELb1EE3runERKNS_10MatrixBaseIS9_EERKNSE_ISC_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26default_inner_product_implINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS2_IKNS2_IS6_Lin1ELi1ELb1EEELin1ELi1ELb1EEELb1EE3runERKNS_10MatrixBaseIS7_EERKNSC_ISA_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26default_inner_product_implINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS2_IS6_Lin1ELi1ELb1EEELb1EE3runERKNS_10MatrixBaseIS9_EERKNSC_ISA_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26default_inner_product_implINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEENS2_IKNS2_IKS6_Lin1ELi1ELb1EEELin1ELi1ELb1EEELb1EE3runERKNS_10MatrixBaseIS9_EERKNSF_ISD_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal26default_inner_product_implINS_5BlockIKNS2_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEENS2_IKS6_Lin1ELi1ELb1EEELb1EE3runERKNS_10MatrixBaseISB_EERKNSF_ISD_EE
  ------------------
  | _ZN5Eigen8internal26default_inner_product_implINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EES9_Lb1EE3runERKNS_10MatrixBaseIS9_EESE_:
  |  238|      1|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type run(const MatrixBase<Lhs>& a, const MatrixBase<Rhs>& b) {
  |  239|      1|    Evaluator eval(a.derived(), b.derived(), Op());
  |  240|      1|    return inner_product_impl<Evaluator>::run(eval);
  |  241|      1|  }
  ------------------
  242|       |};
  243|       |
  244|       |template <typename Lhs, typename Rhs>
  245|       |struct dot_impl : default_inner_product_impl<Lhs, Rhs, true> {};
  246|       |
  247|       |}  // namespace internal
  248|       |}  // namespace Eigen
  249|       |
  250|       |#endif  // EIGEN_INNER_PRODUCT_EVAL_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Map.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2007-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_MAP_H
   12|       |#define EIGEN_MAP_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |template <typename PlainObjectType, int MapOptions, typename StrideType>
   21|       |struct traits<Map<PlainObjectType, MapOptions, StrideType> > : public traits<PlainObjectType> {
   22|       |  typedef traits<PlainObjectType> TraitsBase;
   23|       |  enum {
   24|       |    PlainObjectTypeInnerSize = ((traits<PlainObjectType>::Flags & RowMajorBit) == RowMajorBit)
   25|       |                                   ? PlainObjectType::ColsAtCompileTime
   26|       |                                   : PlainObjectType::RowsAtCompileTime,
   27|       |
   28|       |    InnerStrideAtCompileTime = StrideType::InnerStrideAtCompileTime == 0
   29|       |                                   ? int(PlainObjectType::InnerStrideAtCompileTime)
   30|       |                                   : int(StrideType::InnerStrideAtCompileTime),
   31|       |    OuterStrideAtCompileTime = StrideType::OuterStrideAtCompileTime == 0
   32|       |                                   ? (InnerStrideAtCompileTime == Dynamic || PlainObjectTypeInnerSize == Dynamic
   33|       |                                          ? Dynamic
   34|       |                                          : int(InnerStrideAtCompileTime) * int(PlainObjectTypeInnerSize))
   35|       |                                   : int(StrideType::OuterStrideAtCompileTime),
   36|       |    Alignment = int(MapOptions) & int(AlignedMask),
   37|       |    Flags0 = TraitsBase::Flags & (~NestByRefBit),
   38|       |    Flags = is_lvalue<PlainObjectType>::value ? int(Flags0) : (int(Flags0) & ~LvalueBit)
   39|       |  };
   40|       |
   41|       | private:
   42|       |  enum { Options };  // Expressions don't have Options
   43|       |};
   44|       |}  // namespace internal
   45|       |
   46|       |/** \class Map
   47|       | * \ingroup Core_Module
   48|       | *
   49|       | * \brief A matrix or vector expression mapping an existing array of data.
   50|       | *
   51|       | * \tparam PlainObjectType the equivalent matrix type of the mapped data
   52|       | * \tparam MapOptions specifies the pointer alignment in bytes. It can be: \c #Aligned128, \c #Aligned64, \c #Aligned32,
   53|       | * \c #Aligned16, \c #Aligned8 or \c #Unaligned. The default is \c #Unaligned. \tparam StrideType optionally specifies
   54|       | * strides. By default, Map assumes the memory layout of an ordinary, contiguous array. This can be overridden by
   55|       | * specifying strides. The type passed here must be a specialization of the Stride template, see examples below.
   56|       | *
   57|       | * This class represents a matrix or vector expression mapping an existing array of data.
   58|       | * It can be used to let Eigen interface without any overhead with non-Eigen data structures,
   59|       | * such as plain C arrays or structures from other libraries. By default, it assumes that the
   60|       | * data is laid out contiguously in memory. You can however override this by explicitly specifying
   61|       | * inner and outer strides.
   62|       | *
   63|       | * Here's an example of simply mapping a contiguous array as a \ref TopicStorageOrders "column-major" matrix:
   64|       | * \include Map_simple.cpp
   65|       | * Output: \verbinclude Map_simple.out
   66|       | *
   67|       | * If you need to map non-contiguous arrays, you can do so by specifying strides:
   68|       | *
   69|       | * Here's an example of mapping an array as a vector, specifying an inner stride, that is, the pointer
   70|       | * increment between two consecutive coefficients. Here, we're specifying the inner stride as a compile-time
   71|       | * fixed value.
   72|       | * \include Map_inner_stride.cpp
   73|       | * Output: \verbinclude Map_inner_stride.out
   74|       | *
   75|       | * Here's an example of mapping an array while specifying an outer stride. Here, since we're mapping
   76|       | * as a column-major matrix, 'outer stride' means the pointer increment between two consecutive columns.
   77|       | * Here, we're specifying the outer stride as a runtime parameter. Note that here \c OuterStride<> is
   78|       | * a short version of \c OuterStride<Dynamic> because the default template parameter of OuterStride
   79|       | * is  \c Dynamic
   80|       | * \include Map_outer_stride.cpp
   81|       | * Output: \verbinclude Map_outer_stride.out
   82|       | *
   83|       | * For more details and for an example of specifying both an inner and an outer stride, see class Stride.
   84|       | *
   85|       | * \b Tip: to change the array of data mapped by a Map object, you can use the C++
   86|       | * placement new syntax:
   87|       | *
   88|       | * Example: \include Map_placement_new.cpp
   89|       | * Output: \verbinclude Map_placement_new.out
   90|       | *
   91|       | * This class is the return type of PlainObjectBase::Map() but can also be used directly.
   92|       | *
   93|       | * \sa PlainObjectBase::Map(), \ref TopicStorageOrders
   94|       | */
   95|       |template <typename PlainObjectType, int MapOptions, typename StrideType>
   96|       |class Map : public MapBase<Map<PlainObjectType, MapOptions, StrideType> > {
   97|       | public:
   98|       |  typedef MapBase<Map> Base;
   99|       |  EIGEN_DENSE_PUBLIC_INTERFACE(Map)
  100|       |
  101|       |  typedef typename Base::PointerType PointerType;
  102|       |  typedef PointerType PointerArgType;
  103|      0|  EIGEN_DEVICE_FUNC inline PointerType cast_to_pointer_type(PointerArgType ptr) { return ptr; }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEE20cast_to_pointer_typeEPS2_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEE20cast_to_pointer_typeEPS2_
  ------------------
  104|       |
  105|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const {
  106|      0|    return StrideType::InnerStrideAtCompileTime != 0 ? m_stride.inner() : 1;
  107|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEE11innerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEE11innerStrideEv
  ------------------
  108|       |
  109|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const {
  110|      0|    return StrideType::OuterStrideAtCompileTime != 0 ? m_stride.outer()
  111|      0|           : internal::traits<Map>::OuterStrideAtCompileTime != Dynamic
  112|      0|               ? Index(internal::traits<Map>::OuterStrideAtCompileTime)
  113|      0|           : IsVectorAtCompileTime    ? (this->size() * innerStride())
  114|      0|           : int(Flags) & RowMajorBit ? (this->cols() * innerStride())
  115|      0|                                      : (this->rows() * innerStride());
  116|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEE11outerStrideEv
  ------------------
  117|       |
  118|       |  /** Constructor in the fixed-size case.
  119|       |   *
  120|       |   * \param dataPtr pointer to the array to map
  121|       |   * \param stride optional Stride object, passing the strides.
  122|       |   */
  123|       |  EIGEN_DEVICE_FUNC explicit inline Map(PointerArgType dataPtr, const StrideType& stride = StrideType())
  124|       |      : Base(cast_to_pointer_type(dataPtr)), m_stride(stride) {}
  125|       |
  126|       |  /** Constructor in the dynamic-size vector case.
  127|       |   *
  128|       |   * \param dataPtr pointer to the array to map
  129|       |   * \param size the size of the vector expression
  130|       |   * \param stride optional Stride object, passing the strides.
  131|       |   */
  132|       |  EIGEN_DEVICE_FUNC inline Map(PointerArgType dataPtr, Index size, const StrideType& stride = StrideType())
  133|      0|      : Base(cast_to_pointer_type(dataPtr), size), m_stride(stride) {}
  134|       |
  135|       |  /** Constructor in the dynamic-size matrix case.
  136|       |   *
  137|       |   * \param dataPtr pointer to the array to map
  138|       |   * \param rows the number of rows of the matrix expression
  139|       |   * \param cols the number of columns of the matrix expression
  140|       |   * \param stride optional Stride object, passing the strides.
  141|       |   */
  142|       |  EIGEN_DEVICE_FUNC inline Map(PointerArgType dataPtr, Index rows, Index cols, const StrideType& stride = StrideType())
  143|       |      : Base(cast_to_pointer_type(dataPtr), rows, cols), m_stride(stride) {}
  144|       |
  145|       |  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Map)
  146|       |
  147|       | protected:
  148|       |  StrideType m_stride;
  149|       |};
  150|       |
  151|       |}  // end namespace Eigen
  152|       |
  153|       |#endif  // EIGEN_MAP_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/MapBase.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2007-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_MAPBASE_H
   12|       |#define EIGEN_MAPBASE_H
   13|       |
   14|       |#define EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)                                                               \
   15|       |  EIGEN_STATIC_ASSERT((int(internal::evaluator<Derived>::Flags) & LinearAccessBit) || Derived::IsVectorAtCompileTime, \
   16|       |                      YOU_ARE_TRYING_TO_USE_AN_INDEX_BASED_ACCESSOR_ON_AN_EXPRESSION_THAT_DOES_NOT_SUPPORT_THAT)
   17|       |
   18|       |// IWYU pragma: private
   19|       |#include "./InternalHeaderCheck.h"
   20|       |
   21|       |namespace Eigen {
   22|       |
   23|       |/** \ingroup Core_Module
   24|       | *
   25|       | * \brief Base class for dense Map and Block expression with direct access
   26|       | *
   27|       | * This base class provides the const low-level accessors (e.g. coeff, coeffRef) of dense
   28|       | * Map and Block objects with direct access.
   29|       | * Typical users do not have to directly deal with this class.
   30|       | *
   31|       | * This class can be extended by through the macro plugin \c EIGEN_MAPBASE_PLUGIN.
   32|       | * See \link TopicCustomizing_Plugins customizing Eigen \endlink for details.
   33|       | *
   34|       | * The \c Derived class has to provide the following two methods describing the memory layout:
   35|       | *  \code Index innerStride() const; \endcode
   36|       | *  \code Index outerStride() const; \endcode
   37|       | *
   38|       | * \sa class Map, class Block
   39|       | */
   40|       |template <typename Derived>
   41|       |class MapBase<Derived, ReadOnlyAccessors> : public internal::dense_xpr_base<Derived>::type {
   42|       | public:
   43|       |  typedef typename internal::dense_xpr_base<Derived>::type Base;
   44|       |  enum {
   45|       |    RowsAtCompileTime = internal::traits<Derived>::RowsAtCompileTime,
   46|       |    ColsAtCompileTime = internal::traits<Derived>::ColsAtCompileTime,
   47|       |    InnerStrideAtCompileTime = internal::traits<Derived>::InnerStrideAtCompileTime,
   48|       |    SizeAtCompileTime = Base::SizeAtCompileTime
   49|       |  };
   50|       |
   51|       |  typedef typename internal::traits<Derived>::StorageKind StorageKind;
   52|       |  typedef typename internal::traits<Derived>::Scalar Scalar;
   53|       |  typedef typename internal::packet_traits<Scalar>::type PacketScalar;
   54|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
   55|       |  typedef std::conditional_t<bool(internal::is_lvalue<Derived>::value), Scalar*, const Scalar*> PointerType;
   56|       |
   57|       |  using Base::derived;
   58|       |  //    using Base::RowsAtCompileTime;
   59|       |  //    using Base::ColsAtCompileTime;
   60|       |  //    using Base::SizeAtCompileTime;
   61|       |  using Base::Flags;
   62|       |  using Base::IsRowMajor;
   63|       |  using Base::IsVectorAtCompileTime;
   64|       |  using Base::MaxColsAtCompileTime;
   65|       |  using Base::MaxRowsAtCompileTime;
   66|       |  using Base::MaxSizeAtCompileTime;
   67|       |
   68|       |  using Base::coeff;
   69|       |  using Base::coeffRef;
   70|       |  using Base::cols;
   71|       |  using Base::eval;
   72|       |  using Base::lazyAssign;
   73|       |  using Base::rows;
   74|       |  using Base::size;
   75|       |
   76|       |  using Base::colStride;
   77|       |  using Base::innerStride;
   78|       |  using Base::outerStride;
   79|       |  using Base::rowStride;
   80|       |
   81|       |  // bug 217 - compile error on ICC 11.1
   82|       |  using Base::operator=;
   83|       |
   84|       |  typedef typename Base::CoeffReturnType CoeffReturnType;
   85|       |
   86|       |  /** \copydoc DenseBase::rows() */
   87|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return m_rows.value(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi0EE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi0EE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEELi0EE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEELi0EE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEELi0EE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi0EE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEELi0EE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi0EE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEELi0EE4rowsEv
  ------------------
   88|       |  /** \copydoc DenseBase::cols() */
   89|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return m_cols.value(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi0EE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi0EE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEELi0EE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEELi0EE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEELi0EE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi0EE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEELi0EE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi0EE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEELi0EE4colsEv
  ------------------
   90|       |
   91|       |  /** Returns a pointer to the first coefficient of the matrix or vector.
   92|       |   *
   93|       |   * \note When addressing this data, make sure to honor the strides returned by innerStride() and outerStride().
   94|       |   *
   95|       |   * \sa innerStride(), outerStride()
   96|       |   */
   97|      0|  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const { return m_data; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi0EE4dataEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi0EE4dataEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEELi0EE4dataEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEELi0EE4dataEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEELi0EE4dataEv
  ------------------
   98|       |
   99|       |  /** \copydoc PlainObjectBase::coeff(Index,Index) const */
  100|       |  EIGEN_DEVICE_FUNC inline const Scalar& coeff(Index rowId, Index colId) const {
  101|       |    return m_data[colId * colStride() + rowId * rowStride()];
  102|       |  }
  103|       |
  104|       |  /** \copydoc PlainObjectBase::coeff(Index) const */
  105|       |  EIGEN_DEVICE_FUNC inline const Scalar& coeff(Index index) const {
  106|       |    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)
  107|       |    return m_data[index * innerStride()];
  108|       |  }
  109|       |
  110|       |  /** \copydoc PlainObjectBase::coeffRef(Index,Index) const */
  111|       |  EIGEN_DEVICE_FUNC inline const Scalar& coeffRef(Index rowId, Index colId) const {
  112|       |    return this->m_data[colId * colStride() + rowId * rowStride()];
  113|       |  }
  114|       |
  115|       |  /** \copydoc PlainObjectBase::coeffRef(Index) const */
  116|       |  EIGEN_DEVICE_FUNC inline const Scalar& coeffRef(Index index) const {
  117|       |    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)
  118|       |    return this->m_data[index * innerStride()];
  119|       |  }
  120|       |
  121|       |  /** \internal */
  122|       |  template <int LoadMode>
  123|       |  inline PacketScalar packet(Index rowId, Index colId) const {
  124|       |    return internal::ploadt<PacketScalar, LoadMode>(m_data + (colId * colStride() + rowId * rowStride()));
  125|       |  }
  126|       |
  127|       |  /** \internal */
  128|       |  template <int LoadMode>
  129|       |  inline PacketScalar packet(Index index) const {
  130|       |    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)
  131|       |    return internal::ploadt<PacketScalar, LoadMode>(m_data + index * innerStride());
  132|       |  }
  133|       |
  134|       |  /** \internal Constructor for fixed size matrices or vectors */
  135|       |  EIGEN_DEVICE_FUNC explicit inline MapBase(PointerType dataPtr)
  136|       |      : m_data(dataPtr), m_rows(RowsAtCompileTime), m_cols(ColsAtCompileTime) {
  137|       |    EIGEN_STATIC_ASSERT_FIXED_SIZE(Derived)
  138|       |    checkSanity<Derived>();
  139|       |  }
  140|       |
  141|       |  /** \internal Constructor for dynamically sized vectors */
  142|       |  EIGEN_DEVICE_FUNC inline MapBase(PointerType dataPtr, Index vecSize)
  143|       |      : m_data(dataPtr),
  144|       |        m_rows(RowsAtCompileTime == Dynamic ? vecSize : Index(RowsAtCompileTime)),
  145|      0|        m_cols(ColsAtCompileTime == Dynamic ? vecSize : Index(ColsAtCompileTime)) {
  146|      0|    EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
  147|      0|    eigen_assert(vecSize >= 0);
  148|      0|    eigen_assert(dataPtr == 0 || SizeAtCompileTime == Dynamic || SizeAtCompileTime == vecSize);
  149|      0|    checkSanity<Derived>();
  150|      0|  }
  151|       |
  152|       |  /** \internal Constructor for dynamically sized matrices */
  153|       |  EIGEN_DEVICE_FUNC inline MapBase(PointerType dataPtr, Index rows, Index cols)
  154|      0|      : m_data(dataPtr), m_rows(rows), m_cols(cols) {
  155|      0|    eigen_assert((dataPtr == 0) || (rows >= 0 && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows) &&
  156|      0|                                    cols >= 0 && (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols)));
  157|      0|    checkSanity<Derived>();
  158|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi0EEC2EPKS3_ll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi0EEC2EPKS3_ll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi0EEC2EPS3_ll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEELi0EEC2EPKS3_ll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi0EEC2EPS3_ll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEELi0EEC2EPKS3_ll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_9TransposeINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1EEELi0EEC2EPS4_ll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEELi0EEC2EPKS3_ll
  ------------------
  159|       |
  160|       |#ifdef EIGEN_MAPBASE_PLUGIN
  161|       |#include EIGEN_MAPBASE_PLUGIN
  162|       |#endif
  163|       |
  164|       | protected:
  165|       |  EIGEN_DEFAULT_COPY_CONSTRUCTOR(MapBase)
  166|       |  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(MapBase)
  167|       |
  168|       |  template <typename T>
  169|      0|  EIGEN_DEVICE_FUNC void checkSanity(std::enable_if_t<(internal::traits<T>::Alignment > 0), void*> = 0) const {
  170|      0|// Temporary macro to allow scalars to not be properly aligned.  This is while we sort out failures
  171|      0|// in TensorFlow Lite that are currently relying on this UB.
  172|      0|#ifndef EIGEN_ALLOW_UNALIGNED_SCALARS
  173|      0|    // Pointer must be aligned to the Scalar type, otherwise we get UB.
  174|      0|    eigen_assert((std::uintptr_t(m_data) % alignof(Scalar) == 0) && "data is not scalar-aligned");
  175|      0|#endif
  176|      0|#if EIGEN_MAX_ALIGN_BYTES > 0
  177|      0|    // innerStride() is not set yet when this function is called, so we optimistically assume the lowest plausible
  178|      0|    // value:
  179|      0|    const Index minInnerStride = InnerStrideAtCompileTime == Dynamic ? 1 : Index(InnerStrideAtCompileTime);
  180|      0|    EIGEN_ONLY_USED_FOR_DEBUG(minInnerStride);
  181|      0|    eigen_assert((((std::uintptr_t(m_data) % internal::traits<Derived>::Alignment) == 0) ||
  182|      0|                  (cols() * rows() * minInnerStride * sizeof(Scalar)) < internal::traits<Derived>::Alignment) &&
  183|      0|                 "data is not aligned");
  184|      0|#endif
  185|      0|  }
  186|       |
  187|       |  template <typename T>
  188|      0|  EIGEN_DEVICE_FUNC void checkSanity(std::enable_if_t<internal::traits<T>::Alignment == 0, void*> = 0) const {
  189|      0|#ifndef EIGEN_ALLOW_UNALIGNED_SCALARS
  190|       |    // Pointer must be aligned to the Scalar type, otherwise we get UB.
  191|      0|    eigen_assert((std::uintptr_t(m_data) % alignof(Scalar) == 0) && "data is not scalar-aligned");
  192|      0|#endif
  193|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi0EE11checkSanityIS6_EEvNSt9enable_ifIXeqsr8internal6traitsIT_EE9AlignmentLi0EEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi0EE11checkSanityIS6_EEvNSt9enable_ifIXeqsr8internal6traitsIT_EE9AlignmentLi0EEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi0EE11checkSanityIS5_EEvNSt9enable_ifIXeqsr8internal6traitsIT_EE9AlignmentLi0EEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEELi0EE11checkSanityIS8_EEvNSt9enable_ifIXeqsr8internal6traitsIT_EE9AlignmentLi0EEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi0EE11checkSanityIS5_EEvNSt9enable_ifIXeqsr8internal6traitsIT_EE9AlignmentLi0EEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEELi0EE11checkSanityIS8_EEvNSt9enable_ifIXeqsr8internal6traitsIT_EE9AlignmentLi0EEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEELi0EE11checkSanityIS7_EEvNSt9enable_ifIXeqsr8internal6traitsIT_EE9AlignmentLi0EEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockINS_9TransposeINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1EEELi0EE11checkSanityIS8_EEvNSt9enable_ifIXeqsr8internal6traitsIT_EE9AlignmentLi0EEPvE4typeE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEELi0EE11checkSanityIS6_EEvNSt9enable_ifIXeqsr8internal6traitsIT_EE9AlignmentLi0EEPvE4typeE
  ------------------
  194|       |
  195|       |  PointerType m_data;
  196|       |  const internal::variable_if_dynamic<Index, RowsAtCompileTime> m_rows;
  197|       |  const internal::variable_if_dynamic<Index, ColsAtCompileTime> m_cols;
  198|       |};
  199|       |
  200|       |/** \ingroup Core_Module
  201|       | *
  202|       | * \brief Base class for non-const dense Map and Block expression with direct access
  203|       | *
  204|       | * This base class provides the non-const low-level accessors (e.g. coeff and coeffRef) of
  205|       | * dense Map and Block objects with direct access.
  206|       | * It inherits MapBase<Derived, ReadOnlyAccessors> which defines the const variant for reading specific entries.
  207|       | *
  208|       | * \sa class Map, class Block
  209|       | */
  210|       |template <typename Derived>
  211|       |class MapBase<Derived, WriteAccessors> : public MapBase<Derived, ReadOnlyAccessors> {
  212|       |  typedef MapBase<Derived, ReadOnlyAccessors> ReadOnlyMapBase;
  213|       |
  214|       | public:
  215|       |  typedef MapBase<Derived, ReadOnlyAccessors> Base;
  216|       |
  217|       |  typedef typename Base::Scalar Scalar;
  218|       |  typedef typename Base::PacketScalar PacketScalar;
  219|       |  typedef typename Base::StorageIndex StorageIndex;
  220|       |  typedef typename Base::PointerType PointerType;
  221|       |
  222|       |  using Base::coeff;
  223|       |  using Base::coeffRef;
  224|       |  using Base::cols;
  225|       |  using Base::derived;
  226|       |  using Base::rows;
  227|       |  using Base::size;
  228|       |
  229|       |  using Base::colStride;
  230|       |  using Base::innerStride;
  231|       |  using Base::outerStride;
  232|       |  using Base::rowStride;
  233|       |
  234|       |  typedef std::conditional_t<internal::is_lvalue<Derived>::value, Scalar, const Scalar> ScalarWithConstIfNotLvalue;
  235|       |
  236|      0|  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const { return this->m_data; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEELi1EE4dataEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEELi1EE4dataEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi1EE4dataEv
  ------------------
  237|      0|  EIGEN_DEVICE_FUNC constexpr ScalarWithConstIfNotLvalue* data() {
  238|      0|    return this->m_data;
  239|      0|  }  // no const-cast here so non-const-correct code will give a compile error
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi1EE4dataEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1EE4dataEv
  ------------------
  240|       |
  241|      0|  EIGEN_DEVICE_FUNC inline ScalarWithConstIfNotLvalue& coeffRef(Index row, Index col) {
  242|      0|    return this->m_data[col * colStride() + row * rowStride()];
  243|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi1EE8coeffRefEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1EE8coeffRefEll
  ------------------
  244|       |
  245|       |  EIGEN_DEVICE_FUNC inline ScalarWithConstIfNotLvalue& coeffRef(Index index) {
  246|       |    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)
  247|       |    return this->m_data[index * innerStride()];
  248|       |  }
  249|       |
  250|       |  template <int StoreMode>
  251|       |  inline void writePacket(Index row, Index col, const PacketScalar& val) {
  252|       |    internal::pstoret<Scalar, PacketScalar, StoreMode>(this->m_data + (col * colStride() + row * rowStride()), val);
  253|       |  }
  254|       |
  255|       |  template <int StoreMode>
  256|       |  inline void writePacket(Index index, const PacketScalar& val) {
  257|       |    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)
  258|       |    internal::pstoret<Scalar, PacketScalar, StoreMode>(this->m_data + index * innerStride(), val);
  259|       |  }
  260|       |
  261|       |  EIGEN_DEVICE_FUNC explicit inline MapBase(PointerType dataPtr) : Base(dataPtr) {}
  262|      0|  EIGEN_DEVICE_FUNC inline MapBase(PointerType dataPtr, Index vecSize) : Base(dataPtr, vecSize) {}
  263|      0|  EIGEN_DEVICE_FUNC inline MapBase(PointerType dataPtr, Index rows, Index cols) : Base(dataPtr, rows, cols) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELi1EEC2EPS3_ll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1EEC2EPS3_ll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7MapBaseINS_5BlockINS_9TransposeINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1EEELi1EEC2EPS4_ll
  ------------------
  264|       |
  265|       |  EIGEN_DEVICE_FUNC Derived& operator=(const MapBase& other) {
  266|       |    ReadOnlyMapBase::Base::operator=(other);
  267|       |    return derived();
  268|       |  }
  269|       |
  270|       |  // In theory we could simply refer to Base:Base::operator=, but MSVC does not like Base::Base,
  271|       |  // see bugs 821 and 920.
  272|       |  using ReadOnlyMapBase::Base::operator=;
  273|       |
  274|       | protected:
  275|       |  EIGEN_DEFAULT_COPY_CONSTRUCTOR(MapBase)
  276|       |  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(MapBase)
  277|       |};
  278|       |
  279|       |#undef EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS
  280|       |
  281|       |}  // end namespace Eigen
  282|       |
  283|       |#endif  // EIGEN_MAPBASE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/MathFunctions.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_MATHFUNCTIONS_H
   12|       |#define EIGEN_MATHFUNCTIONS_H
   13|       |
   14|       |// TODO this should better be moved to NumTraits
   15|       |// Source: WolframAlpha
   16|       |#define EIGEN_PI 3.141592653589793238462643383279502884197169399375105820974944592307816406L
   17|       |#define EIGEN_LOG2E 1.442695040888963407359924681001892137426645954152985934135449406931109219L
   18|       |#define EIGEN_LN2 0.693147180559945309417232121458176568075500134360255254120680009493393621L
   19|       |
   20|       |// IWYU pragma: private
   21|       |#include "./InternalHeaderCheck.h"
   22|       |
   23|       |namespace Eigen {
   24|       |
   25|       |namespace internal {
   26|       |
   27|       |/** \internal \class global_math_functions_filtering_base
   28|       | *
   29|       | * What it does:
   30|       | * Defines a typedef 'type' as follows:
   31|       | * - if type T has a member typedef Eigen_BaseClassForSpecializationOfGlobalMathFuncImpl, then
   32|       | *   global_math_functions_filtering_base<T>::type is a typedef for it.
   33|       | * - otherwise, global_math_functions_filtering_base<T>::type is a typedef for T.
   34|       | *
   35|       | * How it's used:
   36|       | * To allow to defined the global math functions (like sin...) in certain cases, like the Array expressions.
   37|       | * When you do sin(array1+array2), the object array1+array2 has a complicated expression type, all what you want to know
   38|       | * is that it inherits ArrayBase. So we implement a partial specialization of sin_impl for ArrayBase<Derived>.
   39|       | * So we must make sure to use sin_impl<ArrayBase<Derived> > and not sin_impl<Derived>, otherwise our partial
   40|       | * specialization won't be used. How does sin know that? That's exactly what global_math_functions_filtering_base tells
   41|       | * it.
   42|       | *
   43|       | * How it's implemented:
   44|       | * SFINAE in the style of enable_if. Highly susceptible of breaking compilers. With GCC, it sure does work, but if you
   45|       | * replace the typename dummy by an integer template parameter, it doesn't work anymore!
   46|       | */
   47|       |
   48|       |template <typename T, typename dummy = void>
   49|       |struct global_math_functions_filtering_base {
   50|       |  typedef T type;
   51|       |};
   52|       |
   53|       |template <typename T>
   54|       |struct always_void {
   55|       |  typedef void type;
   56|       |};
   57|       |
   58|       |template <typename T>
   59|       |struct global_math_functions_filtering_base<
   60|       |    T, typename always_void<typename T::Eigen_BaseClassForSpecializationOfGlobalMathFuncImpl>::type> {
   61|       |  typedef typename T::Eigen_BaseClassForSpecializationOfGlobalMathFuncImpl type;
   62|       |};
   63|       |
   64|       |#define EIGEN_MATHFUNC_IMPL(func, scalar) \
   65|  43.5k|  Eigen::internal::func##_impl<typename Eigen::internal::global_math_functions_filtering_base<scalar>::type>
   66|       |#define EIGEN_MATHFUNC_RETVAL(func, scalar) \
   67|       |  typename Eigen::internal::func##_retval<  \
   68|       |      typename Eigen::internal::global_math_functions_filtering_base<scalar>::type>::type
   69|       |
   70|       |/****************************************************************************
   71|       | * Implementation of real                                                 *
   72|       | ****************************************************************************/
   73|       |
   74|       |template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
   75|       |struct real_default_impl {
   76|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
   77|      0|  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) { return x; }
   78|       |};
   79|       |
   80|       |template <typename Scalar>
   81|       |struct real_default_impl<Scalar, true> {
   82|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
   83|       |  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) {
   84|       |    using std::real;
   85|       |    return real(x);
   86|       |  }
   87|       |};
   88|       |
   89|       |template <typename Scalar>
   90|       |struct real_impl : real_default_impl<Scalar> {};
   91|       |
   92|       |#if defined(EIGEN_GPU_COMPILE_PHASE)
   93|       |template <typename T>
   94|       |struct real_impl<std::complex<T>> {
   95|       |  typedef T RealScalar;
   96|       |  EIGEN_DEVICE_FUNC static inline T run(const std::complex<T>& x) { return x.real(); }
   97|       |};
   98|       |#endif
   99|       |
  100|       |template <typename Scalar>
  101|       |struct real_retval {
  102|       |  typedef typename NumTraits<Scalar>::Real type;
  103|       |};
  104|       |
  105|       |/****************************************************************************
  106|       | * Implementation of imag                                                 *
  107|       | ****************************************************************************/
  108|       |
  109|       |template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
  110|       |struct imag_default_impl {
  111|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  112|      0|  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar&) { return RealScalar(0); }
  113|       |};
  114|       |
  115|       |template <typename Scalar>
  116|       |struct imag_default_impl<Scalar, true> {
  117|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  118|       |  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) {
  119|       |    using std::imag;
  120|       |    return imag(x);
  121|       |  }
  122|       |};
  123|       |
  124|       |template <typename Scalar>
  125|       |struct imag_impl : imag_default_impl<Scalar> {};
  126|       |
  127|       |#if defined(EIGEN_GPU_COMPILE_PHASE)
  128|       |template <typename T>
  129|       |struct imag_impl<std::complex<T>> {
  130|       |  typedef T RealScalar;
  131|       |  EIGEN_DEVICE_FUNC static inline T run(const std::complex<T>& x) { return x.imag(); }
  132|       |};
  133|       |#endif
  134|       |
  135|       |template <typename Scalar>
  136|       |struct imag_retval {
  137|       |  typedef typename NumTraits<Scalar>::Real type;
  138|       |};
  139|       |
  140|       |/****************************************************************************
  141|       | * Implementation of real_ref                                             *
  142|       | ****************************************************************************/
  143|       |
  144|       |template <typename Scalar>
  145|       |struct real_ref_impl {
  146|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  147|      0|  EIGEN_DEVICE_FUNC static inline RealScalar& run(Scalar& x) { return reinterpret_cast<RealScalar*>(&x)[0]; }
  148|      0|  EIGEN_DEVICE_FUNC static inline const RealScalar& run(const Scalar& x) {
  149|      0|    return reinterpret_cast<const RealScalar*>(&x)[0];
  150|      0|  }
  151|       |};
  152|       |
  153|       |template <typename Scalar>
  154|       |struct real_ref_retval {
  155|       |  typedef typename NumTraits<Scalar>::Real& type;
  156|       |};
  157|       |
  158|       |/****************************************************************************
  159|       | * Implementation of imag_ref                                             *
  160|       | ****************************************************************************/
  161|       |
  162|       |template <typename Scalar, bool IsComplex>
  163|       |struct imag_ref_default_impl {
  164|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  165|       |  EIGEN_DEVICE_FUNC static inline RealScalar& run(Scalar& x) { return reinterpret_cast<RealScalar*>(&x)[1]; }
  166|       |  EIGEN_DEVICE_FUNC static inline const RealScalar& run(const Scalar& x) {
  167|       |    return reinterpret_cast<const RealScalar*>(&x)[1];
  168|       |  }
  169|       |};
  170|       |
  171|       |template <typename Scalar>
  172|       |struct imag_ref_default_impl<Scalar, false> {
  173|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline Scalar run(Scalar&) { return Scalar(0); }
  174|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline const Scalar run(const Scalar&) { return Scalar(0); }
  175|       |};
  176|       |
  177|       |template <typename Scalar>
  178|       |struct imag_ref_impl : imag_ref_default_impl<Scalar, NumTraits<Scalar>::IsComplex> {};
  179|       |
  180|       |template <typename Scalar>
  181|       |struct imag_ref_retval {
  182|       |  typedef typename NumTraits<Scalar>::Real& type;
  183|       |};
  184|       |
  185|       |/****************************************************************************
  186|       | * Implementation of conj                                                 *
  187|       | ****************************************************************************/
  188|       |
  189|       |template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
  190|       |struct conj_default_impl {
  191|     33|  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x) { return x; }
  192|       |};
  193|       |
  194|       |template <typename Scalar>
  195|       |struct conj_default_impl<Scalar, true> {
  196|       |  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x) {
  197|       |    using std::conj;
  198|       |    return conj(x);
  199|       |  }
  200|       |};
  201|       |
  202|       |template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
  203|       |struct conj_impl : conj_default_impl<Scalar, IsComplex> {};
  204|       |
  205|       |template <typename Scalar>
  206|       |struct conj_retval {
  207|       |  typedef Scalar type;
  208|       |};
  209|       |
  210|       |/****************************************************************************
  211|       | * Implementation of abs2                                                 *
  212|       | ****************************************************************************/
  213|       |
  214|       |template <typename Scalar, bool IsComplex>
  215|       |struct abs2_impl_default {
  216|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  217|      0|  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) { return x * x; }
  218|       |};
  219|       |
  220|       |template <typename Scalar>
  221|       |struct abs2_impl_default<Scalar, true>  // IsComplex
  222|       |{
  223|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  224|      0|  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) { return x.real() * x.real() + x.imag() * x.imag(); }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17abs2_impl_defaultISt7complexIfELb1EE3runERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17abs2_impl_defaultISt7complexIdELb1EE3runERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17abs2_impl_defaultISt7complexIeELb1EE3runERKS3_
  ------------------
  225|       |};
  226|       |
  227|       |template <typename Scalar>
  228|       |struct abs2_impl {
  229|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  230|      0|  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) {
  231|      0|    return abs2_impl_default<Scalar, NumTraits<Scalar>::IsComplex>::run(x);
  232|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9abs2_implIfE3runERKf
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9abs2_implISt7complexIfEE3runERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9abs2_implISt7complexIdEE3runERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9abs2_implISt7complexIeEE3runERKS3_
  ------------------
  233|       |};
  234|       |
  235|       |template <typename Scalar>
  236|       |struct abs2_retval {
  237|       |  typedef typename NumTraits<Scalar>::Real type;
  238|       |};
  239|       |
  240|       |/****************************************************************************
  241|       | * Implementation of sqrt/rsqrt                                             *
  242|       | ****************************************************************************/
  243|       |
  244|       |template <typename Scalar>
  245|       |struct sqrt_impl {
  246|       |  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE Scalar run(const Scalar& x) {
  247|       |    EIGEN_USING_STD(sqrt);
  248|       |    return sqrt(x);
  249|       |  }
  250|       |};
  251|       |
  252|       |// Complex sqrt defined in MathFunctionsImpl.h.
  253|       |template <typename T>
  254|       |EIGEN_DEVICE_FUNC std::complex<T> complex_sqrt(const std::complex<T>& a_x);
  255|       |
  256|       |// Custom implementation is faster than `std::sqrt`, works on
  257|       |// GPU, and correctly handles special cases (unlike MSVC).
  258|       |template <typename T>
  259|       |struct sqrt_impl<std::complex<T>> {
  260|       |  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE std::complex<T> run(const std::complex<T>& x) {
  261|       |    return complex_sqrt<T>(x);
  262|       |  }
  263|       |};
  264|       |
  265|       |template <typename Scalar>
  266|       |struct sqrt_retval {
  267|       |  typedef Scalar type;
  268|       |};
  269|       |
  270|       |// Default implementation relies on numext::sqrt, at bottom of file.
  271|       |template <typename T>
  272|       |struct rsqrt_impl;
  273|       |
  274|       |// Complex rsqrt defined in MathFunctionsImpl.h.
  275|       |template <typename T>
  276|       |EIGEN_DEVICE_FUNC std::complex<T> complex_rsqrt(const std::complex<T>& a_x);
  277|       |
  278|       |template <typename T>
  279|       |struct rsqrt_impl<std::complex<T>> {
  280|       |  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE std::complex<T> run(const std::complex<T>& x) {
  281|       |    return complex_rsqrt<T>(x);
  282|       |  }
  283|       |};
  284|       |
  285|       |template <typename Scalar>
  286|       |struct rsqrt_retval {
  287|       |  typedef Scalar type;
  288|       |};
  289|       |
  290|       |/****************************************************************************
  291|       | * Implementation of norm1                                                *
  292|       | ****************************************************************************/
  293|       |
  294|       |template <typename Scalar, bool IsComplex>
  295|       |struct norm1_default_impl;
  296|       |
  297|       |template <typename Scalar>
  298|       |struct norm1_default_impl<Scalar, true> {
  299|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  300|       |  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) {
  301|       |    EIGEN_USING_STD(abs);
  302|       |    return abs(x.real()) + abs(x.imag());
  303|       |  }
  304|       |};
  305|       |
  306|       |template <typename Scalar>
  307|       |struct norm1_default_impl<Scalar, false> {
  308|       |  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x) {
  309|       |    EIGEN_USING_STD(abs);
  310|       |    return abs(x);
  311|       |  }
  312|       |};
  313|       |
  314|       |template <typename Scalar>
  315|       |struct norm1_impl : norm1_default_impl<Scalar, NumTraits<Scalar>::IsComplex> {};
  316|       |
  317|       |template <typename Scalar>
  318|       |struct norm1_retval {
  319|       |  typedef typename NumTraits<Scalar>::Real type;
  320|       |};
  321|       |
  322|       |/****************************************************************************
  323|       | * Implementation of hypot                                                *
  324|       | ****************************************************************************/
  325|       |
  326|       |template <typename Scalar>
  327|       |struct hypot_impl;
  328|       |
  329|       |template <typename Scalar>
  330|       |struct hypot_retval {
  331|       |  typedef typename NumTraits<Scalar>::Real type;
  332|       |};
  333|       |
  334|       |/****************************************************************************
  335|       | * Implementation of cast                                                 *
  336|       | ****************************************************************************/
  337|       |
  338|       |template <typename OldType, typename NewType, typename EnableIf = void>
  339|       |struct cast_impl {
  340|       |  EIGEN_DEVICE_FUNC static inline NewType run(const OldType& x) { return static_cast<NewType>(x); }
  341|       |};
  342|       |
  343|       |template <typename OldType>
  344|       |struct cast_impl<OldType, bool> {
  345|       |  EIGEN_DEVICE_FUNC static inline bool run(const OldType& x) { return x != OldType(0); }
  346|       |};
  347|       |
  348|       |// Casting from S -> Complex<T> leads to an implicit conversion from S to T,
  349|       |// generating warnings on clang.  Here we explicitly cast the real component.
  350|       |template <typename OldType, typename NewType>
  351|       |struct cast_impl<OldType, NewType,
  352|       |                 typename std::enable_if_t<!NumTraits<OldType>::IsComplex && NumTraits<NewType>::IsComplex>> {
  353|       |  EIGEN_DEVICE_FUNC static inline NewType run(const OldType& x) {
  354|       |    typedef typename NumTraits<NewType>::Real NewReal;
  355|       |    return static_cast<NewType>(static_cast<NewReal>(x));
  356|       |  }
  357|       |};
  358|       |
  359|       |// here, for once, we're plainly returning NewType: we don't want cast to do weird things.
  360|       |
  361|       |template <typename OldType, typename NewType>
  362|       |EIGEN_DEVICE_FUNC inline NewType cast(const OldType& x) {
  363|       |  return cast_impl<OldType, NewType>::run(x);
  364|       |}
  365|       |
  366|       |/****************************************************************************
  367|       | * Implementation of arg                                                     *
  368|       | ****************************************************************************/
  369|       |
  370|       |// Visual Studio 2017 has a bug where arg(float) returns 0 for negative inputs.
  371|       |// This seems to be fixed in VS 2019.
  372|       |#if (!EIGEN_COMP_MSVC || EIGEN_COMP_MSVC >= 1920)
  373|       |// std::arg is only defined for types of std::complex, or integer types or float/double/long double
  374|       |template <typename Scalar, bool HasStdImpl = NumTraits<Scalar>::IsComplex || is_integral<Scalar>::value ||
  375|       |                                             is_same<Scalar, float>::value || is_same<Scalar, double>::value ||
  376|       |                                             is_same<Scalar, long double>::value>
  377|       |struct arg_default_impl;
  378|       |
  379|       |template <typename Scalar>
  380|       |struct arg_default_impl<Scalar, true> {
  381|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  382|       |  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) {
  383|       |    // There is no official ::arg on device in CUDA/HIP, so we always need to use std::arg.
  384|       |    using std::arg;
  385|       |    return static_cast<RealScalar>(arg(x));
  386|       |  }
  387|       |};
  388|       |
  389|       |// Must be non-complex floating-point type (e.g. half/bfloat16).
  390|       |template <typename Scalar>
  391|       |struct arg_default_impl<Scalar, false> {
  392|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  393|       |  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) {
  394|       |    return (x < Scalar(0)) ? RealScalar(EIGEN_PI) : RealScalar(0);
  395|       |  }
  396|       |};
  397|       |#else
  398|       |template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
  399|       |struct arg_default_impl {
  400|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  401|       |  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) {
  402|       |    return (x < RealScalar(0)) ? RealScalar(EIGEN_PI) : RealScalar(0);
  403|       |  }
  404|       |};
  405|       |
  406|       |template <typename Scalar>
  407|       |struct arg_default_impl<Scalar, true> {
  408|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  409|       |  EIGEN_DEVICE_FUNC static inline RealScalar run(const Scalar& x) {
  410|       |    EIGEN_USING_STD(arg);
  411|       |    return arg(x);
  412|       |  }
  413|       |};
  414|       |#endif
  415|       |template <typename Scalar>
  416|       |struct arg_impl : arg_default_impl<Scalar> {};
  417|       |
  418|       |template <typename Scalar>
  419|       |struct arg_retval {
  420|       |  typedef typename NumTraits<Scalar>::Real type;
  421|       |};
  422|       |
  423|       |/****************************************************************************
  424|       | * Implementation of expm1                                                   *
  425|       | ****************************************************************************/
  426|       |
  427|       |// This implementation is based on GSL Math's expm1.
  428|       |namespace std_fallback {
  429|       |// fallback expm1 implementation in case there is no expm1(Scalar) function in namespace of Scalar,
  430|       |// or that there is no suitable std::expm1 function available. Implementation
  431|       |// attributed to Kahan. See: http://www.plunk.org/~hatch/rightway.php.
  432|       |template <typename Scalar>
  433|       |EIGEN_DEVICE_FUNC inline Scalar expm1(const Scalar& x) {
  434|       |  EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
  435|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  436|       |
  437|       |  EIGEN_USING_STD(exp);
  438|       |  Scalar u = exp(x);
  439|       |  if (numext::equal_strict(u, Scalar(1))) {
  440|       |    return x;
  441|       |  }
  442|       |  Scalar um1 = u - RealScalar(1);
  443|       |  if (numext::equal_strict(um1, Scalar(-1))) {
  444|       |    return RealScalar(-1);
  445|       |  }
  446|       |
  447|       |  EIGEN_USING_STD(log);
  448|       |  Scalar logu = log(u);
  449|       |  return numext::equal_strict(u, logu) ? u : (u - RealScalar(1)) * x / logu;
  450|       |}
  451|       |}  // namespace std_fallback
  452|       |
  453|       |template <typename Scalar>
  454|       |struct expm1_impl {
  455|      0|  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x) {
  456|      0|    EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
  457|      0|    EIGEN_USING_STD(expm1);
  458|      0|    return expm1(x);
  459|      0|  }
  460|       |};
  461|       |
  462|       |template <typename Scalar>
  463|       |struct expm1_retval {
  464|       |  typedef Scalar type;
  465|       |};
  466|       |
  467|       |/****************************************************************************
  468|       | * Implementation of log                                                     *
  469|       | ****************************************************************************/
  470|       |
  471|       |// Complex log defined in MathFunctionsImpl.h.
  472|       |template <typename T>
  473|       |EIGEN_DEVICE_FUNC std::complex<T> complex_log(const std::complex<T>& z);
  474|       |
  475|       |template <typename Scalar>
  476|       |struct log_impl {
  477|       |  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x) {
  478|       |    EIGEN_USING_STD(log);
  479|       |    return static_cast<Scalar>(log(x));
  480|       |  }
  481|       |};
  482|       |
  483|       |template <typename Scalar>
  484|       |struct log_impl<std::complex<Scalar>> {
  485|       |  EIGEN_DEVICE_FUNC static inline std::complex<Scalar> run(const std::complex<Scalar>& z) { return complex_log(z); }
  486|       |};
  487|       |
  488|       |/****************************************************************************
  489|       | * Implementation of log1p                                                   *
  490|       | ****************************************************************************/
  491|       |
  492|       |namespace std_fallback {
  493|       |// fallback log1p implementation in case there is no log1p(Scalar) function in namespace of Scalar,
  494|       |// or that there is no suitable std::log1p function available
  495|       |template <typename Scalar>
  496|       |EIGEN_DEVICE_FUNC inline Scalar log1p(const Scalar& x) {
  497|       |  EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
  498|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  499|       |  EIGEN_USING_STD(log);
  500|       |  Scalar x1p = RealScalar(1) + x;
  501|       |  Scalar log_1p = log_impl<Scalar>::run(x1p);
  502|       |  const bool is_small = numext::equal_strict(x1p, Scalar(1));
  503|       |  const bool is_inf = numext::equal_strict(x1p, log_1p);
  504|       |  return (is_small || is_inf) ? x : x * (log_1p / (x1p - RealScalar(1)));
  505|       |}
  506|       |}  // namespace std_fallback
  507|       |
  508|       |template <typename Scalar>
  509|       |struct log1p_impl {
  510|       |  EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
  511|       |
  512|      0|  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x) {
  513|      0|    EIGEN_USING_STD(log1p);
  514|      0|    return log1p(x);
  515|      0|  }
  516|       |};
  517|       |
  518|       |// Specialization for complex types that are not supported by std::log1p.
  519|       |template <typename RealScalar>
  520|       |struct log1p_impl<std::complex<RealScalar>> {
  521|       |  EIGEN_STATIC_ASSERT_NON_INTEGER(RealScalar)
  522|       |
  523|       |  EIGEN_DEVICE_FUNC static inline std::complex<RealScalar> run(const std::complex<RealScalar>& x) {
  524|       |    return std_fallback::log1p(x);
  525|       |  }
  526|       |};
  527|       |
  528|       |template <typename Scalar>
  529|       |struct log1p_retval {
  530|       |  typedef Scalar type;
  531|       |};
  532|       |
  533|       |/****************************************************************************
  534|       | * Implementation of pow                                                  *
  535|       | ****************************************************************************/
  536|       |
  537|       |template <typename ScalarX, typename ScalarY,
  538|       |          bool IsInteger = NumTraits<ScalarX>::IsInteger && NumTraits<ScalarY>::IsInteger>
  539|       |struct pow_impl {
  540|       |  // typedef Scalar retval;
  541|       |  typedef typename ScalarBinaryOpTraits<ScalarX, ScalarY, internal::scalar_pow_op<ScalarX, ScalarY>>::ReturnType
  542|       |      result_type;
  543|       |  static EIGEN_DEVICE_FUNC inline result_type run(const ScalarX& x, const ScalarY& y) {
  544|       |    EIGEN_USING_STD(pow);
  545|       |    return pow(x, y);
  546|       |  }
  547|       |};
  548|       |
  549|       |template <typename ScalarX, typename ScalarY>
  550|       |struct pow_impl<ScalarX, ScalarY, true> {
  551|       |  typedef ScalarX result_type;
  552|       |  static EIGEN_DEVICE_FUNC inline ScalarX run(ScalarX x, ScalarY y) {
  553|       |    ScalarX res(1);
  554|       |    eigen_assert(!NumTraits<ScalarY>::IsSigned || y >= 0);
  555|       |    if (y & 1) res *= x;
  556|       |    y >>= 1;
  557|       |    while (y) {
  558|       |      x *= x;
  559|       |      if (y & 1) res *= x;
  560|       |      y >>= 1;
  561|       |    }
  562|       |    return res;
  563|       |  }
  564|       |};
  565|       |
  566|       |enum { meta_floor_log2_terminate, meta_floor_log2_move_up, meta_floor_log2_move_down, meta_floor_log2_bogus };
  567|       |
  568|       |template <unsigned int n, int lower, int upper>
  569|       |struct meta_floor_log2_selector {
  570|       |  enum {
  571|       |    middle = (lower + upper) / 2,
  572|       |    value = (upper <= lower + 1)  ? int(meta_floor_log2_terminate)
  573|       |            : (n < (1 << middle)) ? int(meta_floor_log2_move_down)
  574|       |            : (n == 0)            ? int(meta_floor_log2_bogus)
  575|       |                                  : int(meta_floor_log2_move_up)
  576|       |  };
  577|       |};
  578|       |
  579|       |template <unsigned int n, int lower = 0, int upper = sizeof(unsigned int) * CHAR_BIT - 1,
  580|       |          int selector = meta_floor_log2_selector<n, lower, upper>::value>
  581|       |struct meta_floor_log2 {};
  582|       |
  583|       |template <unsigned int n, int lower, int upper>
  584|       |struct meta_floor_log2<n, lower, upper, meta_floor_log2_move_down> {
  585|       |  enum { value = meta_floor_log2<n, lower, meta_floor_log2_selector<n, lower, upper>::middle>::value };
  586|       |};
  587|       |
  588|       |template <unsigned int n, int lower, int upper>
  589|       |struct meta_floor_log2<n, lower, upper, meta_floor_log2_move_up> {
  590|       |  enum { value = meta_floor_log2<n, meta_floor_log2_selector<n, lower, upper>::middle, upper>::value };
  591|       |};
  592|       |
  593|       |template <unsigned int n, int lower, int upper>
  594|       |struct meta_floor_log2<n, lower, upper, meta_floor_log2_terminate> {
  595|       |  enum { value = (n >= ((unsigned int)(1) << (lower + 1))) ? lower + 1 : lower };
  596|       |};
  597|       |
  598|       |template <unsigned int n, int lower, int upper>
  599|       |struct meta_floor_log2<n, lower, upper, meta_floor_log2_bogus> {
  600|       |  // no value, error at compile time
  601|       |};
  602|       |
  603|       |template <typename BitsType, typename EnableIf = void>
  604|       |struct count_bits_impl {
  605|       |  static_assert(std::is_integral<BitsType>::value && std::is_unsigned<BitsType>::value,
  606|       |                "BitsType must be an unsigned integer");
  607|       |  static EIGEN_DEVICE_FUNC inline int clz(BitsType bits) {
  608|       |    int n = CHAR_BIT * sizeof(BitsType);
  609|       |    int shift = n / 2;
  610|       |    while (bits > 0 && shift > 0) {
  611|       |      BitsType y = bits >> shift;
  612|       |      if (y > 0) {
  613|       |        n -= shift;
  614|       |        bits = y;
  615|       |      }
  616|       |      shift /= 2;
  617|       |    }
  618|       |    if (shift == 0) {
  619|       |      --n;
  620|       |    }
  621|       |    return n;
  622|       |  }
  623|       |
  624|       |  static EIGEN_DEVICE_FUNC inline int ctz(BitsType bits) {
  625|       |    int n = CHAR_BIT * sizeof(BitsType);
  626|       |    int shift = n / 2;
  627|       |    while (bits > 0 && shift > 0) {
  628|       |      BitsType y = bits << shift;
  629|       |      if (y > 0) {
  630|       |        n -= shift;
  631|       |        bits = y;
  632|       |      }
  633|       |      shift /= 2;
  634|       |    }
  635|       |    if (shift == 0) {
  636|       |      --n;
  637|       |    }
  638|       |    return n;
  639|       |  }
  640|       |};
  641|       |
  642|       |// Count leading zeros.
  643|       |template <typename BitsType>
  644|       |EIGEN_DEVICE_FUNC inline int clz(BitsType bits) {
  645|       |  return count_bits_impl<BitsType>::clz(bits);
  646|       |}
  647|       |
  648|       |// Count trailing zeros.
  649|       |template <typename BitsType>
  650|       |EIGEN_DEVICE_FUNC inline int ctz(BitsType bits) {
  651|       |  return count_bits_impl<BitsType>::ctz(bits);
  652|       |}
  653|       |
  654|       |#if EIGEN_COMP_GNUC || EIGEN_COMP_CLANG
  655|       |
  656|       |template <typename BitsType>
  657|       |struct count_bits_impl<
  658|       |    BitsType, std::enable_if_t<std::is_integral<BitsType>::value && sizeof(BitsType) <= sizeof(unsigned int)>> {
  659|       |  static constexpr int kNumBits = static_cast<int>(sizeof(BitsType) * CHAR_BIT);
  660|       |  static EIGEN_DEVICE_FUNC inline int clz(BitsType bits) {
  661|       |    static constexpr int kLeadingBitsOffset = (sizeof(unsigned int) - sizeof(BitsType)) * CHAR_BIT;
  662|       |    return bits == 0 ? kNumBits : __builtin_clz(static_cast<unsigned int>(bits)) - kLeadingBitsOffset;
  663|       |  }
  664|       |
  665|       |  static EIGEN_DEVICE_FUNC inline int ctz(BitsType bits) {
  666|       |    return bits == 0 ? kNumBits : __builtin_ctz(static_cast<unsigned int>(bits));
  667|       |  }
  668|       |};
  669|       |
  670|       |template <typename BitsType>
  671|       |struct count_bits_impl<BitsType,
  672|       |                       std::enable_if_t<std::is_integral<BitsType>::value && sizeof(unsigned int) < sizeof(BitsType) &&
  673|       |                                        sizeof(BitsType) <= sizeof(unsigned long)>> {
  674|       |  static constexpr int kNumBits = static_cast<int>(sizeof(BitsType) * CHAR_BIT);
  675|       |  static EIGEN_DEVICE_FUNC inline int clz(BitsType bits) {
  676|       |    static constexpr int kLeadingBitsOffset = (sizeof(unsigned long) - sizeof(BitsType)) * CHAR_BIT;
  677|       |    return bits == 0 ? kNumBits : __builtin_clzl(static_cast<unsigned long>(bits)) - kLeadingBitsOffset;
  678|       |  }
  679|       |
  680|       |  static EIGEN_DEVICE_FUNC inline int ctz(BitsType bits) {
  681|       |    return bits == 0 ? kNumBits : __builtin_ctzl(static_cast<unsigned long>(bits));
  682|       |  }
  683|       |};
  684|       |
  685|       |template <typename BitsType>
  686|       |struct count_bits_impl<BitsType,
  687|       |                       std::enable_if_t<std::is_integral<BitsType>::value && sizeof(unsigned long) < sizeof(BitsType) &&
  688|       |                                        sizeof(BitsType) <= sizeof(unsigned long long)>> {
  689|       |  static constexpr int kNumBits = static_cast<int>(sizeof(BitsType) * CHAR_BIT);
  690|       |  static EIGEN_DEVICE_FUNC inline int clz(BitsType bits) {
  691|       |    static constexpr int kLeadingBitsOffset = (sizeof(unsigned long long) - sizeof(BitsType)) * CHAR_BIT;
  692|       |    return bits == 0 ? kNumBits : __builtin_clzll(static_cast<unsigned long long>(bits)) - kLeadingBitsOffset;
  693|       |  }
  694|       |
  695|       |  static EIGEN_DEVICE_FUNC inline int ctz(BitsType bits) {
  696|       |    return bits == 0 ? kNumBits : __builtin_ctzll(static_cast<unsigned long long>(bits));
  697|       |  }
  698|       |};
  699|       |
  700|       |#elif EIGEN_COMP_MSVC
  701|       |
  702|       |template <typename BitsType>
  703|       |struct count_bits_impl<
  704|       |    BitsType, std::enable_if_t<std::is_integral<BitsType>::value && sizeof(BitsType) <= sizeof(unsigned long)>> {
  705|       |  static constexpr int kNumBits = static_cast<int>(sizeof(BitsType) * CHAR_BIT);
  706|       |  static EIGEN_DEVICE_FUNC inline int clz(BitsType bits) {
  707|       |    unsigned long out;
  708|       |    _BitScanReverse(&out, static_cast<unsigned long>(bits));
  709|       |    return bits == 0 ? kNumBits : (kNumBits - 1) - static_cast<int>(out);
  710|       |  }
  711|       |
  712|       |  static EIGEN_DEVICE_FUNC inline int ctz(BitsType bits) {
  713|       |    unsigned long out;
  714|       |    _BitScanForward(&out, static_cast<unsigned long>(bits));
  715|       |    return bits == 0 ? kNumBits : static_cast<int>(out);
  716|       |  }
  717|       |};
  718|       |
  719|       |#ifdef _WIN64
  720|       |
  721|       |template <typename BitsType>
  722|       |struct count_bits_impl<BitsType,
  723|       |                       std::enable_if_t<std::is_integral<BitsType>::value && sizeof(unsigned long) < sizeof(BitsType) &&
  724|       |                                        sizeof(BitsType) <= sizeof(__int64)>> {
  725|       |  static constexpr int kNumBits = static_cast<int>(sizeof(BitsType) * CHAR_BIT);
  726|       |  static EIGEN_DEVICE_FUNC inline int clz(BitsType bits) {
  727|       |    unsigned long out;
  728|       |    _BitScanReverse64(&out, static_cast<unsigned __int64>(bits));
  729|       |    return bits == 0 ? kNumBits : (kNumBits - 1) - static_cast<int>(out);
  730|       |  }
  731|       |
  732|       |  static EIGEN_DEVICE_FUNC inline int ctz(BitsType bits) {
  733|       |    unsigned long out;
  734|       |    _BitScanForward64(&out, static_cast<unsigned __int64>(bits));
  735|       |    return bits == 0 ? kNumBits : static_cast<int>(out);
  736|       |  }
  737|       |};
  738|       |
  739|       |#endif  // _WIN64
  740|       |
  741|       |#endif  // EIGEN_COMP_GNUC || EIGEN_COMP_CLANG
  742|       |
  743|       |template <typename BitsType>
  744|       |struct log_2_impl {
  745|       |  static constexpr int kTotalBits = sizeof(BitsType) * CHAR_BIT;
  746|       |  static EIGEN_DEVICE_FUNC inline int run_ceil(const BitsType& x) {
  747|       |    const int n = kTotalBits - clz(x);
  748|       |    bool power_of_two = (x & (x - 1)) == 0;
  749|       |    return x == 0 ? 0 : power_of_two ? (n - 1) : n;
  750|       |  }
  751|       |  static EIGEN_DEVICE_FUNC inline int run_floor(const BitsType& x) {
  752|       |    const int n = kTotalBits - clz(x);
  753|       |    return x == 0 ? 0 : n - 1;
  754|       |  }
  755|       |};
  756|       |
  757|       |template <typename BitsType>
  758|       |int log2_ceil(const BitsType& x) {
  759|       |  return log_2_impl<BitsType>::run_ceil(x);
  760|       |}
  761|       |
  762|       |template <typename BitsType>
  763|       |int log2_floor(const BitsType& x) {
  764|       |  return log_2_impl<BitsType>::run_floor(x);
  765|       |}
  766|       |
  767|       |// Implementation of is* functions
  768|       |
  769|       |template <typename T>
  770|       |EIGEN_DEVICE_FUNC std::enable_if_t<!(std::numeric_limits<T>::has_infinity || std::numeric_limits<T>::has_quiet_NaN ||
  771|       |                                     std::numeric_limits<T>::has_signaling_NaN),
  772|       |                                   bool>
  773|       |isfinite_impl(const T&) {
  774|       |  return true;
  775|       |}
  776|       |
  777|       |template <typename T>
  778|       |EIGEN_DEVICE_FUNC std::enable_if_t<(std::numeric_limits<T>::has_infinity || std::numeric_limits<T>::has_quiet_NaN ||
  779|       |                                    std::numeric_limits<T>::has_signaling_NaN) &&
  780|       |                                       (!NumTraits<T>::IsComplex),
  781|       |                                   bool>
  782|      0|isfinite_impl(const T& x) {
  783|      0|  EIGEN_USING_STD(isfinite);
  784|      0|  return isfinite EIGEN_NOT_A_MACRO(x);
  785|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13isfinite_implIdEENSt9enable_ifIXaaoooosr3std14numeric_limitsIT_EE12has_infinitysr3std14numeric_limitsIS3_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNntsr9NumTraitsIS3_EE9IsComplexEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13isfinite_implIfEENSt9enable_ifIXaaoooosr3std14numeric_limitsIT_EE12has_infinitysr3std14numeric_limitsIS3_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNntsr9NumTraitsIS3_EE9IsComplexEbE4typeERKS3_
  ------------------
  786|       |
  787|       |template <typename T>
  788|       |EIGEN_DEVICE_FUNC std::enable_if_t<!std::numeric_limits<T>::has_infinity, bool> isinf_impl(const T&) {
  789|       |  return false;
  790|       |}
  791|       |
  792|       |template <typename T>
  793|       |EIGEN_DEVICE_FUNC std::enable_if_t<(std::numeric_limits<T>::has_infinity && !NumTraits<T>::IsComplex), bool> isinf_impl(
  794|       |    const T& x) {
  795|       |  EIGEN_USING_STD(isinf);
  796|       |  return isinf EIGEN_NOT_A_MACRO(x);
  797|       |}
  798|       |
  799|       |template <typename T>
  800|       |EIGEN_DEVICE_FUNC
  801|       |    std::enable_if_t<!(std::numeric_limits<T>::has_quiet_NaN || std::numeric_limits<T>::has_signaling_NaN), bool>
  802|      0|    isnan_impl(const T&) {
  803|      0|  return false;
  804|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implIsEENSt9enable_ifIXntoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implItEENSt9enable_ifIXntoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implIiEENSt9enable_ifIXntoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implIjEENSt9enable_ifIXntoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implIlEENSt9enable_ifIXntoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implImEENSt9enable_ifIXntoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implIxEENSt9enable_ifIXntoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implIyEENSt9enable_ifIXntoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNEbE4typeERKS3_
  ------------------
  805|       |
  806|       |template <typename T>
  807|       |EIGEN_DEVICE_FUNC std::enable_if_t<
  808|       |    (std::numeric_limits<T>::has_quiet_NaN || std::numeric_limits<T>::has_signaling_NaN) && (!NumTraits<T>::IsComplex),
  809|       |    bool>
  810|      0|isnan_impl(const T& x) {
  811|      0|  EIGEN_USING_STD(isnan);
  812|      0|  return isnan EIGEN_NOT_A_MACRO(x);
  813|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implIfEENSt9enable_ifIXaaoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNntsr9NumTraitsIS3_EE9IsComplexEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implIdEENSt9enable_ifIXaaoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS3_EE17has_signaling_NaNntsr9NumTraitsIS3_EE9IsComplexEbE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal10isnan_implINS_4halfEEENSt9enable_ifIXaaoosr3std14numeric_limitsIT_EE13has_quiet_NaNsr3std14numeric_limitsIS4_EE17has_signaling_NaNntsr9NumTraitsIS4_EE9IsComplexEbE4typeERKS4_
  ------------------
  814|       |
  815|       |// The following overload are defined at the end of this file
  816|       |template <typename T>
  817|       |EIGEN_DEVICE_FUNC bool isfinite_impl(const std::complex<T>& x);
  818|       |template <typename T>
  819|       |EIGEN_DEVICE_FUNC bool isnan_impl(const std::complex<T>& x);
  820|       |template <typename T>
  821|       |EIGEN_DEVICE_FUNC bool isinf_impl(const std::complex<T>& x);
  822|       |template <typename T>
  823|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS T ptanh_float(const T& a_x);
  824|       |
  825|       |/****************************************************************************
  826|       | * Implementation of sign                                                 *
  827|       | ****************************************************************************/
  828|       |template <typename Scalar, bool IsComplex = (NumTraits<Scalar>::IsComplex != 0),
  829|       |          bool IsInteger = (NumTraits<Scalar>::IsInteger != 0)>
  830|       |struct sign_impl {
  831|       |  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& a) { return Scalar((a > Scalar(0)) - (a < Scalar(0))); }
  832|       |};
  833|       |
  834|       |template <typename Scalar>
  835|       |struct sign_impl<Scalar, false, false> {
  836|       |  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& a) {
  837|       |    return (isnan_impl<Scalar>)(a) ? a : Scalar((a > Scalar(0)) - (a < Scalar(0)));
  838|       |  }
  839|       |};
  840|       |
  841|       |template <typename Scalar, bool IsInteger>
  842|       |struct sign_impl<Scalar, true, IsInteger> {
  843|       |  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& a) {
  844|       |    using real_type = typename NumTraits<Scalar>::Real;
  845|       |    EIGEN_USING_STD(abs);
  846|       |    real_type aa = abs(a);
  847|       |    if (aa == real_type(0)) return Scalar(0);
  848|       |    aa = real_type(1) / aa;
  849|       |    return Scalar(a.real() * aa, a.imag() * aa);
  850|       |  }
  851|       |};
  852|       |
  853|       |// The sign function for bool is the identity.
  854|       |template <>
  855|       |struct sign_impl<bool, false, true> {
  856|      0|  EIGEN_DEVICE_FUNC static inline bool run(const bool& a) { return a; }
  857|       |};
  858|       |
  859|       |template <typename Scalar>
  860|       |struct sign_retval {
  861|       |  typedef Scalar type;
  862|       |};
  863|       |
  864|       |// suppress "unary minus operator applied to unsigned type, result still unsigned" warnings on MSVC
  865|       |// note: `0 - a` is distinct from `-a` when Scalar is a floating point type and `a` is zero
  866|       |
  867|       |template <typename Scalar, bool IsInteger = NumTraits<Scalar>::IsInteger>
  868|       |struct negate_impl {
  869|       |  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar run(const Scalar& a) { return -a; }
  870|       |};
  871|       |
  872|       |template <typename Scalar>
  873|       |struct negate_impl<Scalar, true> {
  874|       |  EIGEN_STATIC_ASSERT((!is_same<Scalar, bool>::value), NEGATE IS NOT DEFINED FOR BOOLEAN TYPES)
  875|       |  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar run(const Scalar& a) { return Scalar(0) - a; }
  876|       |};
  877|       |
  878|       |template <typename Scalar>
  879|       |struct negate_retval {
  880|       |  typedef Scalar type;
  881|       |};
  882|       |
  883|       |template <typename Scalar, bool IsInteger = NumTraits<typename unpacket_traits<Scalar>::type>::IsInteger>
  884|       |struct nearest_integer_impl {
  885|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_floor(const Scalar& x) {
  886|       |    EIGEN_USING_STD(floor) return floor(x);
  887|       |  }
  888|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_ceil(const Scalar& x) {
  889|       |    EIGEN_USING_STD(ceil) return ceil(x);
  890|       |  }
  891|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_rint(const Scalar& x) {
  892|       |    EIGEN_USING_STD(rint) return rint(x);
  893|       |  }
  894|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_round(const Scalar& x) {
  895|       |    EIGEN_USING_STD(round) return round(x);
  896|       |  }
  897|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_trunc(const Scalar& x) {
  898|       |    EIGEN_USING_STD(trunc) return trunc(x);
  899|       |  }
  900|       |};
  901|       |template <typename Scalar>
  902|       |struct nearest_integer_impl<Scalar, true> {
  903|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_floor(const Scalar& x) { return x; }
  904|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_ceil(const Scalar& x) { return x; }
  905|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_rint(const Scalar& x) { return x; }
  906|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_round(const Scalar& x) { return x; }
  907|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_trunc(const Scalar& x) { return x; }
  908|       |};
  909|       |
  910|       |}  // end namespace internal
  911|       |
  912|       |/****************************************************************************
  913|       | * Generic math functions                                                    *
  914|       | ****************************************************************************/
  915|       |
  916|       |namespace numext {
  917|       |
  918|       |#if (!defined(EIGEN_GPUCC) || defined(EIGEN_CONSTEXPR_ARE_DEVICE_FUNC))
  919|       |template <typename T>
  920|      4|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T mini(const T& x, const T& y) {
  921|      4|  EIGEN_USING_STD(min)
  922|      4|  return min EIGEN_NOT_A_MACRO(x, y);
  923|      4|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4miniIfEET_RKS2_S4_
  ------------------
  | _ZN5Eigen6numext4miniIlEET_RKS2_S4_:
  |  920|      4|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T mini(const T& x, const T& y) {
  |  921|      4|  EIGEN_USING_STD(min)
  |  922|      4|  return min EIGEN_NOT_A_MACRO(x, y);
  |  923|      4|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4miniIdEET_RKS2_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4miniINS_4halfEEET_RKS3_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4miniINS_8bfloat16EEET_RKS3_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4miniIeEET_RKS2_S4_
  ------------------
  924|       |
  925|       |template <typename T>
  926|      6|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T maxi(const T& x, const T& y) {
  927|      6|  EIGEN_USING_STD(max)
  928|      6|  return max EIGEN_NOT_A_MACRO(x, y);
  929|      6|}
  ------------------
  | _ZN5Eigen6numext4maxiIlEET_RKS2_S4_:
  |  926|      6|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T maxi(const T& x, const T& y) {
  |  927|      6|  EIGEN_USING_STD(max)
  |  928|      6|  return max EIGEN_NOT_A_MACRO(x, y);
  |  929|      6|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4maxiIfEET_RKS2_S4_
  ------------------
  930|       |#else
  931|       |template <typename T>
  932|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T mini(const T& x, const T& y) {
  933|       |  return y < x ? y : x;
  934|       |}
  935|       |template <>
  936|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float mini(const float& x, const float& y) {
  937|       |  return fminf(x, y);
  938|       |}
  939|       |template <>
  940|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double mini(const double& x, const double& y) {
  941|       |  return fmin(x, y);
  942|       |}
  943|       |
  944|       |#ifndef EIGEN_GPU_COMPILE_PHASE
  945|       |template <>
  946|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE long double mini(const long double& x, const long double& y) {
  947|       |#if defined(EIGEN_HIPCC)
  948|       |  // no "fminl" on HIP yet
  949|       |  return (x < y) ? x : y;
  950|       |#else
  951|       |  return fminl(x, y);
  952|       |#endif
  953|       |}
  954|       |#endif
  955|       |
  956|       |template <typename T>
  957|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T maxi(const T& x, const T& y) {
  958|       |  return x < y ? y : x;
  959|       |}
  960|       |template <>
  961|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float maxi(const float& x, const float& y) {
  962|       |  return fmaxf(x, y);
  963|       |}
  964|       |template <>
  965|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double maxi(const double& x, const double& y) {
  966|       |  return fmax(x, y);
  967|       |}
  968|       |#ifndef EIGEN_GPU_COMPILE_PHASE
  969|       |template <>
  970|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE long double maxi(const long double& x, const long double& y) {
  971|       |#if defined(EIGEN_HIPCC)
  972|       |  // no "fmaxl" on HIP yet
  973|       |  return (x > y) ? x : y;
  974|       |#else
  975|       |  return fmaxl(x, y);
  976|       |#endif
  977|       |}
  978|       |#endif
  979|       |#endif
  980|       |
  981|       |#if defined(SYCL_DEVICE_ONLY)
  982|       |
  983|       |#define SYCL_SPECIALIZE_SIGNED_INTEGER_TYPES_BINARY(NAME, FUNC) \
  984|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_char)    \
  985|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_short)   \
  986|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_int)     \
  987|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_long)
  988|       |#define SYCL_SPECIALIZE_SIGNED_INTEGER_TYPES_UNARY(NAME, FUNC) \
  989|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_char)    \
  990|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_short)   \
  991|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_int)     \
  992|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_long)
  993|       |#define SYCL_SPECIALIZE_UNSIGNED_INTEGER_TYPES_BINARY(NAME, FUNC) \
  994|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_uchar)     \
  995|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_ushort)    \
  996|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_uint)      \
  997|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_ulong)
  998|       |#define SYCL_SPECIALIZE_UNSIGNED_INTEGER_TYPES_UNARY(NAME, FUNC) \
  999|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_uchar)     \
 1000|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_ushort)    \
 1001|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_uint)      \
 1002|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_ulong)
 1003|       |#define SYCL_SPECIALIZE_INTEGER_TYPES_BINARY(NAME, FUNC)  \
 1004|       |  SYCL_SPECIALIZE_SIGNED_INTEGER_TYPES_BINARY(NAME, FUNC) \
 1005|       |  SYCL_SPECIALIZE_UNSIGNED_INTEGER_TYPES_BINARY(NAME, FUNC)
 1006|       |#define SYCL_SPECIALIZE_INTEGER_TYPES_UNARY(NAME, FUNC)  \
 1007|       |  SYCL_SPECIALIZE_SIGNED_INTEGER_TYPES_UNARY(NAME, FUNC) \
 1008|       |  SYCL_SPECIALIZE_UNSIGNED_INTEGER_TYPES_UNARY(NAME, FUNC)
 1009|       |#define SYCL_SPECIALIZE_FLOATING_TYPES_BINARY(NAME, FUNC)     \
 1010|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_float) \
 1011|       |  SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, cl::sycl::cl_double)
 1012|       |#define SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(NAME, FUNC)     \
 1013|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_float) \
 1014|       |  SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, cl::sycl::cl_double)
 1015|       |#define SYCL_SPECIALIZE_FLOATING_TYPES_UNARY_FUNC_RET_TYPE(NAME, FUNC, RET_TYPE) \
 1016|       |  SYCL_SPECIALIZE_GEN_UNARY_FUNC(NAME, FUNC, RET_TYPE, cl::sycl::cl_float)       \
 1017|       |  SYCL_SPECIALIZE_GEN_UNARY_FUNC(NAME, FUNC, RET_TYPE, cl::sycl::cl_double)
 1018|       |
 1019|       |#define SYCL_SPECIALIZE_GEN_UNARY_FUNC(NAME, FUNC, RET_TYPE, ARG_TYPE)     \
 1020|       |  template <>                                                              \
 1021|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE RET_TYPE NAME(const ARG_TYPE& x) { \
 1022|       |    return cl::sycl::FUNC(x);                                              \
 1023|       |  }
 1024|       |
 1025|       |#define SYCL_SPECIALIZE_UNARY_FUNC(NAME, FUNC, TYPE) SYCL_SPECIALIZE_GEN_UNARY_FUNC(NAME, FUNC, TYPE, TYPE)
 1026|       |
 1027|       |#define SYCL_SPECIALIZE_GEN1_BINARY_FUNC(NAME, FUNC, RET_TYPE, ARG_TYPE1, ARG_TYPE2)            \
 1028|       |  template <>                                                                                   \
 1029|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE RET_TYPE NAME(const ARG_TYPE1& x, const ARG_TYPE2& y) { \
 1030|       |    return cl::sycl::FUNC(x, y);                                                                \
 1031|       |  }
 1032|       |
 1033|       |#define SYCL_SPECIALIZE_GEN2_BINARY_FUNC(NAME, FUNC, RET_TYPE, ARG_TYPE) \
 1034|       |  SYCL_SPECIALIZE_GEN1_BINARY_FUNC(NAME, FUNC, RET_TYPE, ARG_TYPE, ARG_TYPE)
 1035|       |
 1036|       |#define SYCL_SPECIALIZE_BINARY_FUNC(NAME, FUNC, TYPE) SYCL_SPECIALIZE_GEN2_BINARY_FUNC(NAME, FUNC, TYPE, TYPE)
 1037|       |
 1038|       |SYCL_SPECIALIZE_INTEGER_TYPES_BINARY(mini, min)
 1039|       |SYCL_SPECIALIZE_FLOATING_TYPES_BINARY(mini, fmin)
 1040|       |SYCL_SPECIALIZE_INTEGER_TYPES_BINARY(maxi, max)
 1041|       |SYCL_SPECIALIZE_FLOATING_TYPES_BINARY(maxi, fmax)
 1042|       |
 1043|       |#endif
 1044|       |
 1045|       |template <typename Scalar>
 1046|      0|EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(real, Scalar) real(const Scalar& x) {
 1047|      0|  return EIGEN_MATHFUNC_IMPL(real, Scalar)::run(x);
 1048|      0|}
 1049|       |
 1050|       |template <typename Scalar>
 1051|       |EIGEN_DEVICE_FUNC inline internal::add_const_on_value_type_t<EIGEN_MATHFUNC_RETVAL(real_ref, Scalar)> real_ref(
 1052|      0|    const Scalar& x) {
 1053|      0|  return internal::real_ref_impl<Scalar>::run(x);
 1054|      0|}
 1055|       |
 1056|       |template <typename Scalar>
 1057|      0|EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(real_ref, Scalar) real_ref(Scalar& x) {
 1058|      0|  return EIGEN_MATHFUNC_IMPL(real_ref, Scalar)::run(x);
 1059|      0|}
 1060|       |
 1061|       |template <typename Scalar>
 1062|      0|EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(imag, Scalar) imag(const Scalar& x) {
 1063|      0|  return EIGEN_MATHFUNC_IMPL(imag, Scalar)::run(x);
 1064|      0|}
 1065|       |
 1066|       |template <typename Scalar>
 1067|       |EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(arg, Scalar) arg(const Scalar& x) {
 1068|       |  return EIGEN_MATHFUNC_IMPL(arg, Scalar)::run(x);
 1069|       |}
 1070|       |
 1071|       |template <typename Scalar>
 1072|       |EIGEN_DEVICE_FUNC inline internal::add_const_on_value_type_t<EIGEN_MATHFUNC_RETVAL(imag_ref, Scalar)> imag_ref(
 1073|       |    const Scalar& x) {
 1074|       |  return internal::imag_ref_impl<Scalar>::run(x);
 1075|       |}
 1076|       |
 1077|       |template <typename Scalar>
 1078|       |EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(imag_ref, Scalar) imag_ref(Scalar& x) {
 1079|       |  return EIGEN_MATHFUNC_IMPL(imag_ref, Scalar)::run(x);
 1080|       |}
 1081|       |
 1082|       |template <typename Scalar>
 1083|     33|EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(conj, Scalar) conj(const Scalar& x) {
 1084|     33|  return EIGEN_MATHFUNC_IMPL(conj, Scalar)::run(x);
 1085|     33|}
 1086|       |
 1087|       |template <typename Scalar>
 1088|       |EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(sign, Scalar) sign(const Scalar& x) {
 1089|       |  return EIGEN_MATHFUNC_IMPL(sign, Scalar)::run(x);
 1090|       |}
 1091|       |
 1092|       |template <typename Scalar>
 1093|       |EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(negate, Scalar) negate(const Scalar& x) {
 1094|       |  return EIGEN_MATHFUNC_IMPL(negate, Scalar)::run(x);
 1095|       |}
 1096|       |
 1097|       |template <typename Scalar>
 1098|      0|EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(abs2, Scalar) abs2(const Scalar& x) {
 1099|      0|  return EIGEN_MATHFUNC_IMPL(abs2, Scalar)::run(x);
 1100|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4abs2IfEENS_8internal11abs2_retvalINS2_36global_math_functions_filtering_baseIT_vE4typeEE4typeERKS5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4abs2ISt7complexIfEEENS_8internal11abs2_retvalINS4_36global_math_functions_filtering_baseIT_vE4typeEE4typeERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4abs2ISt7complexIdEEENS_8internal11abs2_retvalINS4_36global_math_functions_filtering_baseIT_vE4typeEE4typeERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext4abs2ISt7complexIeEEENS_8internal11abs2_retvalINS4_36global_math_functions_filtering_baseIT_vE4typeEE4typeERKS7_
  ------------------
 1101|       |
 1102|      0|EIGEN_DEVICE_FUNC inline bool abs2(bool x) { return x; }
 1103|       |
 1104|       |template <typename T>
 1105|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T absdiff(const T& x, const T& y) {
 1106|       |  return x > y ? x - y : y - x;
 1107|       |}
 1108|       |template <>
 1109|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float absdiff(const float& x, const float& y) {
 1110|      0|  return fabsf(x - y);
 1111|      0|}
 1112|       |template <>
 1113|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double absdiff(const double& x, const double& y) {
 1114|      0|  return fabs(x - y);
 1115|      0|}
 1116|       |
 1117|       |// HIP and CUDA do not support long double.
 1118|       |#ifndef EIGEN_GPU_COMPILE_PHASE
 1119|       |template <>
 1120|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE long double absdiff(const long double& x, const long double& y) {
 1121|      0|  return fabsl(x - y);
 1122|      0|}
 1123|       |#endif
 1124|       |
 1125|       |template <typename Scalar>
 1126|       |EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(norm1, Scalar) norm1(const Scalar& x) {
 1127|       |  return EIGEN_MATHFUNC_IMPL(norm1, Scalar)::run(x);
 1128|       |}
 1129|       |
 1130|       |template <typename Scalar>
 1131|       |EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(hypot, Scalar) hypot(const Scalar& x, const Scalar& y) {
 1132|       |  return EIGEN_MATHFUNC_IMPL(hypot, Scalar)::run(x, y);
 1133|       |}
 1134|       |
 1135|       |#if defined(SYCL_DEVICE_ONLY)
 1136|       |SYCL_SPECIALIZE_FLOATING_TYPES_BINARY(hypot, hypot)
 1137|       |#endif
 1138|       |
 1139|       |template <typename Scalar>
 1140|      0|EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(log1p, Scalar) log1p(const Scalar& x) {
 1141|      0|  return EIGEN_MATHFUNC_IMPL(log1p, Scalar)::run(x);
 1142|      0|}
 1143|       |
 1144|       |#if defined(SYCL_DEVICE_ONLY)
 1145|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(log1p, log1p)
 1146|       |#endif
 1147|       |
 1148|       |#if defined(EIGEN_GPUCC)
 1149|       |template <>
 1150|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float log1p(const float& x) {
 1151|       |  return ::log1pf(x);
 1152|       |}
 1153|       |
 1154|       |template <>
 1155|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double log1p(const double& x) {
 1156|       |  return ::log1p(x);
 1157|       |}
 1158|       |#endif
 1159|       |
 1160|       |template <typename ScalarX, typename ScalarY>
 1161|       |EIGEN_DEVICE_FUNC inline typename internal::pow_impl<ScalarX, ScalarY>::result_type pow(const ScalarX& x,
 1162|       |                                                                                        const ScalarY& y) {
 1163|       |  return internal::pow_impl<ScalarX, ScalarY>::run(x, y);
 1164|       |}
 1165|       |
 1166|       |#if defined(SYCL_DEVICE_ONLY)
 1167|       |SYCL_SPECIALIZE_FLOATING_TYPES_BINARY(pow, pow)
 1168|       |#endif
 1169|       |
 1170|       |template <typename T>
 1171|      0|EIGEN_DEVICE_FUNC bool(isnan)(const T& x) {
 1172|      0|  return internal::isnan_impl(x);
 1173|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanIfEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanIsEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanItEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanIiEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanIjEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanIlEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanImEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanIxEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanIyEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanIdEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext5isnanINS_4halfEEEbRKT_
  ------------------
 1174|       |template <typename T>
 1175|       |EIGEN_DEVICE_FUNC bool(isinf)(const T& x) {
 1176|       |  return internal::isinf_impl(x);
 1177|       |}
 1178|       |template <typename T>
 1179|      0|EIGEN_DEVICE_FUNC bool(isfinite)(const T& x) {
 1180|      0|  return internal::isfinite_impl(x);
 1181|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext8isfiniteIdEEbRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext8isfiniteIfEEbRKT_
  ------------------
 1182|       |
 1183|       |#if defined(SYCL_DEVICE_ONLY)
 1184|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY_FUNC_RET_TYPE(isnan, isnan, bool)
 1185|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY_FUNC_RET_TYPE(isinf, isinf, bool)
 1186|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY_FUNC_RET_TYPE(isfinite, isfinite, bool)
 1187|       |#endif
 1188|       |
 1189|       |template <typename Scalar>
 1190|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar rint(const Scalar& x) {
 1191|       |  return internal::nearest_integer_impl<Scalar>::run_rint(x);
 1192|       |}
 1193|       |
 1194|       |template <typename Scalar>
 1195|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar round(const Scalar& x) {
 1196|       |  return internal::nearest_integer_impl<Scalar>::run_round(x);
 1197|       |}
 1198|       |
 1199|       |template <typename Scalar>
 1200|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar(floor)(const Scalar& x) {
 1201|       |  return internal::nearest_integer_impl<Scalar>::run_floor(x);
 1202|       |}
 1203|       |
 1204|       |template <typename Scalar>
 1205|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar(ceil)(const Scalar& x) {
 1206|       |  return internal::nearest_integer_impl<Scalar>::run_ceil(x);
 1207|       |}
 1208|       |
 1209|       |template <typename Scalar>
 1210|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar(trunc)(const Scalar& x) {
 1211|       |  return internal::nearest_integer_impl<Scalar>::run_trunc(x);
 1212|       |}
 1213|       |
 1214|       |#if defined(SYCL_DEVICE_ONLY)
 1215|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(round, round)
 1216|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(floor, floor)
 1217|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(ceil, ceil)
 1218|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(trunc, trunc)
 1219|       |#endif
 1220|       |
 1221|       |#if defined(EIGEN_GPUCC)
 1222|       |template <>
 1223|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float floor(const float& x) {
 1224|       |  return ::floorf(x);
 1225|       |}
 1226|       |template <>
 1227|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double floor(const double& x) {
 1228|       |  return ::floor(x);
 1229|       |}
 1230|       |template <>
 1231|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float ceil(const float& x) {
 1232|       |  return ::ceilf(x);
 1233|       |}
 1234|       |template <>
 1235|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double ceil(const double& x) {
 1236|       |  return ::ceil(x);
 1237|       |}
 1238|       |template <>
 1239|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float trunc(const float& x) {
 1240|       |  return ::truncf(x);
 1241|       |}
 1242|       |template <>
 1243|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double trunc(const double& x) {
 1244|       |  return ::trunc(x);
 1245|       |}
 1246|       |#endif
 1247|       |
 1248|       |// Integer division with rounding up.
 1249|       |// T is assumed to be an integer type with a>=0, and b>0
 1250|       |template <typename T>
 1251|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE EIGEN_CONSTEXPR T div_ceil(T a, T b) {
 1252|      0|  using UnsignedT = typename internal::make_unsigned<T>::type;
 1253|      0|  EIGEN_STATIC_ASSERT((NumTraits<T>::IsInteger), THIS FUNCTION IS FOR INTEGER TYPES)
 1254|      0|  eigen_assert(a >= 0);
 1255|      0|  eigen_assert(b > 0);
 1256|       |  // Note: explicitly declaring a and b as non-negative values allows the compiler to use better optimizations
 1257|      0|  const UnsignedT ua = UnsignedT(a);
 1258|      0|  const UnsignedT ub = UnsignedT(b);
 1259|       |  // Note: This form is used because it cannot overflow.
 1260|      0|  return ua == 0 ? 0 : (ua - 1) / ub + 1;
 1261|      0|}
 1262|       |
 1263|       |// Integer round down to nearest power of b
 1264|       |// T is assumed to be an integer type with a>=0, and b>0
 1265|       |template <typename T, typename U>
 1266|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE EIGEN_CONSTEXPR T round_down(T a, U b) {
 1267|      0|  using UnsignedT = typename internal::make_unsigned<T>::type;
 1268|      0|  using UnsignedU = typename internal::make_unsigned<U>::type;
 1269|      0|  EIGEN_STATIC_ASSERT((NumTraits<T>::IsInteger), THIS FUNCTION IS FOR INTEGER TYPES)
 1270|      0|  EIGEN_STATIC_ASSERT((NumTraits<U>::IsInteger), THIS FUNCTION IS FOR INTEGER TYPES)
 1271|      0|  eigen_assert(a >= 0);
 1272|      0|  eigen_assert(b > 0);
 1273|      0|  // Note: explicitly declaring a and b as non-negative values allows the compiler to use better optimizations
 1274|      0|  const UnsignedT ua = UnsignedT(a);
 1275|      0|  const UnsignedU ub = UnsignedU(b);
 1276|      0|  return ub * (ua / ub);
 1277|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext10round_downImiEET_S2_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext10round_downIllEET_S2_T0_
  ------------------
 1278|       |
 1279|       |/** Log base 2 for 32 bits positive integers.
 1280|       | * Conveniently returns 0 for x==0. */
 1281|      0|EIGEN_CONSTEXPR inline int log2(int x) {
 1282|      0|  eigen_assert(x >= 0);
 1283|      0|  unsigned int v(x);
 1284|      0|  constexpr int table[32] = {0, 9,  1,  10, 13, 21, 2,  29, 11, 14, 16, 18, 22, 25, 3, 30,
 1285|      0|                             8, 12, 20, 28, 15, 17, 24, 7,  19, 27, 23, 6,  26, 5,  4, 31};
 1286|      0|  v |= v >> 1;
 1287|      0|  v |= v >> 2;
 1288|      0|  v |= v >> 4;
 1289|      0|  v |= v >> 8;
 1290|      0|  v |= v >> 16;
 1291|      0|  return table[(v * 0x07C4ACDDU) >> 27];
 1292|      0|}
 1293|       |
 1294|       |/** \returns the square root of \a x.
 1295|       | *
 1296|       | * It is essentially equivalent to
 1297|       | * \code using std::sqrt; return sqrt(x); \endcode
 1298|       | * but slightly faster for float/double and some compilers (e.g., gcc), thanks to
 1299|       | * specializations when SSE is enabled.
 1300|       | *
 1301|       | * It's usage is justified in performance critical functions, like norm/normalize.
 1302|       | */
 1303|       |template <typename Scalar>
 1304|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE EIGEN_MATHFUNC_RETVAL(sqrt, Scalar) sqrt(const Scalar& x) {
 1305|       |  return EIGEN_MATHFUNC_IMPL(sqrt, Scalar)::run(x);
 1306|       |}
 1307|       |
 1308|       |// Boolean specialization, avoids implicit float to bool conversion (-Wimplicit-conversion-floating-point-to-bool).
 1309|       |template <>
 1310|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_DEVICE_FUNC bool sqrt<bool>(const bool& x) {
 1311|      0|  return x;
 1312|      0|}
 1313|       |
 1314|       |#if defined(SYCL_DEVICE_ONLY)
 1315|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(sqrt, sqrt)
 1316|       |#endif
 1317|       |
 1318|       |/** \returns the cube root of \a x. **/
 1319|       |template <typename T>
 1320|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T cbrt(const T& x) {
 1321|       |  EIGEN_USING_STD(cbrt);
 1322|       |  return static_cast<T>(cbrt(x));
 1323|       |}
 1324|       |
 1325|       |/** \returns the reciprocal square root of \a x. **/
 1326|       |template <typename T>
 1327|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T rsqrt(const T& x) {
 1328|       |  return internal::rsqrt_impl<T>::run(x);
 1329|       |}
 1330|       |
 1331|       |template <typename T>
 1332|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T log(const T& x) {
 1333|       |  return internal::log_impl<T>::run(x);
 1334|       |}
 1335|       |
 1336|       |#if defined(SYCL_DEVICE_ONLY)
 1337|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(log, log)
 1338|       |#endif
 1339|       |
 1340|       |#if defined(EIGEN_GPUCC)
 1341|       |template <>
 1342|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float log(const float& x) {
 1343|       |  return ::logf(x);
 1344|       |}
 1345|       |
 1346|       |template <>
 1347|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double log(const double& x) {
 1348|       |  return ::log(x);
 1349|       |}
 1350|       |#endif
 1351|       |
 1352|       |template <typename T>
 1353|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 1354|       |    std::enable_if_t<NumTraits<T>::IsSigned || NumTraits<T>::IsComplex, typename NumTraits<T>::Real>
 1355|      0|    abs(const T& x) {
 1356|      0|  EIGEN_USING_STD(abs);
 1357|      0|  return abs(x);
 1358|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext3absIfEENSt9enable_ifIXoosr9NumTraitsIT_EE8IsSignedsr9NumTraitsIS3_EE9IsComplexENS_9NumTraitsIS3_E4RealEE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext3absIdEENSt9enable_ifIXoosr9NumTraitsIT_EE8IsSignedsr9NumTraitsIS3_EE9IsComplexENS_9NumTraitsIS3_E4RealEE4typeERKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext3absINS_4halfEEENSt9enable_ifIXoosr9NumTraitsIT_EE8IsSignedsr9NumTraitsIS4_EE9IsComplexENS_9NumTraitsIS4_E4RealEE4typeERKS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext3absINS_8bfloat16EEENSt9enable_ifIXoosr9NumTraitsIT_EE8IsSignedsr9NumTraitsIS4_EE9IsComplexENS_9NumTraitsIS4_E4RealEE4typeERKS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext3absIeEENSt9enable_ifIXoosr9NumTraitsIT_EE8IsSignedsr9NumTraitsIS3_EE9IsComplexENS_9NumTraitsIS3_E4RealEE4typeERKS3_
  ------------------
 1359|       |
 1360|       |template <typename T>
 1361|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 1362|       |    std::enable_if_t<!(NumTraits<T>::IsSigned || NumTraits<T>::IsComplex), typename NumTraits<T>::Real>
 1363|       |    abs(const T& x) {
 1364|       |  return x;
 1365|       |}
 1366|       |
 1367|       |#if defined(SYCL_DEVICE_ONLY)
 1368|       |SYCL_SPECIALIZE_INTEGER_TYPES_UNARY(abs, abs)
 1369|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(abs, fabs)
 1370|       |#endif
 1371|       |
 1372|       |#if defined(EIGEN_GPUCC)
 1373|       |template <>
 1374|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float abs(const float& x) {
 1375|       |  return ::fabsf(x);
 1376|       |}
 1377|       |
 1378|       |template <>
 1379|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double abs(const double& x) {
 1380|       |  return ::fabs(x);
 1381|       |}
 1382|       |
 1383|       |template <>
 1384|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float abs(const std::complex<float>& x) {
 1385|       |  return ::hypotf(x.real(), x.imag());
 1386|       |}
 1387|       |
 1388|       |template <>
 1389|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double abs(const std::complex<double>& x) {
 1390|       |  return ::hypot(x.real(), x.imag());
 1391|       |}
 1392|       |#endif
 1393|       |
 1394|       |template <typename Scalar, bool IsInteger = NumTraits<Scalar>::IsInteger, bool IsSigned = NumTraits<Scalar>::IsSigned>
 1395|       |struct signbit_impl;
 1396|       |template <typename Scalar>
 1397|       |struct signbit_impl<Scalar, false, true> {
 1398|       |  static constexpr size_t Size = sizeof(Scalar);
 1399|       |  static constexpr size_t Shift = (CHAR_BIT * Size) - 1;
 1400|       |  using intSize_t = typename get_integer_by_size<Size>::signed_type;
 1401|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static Scalar run(const Scalar& x) {
 1402|       |    intSize_t a = bit_cast<intSize_t, Scalar>(x);
 1403|       |    a = a >> Shift;
 1404|       |    Scalar result = bit_cast<Scalar, intSize_t>(a);
 1405|       |    return result;
 1406|       |  }
 1407|       |};
 1408|       |template <typename Scalar>
 1409|       |struct signbit_impl<Scalar, true, true> {
 1410|       |  static constexpr size_t Size = sizeof(Scalar);
 1411|       |  static constexpr size_t Shift = (CHAR_BIT * Size) - 1;
 1412|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static constexpr Scalar run(const Scalar& x) { return x >> Shift; }
 1413|       |};
 1414|       |template <typename Scalar>
 1415|       |struct signbit_impl<Scalar, true, false> {
 1416|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static constexpr Scalar run(const Scalar&) { return Scalar(0); }
 1417|       |};
 1418|       |template <typename Scalar>
 1419|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static constexpr Scalar signbit(const Scalar& x) {
 1420|       |  return signbit_impl<Scalar>::run(x);
 1421|       |}
 1422|       |
 1423|       |template <typename T>
 1424|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T exp(const T& x) {
 1425|      0|  EIGEN_USING_STD(exp);
 1426|      0|  return exp(x);
 1427|      0|}
 1428|       |
 1429|       |// MSVC screws up some edge-cases for std::exp(complex).
 1430|       |#ifdef EIGEN_COMP_MSVC
 1431|       |template <typename RealScalar>
 1432|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE std::complex<RealScalar> exp(const std::complex<RealScalar>& x) {
 1433|       |  EIGEN_USING_STD(exp);
 1434|       |  // If z is (x,) (for any finite x), the result is (NaN,NaN) and FE_INVALID is raised.
 1435|       |  // If z is (x,NaN) (for any finite x), the result is (NaN,NaN) and FE_INVALID may be raised.
 1436|       |  if ((isfinite)(real_ref(x)) && !(isfinite)(imag_ref(x))) {
 1437|       |    return std::complex<RealScalar>(NumTraits<RealScalar>::quiet_NaN(), NumTraits<RealScalar>::quiet_NaN());
 1438|       |  }
 1439|       |  // If z is (+,), the result is (,NaN) and FE_INVALID is raised (the sign of the real part is unspecified)
 1440|       |  // If z is (+,NaN), the result is (,NaN) (the sign of the real part is unspecified)
 1441|       |  if ((real_ref(x) == NumTraits<RealScalar>::infinity() && !(isfinite)(imag_ref(x)))) {
 1442|       |    return std::complex<RealScalar>(NumTraits<RealScalar>::infinity(), NumTraits<RealScalar>::quiet_NaN());
 1443|       |  }
 1444|       |  return exp(x);
 1445|       |}
 1446|       |#endif
 1447|       |
 1448|       |#if defined(SYCL_DEVICE_ONLY)
 1449|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(exp, exp)
 1450|       |#endif
 1451|       |
 1452|       |#if defined(EIGEN_GPUCC)
 1453|       |template <>
 1454|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float exp(const float& x) {
 1455|       |  return ::expf(x);
 1456|       |}
 1457|       |
 1458|       |template <>
 1459|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double exp(const double& x) {
 1460|       |  return ::exp(x);
 1461|       |}
 1462|       |
 1463|       |template <>
 1464|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE std::complex<float> exp(const std::complex<float>& x) {
 1465|       |  float com = ::expf(x.real());
 1466|       |  float res_real = com * ::cosf(x.imag());
 1467|       |  float res_imag = com * ::sinf(x.imag());
 1468|       |  return std::complex<float>(res_real, res_imag);
 1469|       |}
 1470|       |
 1471|       |template <>
 1472|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE std::complex<double> exp(const std::complex<double>& x) {
 1473|       |  double com = ::exp(x.real());
 1474|       |  double res_real = com * ::cos(x.imag());
 1475|       |  double res_imag = com * ::sin(x.imag());
 1476|       |  return std::complex<double>(res_real, res_imag);
 1477|       |}
 1478|       |#endif
 1479|       |
 1480|       |template <typename T>
 1481|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T exp2(const T& x) {
 1482|       |  EIGEN_USING_STD(exp2);
 1483|       |  return exp2(x);
 1484|       |}
 1485|       |
 1486|       |// MSVC screws up some edge-cases for std::exp2(complex).
 1487|       |#ifdef EIGEN_COMP_MSVC
 1488|       |template <typename RealScalar>
 1489|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE std::complex<RealScalar> exp2(const std::complex<RealScalar>& x) {
 1490|       |  EIGEN_USING_STD(exp);
 1491|       |  // If z is (x,) (for any finite x), the result is (NaN,NaN) and FE_INVALID is raised.
 1492|       |  // If z is (x,NaN) (for any finite x), the result is (NaN,NaN) and FE_INVALID may be raised.
 1493|       |  if ((isfinite)(real_ref(x)) && !(isfinite)(imag_ref(x))) {
 1494|       |    return std::complex<RealScalar>(NumTraits<RealScalar>::quiet_NaN(), NumTraits<RealScalar>::quiet_NaN());
 1495|       |  }
 1496|       |  // If z is (+,), the result is (,NaN) and FE_INVALID is raised (the sign of the real part is unspecified)
 1497|       |  // If z is (+,NaN), the result is (,NaN) (the sign of the real part is unspecified)
 1498|       |  if ((real_ref(x) == NumTraits<RealScalar>::infinity() && !(isfinite)(imag_ref(x)))) {
 1499|       |    return std::complex<RealScalar>(NumTraits<RealScalar>::infinity(), NumTraits<RealScalar>::quiet_NaN());
 1500|       |  }
 1501|       |  return exp2(x);
 1502|       |}
 1503|       |#endif
 1504|       |
 1505|       |#if defined(SYCL_DEVICE_ONLY)
 1506|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(exp2, exp2)
 1507|       |#endif
 1508|       |
 1509|       |#if defined(EIGEN_GPUCC)
 1510|       |template <>
 1511|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float exp2(const float& x) {
 1512|       |  return ::exp2f(x);
 1513|       |}
 1514|       |
 1515|       |template <>
 1516|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double exp2(const double& x) {
 1517|       |  return ::exp2(x);
 1518|       |}
 1519|       |
 1520|       |template <>
 1521|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE std::complex<float> exp2(const std::complex<float>& x) {
 1522|       |  float com = ::exp2f(x.real());
 1523|       |  float res_real = com * ::cosf(static_cast<float>(EIGEN_LN2) * x.imag());
 1524|       |  float res_imag = com * ::sinf(static_cast<float>(EIGEN_LN2) * x.imag());
 1525|       |  return std::complex<float>(res_real, res_imag);
 1526|       |}
 1527|       |
 1528|       |template <>
 1529|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE std::complex<double> exp2(const std::complex<double>& x) {
 1530|       |  double com = ::exp2(x.real());
 1531|       |  double res_real = com * ::cos(static_cast<double>(EIGEN_LN2) * x.imag());
 1532|       |  double res_imag = com * ::sin(static_cast<double>(EIGEN_LN2) * x.imag());
 1533|       |  return std::complex<double>(res_real, res_imag);
 1534|       |}
 1535|       |#endif
 1536|       |
 1537|       |template <typename Scalar>
 1538|      0|EIGEN_DEVICE_FUNC inline EIGEN_MATHFUNC_RETVAL(expm1, Scalar) expm1(const Scalar& x) {
 1539|      0|  return EIGEN_MATHFUNC_IMPL(expm1, Scalar)::run(x);
 1540|      0|}
 1541|       |
 1542|       |#if defined(SYCL_DEVICE_ONLY)
 1543|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(expm1, expm1)
 1544|       |#endif
 1545|       |
 1546|       |#if defined(EIGEN_GPUCC)
 1547|       |template <>
 1548|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float expm1(const float& x) {
 1549|       |  return ::expm1f(x);
 1550|       |}
 1551|       |
 1552|       |template <>
 1553|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double expm1(const double& x) {
 1554|       |  return ::expm1(x);
 1555|       |}
 1556|       |#endif
 1557|       |
 1558|       |template <typename T>
 1559|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T cos(const T& x) {
 1560|       |  EIGEN_USING_STD(cos);
 1561|       |  return cos(x);
 1562|       |}
 1563|       |
 1564|       |#if defined(SYCL_DEVICE_ONLY)
 1565|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(cos, cos)
 1566|       |#endif
 1567|       |
 1568|       |#if defined(EIGEN_GPUCC)
 1569|       |template <>
 1570|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float cos(const float& x) {
 1571|       |  return ::cosf(x);
 1572|       |}
 1573|       |
 1574|       |template <>
 1575|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double cos(const double& x) {
 1576|       |  return ::cos(x);
 1577|       |}
 1578|       |#endif
 1579|       |
 1580|       |template <typename T>
 1581|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T sin(const T& x) {
 1582|       |  EIGEN_USING_STD(sin);
 1583|       |  return sin(x);
 1584|       |}
 1585|       |
 1586|       |#if defined(SYCL_DEVICE_ONLY)
 1587|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(sin, sin)
 1588|       |#endif
 1589|       |
 1590|       |#if defined(EIGEN_GPUCC)
 1591|       |template <>
 1592|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float sin(const float& x) {
 1593|       |  return ::sinf(x);
 1594|       |}
 1595|       |
 1596|       |template <>
 1597|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double sin(const double& x) {
 1598|       |  return ::sin(x);
 1599|       |}
 1600|       |#endif
 1601|       |
 1602|       |template <typename T>
 1603|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T tan(const T& x) {
 1604|       |  EIGEN_USING_STD(tan);
 1605|       |  return tan(x);
 1606|       |}
 1607|       |
 1608|       |#if defined(SYCL_DEVICE_ONLY)
 1609|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(tan, tan)
 1610|       |#endif
 1611|       |
 1612|       |#if defined(EIGEN_GPUCC)
 1613|       |template <>
 1614|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float tan(const float& x) {
 1615|       |  return ::tanf(x);
 1616|       |}
 1617|       |
 1618|       |template <>
 1619|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double tan(const double& x) {
 1620|       |  return ::tan(x);
 1621|       |}
 1622|       |#endif
 1623|       |
 1624|       |template <typename T>
 1625|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T acos(const T& x) {
 1626|       |  EIGEN_USING_STD(acos);
 1627|       |  return acos(x);
 1628|       |}
 1629|       |
 1630|       |template <typename T>
 1631|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T acosh(const T& x) {
 1632|       |  EIGEN_USING_STD(acosh);
 1633|       |  return static_cast<T>(acosh(x));
 1634|       |}
 1635|       |
 1636|       |#if defined(SYCL_DEVICE_ONLY)
 1637|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(acos, acos)
 1638|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(acosh, acosh)
 1639|       |#endif
 1640|       |
 1641|       |#if defined(EIGEN_GPUCC)
 1642|       |template <>
 1643|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float acos(const float& x) {
 1644|       |  return ::acosf(x);
 1645|       |}
 1646|       |
 1647|       |template <>
 1648|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double acos(const double& x) {
 1649|       |  return ::acos(x);
 1650|       |}
 1651|       |#endif
 1652|       |
 1653|       |template <typename T>
 1654|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T asin(const T& x) {
 1655|       |  EIGEN_USING_STD(asin);
 1656|       |  return asin(x);
 1657|       |}
 1658|       |
 1659|       |template <typename T>
 1660|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T asinh(const T& x) {
 1661|       |  EIGEN_USING_STD(asinh);
 1662|       |  return static_cast<T>(asinh(x));
 1663|       |}
 1664|       |
 1665|       |#if defined(SYCL_DEVICE_ONLY)
 1666|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(asin, asin)
 1667|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(asinh, asinh)
 1668|       |#endif
 1669|       |
 1670|       |#if defined(EIGEN_GPUCC)
 1671|       |template <>
 1672|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float asin(const float& x) {
 1673|       |  return ::asinf(x);
 1674|       |}
 1675|       |
 1676|       |template <>
 1677|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double asin(const double& x) {
 1678|       |  return ::asin(x);
 1679|       |}
 1680|       |#endif
 1681|       |
 1682|       |template <typename T>
 1683|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T atan(const T& x) {
 1684|       |  EIGEN_USING_STD(atan);
 1685|       |  return static_cast<T>(atan(x));
 1686|       |}
 1687|       |
 1688|       |template <typename T, std::enable_if_t<!NumTraits<T>::IsComplex, int> = 0>
 1689|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T atan2(const T& y, const T& x) {
 1690|       |  EIGEN_USING_STD(atan2);
 1691|       |  return static_cast<T>(atan2(y, x));
 1692|       |}
 1693|       |
 1694|       |template <typename T>
 1695|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T atanh(const T& x) {
 1696|       |  EIGEN_USING_STD(atanh);
 1697|       |  return static_cast<T>(atanh(x));
 1698|       |}
 1699|       |
 1700|       |#if defined(SYCL_DEVICE_ONLY)
 1701|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(atan, atan)
 1702|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(atanh, atanh)
 1703|       |#endif
 1704|       |
 1705|       |#if defined(EIGEN_GPUCC)
 1706|       |template <>
 1707|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float atan(const float& x) {
 1708|       |  return ::atanf(x);
 1709|       |}
 1710|       |
 1711|       |template <>
 1712|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double atan(const double& x) {
 1713|       |  return ::atan(x);
 1714|       |}
 1715|       |#endif
 1716|       |
 1717|       |template <typename T>
 1718|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T cosh(const T& x) {
 1719|       |  EIGEN_USING_STD(cosh);
 1720|       |  return static_cast<T>(cosh(x));
 1721|       |}
 1722|       |
 1723|       |#if defined(SYCL_DEVICE_ONLY)
 1724|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(cosh, cosh)
 1725|       |#endif
 1726|       |
 1727|       |#if defined(EIGEN_GPUCC)
 1728|       |template <>
 1729|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float cosh(const float& x) {
 1730|       |  return ::coshf(x);
 1731|       |}
 1732|       |
 1733|       |template <>
 1734|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double cosh(const double& x) {
 1735|       |  return ::cosh(x);
 1736|       |}
 1737|       |#endif
 1738|       |
 1739|       |template <typename T>
 1740|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T sinh(const T& x) {
 1741|       |  EIGEN_USING_STD(sinh);
 1742|       |  return static_cast<T>(sinh(x));
 1743|       |}
 1744|       |
 1745|       |#if defined(SYCL_DEVICE_ONLY)
 1746|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(sinh, sinh)
 1747|       |#endif
 1748|       |
 1749|       |#if defined(EIGEN_GPUCC)
 1750|       |template <>
 1751|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float sinh(const float& x) {
 1752|       |  return ::sinhf(x);
 1753|       |}
 1754|       |
 1755|       |template <>
 1756|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double sinh(const double& x) {
 1757|       |  return ::sinh(x);
 1758|       |}
 1759|       |#endif
 1760|       |
 1761|       |template <typename T>
 1762|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T tanh(const T& x) {
 1763|       |  EIGEN_USING_STD(tanh);
 1764|       |  return tanh(x);
 1765|       |}
 1766|       |
 1767|       |#if (!defined(EIGEN_GPUCC)) && EIGEN_FAST_MATH && !defined(SYCL_DEVICE_ONLY)
 1768|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float tanh(float x) { return internal::ptanh_float(x); }
 1769|       |#endif
 1770|       |
 1771|       |#if defined(SYCL_DEVICE_ONLY)
 1772|       |SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(tanh, tanh)
 1773|       |#endif
 1774|       |
 1775|       |#if defined(EIGEN_GPUCC)
 1776|       |template <>
 1777|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float tanh(const float& x) {
 1778|       |  return ::tanhf(x);
 1779|       |}
 1780|       |
 1781|       |template <>
 1782|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double tanh(const double& x) {
 1783|       |  return ::tanh(x);
 1784|       |}
 1785|       |#endif
 1786|       |
 1787|       |template <typename T>
 1788|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE T fmod(const T& a, const T& b) {
 1789|       |  EIGEN_USING_STD(fmod);
 1790|       |  return fmod(a, b);
 1791|       |}
 1792|       |
 1793|       |#if defined(SYCL_DEVICE_ONLY)
 1794|       |SYCL_SPECIALIZE_FLOATING_TYPES_BINARY(fmod, fmod)
 1795|       |#endif
 1796|       |
 1797|       |#if defined(EIGEN_GPUCC)
 1798|       |template <>
 1799|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float fmod(const float& a, const float& b) {
 1800|       |  return ::fmodf(a, b);
 1801|       |}
 1802|       |
 1803|       |template <>
 1804|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double fmod(const double& a, const double& b) {
 1805|       |  return ::fmod(a, b);
 1806|       |}
 1807|       |#endif
 1808|       |
 1809|       |#if defined(SYCL_DEVICE_ONLY)
 1810|       |#undef SYCL_SPECIALIZE_SIGNED_INTEGER_TYPES_BINARY
 1811|       |#undef SYCL_SPECIALIZE_SIGNED_INTEGER_TYPES_UNARY
 1812|       |#undef SYCL_SPECIALIZE_UNSIGNED_INTEGER_TYPES_BINARY
 1813|       |#undef SYCL_SPECIALIZE_UNSIGNED_INTEGER_TYPES_UNARY
 1814|       |#undef SYCL_SPECIALIZE_INTEGER_TYPES_BINARY
 1815|       |#undef SYCL_SPECIALIZE_UNSIGNED_INTEGER_TYPES_UNARY
 1816|       |#undef SYCL_SPECIALIZE_FLOATING_TYPES_BINARY
 1817|       |#undef SYCL_SPECIALIZE_FLOATING_TYPES_UNARY
 1818|       |#undef SYCL_SPECIALIZE_FLOATING_TYPES_UNARY_FUNC_RET_TYPE
 1819|       |#undef SYCL_SPECIALIZE_GEN_UNARY_FUNC
 1820|       |#undef SYCL_SPECIALIZE_UNARY_FUNC
 1821|       |#undef SYCL_SPECIALIZE_GEN1_BINARY_FUNC
 1822|       |#undef SYCL_SPECIALIZE_GEN2_BINARY_FUNC
 1823|       |#undef SYCL_SPECIALIZE_BINARY_FUNC
 1824|       |#endif
 1825|       |
 1826|       |template <typename Scalar, typename Enable = std::enable_if_t<std::is_integral<Scalar>::value>>
 1827|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar logical_shift_left(const Scalar& a, int n) {
 1828|       |  return a << n;
 1829|       |}
 1830|       |
 1831|       |template <typename Scalar, typename Enable = std::enable_if_t<std::is_integral<Scalar>::value>>
 1832|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar logical_shift_right(const Scalar& a, int n) {
 1833|       |  using UnsignedScalar = typename numext::get_integer_by_size<sizeof(Scalar)>::unsigned_type;
 1834|       |  return bit_cast<Scalar, UnsignedScalar>(bit_cast<UnsignedScalar, Scalar>(a) >> n);
 1835|       |}
 1836|       |
 1837|       |template <typename Scalar, typename Enable = std::enable_if_t<std::is_integral<Scalar>::value>>
 1838|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar arithmetic_shift_right(const Scalar& a, int n) {
 1839|       |  using SignedScalar = typename numext::get_integer_by_size<sizeof(Scalar)>::signed_type;
 1840|       |  return bit_cast<Scalar, SignedScalar>(bit_cast<SignedScalar, Scalar>(a) >> n);
 1841|       |}
 1842|       |
 1843|       |}  // end namespace numext
 1844|       |
 1845|       |namespace internal {
 1846|       |
 1847|       |template <typename T>
 1848|       |EIGEN_DEVICE_FUNC bool isfinite_impl(const std::complex<T>& x) {
 1849|       |  return (numext::isfinite)(numext::real(x)) && (numext::isfinite)(numext::imag(x));
 1850|       |}
 1851|       |
 1852|       |template <typename T>
 1853|       |EIGEN_DEVICE_FUNC bool isnan_impl(const std::complex<T>& x) {
 1854|       |  return (numext::isnan)(numext::real(x)) || (numext::isnan)(numext::imag(x));
 1855|       |}
 1856|       |
 1857|       |template <typename T>
 1858|       |EIGEN_DEVICE_FUNC bool isinf_impl(const std::complex<T>& x) {
 1859|       |  return ((numext::isinf)(numext::real(x)) || (numext::isinf)(numext::imag(x))) && (!(numext::isnan)(x));
 1860|       |}
 1861|       |
 1862|       |/****************************************************************************
 1863|       | * Implementation of fuzzy comparisons                                       *
 1864|       | ****************************************************************************/
 1865|       |
 1866|       |template <typename Scalar, bool IsComplex, bool IsInteger>
 1867|       |struct scalar_fuzzy_default_impl {};
 1868|       |
 1869|       |template <typename Scalar>
 1870|       |struct scalar_fuzzy_default_impl<Scalar, false, false> {
 1871|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
 1872|       |  template <typename OtherScalar>
 1873|       |  EIGEN_DEVICE_FUNC static inline bool isMuchSmallerThan(const Scalar& x, const OtherScalar& y,
 1874|      0|                                                         const RealScalar& prec) {
 1875|      0|    return numext::abs(x) <= numext::abs(y) * prec;
 1876|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIfLb0ELb0EE17isMuchSmallerThanIfEEbRKfRKT_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIdLb0ELb0EE17isMuchSmallerThanIdEEbRKdRKT_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implINS_4halfELb0ELb0EE17isMuchSmallerThanIS2_EEbRKS2_RKT_S6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implINS_8bfloat16ELb0ELb0EE17isMuchSmallerThanIS2_EEbRKS2_RKT_S6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIeLb0ELb0EE17isMuchSmallerThanIeEEbRKeRKT_S5_
  ------------------
 1877|      0|  EIGEN_DEVICE_FUNC static inline bool isApprox(const Scalar& x, const Scalar& y, const RealScalar& prec) {
 1878|      0|    return numext::abs(x - y) <= numext::mini(numext::abs(x), numext::abs(y)) * prec;
 1879|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIfLb0ELb0EE8isApproxERKfS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIdLb0ELb0EE8isApproxERKdS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implINS_4halfELb0ELb0EE8isApproxERKS2_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implINS_8bfloat16ELb0ELb0EE8isApproxERKS2_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIeLb0ELb0EE8isApproxERKeS4_S4_
  ------------------
 1880|      0|  EIGEN_DEVICE_FUNC static inline bool isApproxOrLessThan(const Scalar& x, const Scalar& y, const RealScalar& prec) {
 1881|      0|    return x <= y || isApprox(x, y, prec);
 1882|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIfLb0ELb0EE18isApproxOrLessThanERKfS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIdLb0ELb0EE18isApproxOrLessThanERKdS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implINS_4halfELb0ELb0EE18isApproxOrLessThanERKS2_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implINS_8bfloat16ELb0ELb0EE18isApproxOrLessThanERKS2_S5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIeLb0ELb0EE18isApproxOrLessThanERKeS4_S4_
  ------------------
 1883|       |};
 1884|       |
 1885|       |template <typename Scalar>
 1886|       |struct scalar_fuzzy_default_impl<Scalar, false, true> {
 1887|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
 1888|       |  template <typename OtherScalar>
 1889|      0|  EIGEN_DEVICE_FUNC static inline bool isMuchSmallerThan(const Scalar& x, const Scalar&, const RealScalar&) {
 1890|      0|    return x == Scalar(0);
 1891|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIsLb0ELb1EE17isMuchSmallerThanIsEEbRKsS5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implItLb0ELb1EE17isMuchSmallerThanItEEbRKtS5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIiLb0ELb1EE17isMuchSmallerThanIiEEbRKiS5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIjLb0ELb1EE17isMuchSmallerThanIjEEbRKjS5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIlLb0ELb1EE17isMuchSmallerThanIlEEbRKlS5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implImLb0ELb1EE17isMuchSmallerThanImEEbRKmS5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIxLb0ELb1EE17isMuchSmallerThanIxEEbRKxS5_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIyLb0ELb1EE17isMuchSmallerThanIyEEbRKyS5_S5_
  ------------------
 1892|      0|  EIGEN_DEVICE_FUNC static inline bool isApprox(const Scalar& x, const Scalar& y, const RealScalar&) { return x == y; }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIsLb0ELb1EE8isApproxERKsS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implItLb0ELb1EE8isApproxERKtS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIiLb0ELb1EE8isApproxERKiS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIjLb0ELb1EE8isApproxERKjS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIlLb0ELb1EE8isApproxERKlS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implImLb0ELb1EE8isApproxERKmS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIxLb0ELb1EE8isApproxERKxS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIyLb0ELb1EE8isApproxERKyS4_S4_
  ------------------
 1893|      0|  EIGEN_DEVICE_FUNC static inline bool isApproxOrLessThan(const Scalar& x, const Scalar& y, const RealScalar&) {
 1894|      0|    return x <= y;
 1895|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIsLb0ELb1EE18isApproxOrLessThanERKsS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implItLb0ELb1EE18isApproxOrLessThanERKtS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIiLb0ELb1EE18isApproxOrLessThanERKiS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIjLb0ELb1EE18isApproxOrLessThanERKjS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIlLb0ELb1EE18isApproxOrLessThanERKlS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implImLb0ELb1EE18isApproxOrLessThanERKmS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIxLb0ELb1EE18isApproxOrLessThanERKxS4_S4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implIyLb0ELb1EE18isApproxOrLessThanERKyS4_S4_
  ------------------
 1896|       |};
 1897|       |
 1898|       |template <typename Scalar>
 1899|       |struct scalar_fuzzy_default_impl<Scalar, true, false> {
 1900|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
 1901|       |  template <typename OtherScalar>
 1902|       |  EIGEN_DEVICE_FUNC static inline bool isMuchSmallerThan(const Scalar& x, const OtherScalar& y,
 1903|      0|                                                         const RealScalar& prec) {
 1904|      0|    return numext::abs2(x) <= numext::abs2(y) * prec * prec;
 1905|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implISt7complexIfELb1ELb0EE17isMuchSmallerThanIS3_EEbRKS3_RKT_RKf
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implISt7complexIdELb1ELb0EE17isMuchSmallerThanIS3_EEbRKS3_RKT_RKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implISt7complexIeELb1ELb0EE17isMuchSmallerThanIS3_EEbRKS3_RKT_RKe
  ------------------
 1906|      0|  EIGEN_DEVICE_FUNC static inline bool isApprox(const Scalar& x, const Scalar& y, const RealScalar& prec) {
 1907|      0|    return numext::abs2(x - y) <= numext::mini(numext::abs2(x), numext::abs2(y)) * prec * prec;
 1908|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implISt7complexIfELb1ELb0EE8isApproxERKS3_S6_RKf
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implISt7complexIdELb1ELb0EE8isApproxERKS3_S6_RKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25scalar_fuzzy_default_implISt7complexIeELb1ELb0EE8isApproxERKS3_S6_RKe
  ------------------
 1909|       |};
 1910|       |
 1911|       |template <typename Scalar>
 1912|       |struct scalar_fuzzy_impl
 1913|       |    : scalar_fuzzy_default_impl<Scalar, NumTraits<Scalar>::IsComplex, NumTraits<Scalar>::IsInteger> {};
 1914|       |
 1915|       |template <typename Scalar, typename OtherScalar>
 1916|       |EIGEN_DEVICE_FUNC inline bool isMuchSmallerThan(
 1917|       |    const Scalar& x, const OtherScalar& y,
 1918|      0|    const typename NumTraits<Scalar>::Real& precision = NumTraits<Scalar>::dummy_precision()) {
 1919|      0|  return scalar_fuzzy_impl<Scalar>::template isMuchSmallerThan<OtherScalar>(x, y, precision);
 1920|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIssEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIttEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIiiEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIjjEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIllEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanImmEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIxxEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIyyEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIffEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIddEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanINS_4halfES2_EEbRKT_RKT0_RKNS_9NumTraitsIS3_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanINS_8bfloat16ES2_EEbRKT_RKT0_RKNS_9NumTraitsIS3_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanISt7complexIfES3_EEbRKT_RKT0_RKNS_9NumTraitsIS4_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanISt7complexIdES3_EEbRKT_RKT0_RKNS_9NumTraitsIS4_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanISt7complexIeES3_EEbRKT_RKT0_RKNS_9NumTraitsIS4_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17isMuchSmallerThanIeeEEbRKT_RKT0_RKNS_9NumTraitsIS2_E4RealE
  ------------------
 1921|       |
 1922|       |template <typename Scalar>
 1923|       |EIGEN_DEVICE_FUNC inline bool isApprox(
 1924|       |    const Scalar& x, const Scalar& y,
 1925|      0|    const typename NumTraits<Scalar>::Real& precision = NumTraits<Scalar>::dummy_precision()) {
 1926|      0|  return scalar_fuzzy_impl<Scalar>::isApprox(x, y, precision);
 1927|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxIsEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxItEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxIiEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxIjEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxIlEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxImEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxIxEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxIyEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxIfEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxIdEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxINS_4halfEEEbRKT_S5_RKNS_9NumTraitsIS3_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxINS_8bfloat16EEEbRKT_S5_RKNS_9NumTraitsIS3_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxISt7complexIfEEEbRKT_S6_RKNS_9NumTraitsIS4_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxISt7complexIdEEEbRKT_S6_RKNS_9NumTraitsIS4_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxISt7complexIeEEEbRKT_S6_RKNS_9NumTraitsIS4_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal8isApproxIeEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
 1928|       |
 1929|       |template <typename Scalar>
 1930|       |EIGEN_DEVICE_FUNC inline bool isApproxOrLessThan(
 1931|       |    const Scalar& x, const Scalar& y,
 1932|      0|    const typename NumTraits<Scalar>::Real& precision = NumTraits<Scalar>::dummy_precision()) {
 1933|      0|  return scalar_fuzzy_impl<Scalar>::isApproxOrLessThan(x, y, precision);
 1934|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanIsEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanItEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanIiEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanIjEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanIlEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanImEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanIxEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanIyEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanIfEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanIdEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanINS_4halfEEEbRKT_S5_RKNS_9NumTraitsIS3_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanINS_8bfloat16EEEbRKT_S5_RKNS_9NumTraitsIS3_E4RealE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18isApproxOrLessThanIeEEbRKT_S4_RKNS_9NumTraitsIS2_E4RealE
  ------------------
 1935|       |
 1936|       |/******************************************
 1937|       |***  The special case of the  bool type ***
 1938|       |******************************************/
 1939|       |
 1940|       |template <>
 1941|       |struct scalar_fuzzy_impl<bool> {
 1942|       |  typedef bool RealScalar;
 1943|       |
 1944|       |  template <typename OtherScalar>
 1945|       |  EIGEN_DEVICE_FUNC static inline bool isMuchSmallerThan(const bool& x, const bool&, const bool&) {
 1946|       |    return !x;
 1947|       |  }
 1948|       |
 1949|      0|  EIGEN_DEVICE_FUNC static inline bool isApprox(bool x, bool y, bool) { return x == y; }
 1950|       |
 1951|      0|  EIGEN_DEVICE_FUNC static inline bool isApproxOrLessThan(const bool& x, const bool& y, const bool&) {
 1952|      0|    return (!x) || y;
 1953|      0|  }
 1954|       |};
 1955|       |
 1956|       |}  // end namespace internal
 1957|       |
 1958|       |// Default implementations that rely on other numext implementations
 1959|       |namespace internal {
 1960|       |
 1961|       |// Specialization for complex types that are not supported by std::expm1.
 1962|       |template <typename RealScalar>
 1963|       |struct expm1_impl<std::complex<RealScalar>> {
 1964|       |  EIGEN_STATIC_ASSERT_NON_INTEGER(RealScalar)
 1965|       |
 1966|       |  EIGEN_DEVICE_FUNC static inline std::complex<RealScalar> run(const std::complex<RealScalar>& x) {
 1967|       |    RealScalar xr = x.real();
 1968|       |    RealScalar xi = x.imag();
 1969|       |    // expm1(z) = exp(z) - 1
 1970|       |    //          = exp(x +  i * y) - 1
 1971|       |    //          = exp(x) * (cos(y) + i * sin(y)) - 1
 1972|       |    //          = exp(x) * cos(y) - 1 + i * exp(x) * sin(y)
 1973|       |    // Imag(expm1(z)) = exp(x) * sin(y)
 1974|       |    // Real(expm1(z)) = exp(x) * cos(y) - 1
 1975|       |    //          = exp(x) * cos(y) - 1.
 1976|       |    //          = expm1(x) + exp(x) * (cos(y) - 1)
 1977|       |    //          = expm1(x) + exp(x) * (2 * sin(y / 2) ** 2)
 1978|       |    RealScalar erm1 = numext::expm1<RealScalar>(xr);
 1979|       |    RealScalar er = erm1 + RealScalar(1.);
 1980|       |    RealScalar sin2 = numext::sin(xi / RealScalar(2.));
 1981|       |    sin2 = sin2 * sin2;
 1982|       |    RealScalar s = numext::sin(xi);
 1983|       |    RealScalar real_part = erm1 - RealScalar(2.) * er * sin2;
 1984|       |    return std::complex<RealScalar>(real_part, er * s);
 1985|       |  }
 1986|       |};
 1987|       |
 1988|       |template <typename T>
 1989|       |struct rsqrt_impl {
 1990|       |  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE T run(const T& x) { return T(1) / numext::sqrt(x); }
 1991|       |};
 1992|       |
 1993|       |#if defined(EIGEN_GPU_COMPILE_PHASE)
 1994|       |template <typename T>
 1995|       |struct conj_impl<std::complex<T>, true> {
 1996|       |  EIGEN_DEVICE_FUNC static inline std::complex<T> run(const std::complex<T>& x) {
 1997|       |    return std::complex<T>(numext::real(x), -numext::imag(x));
 1998|       |  }
 1999|       |};
 2000|       |#endif
 2001|       |
 2002|       |}  // end namespace internal
 2003|       |
 2004|       |}  // end namespace Eigen
 2005|       |
 2006|       |#endif  // EIGEN_MATHFUNCTIONS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/MathFunctionsImpl.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2014 Pedro Gonnet (pedro.gonnet@gmail.com)
    5|       |// Copyright (C) 2016 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_MATHFUNCTIONSIMPL_H
   12|       |#define EIGEN_MATHFUNCTIONSIMPL_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |
   21|       |/** \internal Fast reciprocal using Newton-Raphson's method.
   22|       |
   23|       | Preconditions:
   24|       |   1. The starting guess provided in approx_a_recip must have at least half
   25|       |      the leading mantissa bits in the correct result, such that a single
   26|       |      Newton-Raphson step is sufficient to get within 1-2 ulps of the correct
   27|       |      result.
   28|       |   2. If a is zero, approx_a_recip must be infinite with the same sign as a.
   29|       |   3. If a is infinite, approx_a_recip must be zero with the same sign as a.
   30|       |
   31|       |   If the preconditions are satisfied, which they are for for the _*_rcp_ps
   32|       |   instructions on x86, the result has a maximum relative error of 2 ulps,
   33|       |   and correctly handles reciprocals of zero, infinity, and NaN.
   34|       |*/
   35|       |template <typename Packet, int Steps>
   36|       |struct generic_reciprocal_newton_step {
   37|       |  static_assert(Steps > 0, "Steps must be at least 1.");
   38|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Packet run(const Packet& a, const Packet& approx_a_recip) {
   39|       |    using Scalar = typename unpacket_traits<Packet>::type;
   40|       |    const Packet two = pset1<Packet>(Scalar(2));
   41|       |    // Refine the approximation using one Newton-Raphson step:
   42|       |    //   x_{i} = x_{i-1} * (2 - a * x_{i-1})
   43|       |    const Packet x = generic_reciprocal_newton_step<Packet, Steps - 1>::run(a, approx_a_recip);
   44|       |    const Packet tmp = pnmadd(a, x, two);
   45|       |    // If tmp is NaN, it means that a is either +/-0 or +/-Inf.
   46|       |    // In this case return the approximation directly.
   47|       |    const Packet is_not_nan = pcmp_eq(tmp, tmp);
   48|       |    return pselect(is_not_nan, pmul(x, tmp), x);
   49|       |  }
   50|       |};
   51|       |
   52|       |template <typename Packet>
   53|       |struct generic_reciprocal_newton_step<Packet, 0> {
   54|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Packet run(const Packet& /*unused*/, const Packet& approx_rsqrt) {
   55|       |    return approx_rsqrt;
   56|       |  }
   57|       |};
   58|       |
   59|       |/** \internal Fast reciprocal sqrt using Newton-Raphson's method.
   60|       |
   61|       | Preconditions:
   62|       |   1. The starting guess provided in approx_a_recip must have at least half
   63|       |      the leading mantissa bits in the correct result, such that a single
   64|       |      Newton-Raphson step is sufficient to get within 1-2 ulps of the correct
   65|       |      result.
   66|       |   2. If a is zero, approx_a_recip must be infinite with the same sign as a.
   67|       |   3. If a is infinite, approx_a_recip must be zero with the same sign as a.
   68|       |
   69|       |   If the preconditions are satisfied, which they are for for the _*_rcp_ps
   70|       |   instructions on x86, the result has a maximum relative error of 2 ulps,
   71|       |   and correctly handles zero, infinity, and NaN. Positive denormals are
   72|       |   treated as zero.
   73|       |*/
   74|       |template <typename Packet, int Steps>
   75|       |struct generic_rsqrt_newton_step {
   76|       |  static_assert(Steps > 0, "Steps must be at least 1.");
   77|       |  using Scalar = typename unpacket_traits<Packet>::type;
   78|      0|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Packet run(const Packet& a, const Packet& approx_rsqrt) {
   79|      0|    constexpr Scalar kMinusHalf = Scalar(-1) / Scalar(2);
   80|      0|    const Packet cst_minus_half = pset1<Packet>(kMinusHalf);
   81|      0|    const Packet cst_minus_one = pset1<Packet>(Scalar(-1));
   82|      0|
   83|      0|    Packet inv_sqrt = approx_rsqrt;
   84|      0|    for (int step = 0; step < Steps; ++step) {
   85|      0|      // Refine the approximation using one Newton-Raphson step:
   86|      0|      // h_n = (x * inv_sqrt) * inv_sqrt - 1 (so that h_n is nearly 0).
   87|      0|      // inv_sqrt = inv_sqrt - 0.5 * inv_sqrt * h_n
   88|      0|      Packet r2 = pmul(a, inv_sqrt);
   89|      0|      Packet half_r = pmul(inv_sqrt, cst_minus_half);
   90|      0|      Packet h_n = pmadd(r2, inv_sqrt, cst_minus_one);
   91|      0|      inv_sqrt = pmadd(half_r, h_n, inv_sqrt);
   92|      0|    }
   93|      0|
   94|      0|    // If x is NaN, then either:
   95|      0|    // 1) the input is NaN
   96|      0|    // 2) zero and infinity were multiplied
   97|      0|    // In either of these cases, return approx_rsqrt
   98|      0|    return pselect(pisnan(inv_sqrt), approx_rsqrt, inv_sqrt);
   99|      0|  }
  100|       |};
  101|       |
  102|       |template <typename Packet>
  103|       |struct generic_rsqrt_newton_step<Packet, 0> {
  104|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Packet run(const Packet& /*unused*/, const Packet& approx_rsqrt) {
  105|       |    return approx_rsqrt;
  106|       |  }
  107|       |};
  108|       |
  109|       |/** \internal Fast sqrt using Newton-Raphson's method.
  110|       |
  111|       | Preconditions:
  112|       |   1. The starting guess for the reciprocal sqrt provided in approx_rsqrt must
  113|       |      have at least half the leading mantissa bits in the correct result, such
  114|       |      that a single Newton-Raphson step is sufficient to get within 1-2 ulps of
  115|       |      the correct result.
  116|       |   2. If a is zero, approx_rsqrt must be infinite.
  117|       |   3. If a is infinite, approx_rsqrt must be zero.
  118|       |
  119|       |   If the preconditions are satisfied, which they are for for the _*_rsqrt_ps
  120|       |   instructions on x86, the result has a maximum relative error of 2 ulps,
  121|       |   and correctly handles zero and infinity, and NaN. Positive denormal inputs
  122|       |   are treated as zero.
  123|       |*/
  124|       |template <typename Packet, int Steps = 1>
  125|       |struct generic_sqrt_newton_step {
  126|       |  static_assert(Steps > 0, "Steps must be at least 1.");
  127|       |
  128|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Packet run(const Packet& a, const Packet& approx_rsqrt) {
  129|       |    using Scalar = typename unpacket_traits<Packet>::type;
  130|       |    const Packet one_point_five = pset1<Packet>(Scalar(1.5));
  131|       |    const Packet minus_half = pset1<Packet>(Scalar(-0.5));
  132|       |    // If a is inf or zero, return a directly.
  133|       |    const Packet inf_mask = pcmp_eq(a, pset1<Packet>(NumTraits<Scalar>::infinity()));
  134|       |    const Packet return_a = por(pcmp_eq(a, pzero(a)), inf_mask);
  135|       |    // Do a single step of Newton's iteration for reciprocal square root:
  136|       |    //   x_{n+1} = x_n * (1.5 + (-0.5 * x_n) * (a * x_n))).
  137|       |    // The Newton's step is computed this way to avoid over/under-flows.
  138|       |    Packet rsqrt = pmul(approx_rsqrt, pmadd(pmul(minus_half, approx_rsqrt), pmul(a, approx_rsqrt), one_point_five));
  139|       |    for (int step = 1; step < Steps; ++step) {
  140|       |      rsqrt = pmul(rsqrt, pmadd(pmul(minus_half, rsqrt), pmul(a, rsqrt), one_point_five));
  141|       |    }
  142|       |
  143|       |    // Return sqrt(x) = x * rsqrt(x) for non-zero finite positive arguments.
  144|       |    // Return a itself for 0 or +inf, NaN for negative arguments.
  145|       |    return pselect(return_a, a, pmul(a, rsqrt));
  146|       |  }
  147|       |};
  148|       |
  149|       |template <typename RealScalar>
  150|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE RealScalar positive_real_hypot(const RealScalar& x, const RealScalar& y) {
  151|       |  // IEEE IEC 6059 special cases.
  152|       |  if ((numext::isinf)(x) || (numext::isinf)(y)) return NumTraits<RealScalar>::infinity();
  153|       |  if ((numext::isnan)(x) || (numext::isnan)(y)) return NumTraits<RealScalar>::quiet_NaN();
  154|       |
  155|       |  EIGEN_USING_STD(sqrt);
  156|       |  RealScalar p, qp;
  157|       |  p = numext::maxi(x, y);
  158|       |  if (numext::is_exactly_zero(p)) return RealScalar(0);
  159|       |  qp = numext::mini(y, x) / p;
  160|       |  return p * sqrt(RealScalar(1) + qp * qp);
  161|       |}
  162|       |
  163|       |template <typename Scalar>
  164|       |struct hypot_impl {
  165|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  166|       |  static EIGEN_DEVICE_FUNC inline RealScalar run(const Scalar& x, const Scalar& y) {
  167|       |    EIGEN_USING_STD(abs);
  168|       |    return positive_real_hypot<RealScalar>(abs(x), abs(y));
  169|       |  }
  170|       |};
  171|       |
  172|       |// Generic complex sqrt implementation that correctly handles corner cases
  173|       |// according to https://en.cppreference.com/w/cpp/numeric/complex/sqrt
  174|       |template <typename T>
  175|       |EIGEN_DEVICE_FUNC std::complex<T> complex_sqrt(const std::complex<T>& z) {
  176|       |  // Computes the principal sqrt of the input.
  177|       |  //
  178|       |  // For a complex square root of the number x + i*y. We want to find real
  179|       |  // numbers u and v such that
  180|       |  //    (u + i*v)^2 = x + i*y  <=>
  181|       |  //    u^2 - v^2 + i*2*u*v = x + i*v.
  182|       |  // By equating the real and imaginary parts we get:
  183|       |  //    u^2 - v^2 = x
  184|       |  //    2*u*v = y.
  185|       |  //
  186|       |  // For x >= 0, this has the numerically stable solution
  187|       |  //    u = sqrt(0.5 * (x + sqrt(x^2 + y^2)))
  188|       |  //    v = y / (2 * u)
  189|       |  // and for x < 0,
  190|       |  //    v = sign(y) * sqrt(0.5 * (-x + sqrt(x^2 + y^2)))
  191|       |  //    u = y / (2 * v)
  192|       |  //
  193|       |  // Letting w = sqrt(0.5 * (|x| + |z|)),
  194|       |  //   if x == 0: u = w, v = sign(y) * w
  195|       |  //   if x > 0:  u = w, v = y / (2 * w)
  196|       |  //   if x < 0:  u = |y| / (2 * w), v = sign(y) * w
  197|       |
  198|       |  const T x = numext::real(z);
  199|       |  const T y = numext::imag(z);
  200|       |  const T zero = T(0);
  201|       |  const T w = numext::sqrt(T(0.5) * (numext::abs(x) + numext::hypot(x, y)));
  202|       |
  203|       |  return (numext::isinf)(y)           ? std::complex<T>(NumTraits<T>::infinity(), y)
  204|       |         : numext::is_exactly_zero(x) ? std::complex<T>(w, y < zero ? -w : w)
  205|       |         : x > zero                   ? std::complex<T>(w, y / (2 * w))
  206|       |                                      : std::complex<T>(numext::abs(y) / (2 * w), y < zero ? -w : w);
  207|       |}
  208|       |
  209|       |// Generic complex rsqrt implementation.
  210|       |template <typename T>
  211|       |EIGEN_DEVICE_FUNC std::complex<T> complex_rsqrt(const std::complex<T>& z) {
  212|       |  // Computes the principal reciprocal sqrt of the input.
  213|       |  //
  214|       |  // For a complex reciprocal square root of the number z = x + i*y. We want to
  215|       |  // find real numbers u and v such that
  216|       |  //    (u + i*v)^2 = 1 / (x + i*y)  <=>
  217|       |  //    u^2 - v^2 + i*2*u*v = x/|z|^2 - i*v/|z|^2.
  218|       |  // By equating the real and imaginary parts we get:
  219|       |  //    u^2 - v^2 = x/|z|^2
  220|       |  //    2*u*v = y/|z|^2.
  221|       |  //
  222|       |  // For x >= 0, this has the numerically stable solution
  223|       |  //    u = sqrt(0.5 * (x + |z|)) / |z|
  224|       |  //    v = -y / (2 * u * |z|)
  225|       |  // and for x < 0,
  226|       |  //    v = -sign(y) * sqrt(0.5 * (-x + |z|)) / |z|
  227|       |  //    u = -y / (2 * v * |z|)
  228|       |  //
  229|       |  // Letting w = sqrt(0.5 * (|x| + |z|)),
  230|       |  //   if x == 0: u = w / |z|, v = -sign(y) * w / |z|
  231|       |  //   if x > 0:  u = w / |z|, v = -y / (2 * w * |z|)
  232|       |  //   if x < 0:  u = |y| / (2 * w * |z|), v = -sign(y) * w / |z|
  233|       |
  234|       |  const T x = numext::real(z);
  235|       |  const T y = numext::imag(z);
  236|       |  const T zero = T(0);
  237|       |
  238|       |  const T abs_z = numext::hypot(x, y);
  239|       |  const T w = numext::sqrt(T(0.5) * (numext::abs(x) + abs_z));
  240|       |  const T woz = w / abs_z;
  241|       |  // Corner cases consistent with 1/sqrt(z) on gcc/clang.
  242|       |  return numext::is_exactly_zero(abs_z) ? std::complex<T>(NumTraits<T>::infinity(), NumTraits<T>::quiet_NaN())
  243|       |         : ((numext::isinf)(x) || (numext::isinf)(y)) ? std::complex<T>(zero, zero)
  244|       |         : numext::is_exactly_zero(x)                 ? std::complex<T>(woz, y < zero ? woz : -woz)
  245|       |         : x > zero                                   ? std::complex<T>(woz, -y / (2 * w * abs_z))
  246|       |                    : std::complex<T>(numext::abs(y) / (2 * w * abs_z), y < zero ? woz : -woz);
  247|       |}
  248|       |
  249|       |template <typename T>
  250|       |EIGEN_DEVICE_FUNC std::complex<T> complex_log(const std::complex<T>& z) {
  251|       |  // Computes complex log.
  252|       |  T a = numext::abs(z);
  253|       |  EIGEN_USING_STD(atan2);
  254|       |  T b = atan2(z.imag(), z.real());
  255|       |  return std::complex<T>(numext::log(a), b);
  256|       |}
  257|       |
  258|       |}  // end namespace internal
  259|       |
  260|       |}  // end namespace Eigen
  261|       |
  262|       |#endif  // EIGEN_MATHFUNCTIONSIMPL_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Matrix.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2008-2009 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_MATRIX_H
   12|       |#define EIGEN_MATRIX_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
   21|       |struct traits<Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>> {
   22|       | private:
   23|       |  constexpr static int size = internal::size_at_compile_time(Rows_, Cols_);
   24|       |  typedef typename find_best_packet<Scalar_, size>::type PacketScalar;
   25|       |  enum {
   26|       |    row_major_bit = Options_ & RowMajor ? RowMajorBit : 0,
   27|       |    is_dynamic_size_storage = MaxRows_ == Dynamic || MaxCols_ == Dynamic,
   28|       |    max_size = is_dynamic_size_storage ? Dynamic : MaxRows_ * MaxCols_,
   29|       |    default_alignment = compute_default_alignment<Scalar_, max_size>::value,
   30|       |    actual_alignment = ((Options_ & DontAlign) == 0) ? default_alignment : 0,
   31|       |    required_alignment = unpacket_traits<PacketScalar>::alignment,
   32|       |    packet_access_bit = (packet_traits<Scalar_>::Vectorizable &&
   33|       |                         (EIGEN_UNALIGNED_VECTORIZE || (int(actual_alignment) >= int(required_alignment))))
   34|       |                            ? PacketAccessBit
   35|       |                            : 0
   36|       |  };
   37|       |
   38|       | public:
   39|       |  typedef Scalar_ Scalar;
   40|       |  typedef Dense StorageKind;
   41|       |  typedef Eigen::Index StorageIndex;
   42|       |  typedef MatrixXpr XprKind;
   43|       |  enum {
   44|       |    RowsAtCompileTime = Rows_,
   45|       |    ColsAtCompileTime = Cols_,
   46|       |    MaxRowsAtCompileTime = MaxRows_,
   47|       |    MaxColsAtCompileTime = MaxCols_,
   48|       |    Flags = compute_matrix_flags(Options_),
   49|       |    Options = Options_,
   50|       |    InnerStrideAtCompileTime = 1,
   51|       |    OuterStrideAtCompileTime = (int(Options) & int(RowMajor)) ? ColsAtCompileTime : RowsAtCompileTime,
   52|       |
   53|       |    // FIXME, the following flag in only used to define NeedsToAlign in PlainObjectBase
   54|       |    EvaluatorFlags = LinearAccessBit | DirectAccessBit | packet_access_bit | row_major_bit,
   55|       |    Alignment = actual_alignment
   56|       |  };
   57|       |};
   58|       |}  // namespace internal
   59|       |
   60|       |/** \class Matrix
   61|       | * \ingroup Core_Module
   62|       | *
   63|       | * \brief The matrix class, also used for vectors and row-vectors
   64|       | *
   65|       | * The %Matrix class is the work-horse for all \em dense (\ref dense "note") matrices and vectors within Eigen.
   66|       | * Vectors are matrices with one column, and row-vectors are matrices with one row.
   67|       | *
   68|       | * The %Matrix class encompasses \em both fixed-size and dynamic-size objects (\ref fixedsize "note").
   69|       | *
   70|       | * The first three template parameters are required:
   71|       | * \tparam Scalar_ Numeric type, e.g. float, double, int or std::complex<float>.
   72|       | *                 User defined scalar types are supported as well (see \ref user_defined_scalars "here").
   73|       | * \tparam Rows_ Number of rows, or \b Dynamic
   74|       | * \tparam Cols_ Number of columns, or \b Dynamic
   75|       | *
   76|       | * The remaining template parameters are optional -- in most cases you don't have to worry about them.
   77|       | * \tparam Options_ A combination of either \b #RowMajor or \b #ColMajor, and of either
   78|       | *                 \b #AutoAlign or \b #DontAlign.
   79|       | *                 The former controls \ref TopicStorageOrders "storage order", and defaults to column-major. The latter
   80|       | * controls alignment, which is required for vectorization. It defaults to aligning matrices except for fixed sizes that
   81|       | * aren't a multiple of the packet size. \tparam MaxRows_ Maximum number of rows. Defaults to \a Rows_ (\ref maxrows
   82|       | * "note"). \tparam MaxCols_ Maximum number of columns. Defaults to \a Cols_ (\ref maxrows "note").
   83|       | *
   84|       | * Eigen provides a number of typedefs covering the usual cases. Here are some examples:
   85|       | *
   86|       | * \li \c Matrix2d is a 2x2 square matrix of doubles (\c Matrix<double, 2, 2>)
   87|       | * \li \c Vector4f is a vector of 4 floats (\c Matrix<float, 4, 1>)
   88|       | * \li \c RowVector3i is a row-vector of 3 ints (\c Matrix<int, 1, 3>)
   89|       | *
   90|       | * \li \c MatrixXf is a dynamic-size matrix of floats (\c Matrix<float, Dynamic, Dynamic>)
   91|       | * \li \c VectorXf is a dynamic-size vector of floats (\c Matrix<float, Dynamic, 1>)
   92|       | *
   93|       | * \li \c Matrix2Xf is a partially fixed-size (dynamic-size) matrix of floats (\c Matrix<float, 2, Dynamic>)
   94|       | * \li \c MatrixX3d is a partially dynamic-size (fixed-size) matrix of double (\c Matrix<double, Dynamic, 3>)
   95|       | *
   96|       | * See \link matrixtypedefs this page \endlink for a complete list of predefined \em %Matrix and \em Vector typedefs.
   97|       | *
   98|       | * You can access elements of vectors and matrices using normal subscripting:
   99|       | *
  100|       | * \code
  101|       | * Eigen::VectorXd v(10);
  102|       | * v[0] = 0.1;
  103|       | * v[1] = 0.2;
  104|       | * v(0) = 0.3;
  105|       | * v(1) = 0.4;
  106|       | *
  107|       | * Eigen::MatrixXi m(10, 10);
  108|       | * m(0, 1) = 1;
  109|       | * m(0, 2) = 2;
  110|       | * m(0, 3) = 3;
  111|       | * \endcode
  112|       | *
  113|       | * This class can be extended with the help of the plugin mechanism described on the page
  114|       | * \ref TopicCustomizing_Plugins by defining the preprocessor symbol \c EIGEN_MATRIX_PLUGIN.
  115|       | *
  116|       | * <i><b>Some notes:</b></i>
  117|       | *
  118|       | * <dl>
  119|       | * <dt><b>\anchor dense Dense versus sparse:</b></dt>
  120|       | * <dd>This %Matrix class handles dense, not sparse matrices and vectors. For sparse matrices and vectors, see the
  121|       | * Sparse module.
  122|       | *
  123|       | * Dense matrices and vectors are plain usual arrays of coefficients. All the coefficients are stored, in an ordinary
  124|       | * contiguous array. This is unlike Sparse matrices and vectors where the coefficients are stored as a list of nonzero
  125|       | * coefficients.</dd>
  126|       | *
  127|       | * <dt><b>\anchor fixedsize Fixed-size versus dynamic-size:</b></dt>
  128|       | * <dd>Fixed-size means that the numbers of rows and columns are known at compile-time. In this case, Eigen allocates
  129|       | * the array of coefficients as a fixed-size array, as a class member. This makes sense for very small matrices,
  130|       | * typically up to 4x4, sometimes up to 16x16. Larger matrices should be declared as dynamic-size even if one happens to
  131|       | * know their size at compile-time.
  132|       | *
  133|       | * Dynamic-size means that the numbers of rows or columns are not necessarily known at compile-time. In this case they
  134|       | * are runtime variables, and the array of coefficients is allocated dynamically on the heap.
  135|       | *
  136|       | * Note that \em dense matrices, be they Fixed-size or Dynamic-size, <em>do not</em> expand dynamically in the sense of
  137|       | * a std::map. If you want this behavior, see the Sparse module.</dd>
  138|       | *
  139|       | * <dt><b>\anchor maxrows MaxRows_ and MaxCols_:</b></dt>
  140|       | * <dd>In most cases, one just leaves these parameters to the default values.
  141|       | * These parameters mean the maximum size of rows and columns that the matrix may have. They are useful in cases
  142|       | * when the exact numbers of rows and columns are not known at compile-time, but it is known at compile-time that they
  143|       | * cannot exceed a certain value. This happens when taking dynamic-size blocks inside fixed-size matrices: in this case
  144|       | * MaxRows_ and MaxCols_ are the dimensions of the original matrix, while Rows_ and Cols_ are Dynamic.</dd>
  145|       | * </dl>
  146|       | *
  147|       | * <i><b>ABI and storage layout</b></i>
  148|       | *
  149|       | * The table below summarizes the ABI of some possible Matrix instances which is fixed thorough the lifetime of Eigen 3.
  150|       | * <table  class="manual">
  151|       | * <tr><th>Matrix type</th><th>Equivalent C structure</th></tr>
  152|       | * <tr><td>\code Matrix<T,Dynamic,Dynamic> \endcode</td><td>\code
  153|       | * struct {
  154|       | *   T *data;                  // with (size_t(data)%EIGEN_MAX_ALIGN_BYTES)==0
  155|       | *   Eigen::Index rows, cols;
  156|       | *  };
  157|       | * \endcode</td></tr>
  158|       | * <tr class="alt"><td>\code
  159|       | * Matrix<T,Dynamic,1>
  160|       | * Matrix<T,1,Dynamic> \endcode</td><td>\code
  161|       | * struct {
  162|       | *   T *data;                  // with (size_t(data)%EIGEN_MAX_ALIGN_BYTES)==0
  163|       | *   Eigen::Index size;
  164|       | *  };
  165|       | * \endcode</td></tr>
  166|       | * <tr><td>\code Matrix<T,Rows,Cols> \endcode</td><td>\code
  167|       | * struct {
  168|       | *   T data[Rows*Cols];        // with (size_t(data)%A(Rows*Cols*sizeof(T)))==0
  169|       | *  };
  170|       | * \endcode</td></tr>
  171|       | * <tr class="alt"><td>\code Matrix<T,Dynamic,Dynamic,0,MaxRows,MaxCols> \endcode</td><td>\code
  172|       | * struct {
  173|       | *   T data[MaxRows*MaxCols];  // with (size_t(data)%A(MaxRows*MaxCols*sizeof(T)))==0
  174|       | *   Eigen::Index rows, cols;
  175|       | *  };
  176|       | * \endcode</td></tr>
  177|       | * </table>
  178|       | * Note that in this table Rows, Cols, MaxRows and MaxCols are all positive integers. A(S) is defined to the largest
  179|       | * possible power-of-two smaller to EIGEN_MAX_STATIC_ALIGN_BYTES.
  180|       | *
  181|       | * \see MatrixBase for the majority of the API methods for matrices, \ref TopicClassHierarchy,
  182|       | * \ref TopicStorageOrders
  183|       | */
  184|       |
  185|       |template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
  186|       |class Matrix : public PlainObjectBase<Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>> {
  187|       | public:
  188|       |  /** \brief Base class typedef.
  189|       |   * \sa PlainObjectBase
  190|       |   */
  191|       |  typedef PlainObjectBase<Matrix> Base;
  192|       |
  193|       |  enum { Options = Options_ };
  194|       |
  195|       |  EIGEN_DENSE_PUBLIC_INTERFACE(Matrix)
  196|       |
  197|       |  typedef typename Base::PlainObject PlainObject;
  198|       |
  199|       |  using Base::base;
  200|       |  using Base::coeffRef;
  201|       |
  202|       |  /**
  203|       |   * \brief Assigns matrices to each other.
  204|       |   *
  205|       |   * \note This is a special case of the templated operator=. Its purpose is
  206|       |   * to prevent a default operator= from hiding the templated operator=.
  207|       |   *
  208|       |   * \callgraph
  209|       |   */
  210|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix& operator=(const Matrix& other) { return Base::_set(other); }
  211|       |
  212|       |  /** \internal
  213|       |   * \brief Copies the value of the expression \a other into \c *this with automatic resizing.
  214|       |   *
  215|       |   * *this might be resized to match the dimensions of \a other. If *this was a null matrix (not already initialized),
  216|       |   * it will be initialized.
  217|       |   *
  218|       |   * Note that copying a row-vector into a vector (and conversely) is allowed.
  219|       |   * The resizing, if any, is then done in the appropriate way so that row-vectors
  220|       |   * remain row-vectors and vectors remain vectors.
  221|       |   */
  222|       |  template <typename OtherDerived>
  223|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix& operator=(const DenseBase<OtherDerived>& other) {
  224|      2|    return Base::_set(other);
  225|      2|  }
  ------------------
  | _ZN5Eigen6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEaSINS_7ProductINS4_INS0_IS1_Lin1ELin1ELi0ELin1ELin1EEES5_Li0EEES2_Li0EEEEERS2_RKNS_9DenseBaseIT_EE:
  |  223|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix& operator=(const DenseBase<OtherDerived>& other) {
  |  224|      1|    return Base::_set(other);
  |  225|      1|  }
  ------------------
  | _ZN5Eigen6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEaSINS_7ProductINS4_IS2_S2_Li0EEES2_Li0EEEEERS2_RKNS_9DenseBaseIT_EE:
  |  223|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix& operator=(const DenseBase<OtherDerived>& other) {
  |  224|      1|    return Base::_set(other);
  |  225|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEaSINS_3MapIS2_Li1ENS_6StrideILi0ELi0EEEEEEERS2_RKNS_9DenseBaseIT_EE
  ------------------
  226|       |
  227|       |  /* Here, doxygen failed to copy the brief information when using \copydoc */
  228|       |
  229|       |  /**
  230|       |   * \brief Copies the generic expression \a other into *this.
  231|       |   * \copydetails DenseBase::operator=(const EigenBase<OtherDerived> &other)
  232|       |   */
  233|       |  template <typename OtherDerived>
  234|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix& operator=(const EigenBase<OtherDerived>& other) {
  235|       |    return Base::operator=(other);
  236|       |  }
  237|       |
  238|       |  template <typename OtherDerived>
  239|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix& operator=(const ReturnByValue<OtherDerived>& func) {
  240|       |    return Base::operator=(func);
  241|       |  }
  242|       |
  243|       |  /** \brief Default constructor.
  244|       |   *
  245|       |   * For fixed-size matrices, does nothing.
  246|       |   *
  247|       |   * For dynamic-size matrices, creates an empty matrix of size 0. Does not allocate any array. Such a matrix
  248|       |   * is called a null matrix. This constructor is the unique way to create null matrices: resizing
  249|       |   * a matrix to 0 is not supported.
  250|       |   *
  251|       |   * \sa resize(Index,Index)
  252|       |   */
  253|       |#if defined(EIGEN_INITIALIZE_COEFFS)
  254|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix() { EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED }
  255|       |#else
  256|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix() = default;
  257|       |#endif
  258|       |  /** \brief Move constructor */
  259|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix(Matrix&&) = default;
  260|       |  /** \brief Moves the matrix into the other one.
  261|       |   *
  262|       |   */
  263|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix& operator=(Matrix&& other)
  264|       |      EIGEN_NOEXCEPT_IF(std::is_nothrow_move_assignable<Scalar>::value) {
  265|       |    Base::operator=(std::move(other));
  266|       |    return *this;
  267|       |  }
  268|       |
  269|       |  /** \copydoc PlainObjectBase(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&... args)
  270|       |   *
  271|       |   * Example: \include Matrix_variadic_ctor_cxx11.cpp
  272|       |   * Output: \verbinclude Matrix_variadic_ctor_cxx11.out
  273|       |   *
  274|       |   * \sa Matrix(const std::initializer_list<std::initializer_list<Scalar>>&)
  275|       |   */
  276|       |  template <typename... ArgTypes>
  277|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3,
  278|       |                                               const ArgTypes&... args)
  279|       |      : Base(a0, a1, a2, a3, args...) {}
  280|       |
  281|       |  /** \brief Constructs a Matrix and initializes it from the coefficients given as initializer-lists grouped by row.
  282|       |   * \cpp11
  283|       |   *
  284|       |   * In the general case, the constructor takes a list of rows, each row being represented as a list of coefficients:
  285|       |   *
  286|       |   * Example: \include Matrix_initializer_list_23_cxx11.cpp
  287|       |   * Output: \verbinclude Matrix_initializer_list_23_cxx11.out
  288|       |   *
  289|       |   * Each of the inner initializer lists must contain the exact same number of elements, otherwise an assertion is
  290|       |   * triggered.
  291|       |   *
  292|       |   * In the case of a compile-time column vector, implicit transposition from a single row is allowed.
  293|       |   * Therefore <code>VectorXd{{1,2,3,4,5}}</code> is legal and the more verbose syntax
  294|       |   * <code>RowVectorXd{{1},{2},{3},{4},{5}}</code> can be avoided:
  295|       |   *
  296|       |   * Example: \include Matrix_initializer_list_vector_cxx11.cpp
  297|       |   * Output: \verbinclude Matrix_initializer_list_vector_cxx11.out
  298|       |   *
  299|       |   * In the case of fixed-sized matrices, the initializer list sizes must exactly match the matrix sizes,
  300|       |   * and implicit transposition is allowed for compile-time vectors only.
  301|       |   *
  302|       |   * \sa Matrix(const Scalar& a0, const Scalar& a1, const Scalar& a2,  const Scalar& a3, const ArgTypes&... args)
  303|       |   */
  304|       |  EIGEN_DEVICE_FUNC explicit constexpr EIGEN_STRONG_INLINE Matrix(
  305|       |      const std::initializer_list<std::initializer_list<Scalar>>& list)
  306|       |      : Base(list) {}
  307|       |
  308|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  309|       |
  310|       |  // This constructor is for both 1x1 matrices and dynamic vectors
  311|       |  template <typename T>
  312|      5|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit Matrix(const T& x) {
  313|      5|    Base::template _init1<T>(x);
  314|      5|  }
  ------------------
  | _ZN5Eigen6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEC2IiEERKT_:
  |  312|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit Matrix(const T& x) {
  |  313|      2|    Base::template _init1<T>(x);
  |  314|      2|  }
  ------------------
  | _ZN5Eigen6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEC2INS_7ProductINS4_INS0_IS1_Lin1ELin1ELi0ELin1ELin1EEES5_Li0EEES2_Li0EEEEERKT_:
  |  312|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit Matrix(const T& x) {
  |  313|      1|    Base::template _init1<T>(x);
  |  314|      1|  }
  ------------------
  | _ZN5Eigen6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEC2INS_7ProductIS2_S2_Li0EEEEERKT_:
  |  312|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit Matrix(const T& x) {
  |  313|      1|    Base::template _init1<T>(x);
  |  314|      1|  }
  ------------------
  | _ZN5Eigen6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEC2INS_7ProductINS4_IS2_S2_Li0EEES2_Li0EEEEERKT_:
  |  312|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit Matrix(const T& x) {
  |  313|      1|    Base::template _init1<T>(x);
  |  314|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEC2INS_5BlockIKNS_7ProductINS0_IS1_Lin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEEEERKT_
  ------------------
  315|       |
  316|       |  template <typename T0, typename T1>
  317|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const T0& x, const T1& y) {
  318|      3|    Base::template _init2<T0, T1>(x, y);
  319|      3|  }
  ------------------
  | _ZN5Eigen6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEC2IiiEERKT_RKT0_:
  |  317|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const T0& x, const T1& y) {
  |  318|      3|    Base::template _init2<T0, T1>(x, y);
  |  319|      3|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEC2IllEERKT_RKT0_
  ------------------
  320|       |
  321|       |#else
  322|       |  /** \brief Constructs a fixed-sized matrix initialized with coefficients starting at \a data */
  323|       |  EIGEN_DEVICE_FUNC explicit Matrix(const Scalar* data);
  324|       |
  325|       |  /** \brief Constructs a vector or row-vector with given dimension. \only_for_vectors
  326|       |   *
  327|       |   * This is useful for dynamic-size vectors. For fixed-size vectors,
  328|       |   * it is redundant to pass these parameters, so one should use the default constructor
  329|       |   * Matrix() instead.
  330|       |   *
  331|       |   * \warning This constructor is disabled for fixed-size \c 1x1 matrices. For instance,
  332|       |   * calling Matrix<double,1,1>(1) will call the initialization constructor: Matrix(const Scalar&).
  333|       |   * For fixed-size \c 1x1 matrices it is therefore recommended to use the default
  334|       |   * constructor Matrix() instead, especially when using one of the non standard
  335|       |   * \c EIGEN_INITIALIZE_MATRICES_BY_{ZERO,\c NAN} macros (see \ref TopicPreprocessorDirectives).
  336|       |   */
  337|       |  EIGEN_STRONG_INLINE explicit Matrix(Index dim);
  338|       |  /** \brief Constructs an initialized 1x1 matrix with the given coefficient
  339|       |   * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...) */
  340|       |  Matrix(const Scalar& x);
  341|       |  /** \brief Constructs an uninitialized matrix with \a rows rows and \a cols columns.
  342|       |   *
  343|       |   * This is useful for dynamic-size matrices. For fixed-size matrices,
  344|       |   * it is redundant to pass these parameters, so one should use the default constructor
  345|       |   * Matrix() instead.
  346|       |   *
  347|       |   * \warning This constructor is disabled for fixed-size \c 1x2 and \c 2x1 vectors. For instance,
  348|       |   * calling Matrix2f(2,1) will call the initialization constructor: Matrix(const Scalar& x, const Scalar& y).
  349|       |   * For fixed-size \c 1x2 or \c 2x1 vectors it is therefore recommended to use the default
  350|       |   * constructor Matrix() instead, especially when using one of the non standard
  351|       |   * \c EIGEN_INITIALIZE_MATRICES_BY_{ZERO,\c NAN} macros (see \ref TopicPreprocessorDirectives).
  352|       |   */
  353|       |  EIGEN_DEVICE_FUNC Matrix(Index rows, Index cols);
  354|       |
  355|       |  /** \brief Constructs an initialized 2D vector with given coefficients
  356|       |   * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...) */
  357|       |  Matrix(const Scalar& x, const Scalar& y);
  358|       |#endif  // end EIGEN_PARSED_BY_DOXYGEN
  359|       |
  360|       |  /** \brief Constructs an initialized 3D vector with given coefficients
  361|       |   * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...)
  362|       |   */
  363|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const Scalar& x, const Scalar& y, const Scalar& z) {
  364|       |    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(Matrix, 3)
  365|       |    m_storage.data()[0] = x;
  366|       |    m_storage.data()[1] = y;
  367|       |    m_storage.data()[2] = z;
  368|       |  }
  369|       |  /** \brief Constructs an initialized 4D vector with given coefficients
  370|       |   * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...)
  371|       |   */
  372|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const Scalar& x, const Scalar& y, const Scalar& z, const Scalar& w) {
  373|       |    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(Matrix, 4)
  374|       |    m_storage.data()[0] = x;
  375|       |    m_storage.data()[1] = y;
  376|       |    m_storage.data()[2] = z;
  377|       |    m_storage.data()[3] = w;
  378|       |  }
  379|       |
  380|       |  /** \brief Copy constructor */
  381|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix(const Matrix&) = default;
  382|       |
  383|       |  /** \brief Copy constructor for generic expressions.
  384|       |   * \sa MatrixBase::operator=(const EigenBase<OtherDerived>&)
  385|       |   */
  386|       |  template <typename OtherDerived>
  387|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const EigenBase<OtherDerived>& other) : Base(other.derived()) {}
  388|       |
  389|      2|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const EIGEN_NOEXCEPT { return 1; }
  ------------------
  | _ZNK5Eigen6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EE11innerStrideEv:
  |  389|      2|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const EIGEN_NOEXCEPT { return 1; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EE11innerStrideEv
  ------------------
  390|      9|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const EIGEN_NOEXCEPT { return this->innerSize(); }
  ------------------
  | _ZNK5Eigen6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EE11outerStrideEv:
  |  390|      9|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const EIGEN_NOEXCEPT { return this->innerSize(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EE11outerStrideEv
  ------------------
  391|       |
  392|       |  /////////// Geometry module ///////////
  393|       |
  394|       |  template <typename OtherDerived>
  395|       |  EIGEN_DEVICE_FUNC explicit Matrix(const RotationBase<OtherDerived, ColsAtCompileTime>& r);
  396|       |  template <typename OtherDerived>
  397|       |  EIGEN_DEVICE_FUNC Matrix& operator=(const RotationBase<OtherDerived, ColsAtCompileTime>& r);
  398|       |
  399|       |// allow to extend Matrix outside Eigen
  400|       |#ifdef EIGEN_MATRIX_PLUGIN
  401|       |#include EIGEN_MATRIX_PLUGIN
  402|       |#endif
  403|       |
  404|       | protected:
  405|       |  template <typename Derived, typename OtherDerived, bool IsVector>
  406|       |  friend struct internal::conservative_resize_like_impl;
  407|       |
  408|       |  using Base::m_storage;
  409|       |};
  410|       |
  411|       |/** \defgroup matrixtypedefs Global matrix typedefs
  412|       | *
  413|       | * \ingroup Core_Module
  414|       | *
  415|       | * %Eigen defines several typedef shortcuts for most common matrix and vector types.
  416|       | *
  417|       | * The general patterns are the following:
  418|       | *
  419|       | * \c MatrixSizeType where \c Size can be \c 2,\c 3,\c 4 for fixed size square matrices or \c X for dynamic size,
  420|       | * and where \c Type can be \c i for integer, \c f for float, \c d for double, \c cf for complex float, \c cd
  421|       | * for complex double.
  422|       | *
  423|       | * For example, \c Matrix3d is a fixed-size 3x3 matrix type of doubles, and \c MatrixXf is a dynamic-size matrix of
  424|       | * floats.
  425|       | *
  426|       | * There are also \c VectorSizeType and \c RowVectorSizeType which are self-explanatory. For example, \c Vector4cf is
  427|       | * a fixed-size vector of 4 complex floats.
  428|       | *
  429|       | * With \cpp11, template alias are also defined for common sizes.
  430|       | * They follow the same pattern as above except that the scalar type suffix is replaced by a
  431|       | * template parameter, i.e.:
  432|       | *   - `MatrixSize<Type>` where `Size` can be \c 2,\c 3,\c 4 for fixed size square matrices or \c X for dynamic size.
  433|       | *   - `MatrixXSize<Type>` and `MatrixSizeX<Type>` where `Size` can be \c 2,\c 3,\c 4 for hybrid dynamic/fixed matrices.
  434|       | *   - `VectorSize<Type>` and `RowVectorSize<Type>` for column and row vectors.
  435|       | *
  436|       | * With \cpp11, you can also use fully generic column and row vector types: `Vector<Type,Size>` and
  437|       | * `RowVector<Type,Size>`.
  438|       | *
  439|       | * \sa class Matrix
  440|       | */
  441|       |
  442|       |#define EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, Size, SizeSuffix)    \
  443|       |  /** \ingroup matrixtypedefs */                                   \
  444|       |  /** \brief `Size`&times;`Size` matrix of type `Type`. */         \
  445|       |  typedef Matrix<Type, Size, Size> Matrix##SizeSuffix##TypeSuffix; \
  446|       |  /** \ingroup matrixtypedefs */                                   \
  447|       |  /** \brief `Size`&times;`1` vector of type `Type`. */            \
  448|       |  typedef Matrix<Type, Size, 1> Vector##SizeSuffix##TypeSuffix;    \
  449|       |  /** \ingroup matrixtypedefs */                                   \
  450|       |  /** \brief `1`&times;`Size` vector of type `Type`. */            \
  451|       |  typedef Matrix<Type, 1, Size> RowVector##SizeSuffix##TypeSuffix;
  452|       |
  453|       |#define EIGEN_MAKE_FIXED_TYPEDEFS(Type, TypeSuffix, Size)          \
  454|       |  /** \ingroup matrixtypedefs */                                   \
  455|       |  /** \brief `Size`&times;`Dynamic` matrix of type `Type`. */      \
  456|       |  typedef Matrix<Type, Size, Dynamic> Matrix##Size##X##TypeSuffix; \
  457|       |  /** \ingroup matrixtypedefs */                                   \
  458|       |  /** \brief `Dynamic`&times;`Size` matrix of type `Type`. */      \
  459|       |  typedef Matrix<Type, Dynamic, Size> Matrix##X##Size##TypeSuffix;
  460|       |
  461|       |#define EIGEN_MAKE_TYPEDEFS_ALL_SIZES(Type, TypeSuffix) \
  462|       |  EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, 2, 2)           \
  463|       |  EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, 3, 3)           \
  464|       |  EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, 4, 4)           \
  465|       |  EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, Dynamic, X)     \
  466|       |  EIGEN_MAKE_FIXED_TYPEDEFS(Type, TypeSuffix, 2)        \
  467|       |  EIGEN_MAKE_FIXED_TYPEDEFS(Type, TypeSuffix, 3)        \
  468|       |  EIGEN_MAKE_FIXED_TYPEDEFS(Type, TypeSuffix, 4)
  469|       |
  470|       |EIGEN_MAKE_TYPEDEFS_ALL_SIZES(int, i)
  471|       |EIGEN_MAKE_TYPEDEFS_ALL_SIZES(float, f)
  472|       |EIGEN_MAKE_TYPEDEFS_ALL_SIZES(double, d)
  473|       |EIGEN_MAKE_TYPEDEFS_ALL_SIZES(std::complex<float>, cf)
  474|       |EIGEN_MAKE_TYPEDEFS_ALL_SIZES(std::complex<double>, cd)
  475|       |
  476|       |#undef EIGEN_MAKE_TYPEDEFS_ALL_SIZES
  477|       |#undef EIGEN_MAKE_TYPEDEFS
  478|       |#undef EIGEN_MAKE_FIXED_TYPEDEFS
  479|       |
  480|       |#define EIGEN_MAKE_TYPEDEFS(Size, SizeSuffix)                    \
  481|       |  /** \ingroup matrixtypedefs */                                 \
  482|       |  /** \brief \cpp11 `Size`&times;`Size` matrix of type `Type`.*/ \
  483|       |  template <typename Type>                                       \
  484|       |  using Matrix##SizeSuffix = Matrix<Type, Size, Size>;           \
  485|       |  /** \ingroup matrixtypedefs */                                 \
  486|       |  /** \brief \cpp11 `Size`&times;`1` vector of type `Type`.*/    \
  487|       |  template <typename Type>                                       \
  488|       |  using Vector##SizeSuffix = Matrix<Type, Size, 1>;              \
  489|       |  /** \ingroup matrixtypedefs */                                 \
  490|       |  /** \brief \cpp11 `1`&times;`Size` vector of type `Type`.*/    \
  491|       |  template <typename Type>                                       \
  492|       |  using RowVector##SizeSuffix = Matrix<Type, 1, Size>;
  493|       |
  494|       |#define EIGEN_MAKE_FIXED_TYPEDEFS(Size)                              \
  495|       |  /** \ingroup matrixtypedefs */                                     \
  496|       |  /** \brief \cpp11 `Size`&times;`Dynamic` matrix of type `Type` */  \
  497|       |  template <typename Type>                                           \
  498|       |  using Matrix##Size##X = Matrix<Type, Size, Dynamic>;               \
  499|       |  /** \ingroup matrixtypedefs */                                     \
  500|       |  /** \brief \cpp11 `Dynamic`&times;`Size` matrix of type `Type`. */ \
  501|       |  template <typename Type>                                           \
  502|       |  using Matrix##X##Size = Matrix<Type, Dynamic, Size>;
  503|       |
  504|       |EIGEN_MAKE_TYPEDEFS(2, 2)
  505|       |EIGEN_MAKE_TYPEDEFS(3, 3)
  506|       |EIGEN_MAKE_TYPEDEFS(4, 4)
  507|       |EIGEN_MAKE_TYPEDEFS(Dynamic, X)
  508|       |EIGEN_MAKE_FIXED_TYPEDEFS(2)
  509|       |EIGEN_MAKE_FIXED_TYPEDEFS(3)
  510|       |EIGEN_MAKE_FIXED_TYPEDEFS(4)
  511|       |
  512|       |/** \ingroup matrixtypedefs
  513|       | * \brief \cpp11 `Size`&times;`1` vector of type `Type`. */
  514|       |template <typename Type, int Size>
  515|       |using Vector = Matrix<Type, Size, 1>;
  516|       |
  517|       |/** \ingroup matrixtypedefs
  518|       | * \brief \cpp11 `1`&times;`Size` vector of type `Type`. */
  519|       |template <typename Type, int Size>
  520|       |using RowVector = Matrix<Type, 1, Size>;
  521|       |
  522|       |#undef EIGEN_MAKE_TYPEDEFS
  523|       |#undef EIGEN_MAKE_FIXED_TYPEDEFS
  524|       |
  525|       |}  // end namespace Eigen
  526|       |
  527|       |#endif  // EIGEN_MATRIX_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/MatrixBase.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2009 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_MATRIXBASE_H
   12|       |#define EIGEN_MATRIXBASE_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |/** \class MatrixBase
   20|       |  * \ingroup Core_Module
   21|       |  *
   22|       |  * \brief Base class for all dense matrices, vectors, and expressions
   23|       |  *
   24|       |  * This class is the base that is inherited by all matrix, vector, and related expression
   25|       |  * types. Most of the Eigen API is contained in this class, and its base classes. Other important
   26|       |  * classes for the Eigen API are Matrix, and VectorwiseOp.
   27|       |  *
   28|       |  * Note that some methods are defined in other modules such as the \ref LU_Module LU module
   29|       |  * for all functions related to matrix inversions.
   30|       |  *
   31|       |  * \tparam Derived is the derived type, e.g. a matrix type, or an expression, etc.
   32|       |  *
   33|       |  * When writing a function taking Eigen objects as argument, if you want your function
   34|       |  * to take as argument any matrix, vector, or expression, just let it take a
   35|       |  * MatrixBase argument. As an example, here is a function printFirstRow which, given
   36|       |  * a matrix, vector, or expression \a x, prints the first row of \a x.
   37|       |  *
   38|       |  * \code
   39|       |    template<typename Derived>
   40|       |    void printFirstRow(const Eigen::MatrixBase<Derived>& x)
   41|       |    {
   42|       |      cout << x.row(0) << endl;
   43|       |    }
   44|       |  * \endcode
   45|       |  *
   46|       |  * This class can be extended with the help of the plugin mechanism described on the page
   47|       |  * \ref TopicCustomizing_Plugins by defining the preprocessor symbol \c EIGEN_MATRIXBASE_PLUGIN.
   48|       |  *
   49|       |  * \sa \blank \ref TopicClassHierarchy
   50|       |  */
   51|       |template <typename Derived>
   52|       |class MatrixBase : public DenseBase<Derived> {
   53|       | public:
   54|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
   55|       |  typedef MatrixBase StorageBaseType;
   56|       |  typedef typename internal::traits<Derived>::StorageKind StorageKind;
   57|       |  typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
   58|       |  typedef typename internal::traits<Derived>::Scalar Scalar;
   59|       |  typedef typename internal::packet_traits<Scalar>::type PacketScalar;
   60|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
   61|       |
   62|       |  typedef DenseBase<Derived> Base;
   63|       |  using Base::ColsAtCompileTime;
   64|       |  using Base::Flags;
   65|       |  using Base::IsVectorAtCompileTime;
   66|       |  using Base::MaxColsAtCompileTime;
   67|       |  using Base::MaxRowsAtCompileTime;
   68|       |  using Base::MaxSizeAtCompileTime;
   69|       |  using Base::RowsAtCompileTime;
   70|       |  using Base::SizeAtCompileTime;
   71|       |
   72|       |  using Base::coeff;
   73|       |  using Base::coeffRef;
   74|       |  using Base::cols;
   75|       |  using Base::const_cast_derived;
   76|       |  using Base::derived;
   77|       |  using Base::eval;
   78|       |  using Base::lazyAssign;
   79|       |  using Base::rows;
   80|       |  using Base::size;
   81|       |  using Base::operator-;
   82|       |  using Base::operator+=;
   83|       |  using Base::operator-=;
   84|       |  using Base::operator*=;
   85|       |  using Base::operator/=;
   86|       |
   87|       |  typedef typename Base::CoeffReturnType CoeffReturnType;
   88|       |  typedef typename Base::ConstTransposeReturnType ConstTransposeReturnType;
   89|       |  typedef typename Base::RowXpr RowXpr;
   90|       |  typedef typename Base::ColXpr ColXpr;
   91|       |#endif  // not EIGEN_PARSED_BY_DOXYGEN
   92|       |
   93|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
   94|       |  /** type of the equivalent square matrix */
   95|       |  typedef Matrix<Scalar, internal::max_size_prefer_dynamic(RowsAtCompileTime, ColsAtCompileTime),
   96|       |                 internal::max_size_prefer_dynamic(RowsAtCompileTime, ColsAtCompileTime)>
   97|       |      SquareMatrixType;
   98|       |#endif  // not EIGEN_PARSED_BY_DOXYGEN
   99|       |
  100|       |  /** \returns the size of the main diagonal, which is min(rows(),cols()).
  101|       |   * \sa rows(), cols(), SizeAtCompileTime. */
  102|       |  EIGEN_DEVICE_FUNC inline Index diagonalSize() const { return (numext::mini)(rows(), cols()); }
  103|       |
  104|       |  typedef typename Base::PlainObject PlainObject;
  105|       |
  106|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  107|       |  /** \internal Represents a matrix with all coefficients equal to one another*/
  108|       |  typedef CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> ConstantReturnType;
  109|       |  /** \internal the return type of MatrixBase::adjoint() */
  110|       |  typedef std::conditional_t<NumTraits<Scalar>::IsComplex,
  111|       |                             CwiseUnaryOp<internal::scalar_conjugate_op<Scalar>, ConstTransposeReturnType>,
  112|       |                             ConstTransposeReturnType>
  113|       |      AdjointReturnType;
  114|       |  /** \internal Return type of eigenvalues() */
  115|       |  typedef Matrix<std::complex<RealScalar>, internal::traits<Derived>::ColsAtCompileTime, 1, ColMajor>
  116|       |      EigenvaluesReturnType;
  117|       |  /** \internal the return type of identity */
  118|       |  typedef CwiseNullaryOp<internal::scalar_identity_op<Scalar>, PlainObject> IdentityReturnType;
  119|       |  /** \internal the return type of unit vectors */
  120|       |  typedef Block<const CwiseNullaryOp<internal::scalar_identity_op<Scalar>, SquareMatrixType>,
  121|       |                internal::traits<Derived>::RowsAtCompileTime, internal::traits<Derived>::ColsAtCompileTime>
  122|       |      BasisReturnType;
  123|       |#endif  // not EIGEN_PARSED_BY_DOXYGEN
  124|       |
  125|       |#define EIGEN_CURRENT_STORAGE_BASE_CLASS Eigen::MatrixBase
  126|       |#define EIGEN_DOC_UNARY_ADDONS(X, Y)
  127|       |#include "../plugins/CommonCwiseBinaryOps.inc"
  128|       |#include "../plugins/MatrixCwiseUnaryOps.inc"
  129|       |#include "../plugins/MatrixCwiseBinaryOps.inc"
  130|       |#ifdef EIGEN_MATRIXBASE_PLUGIN
  131|       |#include EIGEN_MATRIXBASE_PLUGIN
  132|       |#endif
  133|       |#undef EIGEN_CURRENT_STORAGE_BASE_CLASS
  134|       |#undef EIGEN_DOC_UNARY_ADDONS
  135|       |
  136|       |  /** Special case of the template operator=, in order to prevent the compiler
  137|       |   * from generating a default operator= (issue hit with g++ 4.1)
  138|       |   */
  139|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const MatrixBase& other);
  140|       |
  141|       |  // We cannot inherit here via Base::operator= since it is causing
  142|       |  // trouble with MSVC.
  143|       |
  144|       |  template <typename OtherDerived>
  145|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const DenseBase<OtherDerived>& other);
  146|       |
  147|       |  template <typename OtherDerived>
  148|       |  EIGEN_DEVICE_FUNC Derived& operator=(const EigenBase<OtherDerived>& other);
  149|       |
  150|       |  template <typename OtherDerived>
  151|       |  EIGEN_DEVICE_FUNC Derived& operator=(const ReturnByValue<OtherDerived>& other);
  152|       |
  153|       |  template <typename OtherDerived>
  154|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator+=(const MatrixBase<OtherDerived>& other);
  155|       |  template <typename OtherDerived>
  156|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator-=(const MatrixBase<OtherDerived>& other);
  157|       |
  158|       |  template <typename OtherDerived>
  159|       |  EIGEN_DEVICE_FUNC const Product<Derived, OtherDerived> operator*(const MatrixBase<OtherDerived>& other) const;
  160|       |
  161|       |  template <typename OtherDerived>
  162|       |  EIGEN_DEVICE_FUNC const Product<Derived, OtherDerived, LazyProduct> lazyProduct(
  163|       |      const MatrixBase<OtherDerived>& other) const;
  164|       |
  165|       |  template <typename OtherDerived>
  166|       |  Derived& operator*=(const EigenBase<OtherDerived>& other);
  167|       |
  168|       |  template <typename OtherDerived>
  169|       |  void applyOnTheLeft(const EigenBase<OtherDerived>& other);
  170|       |
  171|       |  template <typename OtherDerived>
  172|       |  void applyOnTheRight(const EigenBase<OtherDerived>& other);
  173|       |
  174|       |  template <typename DiagonalDerived>
  175|       |  EIGEN_DEVICE_FUNC const Product<Derived, DiagonalDerived, LazyProduct> operator*(
  176|       |      const DiagonalBase<DiagonalDerived>& diagonal) const;
  177|       |
  178|       |  template <typename SkewDerived>
  179|       |  EIGEN_DEVICE_FUNC const Product<Derived, SkewDerived, LazyProduct> operator*(
  180|       |      const SkewSymmetricBase<SkewDerived>& skew) const;
  181|       |
  182|       |  template <typename OtherDerived>
  183|       |  EIGEN_DEVICE_FUNC typename ScalarBinaryOpTraits<typename internal::traits<Derived>::Scalar,
  184|       |                                                  typename internal::traits<OtherDerived>::Scalar>::ReturnType
  185|       |  dot(const MatrixBase<OtherDerived>& other) const;
  186|       |
  187|       |  EIGEN_DEVICE_FUNC RealScalar squaredNorm() const;
  188|       |  EIGEN_DEVICE_FUNC RealScalar norm() const;
  189|       |  RealScalar stableNorm() const;
  190|       |  RealScalar blueNorm() const;
  191|       |  RealScalar hypotNorm() const;
  192|       |  EIGEN_DEVICE_FUNC const PlainObject normalized() const;
  193|       |  EIGEN_DEVICE_FUNC const PlainObject stableNormalized() const;
  194|       |  EIGEN_DEVICE_FUNC void normalize();
  195|       |  EIGEN_DEVICE_FUNC void stableNormalize();
  196|       |
  197|       |  EIGEN_DEVICE_FUNC const AdjointReturnType adjoint() const;
  198|       |  EIGEN_DEVICE_FUNC void adjointInPlace();
  199|       |
  200|       |  typedef Diagonal<Derived> DiagonalReturnType;
  201|       |  EIGEN_DEVICE_FUNC DiagonalReturnType diagonal();
  202|       |
  203|       |  typedef Diagonal<const Derived> ConstDiagonalReturnType;
  204|       |  EIGEN_DEVICE_FUNC const ConstDiagonalReturnType diagonal() const;
  205|       |
  206|       |  template <int Index>
  207|       |  EIGEN_DEVICE_FUNC Diagonal<Derived, Index> diagonal();
  208|       |
  209|       |  template <int Index>
  210|       |  EIGEN_DEVICE_FUNC const Diagonal<const Derived, Index> diagonal() const;
  211|       |
  212|       |  EIGEN_DEVICE_FUNC Diagonal<Derived, DynamicIndex> diagonal(Index index);
  213|       |  EIGEN_DEVICE_FUNC const Diagonal<const Derived, DynamicIndex> diagonal(Index index) const;
  214|       |
  215|       |  template <unsigned int Mode>
  216|       |  struct TriangularViewReturnType {
  217|       |    typedef TriangularView<Derived, Mode> Type;
  218|       |  };
  219|       |  template <unsigned int Mode>
  220|       |  struct ConstTriangularViewReturnType {
  221|       |    typedef const TriangularView<const Derived, Mode> Type;
  222|       |  };
  223|       |
  224|       |  template <unsigned int Mode>
  225|       |  EIGEN_DEVICE_FUNC typename TriangularViewReturnType<Mode>::Type triangularView();
  226|       |  template <unsigned int Mode>
  227|       |  EIGEN_DEVICE_FUNC typename ConstTriangularViewReturnType<Mode>::Type triangularView() const;
  228|       |
  229|       |  template <unsigned int UpLo>
  230|       |  struct SelfAdjointViewReturnType {
  231|       |    typedef SelfAdjointView<Derived, UpLo> Type;
  232|       |  };
  233|       |  template <unsigned int UpLo>
  234|       |  struct ConstSelfAdjointViewReturnType {
  235|       |    typedef const SelfAdjointView<const Derived, UpLo> Type;
  236|       |  };
  237|       |
  238|       |  template <unsigned int UpLo>
  239|       |  EIGEN_DEVICE_FUNC typename SelfAdjointViewReturnType<UpLo>::Type selfadjointView();
  240|       |  template <unsigned int UpLo>
  241|       |  EIGEN_DEVICE_FUNC typename ConstSelfAdjointViewReturnType<UpLo>::Type selfadjointView() const;
  242|       |
  243|       |  const SparseView<Derived> sparseView(
  244|       |      const Scalar& m_reference = Scalar(0),
  245|       |      const typename NumTraits<Scalar>::Real& m_epsilon = NumTraits<Scalar>::dummy_precision()) const;
  246|       |  EIGEN_DEVICE_FUNC static const IdentityReturnType Identity();
  247|       |  EIGEN_DEVICE_FUNC static const IdentityReturnType Identity(Index rows, Index cols);
  248|       |  EIGEN_DEVICE_FUNC static const BasisReturnType Unit(Index size, Index i);
  249|       |  EIGEN_DEVICE_FUNC static const BasisReturnType Unit(Index i);
  250|       |  EIGEN_DEVICE_FUNC static const BasisReturnType UnitX();
  251|       |  EIGEN_DEVICE_FUNC static const BasisReturnType UnitY();
  252|       |  EIGEN_DEVICE_FUNC static const BasisReturnType UnitZ();
  253|       |  EIGEN_DEVICE_FUNC static const BasisReturnType UnitW();
  254|       |
  255|       |  EIGEN_DEVICE_FUNC const DiagonalWrapper<const Derived> asDiagonal() const;
  256|       |  const PermutationWrapper<const Derived> asPermutation() const;
  257|       |  EIGEN_DEVICE_FUNC const SkewSymmetricWrapper<const Derived> asSkewSymmetric() const;
  258|       |
  259|       |  EIGEN_DEVICE_FUNC Derived& setIdentity();
  260|       |  EIGEN_DEVICE_FUNC Derived& setIdentity(Index rows, Index cols);
  261|       |  EIGEN_DEVICE_FUNC Derived& setUnit(Index i);
  262|       |  EIGEN_DEVICE_FUNC Derived& setUnit(Index newSize, Index i);
  263|       |
  264|       |  bool isIdentity(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  265|       |  bool isDiagonal(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  266|       |
  267|       |  bool isUpperTriangular(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  268|       |  bool isLowerTriangular(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  269|       |
  270|       |  bool isSkewSymmetric(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  271|       |
  272|       |  template <typename OtherDerived>
  273|       |  bool isOrthogonal(const MatrixBase<OtherDerived>& other,
  274|       |                    const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  275|       |  bool isUnitary(const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const;
  276|       |
  277|       |  /** \returns true if each coefficients of \c *this and \a other are all exactly equal.
  278|       |   * \warning When using floating point scalar values you probably should rather use a
  279|       |   *          fuzzy comparison such as isApprox()
  280|       |   * \sa isApprox(), operator!= */
  281|       |  template <typename OtherDerived>
  282|       |  EIGEN_DEVICE_FUNC inline bool operator==(const MatrixBase<OtherDerived>& other) const {
  283|       |    return (this->rows() == other.rows()) && (this->cols() == other.cols()) && cwiseEqual(other).all();
  284|       |  }
  285|       |
  286|       |  /** \returns true if at least one pair of coefficients of \c *this and \a other are not exactly equal to each other.
  287|       |   * \warning When using floating point scalar values you probably should rather use a
  288|       |   *          fuzzy comparison such as isApprox()
  289|       |   * \sa isApprox(), operator== */
  290|       |  template <typename OtherDerived>
  291|       |  EIGEN_DEVICE_FUNC inline bool operator!=(const MatrixBase<OtherDerived>& other) const {
  292|       |    return !(*this == other);
  293|       |  }
  294|       |
  295|       |  NoAlias<Derived, Eigen::MatrixBase> EIGEN_DEVICE_FUNC noalias();
  296|       |
  297|       |  // TODO forceAlignedAccess is temporarily disabled
  298|       |  // Need to find a nicer workaround.
  299|       |  inline const Derived& forceAlignedAccess() const { return derived(); }
  300|       |  inline Derived& forceAlignedAccess() { return derived(); }
  301|       |  template <bool Enable>
  302|       |  inline const Derived& forceAlignedAccessIf() const {
  303|       |    return derived();
  304|       |  }
  305|       |  template <bool Enable>
  306|       |  inline Derived& forceAlignedAccessIf() {
  307|       |    return derived();
  308|       |  }
  309|       |
  310|       |  EIGEN_DEVICE_FUNC Scalar trace() const;
  311|       |
  312|       |  template <int p>
  313|       |  EIGEN_DEVICE_FUNC RealScalar lpNorm() const;
  314|       |
  315|      0|  EIGEN_DEVICE_FUNC MatrixBase<Derived>& matrix() { return *this; }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE6matrixEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE6matrixEv
  ------------------
  316|       |  EIGEN_DEVICE_FUNC const MatrixBase<Derived>& matrix() const { return *this; }
  317|       |
  318|       |  /** \returns an \link Eigen::ArrayBase Array \endlink expression of this matrix
  319|       |   * \sa ArrayBase::matrix() */
  320|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ArrayWrapper<Derived> array() { return ArrayWrapper<Derived>(derived()); }
  321|       |  /** \returns a const \link Eigen::ArrayBase Array \endlink expression of this matrix
  322|       |   * \sa ArrayBase::matrix() */
  323|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const ArrayWrapper<const Derived> array() const {
  324|       |    return ArrayWrapper<const Derived>(derived());
  325|       |  }
  326|       |
  327|       |  /////////// LU module ///////////
  328|       |
  329|       |  template <typename PermutationIndex = DefaultPermutationIndex>
  330|       |  inline const FullPivLU<PlainObject, PermutationIndex> fullPivLu() const;
  331|       |  template <typename PermutationIndex = DefaultPermutationIndex>
  332|       |  inline const PartialPivLU<PlainObject, PermutationIndex> partialPivLu() const;
  333|       |
  334|       |  template <typename PermutationIndex = DefaultPermutationIndex>
  335|       |  inline const PartialPivLU<PlainObject, PermutationIndex> lu() const;
  336|       |
  337|       |  EIGEN_DEVICE_FUNC inline const Inverse<Derived> inverse() const;
  338|       |
  339|       |  template <typename ResultType>
  340|       |  inline void computeInverseAndDetWithCheck(
  341|       |      ResultType& inverse, typename ResultType::Scalar& determinant, bool& invertible,
  342|       |      const RealScalar& absDeterminantThreshold = NumTraits<Scalar>::dummy_precision()) const;
  343|       |
  344|       |  template <typename ResultType>
  345|       |  inline void computeInverseWithCheck(
  346|       |      ResultType& inverse, bool& invertible,
  347|       |      const RealScalar& absDeterminantThreshold = NumTraits<Scalar>::dummy_precision()) const;
  348|       |
  349|       |  EIGEN_DEVICE_FUNC Scalar determinant() const;
  350|       |
  351|       |  /////////// Cholesky module ///////////
  352|       |
  353|       |  inline const LLT<PlainObject> llt() const;
  354|       |  inline const LDLT<PlainObject> ldlt() const;
  355|       |
  356|       |  /////////// QR module ///////////
  357|       |
  358|       |  inline const HouseholderQR<PlainObject> householderQr() const;
  359|       |  template <typename PermutationIndex = DefaultPermutationIndex>
  360|       |  inline const ColPivHouseholderQR<PlainObject, PermutationIndex> colPivHouseholderQr() const;
  361|       |  template <typename PermutationIndex = DefaultPermutationIndex>
  362|       |  inline const FullPivHouseholderQR<PlainObject, PermutationIndex> fullPivHouseholderQr() const;
  363|       |  template <typename PermutationIndex = DefaultPermutationIndex>
  364|       |  inline const CompleteOrthogonalDecomposition<PlainObject, PermutationIndex> completeOrthogonalDecomposition() const;
  365|       |
  366|       |  /////////// Eigenvalues module ///////////
  367|       |
  368|       |  inline EigenvaluesReturnType eigenvalues() const;
  369|       |  inline RealScalar operatorNorm() const;
  370|       |
  371|       |  /////////// SVD module ///////////
  372|       |
  373|       |  template <int Options = 0>
  374|       |  inline JacobiSVD<PlainObject, Options> jacobiSvd() const;
  375|       |  template <int Options = 0>
  376|       |  EIGEN_DEPRECATED inline JacobiSVD<PlainObject, Options> jacobiSvd(unsigned int computationOptions) const;
  377|       |
  378|       |  template <int Options = 0>
  379|       |  inline BDCSVD<PlainObject, Options> bdcSvd() const;
  380|       |  template <int Options = 0>
  381|       |  EIGEN_DEPRECATED inline BDCSVD<PlainObject, Options> bdcSvd(unsigned int computationOptions) const;
  382|       |
  383|       |  /////////// Geometry module ///////////
  384|       |
  385|       |  template <typename OtherDerived>
  386|       |  EIGEN_DEVICE_FUNC inline typename internal::cross_impl<Derived, OtherDerived>::return_type cross(
  387|       |      const MatrixBase<OtherDerived>& other) const;
  388|       |
  389|       |  template <typename OtherDerived>
  390|       |  EIGEN_DEVICE_FUNC inline PlainObject cross3(const MatrixBase<OtherDerived>& other) const;
  391|       |
  392|       |  EIGEN_DEVICE_FUNC inline PlainObject unitOrthogonal(void) const;
  393|       |
  394|       |  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline Matrix<Scalar, 3, 1> eulerAngles(Index a0, Index a1, Index a2) const;
  395|       |
  396|       |  EIGEN_DEVICE_FUNC inline Matrix<Scalar, 3, 1> canonicalEulerAngles(Index a0, Index a1, Index a2) const;
  397|       |
  398|       |  // put this as separate enum value to work around possible GCC 4.3 bug (?)
  399|       |  enum {
  400|       |    HomogeneousReturnTypeDirection =
  401|       |        ColsAtCompileTime == 1 && RowsAtCompileTime == 1
  402|       |            ? ((internal::traits<Derived>::Flags & RowMajorBit) == RowMajorBit ? Horizontal : Vertical)
  403|       |        : ColsAtCompileTime == 1 ? Vertical
  404|       |                                 : Horizontal
  405|       |  };
  406|       |  typedef Homogeneous<Derived, HomogeneousReturnTypeDirection> HomogeneousReturnType;
  407|       |  EIGEN_DEVICE_FUNC inline HomogeneousReturnType homogeneous() const;
  408|       |
  409|       |  enum { SizeMinusOne = SizeAtCompileTime == Dynamic ? Dynamic : SizeAtCompileTime - 1 };
  410|       |  typedef Block<const Derived, internal::traits<Derived>::ColsAtCompileTime == 1 ? SizeMinusOne : 1,
  411|       |                internal::traits<Derived>::ColsAtCompileTime == 1 ? 1 : SizeMinusOne>
  412|       |      ConstStartMinusOne;
  413|       |  typedef EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(ConstStartMinusOne, Scalar, quotient) HNormalizedReturnType;
  414|       |  EIGEN_DEVICE_FUNC inline const HNormalizedReturnType hnormalized() const;
  415|       |
  416|       |  ////////// Householder module ///////////
  417|       |
  418|       |  EIGEN_DEVICE_FUNC void makeHouseholderInPlace(Scalar& tau, RealScalar& beta);
  419|       |  template <typename EssentialPart>
  420|       |  EIGEN_DEVICE_FUNC void makeHouseholder(EssentialPart& essential, Scalar& tau, RealScalar& beta) const;
  421|       |  template <typename EssentialPart>
  422|       |  EIGEN_DEVICE_FUNC void applyHouseholderOnTheLeft(const EssentialPart& essential, const Scalar& tau,
  423|       |                                                   Scalar* workspace);
  424|       |  template <typename EssentialPart>
  425|       |  EIGEN_DEVICE_FUNC void applyHouseholderOnTheRight(const EssentialPart& essential, const Scalar& tau,
  426|       |                                                    Scalar* workspace);
  427|       |
  428|       |  ///////// Jacobi module /////////
  429|       |
  430|       |  template <typename OtherScalar>
  431|       |  EIGEN_DEVICE_FUNC void applyOnTheLeft(Index p, Index q, const JacobiRotation<OtherScalar>& j);
  432|       |  template <typename OtherScalar>
  433|       |  EIGEN_DEVICE_FUNC void applyOnTheRight(Index p, Index q, const JacobiRotation<OtherScalar>& j);
  434|       |
  435|       |  ///////// SparseCore module /////////
  436|       |
  437|       |  template <typename OtherDerived>
  438|       |  EIGEN_STRONG_INLINE const typename SparseMatrixBase<OtherDerived>::template CwiseProductDenseReturnType<Derived>::Type
  439|       |  cwiseProduct(const SparseMatrixBase<OtherDerived>& other) const {
  440|       |    return other.cwiseProduct(derived());
  441|       |  }
  442|       |
  443|       |  ///////// MatrixFunctions module /////////
  444|       |
  445|       |  typedef typename internal::stem_function<Scalar>::type StemFunction;
  446|       |#define EIGEN_MATRIX_FUNCTION(ReturnType, Name, Description)                                                        \
  447|       |  /** \returns an expression of the matrix Description of \c *this. \brief This function requires the <a            \
  448|       |   * href="unsupported/group__MatrixFunctions__Module.html"> unsupported MatrixFunctions module</a>. To compute the \
  449|       |   * coefficient-wise Description use ArrayBase::##Name . */                                                        \
  450|       |  const ReturnType<Derived> Name() const;
  451|       |#define EIGEN_MATRIX_FUNCTION_1(ReturnType, Name, Description, Argument)                                            \
  452|       |  /** \returns an expression of the matrix Description of \c *this. \brief This function requires the <a            \
  453|       |   * href="unsupported/group__MatrixFunctions__Module.html"> unsupported MatrixFunctions module</a>. To compute the \
  454|       |   * coefficient-wise Description use ArrayBase::##Name . */                                                        \
  455|       |  const ReturnType<Derived> Name(Argument) const;
  456|       |
  457|       |  EIGEN_MATRIX_FUNCTION(MatrixExponentialReturnValue, exp, exponential)
  458|       |  /** \brief Helper function for the <a href="unsupported/group__MatrixFunctions__Module.html"> unsupported
  459|       |   * MatrixFunctions module</a>.*/
  460|       |  const MatrixFunctionReturnValue<Derived> matrixFunction(StemFunction f) const;
  461|       |  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, cosh, hyperbolic cosine)
  462|       |  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, sinh, hyperbolic sine)
  463|       |  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, atanh, inverse hyperbolic cosine)
  464|       |  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, acosh, inverse hyperbolic cosine)
  465|       |  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, asinh, inverse hyperbolic sine)
  466|       |  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, cos, cosine)
  467|       |  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, sin, sine)
  468|       |  EIGEN_MATRIX_FUNCTION(MatrixSquareRootReturnValue, sqrt, square root)
  469|       |  EIGEN_MATRIX_FUNCTION(MatrixLogarithmReturnValue, log, logarithm)
  470|       |  EIGEN_MATRIX_FUNCTION_1(MatrixPowerReturnValue, pow, power to \c p, const RealScalar& p)
  471|       |  EIGEN_MATRIX_FUNCTION_1(MatrixComplexPowerReturnValue, pow, power to \c p, const std::complex<RealScalar>& p)
  472|       |
  473|       | protected:
  474|       |  EIGEN_DEFAULT_COPY_CONSTRUCTOR(MatrixBase)
  475|       |  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(MatrixBase)
  476|       |
  477|       | private:
  478|       |  EIGEN_DEVICE_FUNC explicit MatrixBase(int);
  479|       |  EIGEN_DEVICE_FUNC MatrixBase(int, int);
  480|       |  template <typename OtherDerived>
  481|       |  EIGEN_DEVICE_FUNC explicit MatrixBase(const MatrixBase<OtherDerived>&);
  482|       |
  483|       | protected:
  484|       |  // mixing arrays and matrices is not legal
  485|       |  template <typename OtherDerived>
  486|       |  Derived& operator+=(const ArrayBase<OtherDerived>&) {
  487|       |    EIGEN_STATIC_ASSERT(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1,
  488|       |                        YOU_CANNOT_MIX_ARRAYS_AND_MATRICES);
  489|       |    return *this;
  490|       |  }
  491|       |  // mixing arrays and matrices is not legal
  492|       |  template <typename OtherDerived>
  493|       |  Derived& operator-=(const ArrayBase<OtherDerived>&) {
  494|       |    EIGEN_STATIC_ASSERT(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1,
  495|       |                        YOU_CANNOT_MIX_ARRAYS_AND_MATRICES);
  496|       |    return *this;
  497|       |  }
  498|       |};
  499|       |
  500|       |/***************************************************************************
  501|       | * Implementation of matrix base methods
  502|       | ***************************************************************************/
  503|       |
  504|       |/** replaces \c *this by \c *this * \a other.
  505|       | *
  506|       | * \returns a reference to \c *this
  507|       | *
  508|       | * Example: \include MatrixBase_applyOnTheRight.cpp
  509|       | * Output: \verbinclude MatrixBase_applyOnTheRight.out
  510|       | */
  511|       |template <typename Derived>
  512|       |template <typename OtherDerived>
  513|       |inline Derived& MatrixBase<Derived>::operator*=(const EigenBase<OtherDerived>& other) {
  514|       |  other.derived().applyThisOnTheRight(derived());
  515|       |  return derived();
  516|       |}
  517|       |
  518|       |/** replaces \c *this by \c *this * \a other. It is equivalent to MatrixBase::operator*=().
  519|       | *
  520|       | * Example: \include MatrixBase_applyOnTheRight.cpp
  521|       | * Output: \verbinclude MatrixBase_applyOnTheRight.out
  522|       | */
  523|       |template <typename Derived>
  524|       |template <typename OtherDerived>
  525|       |inline void MatrixBase<Derived>::applyOnTheRight(const EigenBase<OtherDerived>& other) {
  526|       |  other.derived().applyThisOnTheRight(derived());
  527|       |}
  528|       |
  529|       |/** replaces \c *this by \a other * \c *this.
  530|       | *
  531|       | * Example: \include MatrixBase_applyOnTheLeft.cpp
  532|       | * Output: \verbinclude MatrixBase_applyOnTheLeft.out
  533|       | */
  534|       |template <typename Derived>
  535|       |template <typename OtherDerived>
  536|       |inline void MatrixBase<Derived>::applyOnTheLeft(const EigenBase<OtherDerived>& other) {
  537|       |  other.derived().applyThisOnTheLeft(derived());
  538|       |}
  539|       |
  540|       |}  // end namespace Eigen
  541|       |
  542|       |#endif  // EIGEN_MATRIXBASE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/NumTraits.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_NUMTRAITS_H
   11|       |#define EIGEN_NUMTRAITS_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "./InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |// default implementation of digits(), based on numeric_limits if specialized,
   21|       |// 0 for integer types, and log2(epsilon()) otherwise.
   22|       |template <typename T, bool use_numeric_limits = std::numeric_limits<T>::is_specialized,
   23|       |          bool is_integer = NumTraits<T>::IsInteger>
   24|       |struct default_digits_impl {
   25|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static int run() { return std::numeric_limits<T>::digits; }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19default_digits_implIdLb1ELb0EE3runEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19default_digits_implIeLb1ELb0EE3runEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19default_digits_implIfLb1ELb0EE3runEv
  ------------------
   26|       |};
   27|       |
   28|       |template <typename T>
   29|       |struct default_digits_impl<T, false, false>  // Floating point
   30|       |{
   31|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static int run() {
   32|       |    using std::ceil;
   33|       |    using std::log2;
   34|       |    typedef typename NumTraits<T>::Real Real;
   35|       |    return int(ceil(-log2(NumTraits<Real>::epsilon())));
   36|       |  }
   37|       |};
   38|       |
   39|       |template <typename T>
   40|       |struct default_digits_impl<T, false, true>  // Integer
   41|       |{
   42|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static int run() { return 0; }
   43|       |};
   44|       |
   45|       |// default implementation of digits10(), based on numeric_limits if specialized,
   46|       |// 0 for integer types, and floor((digits()-1)*log10(2)) otherwise.
   47|       |template <typename T, bool use_numeric_limits = std::numeric_limits<T>::is_specialized,
   48|       |          bool is_integer = NumTraits<T>::IsInteger>
   49|       |struct default_digits10_impl {
   50|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static int run() { return std::numeric_limits<T>::digits10; }
   51|       |};
   52|       |
   53|       |template <typename T>
   54|       |struct default_digits10_impl<T, false, false>  // Floating point
   55|       |{
   56|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static int run() {
   57|       |    using std::floor;
   58|       |    using std::log10;
   59|       |    typedef typename NumTraits<T>::Real Real;
   60|       |    return int(floor((internal::default_digits_impl<Real>::run() - 1) * log10(2)));
   61|       |  }
   62|       |};
   63|       |
   64|       |template <typename T>
   65|       |struct default_digits10_impl<T, false, true>  // Integer
   66|       |{
   67|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static int run() { return 0; }
   68|       |};
   69|       |
   70|       |// default implementation of max_digits10(), based on numeric_limits if specialized,
   71|       |// 0 for integer types, and log10(2) * digits() + 1 otherwise.
   72|       |template <typename T, bool use_numeric_limits = std::numeric_limits<T>::is_specialized,
   73|       |          bool is_integer = NumTraits<T>::IsInteger>
   74|       |struct default_max_digits10_impl {
   75|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static int run() { return std::numeric_limits<T>::max_digits10; }
   76|       |};
   77|       |
   78|       |template <typename T>
   79|       |struct default_max_digits10_impl<T, false, false>  // Floating point
   80|       |{
   81|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static int run() {
   82|       |    using std::ceil;
   83|       |    using std::log10;
   84|       |    typedef typename NumTraits<T>::Real Real;
   85|       |    return int(ceil(internal::default_digits_impl<Real>::run() * log10(2) + 1));
   86|       |  }
   87|       |};
   88|       |
   89|       |template <typename T>
   90|       |struct default_max_digits10_impl<T, false, true>  // Integer
   91|       |{
   92|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static int run() { return 0; }
   93|       |};
   94|       |
   95|       |}  // end namespace internal
   96|       |
   97|       |namespace numext {
   98|       |/** \internal bit-wise cast without changing the underlying bit representation. */
   99|       |
  100|       |// TODO: Replace by std::bit_cast (available in C++20)
  101|       |template <typename Tgt, typename Src>
  102|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Tgt bit_cast(const Src& src) {
  103|      0|  // The behaviour of memcpy is not specified for non-trivially copyable types
  104|      0|  EIGEN_STATIC_ASSERT(std::is_trivially_copyable<Src>::value, THIS_TYPE_IS_NOT_SUPPORTED)
  105|      0|  EIGEN_STATIC_ASSERT(std::is_trivially_copyable<Tgt>::value && std::is_default_constructible<Tgt>::value,
  106|      0|                      THIS_TYPE_IS_NOT_SUPPORTED)
  107|      0|  EIGEN_STATIC_ASSERT(sizeof(Src) == sizeof(Tgt), THIS_TYPE_IS_NOT_SUPPORTED)
  108|      0|
  109|      0|  Tgt tgt;
  110|      0|  // Load src into registers first. This allows the memcpy to be elided by CUDA.
  111|      0|  const Src staged = src;
  112|      0|  EIGEN_USING_STD(memcpy)
  113|      0|  memcpy(static_cast<void*>(&tgt), static_cast<const void*>(&staged), sizeof(Tgt));
  114|      0|  return tgt;
  115|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext8bit_castImdEET_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext8bit_castIdmEET_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext8bit_castIjfEET_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext8bit_castIfjEET_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext8bit_castIijEET_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext8bit_castIjiEET_RKT0_
  ------------------
  116|       |}  // namespace numext
  117|       |
  118|       |/** \class NumTraits
  119|       | * \ingroup Core_Module
  120|       | *
  121|       | * \brief Holds information about the various numeric (i.e. scalar) types allowed by Eigen.
  122|       | *
  123|       | * \tparam T the numeric type at hand
  124|       | *
  125|       | * This class stores enums, typedefs and static methods giving information about a numeric type.
  126|       | *
  127|       | * The provided data consists of:
  128|       | * \li A typedef \c Real, giving the "real part" type of \a T. If \a T is already real,
  129|       | *     then \c Real is just a typedef to \a T. If \a T is \c std::complex<U> then \c Real
  130|       | *     is a typedef to \a U.
  131|       | * \li A typedef \c NonInteger, giving the type that should be used for operations producing non-integral values,
  132|       | *     such as quotients, square roots, etc. If \a T is a floating-point type, then this typedef just gives
  133|       | *     \a T again. Note however that many Eigen functions such as internal::sqrt simply refuse to
  134|       | *     take integers. Outside of a few cases, Eigen doesn't do automatic type promotion. Thus, this typedef is
  135|       | *     only intended as a helper for code that needs to explicitly promote types.
  136|       | * \li A typedef \c Literal giving the type to use for numeric literals such as "2" or "0.5". For instance, for \c
  137|       | * std::complex<U>, Literal is defined as \c U. Of course, this type must be fully compatible with \a T. In doubt, just
  138|       | * use \a T here. \li A typedef \a Nested giving the type to use to nest a value inside of the expression tree. If you
  139|       | * don't know what this means, just use \a T here. \li An enum value \a IsComplex. It is equal to 1 if \a T is a \c
  140|       | * std::complex type, and to 0 otherwise. \li An enum value \a IsInteger. It is equal to \c 1 if \a T is an integer type
  141|       | * such as \c int, and to \c 0 otherwise. \li Enum values ReadCost, AddCost and MulCost representing a rough estimate of
  142|       | * the number of CPU cycles needed to by move / add / mul instructions respectively, assuming the data is already stored
  143|       | * in CPU registers. Stay vague here. No need to do architecture-specific stuff. If you don't know what this means, just
  144|       | * use \c Eigen::HugeCost. \li An enum value \a IsSigned. It is equal to \c 1 if \a T is a signed type and to 0 if \a T
  145|       | * is unsigned. \li An enum value \a RequireInitialization. It is equal to \c 1 if the constructor of the numeric type
  146|       | * \a T must be called, and to 0 if it is safe not to call it. Default is 0 if \a T is an arithmetic type, and 1
  147|       | * otherwise. \li An epsilon() function which, unlike <a
  148|       | * href="http://en.cppreference.com/w/cpp/types/numeric_limits/epsilon">std::numeric_limits::epsilon()</a>, it returns a
  149|       | * \a Real instead of a \a T. \li A dummy_precision() function returning a weak epsilon value. It is mainly used as a
  150|       | * default value by the fuzzy comparison operators. \li highest() and lowest() functions returning the highest and
  151|       | * lowest possible values respectively. \li digits() function returning the number of radix digits (non-sign digits for
  152|       | * integers, mantissa for floating-point). This is the analogue of <a
  153|       | * href="http://en.cppreference.com/w/cpp/types/numeric_limits/digits">std::numeric_limits<T>::digits</a> which is used
  154|       | * as the default implementation if specialized. \li digits10() function returning the number of decimal digits that can
  155|       | * be represented without change. This is the analogue of <a
  156|       | * href="http://en.cppreference.com/w/cpp/types/numeric_limits/digits10">std::numeric_limits<T>::digits10</a> which is
  157|       | * used as the default implementation if specialized. \li max_digits10() function returning the number of decimal digits
  158|       | * required to uniquely represent all distinct values of the type. This is the analogue of <a
  159|       | * href="http://en.cppreference.com/w/cpp/types/numeric_limits/max_digits10">std::numeric_limits<T>::max_digits10</a>
  160|       | *     which is used as the default implementation if specialized.
  161|       | * \li min_exponent() and max_exponent() functions returning the highest and lowest possible values, respectively,
  162|       | *     such that the radix raised to the power exponent-1 is a normalized floating-point number.  These are equivalent
  163|       | * to <a
  164|       | * href="http://en.cppreference.com/w/cpp/types/numeric_limits/min_exponent">std::numeric_limits<T>::min_exponent</a>/
  165|       | *     <a
  166|       | * href="http://en.cppreference.com/w/cpp/types/numeric_limits/max_exponent">std::numeric_limits<T>::max_exponent</a>.
  167|       | * \li infinity() function returning a representation of positive infinity, if available.
  168|       | * \li quiet_NaN function returning a non-signaling "not-a-number", if available.
  169|       | */
  170|       |
  171|       |template <typename T>
  172|       |struct GenericNumTraits {
  173|       |  enum {
  174|       |    IsInteger = std::numeric_limits<T>::is_integer,
  175|       |    IsSigned = std::numeric_limits<T>::is_signed,
  176|       |    IsComplex = 0,
  177|       |    RequireInitialization = internal::is_arithmetic<T>::value ? 0 : 1,
  178|       |    ReadCost = 1,
  179|       |    AddCost = 1,
  180|       |    MulCost = 1
  181|       |  };
  182|       |
  183|       |  typedef T Real;
  184|       |  typedef std::conditional_t<IsInteger, std::conditional_t<sizeof(T) <= 2, float, double>, T> NonInteger;
  185|       |  typedef T Nested;
  186|       |  typedef T Literal;
  187|       |
  188|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline Real epsilon() { return numext::numeric_limits<T>::epsilon(); }
  189|       |
  190|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline int digits10() { return internal::default_digits10_impl<T>::run(); }
  191|       |
  192|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline int max_digits10() {
  193|       |    return internal::default_max_digits10_impl<T>::run();
  194|       |  }
  195|       |
  196|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline int digits() { return internal::default_digits_impl<T>::run(); }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIdE6digitsEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIeE6digitsEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIfE6digitsEv
  ------------------
  197|       |
  198|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline int min_exponent() { return numext::numeric_limits<T>::min_exponent; }
  199|       |
  200|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline int max_exponent() { return numext::numeric_limits<T>::max_exponent; }
  201|       |
  202|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline Real dummy_precision() {
  203|      0|    // make sure to override this for floating-point types
  204|      0|    return Real(0);
  205|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIsE15dummy_precisionEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsItE15dummy_precisionEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIiE15dummy_precisionEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIjE15dummy_precisionEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIlE15dummy_precisionEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsImE15dummy_precisionEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIxE15dummy_precisionEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIyE15dummy_precisionEv
  ------------------
  206|       |
  207|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline T highest() { return (numext::numeric_limits<T>::max)(); }
  208|       |
  209|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline T lowest() { return (numext::numeric_limits<T>::lowest)(); }
  210|       |
  211|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline T infinity() { return numext::numeric_limits<T>::infinity(); }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIdE8infinityEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen16GenericNumTraitsIfE8infinityEv
  ------------------
  212|       |
  213|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline T quiet_NaN() { return numext::numeric_limits<T>::quiet_NaN(); }
  214|       |};
  215|       |
  216|       |template <typename T>
  217|       |struct NumTraits : GenericNumTraits<T> {};
  218|       |
  219|       |template <>
  220|       |struct NumTraits<float> : GenericNumTraits<float> {
  221|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline float dummy_precision() { return 1e-5f; }
  222|       |};
  223|       |
  224|       |template <>
  225|       |struct NumTraits<double> : GenericNumTraits<double> {
  226|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline double dummy_precision() { return 1e-12; }
  227|       |};
  228|       |
  229|       |// GPU devices treat `long double` as `double`.
  230|       |#ifndef EIGEN_GPU_COMPILE_PHASE
  231|       |template <>
  232|       |struct NumTraits<long double> : GenericNumTraits<long double> {
  233|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline long double dummy_precision() {
  234|      0|    return static_cast<long double>(1e-15l);
  235|      0|  }
  236|       |
  237|       |#if defined(EIGEN_ARCH_PPC) && (__LDBL_MANT_DIG__ == 106)
  238|       |  // PowerPC double double causes issues with some values
  239|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline long double epsilon() {
  240|       |    // 2^(-(__LDBL_MANT_DIG__)+1)
  241|       |    return static_cast<long double>(2.4651903288156618919116517665087e-32l);
  242|       |  }
  243|       |#endif
  244|       |};
  245|       |#endif
  246|       |
  247|       |template <typename Real_>
  248|       |struct NumTraits<std::complex<Real_> > : GenericNumTraits<std::complex<Real_> > {
  249|       |  typedef Real_ Real;
  250|       |  typedef typename NumTraits<Real_>::Literal Literal;
  251|       |  enum {
  252|       |    IsComplex = 1,
  253|       |    IsSigned = NumTraits<Real_>::IsSigned,
  254|       |    RequireInitialization = NumTraits<Real_>::RequireInitialization,
  255|       |    ReadCost = 2 * NumTraits<Real_>::ReadCost,
  256|       |    AddCost = 2 * NumTraits<Real>::AddCost,
  257|       |    MulCost = 4 * NumTraits<Real>::MulCost + 2 * NumTraits<Real>::AddCost
  258|       |  };
  259|       |
  260|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline Real epsilon() { return NumTraits<Real>::epsilon(); }
  261|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline Real dummy_precision() { return NumTraits<Real>::dummy_precision(); }
  262|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline int digits10() { return NumTraits<Real>::digits10(); }
  263|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline int max_digits10() { return NumTraits<Real>::max_digits10(); }
  264|       |};
  265|       |
  266|       |template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  267|       |struct NumTraits<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> > {
  268|       |  typedef Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> ArrayType;
  269|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  270|       |  typedef Array<RealScalar, Rows, Cols, Options, MaxRows, MaxCols> Real;
  271|       |  typedef typename NumTraits<Scalar>::NonInteger NonIntegerScalar;
  272|       |  typedef Array<NonIntegerScalar, Rows, Cols, Options, MaxRows, MaxCols> NonInteger;
  273|       |  typedef ArrayType& Nested;
  274|       |  typedef typename NumTraits<Scalar>::Literal Literal;
  275|       |
  276|       |  enum {
  277|       |    IsComplex = NumTraits<Scalar>::IsComplex,
  278|       |    IsInteger = NumTraits<Scalar>::IsInteger,
  279|       |    IsSigned = NumTraits<Scalar>::IsSigned,
  280|       |    RequireInitialization = 1,
  281|       |    ReadCost = ArrayType::SizeAtCompileTime == Dynamic
  282|       |                   ? HugeCost
  283|       |                   : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::ReadCost),
  284|       |    AddCost = ArrayType::SizeAtCompileTime == Dynamic ? HugeCost
  285|       |                                                      : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::AddCost),
  286|       |    MulCost = ArrayType::SizeAtCompileTime == Dynamic ? HugeCost
  287|       |                                                      : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::MulCost)
  288|       |  };
  289|       |
  290|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline RealScalar epsilon() { return NumTraits<RealScalar>::epsilon(); }
  291|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static inline RealScalar dummy_precision() {
  292|       |    return NumTraits<RealScalar>::dummy_precision();
  293|       |  }
  294|       |
  295|       |  EIGEN_CONSTEXPR
  296|       |  static inline int digits10() { return NumTraits<Scalar>::digits10(); }
  297|       |  EIGEN_CONSTEXPR
  298|       |  static inline int max_digits10() { return NumTraits<Scalar>::max_digits10(); }
  299|       |};
  300|       |
  301|       |template <>
  302|       |struct NumTraits<std::string> : GenericNumTraits<std::string> {
  303|       |  enum { RequireInitialization = 1, ReadCost = HugeCost, AddCost = HugeCost, MulCost = HugeCost };
  304|       |
  305|       |  EIGEN_CONSTEXPR
  306|      0|  static inline int digits10() { return 0; }
  307|       |  EIGEN_CONSTEXPR
  308|      0|  static inline int max_digits10() { return 0; }
  309|       |
  310|       | private:
  311|       |  static inline std::string epsilon();
  312|       |  static inline std::string dummy_precision();
  313|       |  static inline std::string lowest();
  314|       |  static inline std::string highest();
  315|       |  static inline std::string infinity();
  316|       |  static inline std::string quiet_NaN();
  317|       |};
  318|       |
  319|       |// Empty specialization for void to allow template specialization based on NumTraits<T>::Real with T==void and SFINAE.
  320|       |template <>
  321|       |struct NumTraits<void> {};
  322|       |
  323|       |template <>
  324|       |struct NumTraits<bool> : GenericNumTraits<bool> {};
  325|       |
  326|       |}  // end namespace Eigen
  327|       |
  328|       |#endif  // EIGEN_NUMTRAITS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/PlainObjectBase.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2009 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_DENSESTORAGEBASE_H
   12|       |#define EIGEN_DENSESTORAGEBASE_H
   13|       |
   14|       |#if defined(EIGEN_INITIALIZE_MATRICES_BY_ZERO)
   15|       |#define EIGEN_INITIALIZE_COEFFS
   16|       |#define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED \
   17|       |  for (Index i = 0; i < base().size(); ++i) coeffRef(i) = Scalar(0);
   18|       |#elif defined(EIGEN_INITIALIZE_MATRICES_BY_NAN)
   19|       |#define EIGEN_INITIALIZE_COEFFS
   20|       |#define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED \
   21|       |  for (Index i = 0; i < base().size(); ++i) coeffRef(i) = std::numeric_limits<Scalar>::quiet_NaN();
   22|       |#else
   23|       |#undef EIGEN_INITIALIZE_COEFFS
   24|       |#define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
   25|       |#endif
   26|       |
   27|       |// IWYU pragma: private
   28|       |#include "./InternalHeaderCheck.h"
   29|       |
   30|       |namespace Eigen {
   31|       |
   32|       |namespace internal {
   33|       |
   34|       |#ifndef EIGEN_NO_DEBUG
   35|       |template <int MaxSizeAtCompileTime, int MaxRowsAtCompileTime, int MaxColsAtCompileTime>
   36|       |struct check_rows_cols_for_overflow {
   37|       |  EIGEN_STATIC_ASSERT(MaxRowsAtCompileTime* MaxColsAtCompileTime == MaxSizeAtCompileTime,
   38|       |                      YOU MADE A PROGRAMMING MISTAKE)
   39|       |  template <typename Index>
   40|       |  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE constexpr void run(Index, Index) {}
   41|       |};
   42|       |
   43|       |template <int MaxRowsAtCompileTime>
   44|       |struct check_rows_cols_for_overflow<Dynamic, MaxRowsAtCompileTime, Dynamic> {
   45|       |  template <typename Index>
   46|      0|  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE constexpr void run(Index, Index cols) {
   47|      0|    constexpr Index MaxIndex = NumTraits<Index>::highest();
   48|      0|    bool error = cols > (MaxIndex / MaxRowsAtCompileTime);
   49|      0|    if (error) throw_std_bad_alloc();
   50|      0|  }
   51|       |};
   52|       |
   53|       |template <int MaxColsAtCompileTime>
   54|       |struct check_rows_cols_for_overflow<Dynamic, Dynamic, MaxColsAtCompileTime> {
   55|       |  template <typename Index>
   56|      1|  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE constexpr void run(Index rows, Index) {
   57|      1|    constexpr Index MaxIndex = NumTraits<Index>::highest();
   58|      1|    bool error = rows > (MaxIndex / MaxColsAtCompileTime);
   59|      1|    if (error) throw_std_bad_alloc();
   60|      1|  }
   61|       |};
   62|       |
   63|       |template <>
   64|       |struct check_rows_cols_for_overflow<Dynamic, Dynamic, Dynamic> {
   65|       |  template <typename Index>
   66|      7|  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE constexpr void run(Index rows, Index cols) {
   67|      7|    constexpr Index MaxIndex = NumTraits<Index>::highest();
   68|      7|    bool error = cols == 0 ? false : (rows > (MaxIndex / cols));
   69|      7|    if (error) throw_std_bad_alloc();
   70|      7|  }
   71|       |};
   72|       |#endif
   73|       |
   74|       |template <typename Derived, typename OtherDerived = Derived,
   75|       |          bool IsVector = bool(Derived::IsVectorAtCompileTime) && bool(OtherDerived::IsVectorAtCompileTime)>
   76|       |struct conservative_resize_like_impl;
   77|       |
   78|       |template <typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers>
   79|       |struct matrix_swap_impl;
   80|       |
   81|       |}  // end namespace internal
   82|       |
   83|       |#ifdef EIGEN_PARSED_BY_DOXYGEN
   84|       |namespace doxygen {
   85|       |
   86|       |// This is a workaround to doxygen not being able to understand the inheritance logic
   87|       |// when it is hidden by the dense_xpr_base helper struct.
   88|       |// Moreover, doxygen fails to include members that are not documented in the declaration body of
   89|       |// MatrixBase if we inherits MatrixBase<Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_> >,
   90|       |// this is why we simply inherits MatrixBase, though this does not make sense.
   91|       |
   92|       |/** This class is just a workaround for Doxygen and it does not not actually exist. */
   93|       |template <typename Derived>
   94|       |struct dense_xpr_base_dispatcher;
   95|       |/** This class is just a workaround for Doxygen and it does not not actually exist. */
   96|       |template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
   97|       |struct dense_xpr_base_dispatcher<Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>> : public MatrixBase {};
   98|       |/** This class is just a workaround for Doxygen and it does not not actually exist. */
   99|       |template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
  100|       |struct dense_xpr_base_dispatcher<Array<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>> : public ArrayBase {};
  101|       |
  102|       |}  // namespace doxygen
  103|       |
  104|       |/** \class PlainObjectBase
  105|       | * \ingroup Core_Module
  106|       | * \brief %Dense storage base class for matrices and arrays.
  107|       | *
  108|       | * This class can be extended with the help of the plugin mechanism described on the page
  109|       | * \ref TopicCustomizing_Plugins by defining the preprocessor symbol \c EIGEN_PLAINOBJECTBASE_PLUGIN.
  110|       | *
  111|       | * \tparam Derived is the derived type, e.g., a Matrix or Array
  112|       | *
  113|       | * \sa \ref TopicClassHierarchy
  114|       | */
  115|       |template <typename Derived>
  116|       |class PlainObjectBase : public doxygen::dense_xpr_base_dispatcher<Derived>
  117|       |#else
  118|       |template <typename Derived>
  119|       |class PlainObjectBase : public internal::dense_xpr_base<Derived>::type
  120|       |#endif
  121|       |{
  122|       | public:
  123|       |  enum { Options = internal::traits<Derived>::Options };
  124|       |  typedef typename internal::dense_xpr_base<Derived>::type Base;
  125|       |
  126|       |  typedef typename internal::traits<Derived>::StorageKind StorageKind;
  127|       |  typedef typename internal::traits<Derived>::Scalar Scalar;
  128|       |
  129|       |  typedef typename internal::packet_traits<Scalar>::type PacketScalar;
  130|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  131|       |  typedef Derived DenseType;
  132|       |
  133|       |  using Base::ColsAtCompileTime;
  134|       |  using Base::Flags;
  135|       |  using Base::IsVectorAtCompileTime;
  136|       |  using Base::MaxColsAtCompileTime;
  137|       |  using Base::MaxRowsAtCompileTime;
  138|       |  using Base::MaxSizeAtCompileTime;
  139|       |  using Base::RowsAtCompileTime;
  140|       |  using Base::SizeAtCompileTime;
  141|       |
  142|       |  typedef Eigen::Map<Derived, Unaligned> MapType;
  143|       |  typedef const Eigen::Map<const Derived, Unaligned> ConstMapType;
  144|       |  typedef Eigen::Map<Derived, AlignedMax> AlignedMapType;
  145|       |  typedef const Eigen::Map<const Derived, AlignedMax> ConstAlignedMapType;
  146|       |  template <typename StrideType>
  147|       |  struct StridedMapType {
  148|       |    typedef Eigen::Map<Derived, Unaligned, StrideType> type;
  149|       |  };
  150|       |  template <typename StrideType>
  151|       |  struct StridedConstMapType {
  152|       |    typedef Eigen::Map<const Derived, Unaligned, StrideType> type;
  153|       |  };
  154|       |  template <typename StrideType>
  155|       |  struct StridedAlignedMapType {
  156|       |    typedef Eigen::Map<Derived, AlignedMax, StrideType> type;
  157|       |  };
  158|       |  template <typename StrideType>
  159|       |  struct StridedConstAlignedMapType {
  160|       |    typedef Eigen::Map<const Derived, AlignedMax, StrideType> type;
  161|       |  };
  162|       |
  163|       | protected:
  164|       |  DenseStorage<Scalar, Base::MaxSizeAtCompileTime, Base::RowsAtCompileTime, Base::ColsAtCompileTime, Options> m_storage;
  165|       |
  166|       | public:
  167|       |  enum { NeedsToAlign = (SizeAtCompileTime != Dynamic) && (internal::traits<Derived>::Alignment > 0) };
  168|       |  EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
  169|       |
  170|       |  EIGEN_STATIC_ASSERT(internal::check_implication(MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1,
  171|       |                                                  (int(Options) & RowMajor) == RowMajor),
  172|       |                      INVALID_MATRIX_TEMPLATE_PARAMETERS)
  173|       |  EIGEN_STATIC_ASSERT(internal::check_implication(MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1,
  174|       |                                                  (int(Options) & RowMajor) == 0),
  175|       |                      INVALID_MATRIX_TEMPLATE_PARAMETERS)
  176|       |  EIGEN_STATIC_ASSERT((RowsAtCompileTime == Dynamic) || (RowsAtCompileTime >= 0), INVALID_MATRIX_TEMPLATE_PARAMETERS)
  177|       |  EIGEN_STATIC_ASSERT((ColsAtCompileTime == Dynamic) || (ColsAtCompileTime >= 0), INVALID_MATRIX_TEMPLATE_PARAMETERS)
  178|       |  EIGEN_STATIC_ASSERT((MaxRowsAtCompileTime == Dynamic) || (MaxRowsAtCompileTime >= 0),
  179|       |                      INVALID_MATRIX_TEMPLATE_PARAMETERS)
  180|       |  EIGEN_STATIC_ASSERT((MaxColsAtCompileTime == Dynamic) || (MaxColsAtCompileTime >= 0),
  181|       |                      INVALID_MATRIX_TEMPLATE_PARAMETERS)
  182|       |  EIGEN_STATIC_ASSERT((MaxRowsAtCompileTime == RowsAtCompileTime || RowsAtCompileTime == Dynamic),
  183|       |                      INVALID_MATRIX_TEMPLATE_PARAMETERS)
  184|       |  EIGEN_STATIC_ASSERT((MaxColsAtCompileTime == ColsAtCompileTime || ColsAtCompileTime == Dynamic),
  185|       |                      INVALID_MATRIX_TEMPLATE_PARAMETERS)
  186|       |  EIGEN_STATIC_ASSERT(((Options & (DontAlign | RowMajor)) == Options), INVALID_MATRIX_TEMPLATE_PARAMETERS)
  187|       |
  188|       |  EIGEN_DEVICE_FUNC Base& base() { return *static_cast<Base*>(this); }
  189|       |  EIGEN_DEVICE_FUNC const Base& base() const { return *static_cast<const Base*>(this); }
  190|       |
  191|     75|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_storage.rows(); }
  ------------------
  | _ZNK5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE4rowsEv:
  |  191|     15|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_storage.rows(); }
  ------------------
  | _ZNK5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4rowsEv:
  |  191|     60|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_storage.rows(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE4rowsEv
  ------------------
  192|     68|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_storage.cols(); }
  ------------------
  | _ZNK5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE4colsEv:
  |  192|     14|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_storage.cols(); }
  ------------------
  | _ZNK5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4colsEv:
  |  192|     54|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_storage.cols(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE4colsEv
  ------------------
  193|       |
  194|       |  /** This is an overloaded version of DenseCoeffsBase<Derived,ReadOnlyAccessors>::coeff(Index,Index) const
  195|       |   * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.
  196|       |   *
  197|       |   * See DenseCoeffsBase<Derived,ReadOnlyAccessors>::coeff(Index) const for details. */
  198|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const Scalar& coeff(Index rowId, Index colId) const {
  199|       |    if (Flags & RowMajorBit)
  200|       |      return m_storage.data()[colId + rowId * m_storage.cols()];
  201|       |    else  // column-major
  202|       |      return m_storage.data()[rowId + colId * m_storage.rows()];
  203|       |  }
  204|       |
  205|       |  /** This is an overloaded version of DenseCoeffsBase<Derived,ReadOnlyAccessors>::coeff(Index) const
  206|       |   * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.
  207|       |   *
  208|       |   * See DenseCoeffsBase<Derived,ReadOnlyAccessors>::coeff(Index) const for details. */
  209|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const Scalar& coeff(Index index) const {
  210|       |    return m_storage.data()[index];
  211|       |  }
  212|       |
  213|       |  /** This is an overloaded version of DenseCoeffsBase<Derived,WriteAccessors>::coeffRef(Index,Index) const
  214|       |   * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.
  215|       |   *
  216|       |   * See DenseCoeffsBase<Derived,WriteAccessors>::coeffRef(Index,Index) const for details. */
  217|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& coeffRef(Index rowId, Index colId) {
  218|      2|    if (Flags & RowMajorBit)
  219|      0|      return m_storage.data()[colId + rowId * m_storage.cols()];
  220|      2|    else  // column-major
  221|      2|      return m_storage.data()[rowId + colId * m_storage.rows()];
  222|      2|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE8coeffRefEll:
  |  217|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& coeffRef(Index rowId, Index colId) {
  |  218|      2|    if (Flags & RowMajorBit)
  |  219|      0|      return m_storage.data()[colId + rowId * m_storage.cols()];
  |  220|      2|    else  // column-major
  |  221|      2|      return m_storage.data()[rowId + colId * m_storage.rows()];
  |  222|      2|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE8coeffRefEll
  ------------------
  223|       |
  224|       |  /** This is an overloaded version of DenseCoeffsBase<Derived,WriteAccessors>::coeffRef(Index) const
  225|       |   * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.
  226|       |   *
  227|       |   * See DenseCoeffsBase<Derived,WriteAccessors>::coeffRef(Index) const for details. */
  228|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar& coeffRef(Index index) { return m_storage.data()[index]; }
  229|       |
  230|       |  /** This is the const version of coeffRef(Index,Index) which is thus synonym of coeff(Index,Index).
  231|       |   * It is provided for convenience. */
  232|      4|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const Scalar& coeffRef(Index rowId, Index colId) const {
  233|      4|    if (Flags & RowMajorBit)
  234|      0|      return m_storage.data()[colId + rowId * m_storage.cols()];
  235|      4|    else  // column-major
  236|      4|      return m_storage.data()[rowId + colId * m_storage.rows()];
  237|      4|  }
  238|       |
  239|       |  /** This is the const version of coeffRef(Index) which is thus synonym of coeff(Index).
  240|       |   * It is provided for convenience. */
  241|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const Scalar& coeffRef(Index index) const {
  242|       |    return m_storage.data()[index];
  243|       |  }
  244|       |
  245|       |  /** \internal */
  246|       |  template <int LoadMode>
  247|       |  EIGEN_STRONG_INLINE PacketScalar packet(Index rowId, Index colId) const {
  248|       |    return internal::ploadt<PacketScalar, LoadMode>(
  249|       |        m_storage.data() + (Flags & RowMajorBit ? colId + rowId * m_storage.cols() : rowId + colId * m_storage.rows()));
  250|       |  }
  251|       |
  252|       |  /** \internal */
  253|       |  template <int LoadMode>
  254|       |  EIGEN_STRONG_INLINE PacketScalar packet(Index index) const {
  255|       |    return internal::ploadt<PacketScalar, LoadMode>(m_storage.data() + index);
  256|       |  }
  257|       |
  258|       |  /** \internal */
  259|       |  template <int StoreMode>
  260|       |  EIGEN_STRONG_INLINE void writePacket(Index rowId, Index colId, const PacketScalar& val) {
  261|       |    internal::pstoret<Scalar, PacketScalar, StoreMode>(
  262|       |        m_storage.data() + (Flags & RowMajorBit ? colId + rowId * m_storage.cols() : rowId + colId * m_storage.rows()),
  263|       |        val);
  264|       |  }
  265|       |
  266|       |  /** \internal */
  267|       |  template <int StoreMode>
  268|       |  EIGEN_STRONG_INLINE void writePacket(Index index, const PacketScalar& val) {
  269|       |    internal::pstoret<Scalar, PacketScalar, StoreMode>(m_storage.data() + index, val);
  270|       |  }
  271|       |
  272|       |  /** \returns a const pointer to the data array of this matrix */
  273|      8|  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const { return m_storage.data(); }
  ------------------
  | _ZNK5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE4dataEv:
  |  273|      5|  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const { return m_storage.data(); }
  ------------------
  | _ZNK5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4dataEv:
  |  273|      3|  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const { return m_storage.data(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE4dataEv
  ------------------
  274|       |
  275|       |  /** \returns a pointer to the data array of this matrix */
  276|      5|  EIGEN_DEVICE_FUNC constexpr Scalar* data() { return m_storage.data(); }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE4dataEv:
  |  276|      2|  EIGEN_DEVICE_FUNC constexpr Scalar* data() { return m_storage.data(); }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4dataEv:
  |  276|      3|  EIGEN_DEVICE_FUNC constexpr Scalar* data() { return m_storage.data(); }
  ------------------
  277|       |
  278|       |  /** Resizes \c *this to a \a rows x \a cols matrix.
  279|       |   *
  280|       |   * This method is intended for dynamic-size matrices, although it is legal to call it on any
  281|       |   * matrix as long as fixed dimensions are left unchanged. If you only want to change the number
  282|       |   * of rows and/or of columns, you can use resize(NoChange_t, Index), resize(Index, NoChange_t).
  283|       |   *
  284|       |   * If the current number of coefficients of \c *this exactly matches the
  285|       |   * product \a rows * \a cols, then no memory allocation is performed and
  286|       |   * the current values are left unchanged. In all other cases, including
  287|       |   * shrinking, the data is reallocated and all previous values are lost.
  288|       |   *
  289|       |   * Example: \include Matrix_resize_int_int.cpp
  290|       |   * Output: \verbinclude Matrix_resize_int_int.out
  291|       |   *
  292|       |   * \sa resize(Index) for vectors, resize(NoChange_t, Index), resize(Index, NoChange_t)
  293|       |   */
  294|      7|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index rows, Index cols) {
  295|      7|    eigen_assert(internal::check_implication(RowsAtCompileTime != Dynamic, rows == RowsAtCompileTime) &&
  296|      7|                 internal::check_implication(ColsAtCompileTime != Dynamic, cols == ColsAtCompileTime) &&
  297|      7|                 internal::check_implication(RowsAtCompileTime == Dynamic && MaxRowsAtCompileTime != Dynamic,
  298|      7|                                             rows <= MaxRowsAtCompileTime) &&
  299|      7|                 internal::check_implication(ColsAtCompileTime == Dynamic && MaxColsAtCompileTime != Dynamic,
  300|      7|                                             cols <= MaxColsAtCompileTime) &&
  301|      7|                 rows >= 0 && cols >= 0 && "Invalid sizes when resizing a matrix or array.");
  302|      7|#ifndef EIGEN_NO_DEBUG
  303|      7|    internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime, MaxRowsAtCompileTime, MaxColsAtCompileTime>::run(rows,
  304|      7|                                                                                                                  cols);
  305|      7|#endif
  306|       |#ifdef EIGEN_INITIALIZE_COEFFS
  307|       |    Index size = rows * cols;
  308|       |    bool size_changed = size != this->size();
  309|       |    m_storage.resize(size, rows, cols);
  310|       |    if (size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
  311|       |#else
  312|      7|    m_storage.resize(rows * cols, rows, cols);
  313|      7|#endif
  314|      7|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE6resizeEll:
  |  294|      6|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index rows, Index cols) {
  |  295|      6|    eigen_assert(internal::check_implication(RowsAtCompileTime != Dynamic, rows == RowsAtCompileTime) &&
  |  296|      6|                 internal::check_implication(ColsAtCompileTime != Dynamic, cols == ColsAtCompileTime) &&
  |  297|      6|                 internal::check_implication(RowsAtCompileTime == Dynamic && MaxRowsAtCompileTime != Dynamic,
  |  298|      6|                                             rows <= MaxRowsAtCompileTime) &&
  |  299|      6|                 internal::check_implication(ColsAtCompileTime == Dynamic && MaxColsAtCompileTime != Dynamic,
  |  300|      6|                                             cols <= MaxColsAtCompileTime) &&
  |  301|      6|                 rows >= 0 && cols >= 0 && "Invalid sizes when resizing a matrix or array.");
  |  302|      6|#ifndef EIGEN_NO_DEBUG
  |  303|      6|    internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime, MaxRowsAtCompileTime, MaxColsAtCompileTime>::run(rows,
  |  304|      6|                                                                                                                  cols);
  |  305|      6|#endif
  |  306|       |#ifdef EIGEN_INITIALIZE_COEFFS
  |  307|       |    Index size = rows * cols;
  |  308|       |    bool size_changed = size != this->size();
  |  309|       |    m_storage.resize(size, rows, cols);
  |  310|       |    if (size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
  |  311|       |#else
  |  312|      6|    m_storage.resize(rows * cols, rows, cols);
  |  313|      6|#endif
  |  314|      6|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE6resizeEll:
  |  294|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index rows, Index cols) {
  |  295|      1|    eigen_assert(internal::check_implication(RowsAtCompileTime != Dynamic, rows == RowsAtCompileTime) &&
  |  296|      1|                 internal::check_implication(ColsAtCompileTime != Dynamic, cols == ColsAtCompileTime) &&
  |  297|      1|                 internal::check_implication(RowsAtCompileTime == Dynamic && MaxRowsAtCompileTime != Dynamic,
  |  298|      1|                                             rows <= MaxRowsAtCompileTime) &&
  |  299|      1|                 internal::check_implication(ColsAtCompileTime == Dynamic && MaxColsAtCompileTime != Dynamic,
  |  300|      1|                                             cols <= MaxColsAtCompileTime) &&
  |  301|      1|                 rows >= 0 && cols >= 0 && "Invalid sizes when resizing a matrix or array.");
  |  302|      1|#ifndef EIGEN_NO_DEBUG
  |  303|      1|    internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime, MaxRowsAtCompileTime, MaxColsAtCompileTime>::run(rows,
  |  304|      1|                                                                                                                  cols);
  |  305|      1|#endif
  |  306|       |#ifdef EIGEN_INITIALIZE_COEFFS
  |  307|       |    Index size = rows * cols;
  |  308|       |    bool size_changed = size != this->size();
  |  309|       |    m_storage.resize(size, rows, cols);
  |  310|       |    if (size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
  |  311|       |#else
  |  312|      1|    m_storage.resize(rows * cols, rows, cols);
  |  313|      1|#endif
  |  314|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE6resizeEll
  ------------------
  315|       |
  316|       |  /** Resizes \c *this to a vector of length \a size
  317|       |   *
  318|       |   * \only_for_vectors. This method does not work for
  319|       |   * partially dynamic matrices when the static dimension is anything other
  320|       |   * than 1. For example it will not work with Matrix<double, 2, Dynamic>.
  321|       |   *
  322|       |   * Example: \include Matrix_resize_int.cpp
  323|       |   * Output: \verbinclude Matrix_resize_int.out
  324|       |   *
  325|       |   * \sa resize(Index,Index), resize(NoChange_t, Index), resize(Index, NoChange_t)
  326|       |   */
  327|      2|  EIGEN_DEVICE_FUNC inline constexpr void resize(Index size) {
  328|      2|    EIGEN_STATIC_ASSERT_VECTOR_ONLY(PlainObjectBase)
  329|      2|    eigen_assert(((SizeAtCompileTime == Dynamic && (MaxSizeAtCompileTime == Dynamic || size <= MaxSizeAtCompileTime)) ||
  330|      2|                  SizeAtCompileTime == size) &&
  331|      2|                 size >= 0);
  332|       |#ifdef EIGEN_INITIALIZE_COEFFS
  333|       |    bool size_changed = size != this->size();
  334|       |#endif
  335|      2|    if (RowsAtCompileTime == 1)
  336|      0|      m_storage.resize(size, 1, size);
  337|      2|    else
  338|      2|      m_storage.resize(size, size, 1);
  339|       |#ifdef EIGEN_INITIALIZE_COEFFS
  340|       |    if (size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
  341|       |#endif
  342|      2|  }
  343|       |
  344|       |  /** Resizes the matrix, changing only the number of columns. For the parameter of type NoChange_t, just pass the
  345|       |   * special value \c NoChange as in the example below.
  346|       |   *
  347|       |   * Example: \include Matrix_resize_NoChange_int.cpp
  348|       |   * Output: \verbinclude Matrix_resize_NoChange_int.out
  349|       |   *
  350|       |   * \sa resize(Index,Index)
  351|       |   */
  352|       |  EIGEN_DEVICE_FUNC inline constexpr void resize(NoChange_t, Index cols) { resize(rows(), cols); }
  353|       |
  354|       |  /** Resizes the matrix, changing only the number of rows. For the parameter of type NoChange_t, just pass the special
  355|       |   * value \c NoChange as in the example below.
  356|       |   *
  357|       |   * Example: \include Matrix_resize_int_NoChange.cpp
  358|       |   * Output: \verbinclude Matrix_resize_int_NoChange.out
  359|       |   *
  360|       |   * \sa resize(Index,Index)
  361|       |   */
  362|       |  EIGEN_DEVICE_FUNC inline constexpr void resize(Index rows, NoChange_t) { resize(rows, cols()); }
  363|       |
  364|       |  /** Resizes \c *this to have the same dimensions as \a other.
  365|       |   * Takes care of doing all the checking that's needed.
  366|       |   *
  367|       |   * Note that copying a row-vector into a vector (and conversely) is allowed.
  368|       |   * The resizing, if any, is then done in the appropriate way so that row-vectors
  369|       |   * remain row-vectors and vectors remain vectors.
  370|       |   */
  371|       |  template <typename OtherDerived>
  372|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resizeLike(const EigenBase<OtherDerived>& _other) {
  373|      1|    const OtherDerived& other = _other.derived();
  374|      1|#ifndef EIGEN_NO_DEBUG
  375|      1|    internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime, MaxRowsAtCompileTime, MaxColsAtCompileTime>::run(
  376|      1|        other.rows(), other.cols());
  377|      1|#endif
  378|      1|    const Index othersize = other.rows() * other.cols();
  379|      1|    if (RowsAtCompileTime == 1) {
  380|      0|      eigen_assert(other.rows() == 1 || other.cols() == 1);
  381|      0|      resize(1, othersize);
  382|      1|    } else if (ColsAtCompileTime == 1) {
  383|      0|      eigen_assert(other.rows() == 1 || other.cols() == 1);
  384|      0|      resize(othersize, 1);
  385|      0|    } else
  386|      1|      resize(other.rows(), other.cols());
  387|      1|  }
  388|       |
  389|       |  /** Resizes the matrix to \a rows x \a cols while leaving old values untouched.
  390|       |   *
  391|       |   * The method is intended for matrices of dynamic size. If you only want to change the number
  392|       |   * of rows and/or of columns, you can use conservativeResize(NoChange_t, Index) or
  393|       |   * conservativeResize(Index, NoChange_t).
  394|       |   *
  395|       |   * Matrices are resized relative to the top-left element. In case values need to be
  396|       |   * appended to the matrix they will be uninitialized.
  397|       |   */
  398|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResize(Index rows, Index cols) {
  399|       |    internal::conservative_resize_like_impl<Derived>::run(*this, rows, cols);
  400|       |  }
  401|       |
  402|       |  /** Resizes the matrix to \a rows x \a cols while leaving old values untouched.
  403|       |   *
  404|       |   * As opposed to conservativeResize(Index rows, Index cols), this version leaves
  405|       |   * the number of columns unchanged.
  406|       |   *
  407|       |   * In case the matrix is growing, new rows will be uninitialized.
  408|       |   */
  409|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResize(Index rows, NoChange_t) {
  410|       |    // Note: see the comment in conservativeResize(Index,Index)
  411|       |    conservativeResize(rows, cols());
  412|       |  }
  413|       |
  414|       |  /** Resizes the matrix to \a rows x \a cols while leaving old values untouched.
  415|       |   *
  416|       |   * As opposed to conservativeResize(Index rows, Index cols), this version leaves
  417|       |   * the number of rows unchanged.
  418|       |   *
  419|       |   * In case the matrix is growing, new columns will be uninitialized.
  420|       |   */
  421|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResize(NoChange_t, Index cols) {
  422|       |    // Note: see the comment in conservativeResize(Index,Index)
  423|       |    conservativeResize(rows(), cols);
  424|       |  }
  425|       |
  426|       |  /** Resizes the vector to \a size while retaining old values.
  427|       |   *
  428|       |   * \only_for_vectors. This method does not work for
  429|       |   * partially dynamic matrices when the static dimension is anything other
  430|       |   * than 1. For example it will not work with Matrix<double, 2, Dynamic>.
  431|       |   *
  432|       |   * When values are appended, they will be uninitialized.
  433|       |   */
  434|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResize(Index size) {
  435|       |    internal::conservative_resize_like_impl<Derived>::run(*this, size);
  436|       |  }
  437|       |
  438|       |  /** Resizes the matrix to \a rows x \a cols of \c other, while leaving old values untouched.
  439|       |   *
  440|       |   * The method is intended for matrices of dynamic size. If you only want to change the number
  441|       |   * of rows and/or of columns, you can use conservativeResize(NoChange_t, Index) or
  442|       |   * conservativeResize(Index, NoChange_t).
  443|       |   *
  444|       |   * Matrices are resized relative to the top-left element. In case values need to be
  445|       |   * appended to the matrix they will copied from \c other.
  446|       |   */
  447|       |  template <typename OtherDerived>
  448|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResizeLike(const DenseBase<OtherDerived>& other) {
  449|       |    internal::conservative_resize_like_impl<Derived, OtherDerived>::run(*this, other);
  450|       |  }
  451|       |
  452|       |  /** This is a special case of the templated operator=. Its purpose is to
  453|       |   * prevent a default operator= from hiding the templated operator=.
  454|       |   */
  455|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived& operator=(const PlainObjectBase& other) {
  456|       |    return _set(other);
  457|       |  }
  458|       |
  459|       |  /** \sa MatrixBase::lazyAssign() */
  460|       |  template <typename OtherDerived>
  461|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& lazyAssign(const DenseBase<OtherDerived>& other) {
  462|       |    _resize_to_match(other);
  463|       |    return Base::lazyAssign(other.derived());
  464|       |  }
  465|       |
  466|       |  template <typename OtherDerived>
  467|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const ReturnByValue<OtherDerived>& func) {
  468|       |    resize(func.rows(), func.cols());
  469|       |    return Base::operator=(func);
  470|       |  }
  471|       |
  472|       |  // Prevent user from trying to instantiate PlainObjectBase objects
  473|       |  // by making all its constructor protected. See bug 1074.
  474|       | protected:
  475|      8|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr PlainObjectBase() = default;
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEC2Ev:
  |  475|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr PlainObjectBase() = default;
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEC2Ev:
  |  475|      5|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr PlainObjectBase() = default;
  ------------------
  | Unexecuted instantiation: _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEC2Ev
  ------------------
  476|       |  /** \brief Move constructor */
  477|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr PlainObjectBase(PlainObjectBase&&) = default;
  478|       |  /** \brief Move assignment operator */
  479|       |  EIGEN_DEVICE_FUNC constexpr PlainObjectBase& operator=(PlainObjectBase&& other) EIGEN_NOEXCEPT {
  480|       |    m_storage = std::move(other.m_storage);
  481|       |    return *this;
  482|       |  }
  483|       |
  484|       |  /** Copy constructor */
  485|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr PlainObjectBase(const PlainObjectBase&) = default;
  486|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(Index size, Index rows, Index cols)
  487|       |      : m_storage(size, rows, cols) {}
  488|       |
  489|       |  /** \brief Construct a row of column vector with fixed size from an arbitrary number of coefficients.
  490|       |   *
  491|       |   * \only_for_vectors
  492|       |   *
  493|       |   * This constructor is for 1D array or vectors with more than 4 coefficients.
  494|       |   *
  495|       |   * \warning To construct a column (resp. row) vector of fixed length, the number of values passed to this
  496|       |   * constructor must match the the fixed number of rows (resp. columns) of \c *this.
  497|       |   */
  498|       |  template <typename... ArgTypes>
  499|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(const Scalar& a0, const Scalar& a1, const Scalar& a2,
  500|       |                                                        const Scalar& a3, const ArgTypes&... args)
  501|       |      : m_storage() {
  502|       |    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, sizeof...(args) + 4);
  503|       |    m_storage.data()[0] = a0;
  504|       |    m_storage.data()[1] = a1;
  505|       |    m_storage.data()[2] = a2;
  506|       |    m_storage.data()[3] = a3;
  507|       |    Index i = 4;
  508|       |    auto x = {(m_storage.data()[i++] = args, 0)...};
  509|       |    static_cast<void>(x);
  510|       |  }
  511|       |
  512|       |  /** \brief Constructs a Matrix or Array and initializes it by elements given by an initializer list of initializer
  513|       |   * lists
  514|       |   */
  515|       |  EIGEN_DEVICE_FUNC explicit constexpr EIGEN_STRONG_INLINE PlainObjectBase(
  516|       |      const std::initializer_list<std::initializer_list<Scalar>>& list)
  517|       |      : m_storage() {
  518|       |    size_t list_size = 0;
  519|       |    if (list.begin() != list.end()) {
  520|       |      list_size = list.begin()->size();
  521|       |    }
  522|       |
  523|       |    // This is to allow syntax like VectorXi {{1, 2, 3, 4}}
  524|       |    if (ColsAtCompileTime == 1 && list.size() == 1) {
  525|       |      eigen_assert(list_size == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic);
  526|       |      resize(list_size, ColsAtCompileTime);
  527|       |      if (list.begin()->begin() != nullptr) {
  528|       |        Index index = 0;
  529|       |        for (const Scalar& e : *list.begin()) {
  530|       |          coeffRef(index++) = e;
  531|       |        }
  532|       |      }
  533|       |    } else {
  534|       |      eigen_assert(list.size() == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic);
  535|       |      eigen_assert(list_size == static_cast<size_t>(ColsAtCompileTime) || ColsAtCompileTime == Dynamic);
  536|       |      resize(list.size(), list_size);
  537|       |
  538|       |      Index row_index = 0;
  539|       |      for (const std::initializer_list<Scalar>& row : list) {
  540|       |        eigen_assert(list_size == row.size());
  541|       |        Index col_index = 0;
  542|       |        for (const Scalar& e : row) {
  543|       |          coeffRef(row_index, col_index) = e;
  544|       |          ++col_index;
  545|       |        }
  546|       |        ++row_index;
  547|       |      }
  548|       |    }
  549|       |  }
  550|       |
  551|       |  /** \sa PlainObjectBase::operator=(const EigenBase<OtherDerived>&) */
  552|       |  template <typename OtherDerived>
  553|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(const DenseBase<OtherDerived>& other) : m_storage() {
  554|      1|    resizeLike(other);
  555|      1|    _set_noalias(other);
  556|      1|  }
  557|       |
  558|       |  /** \sa PlainObjectBase::operator=(const EigenBase<OtherDerived>&) */
  559|       |  template <typename OtherDerived>
  560|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(const EigenBase<OtherDerived>& other) : m_storage() {
  561|       |    resizeLike(other);
  562|       |    *this = other.derived();
  563|       |  }
  564|       |  /** \brief Copy constructor with in-place evaluation */
  565|       |  template <typename OtherDerived>
  566|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(const ReturnByValue<OtherDerived>& other) {
  567|       |    // FIXME this does not automatically transpose vectors if necessary
  568|       |    resize(other.rows(), other.cols());
  569|       |    other.evalTo(this->derived());
  570|       |  }
  571|       |
  572|       | public:
  573|       |  /** \brief Copies the generic expression \a other into *this.
  574|       |   * \copydetails DenseBase::operator=(const EigenBase<OtherDerived> &other)
  575|       |   */
  576|       |  template <typename OtherDerived>
  577|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const EigenBase<OtherDerived>& other) {
  578|       |    _resize_to_match(other);
  579|       |    Base::operator=(other.derived());
  580|       |    return this->derived();
  581|       |  }
  582|       |
  583|       |  /** \name Map
  584|       |   * These are convenience functions returning Map objects. The Map() static functions return unaligned Map objects,
  585|       |   * while the AlignedMap() functions return aligned Map objects and thus should be called only with 16-byte-aligned
  586|       |   * \a data pointers.
  587|       |   *
  588|       |   * Here is an example using strides:
  589|       |   * \include Matrix_Map_stride.cpp
  590|       |   * Output: \verbinclude Matrix_Map_stride.out
  591|       |   *
  592|       |   * \see class Map
  593|       |   */
  594|       |  ///@{
  595|       |  static inline ConstMapType Map(const Scalar* data) { return ConstMapType(data); }
  596|       |  static inline MapType Map(Scalar* data) { return MapType(data); }
  597|       |  static inline ConstMapType Map(const Scalar* data, Index size) { return ConstMapType(data, size); }
  598|       |  static inline MapType Map(Scalar* data, Index size) { return MapType(data, size); }
  599|       |  static inline ConstMapType Map(const Scalar* data, Index rows, Index cols) { return ConstMapType(data, rows, cols); }
  600|       |  static inline MapType Map(Scalar* data, Index rows, Index cols) { return MapType(data, rows, cols); }
  601|       |
  602|       |  static inline ConstAlignedMapType MapAligned(const Scalar* data) { return ConstAlignedMapType(data); }
  603|       |  static inline AlignedMapType MapAligned(Scalar* data) { return AlignedMapType(data); }
  604|       |  static inline ConstAlignedMapType MapAligned(const Scalar* data, Index size) {
  605|       |    return ConstAlignedMapType(data, size);
  606|       |  }
  607|       |  static inline AlignedMapType MapAligned(Scalar* data, Index size) { return AlignedMapType(data, size); }
  608|       |  static inline ConstAlignedMapType MapAligned(const Scalar* data, Index rows, Index cols) {
  609|       |    return ConstAlignedMapType(data, rows, cols);
  610|       |  }
  611|       |  static inline AlignedMapType MapAligned(Scalar* data, Index rows, Index cols) {
  612|       |    return AlignedMapType(data, rows, cols);
  613|       |  }
  614|       |
  615|       |  template <int Outer, int Inner>
  616|       |  static inline typename StridedConstMapType<Stride<Outer, Inner>>::type Map(const Scalar* data,
  617|       |                                                                             const Stride<Outer, Inner>& stride) {
  618|       |    return typename StridedConstMapType<Stride<Outer, Inner>>::type(data, stride);
  619|       |  }
  620|       |  template <int Outer, int Inner>
  621|       |  static inline typename StridedMapType<Stride<Outer, Inner>>::type Map(Scalar* data,
  622|       |                                                                        const Stride<Outer, Inner>& stride) {
  623|       |    return typename StridedMapType<Stride<Outer, Inner>>::type(data, stride);
  624|       |  }
  625|       |  template <int Outer, int Inner>
  626|       |  static inline typename StridedConstMapType<Stride<Outer, Inner>>::type Map(const Scalar* data, Index size,
  627|       |                                                                             const Stride<Outer, Inner>& stride) {
  628|       |    return typename StridedConstMapType<Stride<Outer, Inner>>::type(data, size, stride);
  629|       |  }
  630|       |  template <int Outer, int Inner>
  631|       |  static inline typename StridedMapType<Stride<Outer, Inner>>::type Map(Scalar* data, Index size,
  632|       |                                                                        const Stride<Outer, Inner>& stride) {
  633|       |    return typename StridedMapType<Stride<Outer, Inner>>::type(data, size, stride);
  634|       |  }
  635|       |  template <int Outer, int Inner>
  636|       |  static inline typename StridedConstMapType<Stride<Outer, Inner>>::type Map(const Scalar* data, Index rows, Index cols,
  637|       |                                                                             const Stride<Outer, Inner>& stride) {
  638|       |    return typename StridedConstMapType<Stride<Outer, Inner>>::type(data, rows, cols, stride);
  639|       |  }
  640|       |  template <int Outer, int Inner>
  641|       |  static inline typename StridedMapType<Stride<Outer, Inner>>::type Map(Scalar* data, Index rows, Index cols,
  642|       |                                                                        const Stride<Outer, Inner>& stride) {
  643|       |    return typename StridedMapType<Stride<Outer, Inner>>::type(data, rows, cols, stride);
  644|       |  }
  645|       |
  646|       |  template <int Outer, int Inner>
  647|       |  static inline typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
  648|       |      const Scalar* data, const Stride<Outer, Inner>& stride) {
  649|       |    return typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type(data, stride);
  650|       |  }
  651|       |  template <int Outer, int Inner>
  652|       |  static inline typename StridedAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
  653|       |      Scalar* data, const Stride<Outer, Inner>& stride) {
  654|       |    return typename StridedAlignedMapType<Stride<Outer, Inner>>::type(data, stride);
  655|       |  }
  656|       |  template <int Outer, int Inner>
  657|       |  static inline typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
  658|       |      const Scalar* data, Index size, const Stride<Outer, Inner>& stride) {
  659|       |    return typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type(data, size, stride);
  660|       |  }
  661|       |  template <int Outer, int Inner>
  662|       |  static inline typename StridedAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
  663|       |      Scalar* data, Index size, const Stride<Outer, Inner>& stride) {
  664|       |    return typename StridedAlignedMapType<Stride<Outer, Inner>>::type(data, size, stride);
  665|       |  }
  666|       |  template <int Outer, int Inner>
  667|       |  static inline typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
  668|       |      const Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride) {
  669|       |    return typename StridedConstAlignedMapType<Stride<Outer, Inner>>::type(data, rows, cols, stride);
  670|       |  }
  671|       |  template <int Outer, int Inner>
  672|       |  static inline typename StridedAlignedMapType<Stride<Outer, Inner>>::type MapAligned(
  673|       |      Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride) {
  674|       |    return typename StridedAlignedMapType<Stride<Outer, Inner>>::type(data, rows, cols, stride);
  675|       |  }
  676|       |  ///@}
  677|       |
  678|       |  using Base::setConstant;
  679|       |  EIGEN_DEVICE_FUNC Derived& setConstant(Index size, const Scalar& val);
  680|       |  EIGEN_DEVICE_FUNC Derived& setConstant(Index rows, Index cols, const Scalar& val);
  681|       |  EIGEN_DEVICE_FUNC Derived& setConstant(NoChange_t, Index cols, const Scalar& val);
  682|       |  EIGEN_DEVICE_FUNC Derived& setConstant(Index rows, NoChange_t, const Scalar& val);
  683|       |
  684|       |  using Base::setZero;
  685|       |  EIGEN_DEVICE_FUNC Derived& setZero(Index size);
  686|       |  EIGEN_DEVICE_FUNC Derived& setZero(Index rows, Index cols);
  687|       |  EIGEN_DEVICE_FUNC Derived& setZero(NoChange_t, Index cols);
  688|       |  EIGEN_DEVICE_FUNC Derived& setZero(Index rows, NoChange_t);
  689|       |
  690|       |  using Base::setOnes;
  691|       |  EIGEN_DEVICE_FUNC Derived& setOnes(Index size);
  692|       |  EIGEN_DEVICE_FUNC Derived& setOnes(Index rows, Index cols);
  693|       |  EIGEN_DEVICE_FUNC Derived& setOnes(NoChange_t, Index cols);
  694|       |  EIGEN_DEVICE_FUNC Derived& setOnes(Index rows, NoChange_t);
  695|       |
  696|       |  using Base::setRandom;
  697|       |  Derived& setRandom(Index size);
  698|       |  Derived& setRandom(Index rows, Index cols);
  699|       |  Derived& setRandom(NoChange_t, Index cols);
  700|       |  Derived& setRandom(Index rows, NoChange_t);
  701|       |
  702|       |#ifdef EIGEN_PLAINOBJECTBASE_PLUGIN
  703|       |#include EIGEN_PLAINOBJECTBASE_PLUGIN
  704|       |#endif
  705|       |
  706|       | protected:
  707|       |  /** \internal Resizes *this in preparation for assigning \a other to it.
  708|       |   * Takes care of doing all the checking that's needed.
  709|       |   *
  710|       |   * Note that copying a row-vector into a vector (and conversely) is allowed.
  711|       |   * The resizing, if any, is then done in the appropriate way so that row-vectors
  712|       |   * remain row-vectors and vectors remain vectors.
  713|       |   */
  714|       |  template <typename OtherDerived>
  715|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _resize_to_match(const EigenBase<OtherDerived>& other) {
  716|       |#ifdef EIGEN_NO_AUTOMATIC_RESIZING
  717|       |    eigen_assert((this->size() == 0 || (IsVectorAtCompileTime ? (this->size() == other.size())
  718|       |                                                              : (rows() == other.rows() && cols() == other.cols()))) &&
  719|       |                 "Size mismatch. Automatic resizing is disabled because EIGEN_NO_AUTOMATIC_RESIZING is defined");
  720|       |    EIGEN_ONLY_USED_FOR_DEBUG(other);
  721|       |#else
  722|       |    resizeLike(other);
  723|       |#endif
  724|       |  }
  725|       |
  726|       |  /**
  727|       |   * \brief Copies the value of the expression \a other into \c *this with automatic resizing.
  728|       |   *
  729|       |   * *this might be resized to match the dimensions of \a other. If *this was a null matrix (not already initialized),
  730|       |   * it will be initialized.
  731|       |   *
  732|       |   * Note that copying a row-vector into a vector (and conversely) is allowed.
  733|       |   * The resizing, if any, is then done in the appropriate way so that row-vectors
  734|       |   * remain row-vectors and vectors remain vectors.
  735|       |   *
  736|       |   * \sa operator=(const MatrixBase<OtherDerived>&), _set_noalias()
  737|       |   *
  738|       |   * \internal
  739|       |   */
  740|       |  // aliasing is dealt once in internal::call_assignment
  741|       |  // so at this stage we have to assume aliasing... and resising has to be done later.
  742|       |  template <typename OtherDerived>
  743|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived& _set(const DenseBase<OtherDerived>& other) {
  744|      2|    internal::call_assignment(this->derived(), other.derived());
  745|      2|    return this->derived();
  746|      2|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE4_setINS_7ProductINS6_INS1_IS2_Lin1ELin1ELi0ELin1ELin1EEES7_Li0EEES3_Li0EEEEERS3_RKNS_9DenseBaseIT_EE:
  |  743|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived& _set(const DenseBase<OtherDerived>& other) {
  |  744|      1|    internal::call_assignment(this->derived(), other.derived());
  |  745|      1|    return this->derived();
  |  746|      1|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4_setINS_7ProductINS6_IS3_S3_Li0EEES3_Li0EEEEERS3_RKNS_9DenseBaseIT_EE:
  |  743|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived& _set(const DenseBase<OtherDerived>& other) {
  |  744|      1|    internal::call_assignment(this->derived(), other.derived());
  |  745|      1|    return this->derived();
  |  746|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE4_setINS_3MapIS3_Li1ENS_6StrideILi0ELi0EEEEEEERS3_RKNS_9DenseBaseIT_EE
  ------------------
  747|       |
  748|       |  /** \internal Like _set() but additionally makes the assumption that no aliasing effect can happen (which
  749|       |   * is the case when creating a new matrix) so one can enforce lazy evaluation.
  750|       |   *
  751|       |   * \sa operator=(const MatrixBase<OtherDerived>&), _set()
  752|       |   */
  753|       |  template <typename OtherDerived>
  754|      4|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived& _set_noalias(const DenseBase<OtherDerived>& other) {
  755|       |    // I don't think we need this resize call since the lazyAssign will anyways resize
  756|       |    // and lazyAssign will be called by the assign selector.
  757|       |    //_resize_to_match(other);
  758|       |    // the 'false' below means to enforce lazy evaluation. We don't use lazyAssign() because
  759|       |    // it wouldn't allow to copy a row-vector into a column-vector.
  760|      4|    internal::call_assignment_no_alias(this->derived(), other.derived(),
  761|      4|                                       internal::assign_op<Scalar, typename OtherDerived::Scalar>());
  762|      4|    return this->derived();
  763|      4|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE12_set_noaliasINS_7ProductINS6_INS1_IS2_Lin1ELin1ELi0ELin1ELin1EEES7_Li0EEES3_Li0EEEEERS3_RKNS_9DenseBaseIT_EE:
  |  754|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived& _set_noalias(const DenseBase<OtherDerived>& other) {
  |  755|       |    // I don't think we need this resize call since the lazyAssign will anyways resize
  |  756|       |    // and lazyAssign will be called by the assign selector.
  |  757|       |    //_resize_to_match(other);
  |  758|       |    // the 'false' below means to enforce lazy evaluation. We don't use lazyAssign() because
  |  759|       |    // it wouldn't allow to copy a row-vector into a column-vector.
  |  760|      1|    internal::call_assignment_no_alias(this->derived(), other.derived(),
  |  761|      1|                                       internal::assign_op<Scalar, typename OtherDerived::Scalar>());
  |  762|      1|    return this->derived();
  |  763|      1|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE12_set_noaliasINS_7ProductIS3_S3_Li0EEEEERS3_RKNS_9DenseBaseIT_EE:
  |  754|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived& _set_noalias(const DenseBase<OtherDerived>& other) {
  |  755|       |    // I don't think we need this resize call since the lazyAssign will anyways resize
  |  756|       |    // and lazyAssign will be called by the assign selector.
  |  757|       |    //_resize_to_match(other);
  |  758|       |    // the 'false' below means to enforce lazy evaluation. We don't use lazyAssign() because
  |  759|       |    // it wouldn't allow to copy a row-vector into a column-vector.
  |  760|      2|    internal::call_assignment_no_alias(this->derived(), other.derived(),
  |  761|      2|                                       internal::assign_op<Scalar, typename OtherDerived::Scalar>());
  |  762|      2|    return this->derived();
  |  763|      2|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE12_set_noaliasINS_7ProductINS6_IS3_S3_Li0EEES3_Li0EEEEERS3_RKNS_9DenseBaseIT_EE:
  |  754|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived& _set_noalias(const DenseBase<OtherDerived>& other) {
  |  755|       |    // I don't think we need this resize call since the lazyAssign will anyways resize
  |  756|       |    // and lazyAssign will be called by the assign selector.
  |  757|       |    //_resize_to_match(other);
  |  758|       |    // the 'false' below means to enforce lazy evaluation. We don't use lazyAssign() because
  |  759|       |    // it wouldn't allow to copy a row-vector into a column-vector.
  |  760|      1|    internal::call_assignment_no_alias(this->derived(), other.derived(),
  |  761|      1|                                       internal::assign_op<Scalar, typename OtherDerived::Scalar>());
  |  762|      1|    return this->derived();
  |  763|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE12_set_noaliasINS_5BlockIKNS_7ProductINS1_IS2_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEEEERS3_RKNS_9DenseBaseIT_EE
  ------------------
  764|       |
  765|       |  template <typename T0, typename T1>
  766|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init2(Index rows, Index cols,
  767|      3|                                                    std::enable_if_t<Base::SizeAtCompileTime != 2, T0>* = 0) {
  768|      3|    EIGEN_STATIC_ASSERT(internal::is_valid_index_type<T0>::value && internal::is_valid_index_type<T1>::value,
  769|      3|                        T0 AND T1 MUST BE INTEGER TYPES)
  770|      3|    resize(rows, cols);
  771|      3|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE6_init2IiiEEvllPNSt9enable_ifILb1ET_E4typeE:
  |  767|      3|                                                    std::enable_if_t<Base::SizeAtCompileTime != 2, T0>* = 0) {
  |  768|      3|    EIGEN_STATIC_ASSERT(internal::is_valid_index_type<T0>::value && internal::is_valid_index_type<T1>::value,
  |  769|      3|                        T0 AND T1 MUST BE INTEGER TYPES)
  |  770|      3|    resize(rows, cols);
  |  771|      3|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE6_init2IllEEvllPNSt9enable_ifILb1ET_E4typeE
  ------------------
  772|       |
  773|       |  template <typename T0, typename T1>
  774|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init2(const T0& val0, const T1& val1,
  775|       |                                                    std::enable_if_t<Base::SizeAtCompileTime == 2, T0>* = 0) {
  776|       |    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, 2)
  777|       |    m_storage.data()[0] = Scalar(val0);
  778|       |    m_storage.data()[1] = Scalar(val1);
  779|       |  }
  780|       |
  781|       |  template <typename T0, typename T1>
  782|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init2(
  783|       |      const Index& val0, const Index& val1,
  784|       |      std::enable_if_t<(!internal::is_same<Index, Scalar>::value) && (internal::is_same<T0, Index>::value) &&
  785|       |                           (internal::is_same<T1, Index>::value) && Base::SizeAtCompileTime == 2,
  786|       |                       T1>* = 0) {
  787|       |    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, 2)
  788|       |    m_storage.data()[0] = Scalar(val0);
  789|       |    m_storage.data()[1] = Scalar(val1);
  790|       |  }
  791|       |
  792|       |  // The argument is convertible to the Index type and we either have a non 1x1 Matrix, or a dynamic-sized Array,
  793|       |  // then the argument is meant to be the size of the object.
  794|       |  template <typename T>
  795|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(
  796|       |      Index size,
  797|       |      std::enable_if_t<(Base::SizeAtCompileTime != 1 || !internal::is_convertible<T, Scalar>::value) &&
  798|       |                           ((!internal::is_same<typename internal::traits<Derived>::XprKind, ArrayXpr>::value ||
  799|       |                             Base::SizeAtCompileTime == Dynamic)),
  800|      2|                       T>* = 0) {
  801|       |    // NOTE MSVC 2008 complains if we directly put bool(NumTraits<T>::IsInteger) as the EIGEN_STATIC_ASSERT argument.
  802|      2|    const bool is_integer_alike = internal::is_valid_index_type<T>::value;
  803|      2|    EIGEN_UNUSED_VARIABLE(is_integer_alike);
  804|      2|    EIGEN_STATIC_ASSERT(is_integer_alike, FLOATING_POINT_ARGUMENT_PASSED__INTEGER_WAS_EXPECTED)
  805|      2|    resize(size);
  806|      2|  }
  807|       |
  808|       |  // We have a 1x1 matrix/array => the argument is interpreted as the value of the unique coefficient (case where scalar
  809|       |  // type can be implicitly converted)
  810|       |  template <typename T>
  811|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(
  812|       |      const Scalar& val0,
  813|       |      std::enable_if_t<Base::SizeAtCompileTime == 1 && internal::is_convertible<T, Scalar>::value, T>* = 0) {
  814|       |    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, 1)
  815|       |    m_storage.data()[0] = val0;
  816|       |  }
  817|       |
  818|       |  // We have a 1x1 matrix/array => the argument is interpreted as the value of the unique coefficient (case where scalar
  819|       |  // type match the index type)
  820|       |  template <typename T>
  821|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(
  822|       |      const Index& val0,
  823|       |      std::enable_if_t<(!internal::is_same<Index, Scalar>::value) && (internal::is_same<Index, T>::value) &&
  824|       |                           Base::SizeAtCompileTime == 1 && internal::is_convertible<T, Scalar>::value,
  825|       |                       T*>* = 0) {
  826|       |    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, 1)
  827|       |    m_storage.data()[0] = Scalar(val0);
  828|       |  }
  829|       |
  830|       |  // Initialize a fixed size matrix from a pointer to raw data
  831|       |  template <typename T>
  832|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const Scalar* data) {
  833|       |    this->_set_noalias(ConstMapType(data));
  834|       |  }
  835|       |
  836|       |  // Initialize an arbitrary matrix from a dense expression
  837|       |  template <typename T, typename OtherDerived>
  838|      3|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const DenseBase<OtherDerived>& other) {
  839|      3|    this->_set_noalias(other);
  840|      3|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE6_init1INS_7ProductINS6_INS1_IS2_Lin1ELin1ELi0ELin1ELin1EEES7_Li0EEES3_Li0EEES9_EEvRKNS_9DenseBaseIT0_EE:
  |  838|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const DenseBase<OtherDerived>& other) {
  |  839|      1|    this->_set_noalias(other);
  |  840|      1|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE6_init1INS_7ProductIS3_S3_Li0EEES7_EEvRKNS_9DenseBaseIT0_EE:
  |  838|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const DenseBase<OtherDerived>& other) {
  |  839|      1|    this->_set_noalias(other);
  |  840|      1|  }
  ------------------
  | _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE6_init1INS_7ProductINS6_IS3_S3_Li0EEES3_Li0EEES8_EEvRKNS_9DenseBaseIT0_EE:
  |  838|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const DenseBase<OtherDerived>& other) {
  |  839|      1|    this->_set_noalias(other);
  |  840|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE6_init1INS_5BlockIKNS_7ProductINS1_IS2_Lin1ELin1ELi0ELin1ELin1EEES8_Li0EEELi1ELin1ELb0EEESB_EEvRKNS_9DenseBaseIT0_EE
  ------------------
  841|       |
  842|       |  // Initialize an arbitrary matrix from an object convertible to the Derived type.
  843|       |  template <typename T>
  844|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const Derived& other) {
  845|       |    this->_set_noalias(other);
  846|       |  }
  847|       |
  848|       |  // Initialize an arbitrary matrix from a generic Eigen expression
  849|       |  template <typename T, typename OtherDerived>
  850|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const EigenBase<OtherDerived>& other) {
  851|       |    this->derived() = other;
  852|       |  }
  853|       |
  854|       |  template <typename T, typename OtherDerived>
  855|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const ReturnByValue<OtherDerived>& other) {
  856|       |    resize(other.rows(), other.cols());
  857|       |    other.evalTo(this->derived());
  858|       |  }
  859|       |
  860|       |  template <typename T, typename OtherDerived, int ColsAtCompileTime>
  861|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const RotationBase<OtherDerived, ColsAtCompileTime>& r) {
  862|       |    this->derived() = r;
  863|       |  }
  864|       |
  865|       |  // For fixed-size Array<Scalar,...>
  866|       |  template <typename T>
  867|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(
  868|       |      const Scalar& val0,
  869|       |      std::enable_if_t<Base::SizeAtCompileTime != Dynamic && Base::SizeAtCompileTime != 1 &&
  870|       |                           internal::is_convertible<T, Scalar>::value &&
  871|       |                           internal::is_same<typename internal::traits<Derived>::XprKind, ArrayXpr>::value,
  872|       |                       T>* = 0) {
  873|       |    Base::setConstant(val0);
  874|       |  }
  875|       |
  876|       |  // For fixed-size Array<Index,...>
  877|       |  template <typename T>
  878|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(
  879|       |      const Index& val0,
  880|       |      std::enable_if_t<(!internal::is_same<Index, Scalar>::value) && (internal::is_same<Index, T>::value) &&
  881|       |                           Base::SizeAtCompileTime != Dynamic && Base::SizeAtCompileTime != 1 &&
  882|       |                           internal::is_convertible<T, Scalar>::value &&
  883|       |                           internal::is_same<typename internal::traits<Derived>::XprKind, ArrayXpr>::value,
  884|       |                       T*>* = 0) {
  885|       |    Base::setConstant(val0);
  886|       |  }
  887|       |
  888|       |  template <typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers>
  889|       |  friend struct internal::matrix_swap_impl;
  890|       |
  891|       | public:
  892|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  893|       |  /** \internal
  894|       |   * \brief Override DenseBase::swap() since for dynamic-sized matrices
  895|       |   * of same type it is enough to swap the data pointers.
  896|       |   */
  897|       |  template <typename OtherDerived>
  898|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void swap(DenseBase<OtherDerived>& other) {
  899|       |    enum {SwapPointers = internal::is_same<Derived, OtherDerived>::value && Base::SizeAtCompileTime == Dynamic};
  900|       |    internal::matrix_swap_impl<Derived, OtherDerived, bool(SwapPointers)>::run(this->derived(), other.derived());
  901|       |  }
  902|       |
  903|       |  /** \internal
  904|       |   * \brief const version forwarded to DenseBase::swap
  905|       |   */
  906|       |  template <typename OtherDerived>
  907|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void swap(DenseBase<OtherDerived> const& other) {
  908|       |    Base::swap(other.derived());
  909|       |  }
  910|       |
  911|       |  enum {IsPlainObjectBase = 1};
  912|       |#endif
  913|       | public:
  914|       |  // These apparently need to be down here for nvcc+icc to prevent duplicate
  915|       |  // Map symbol.
  916|       |  template <typename PlainObjectType, int MapOptions, typename StrideType>
  917|       |  friend class Eigen::Map;
  918|       |  friend class Eigen::Map<Derived, Unaligned>;
  919|       |  friend class Eigen::Map<const Derived, Unaligned>;
  920|       |#if EIGEN_MAX_ALIGN_BYTES > 0
  921|       |  // for EIGEN_MAX_ALIGN_BYTES==0, AlignedMax==Unaligned, and many compilers generate warnings for friend-ing a class
  922|       |  // twice.
  923|       |  friend class Eigen::Map<Derived, AlignedMax>;
  924|       |  friend class Eigen::Map<const Derived, AlignedMax>;
  925|       |#endif
  926|       |};
  927|       |
  928|       |namespace internal {
  929|       |
  930|       |template <typename Derived, typename OtherDerived, bool IsVector>
  931|       |struct conservative_resize_like_impl {
  932|       |  static constexpr bool IsRelocatable = std::is_trivially_copyable<typename Derived::Scalar>::value;
  933|       |  static void run(DenseBase<Derived>& _this, Index rows, Index cols) {
  934|       |    if (_this.rows() == rows && _this.cols() == cols) return;
  935|       |    EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(Derived)
  936|       |
  937|       |    if (IsRelocatable &&
  938|       |        ((Derived::IsRowMajor && _this.cols() == cols) ||  // row-major and we change only the number of rows
  939|       |         (!Derived::IsRowMajor && _this.rows() == rows)))  // column-major and we change only the number of columns
  940|       |    {
  941|       |#ifndef EIGEN_NO_DEBUG
  942|       |      internal::check_rows_cols_for_overflow<Derived::MaxSizeAtCompileTime, Derived::MaxRowsAtCompileTime,
  943|       |                                             Derived::MaxColsAtCompileTime>::run(rows, cols);
  944|       |#endif
  945|       |      _this.derived().m_storage.conservativeResize(rows * cols, rows, cols);
  946|       |    } else {
  947|       |      // The storage order does not allow us to use reallocation.
  948|       |      Derived tmp(rows, cols);
  949|       |      const Index common_rows = numext::mini(rows, _this.rows());
  950|       |      const Index common_cols = numext::mini(cols, _this.cols());
  951|       |      tmp.block(0, 0, common_rows, common_cols) = _this.block(0, 0, common_rows, common_cols);
  952|       |      _this.derived().swap(tmp);
  953|       |    }
  954|       |  }
  955|       |
  956|       |  static void run(DenseBase<Derived>& _this, const DenseBase<OtherDerived>& other) {
  957|       |    if (_this.rows() == other.rows() && _this.cols() == other.cols()) return;
  958|       |
  959|       |    // Note: Here is space for improvement. Basically, for conservativeResize(Index,Index),
  960|       |    // neither RowsAtCompileTime or ColsAtCompileTime must be Dynamic. If only one of the
  961|       |    // dimensions is dynamic, one could use either conservativeResize(Index rows, NoChange_t) or
  962|       |    // conservativeResize(NoChange_t, Index cols). For these methods new static asserts like
  963|       |    // EIGEN_STATIC_ASSERT_DYNAMIC_ROWS and EIGEN_STATIC_ASSERT_DYNAMIC_COLS would be good.
  964|       |    EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(Derived)
  965|       |    EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(OtherDerived)
  966|       |
  967|       |    if (IsRelocatable &&
  968|       |        ((Derived::IsRowMajor && _this.cols() == other.cols()) ||  // row-major and we change only the number of rows
  969|       |         (!Derived::IsRowMajor &&
  970|       |          _this.rows() == other.rows())))  // column-major and we change only the number of columns
  971|       |    {
  972|       |      const Index new_rows = other.rows() - _this.rows();
  973|       |      const Index new_cols = other.cols() - _this.cols();
  974|       |      _this.derived().m_storage.conservativeResize(other.size(), other.rows(), other.cols());
  975|       |      if (new_rows > 0)
  976|       |        _this.bottomRightCorner(new_rows, other.cols()) = other.bottomRows(new_rows);
  977|       |      else if (new_cols > 0)
  978|       |        _this.bottomRightCorner(other.rows(), new_cols) = other.rightCols(new_cols);
  979|       |    } else {
  980|       |      // The storage order does not allow us to use reallocation.
  981|       |      Derived tmp(other);
  982|       |      const Index common_rows = numext::mini(tmp.rows(), _this.rows());
  983|       |      const Index common_cols = numext::mini(tmp.cols(), _this.cols());
  984|       |      tmp.block(0, 0, common_rows, common_cols) = _this.block(0, 0, common_rows, common_cols);
  985|       |      _this.derived().swap(tmp);
  986|       |    }
  987|       |  }
  988|       |};
  989|       |
  990|       |// Here, the specialization for vectors inherits from the general matrix case
  991|       |// to allow calling .conservativeResize(rows,cols) on vectors.
  992|       |template <typename Derived, typename OtherDerived>
  993|       |struct conservative_resize_like_impl<Derived, OtherDerived, true>
  994|       |    : conservative_resize_like_impl<Derived, OtherDerived, false> {
  995|       |  typedef conservative_resize_like_impl<Derived, OtherDerived, false> Base;
  996|       |  using Base::IsRelocatable;
  997|       |  using Base::run;
  998|       |
  999|       |  static void run(DenseBase<Derived>& _this, Index size) {
 1000|       |    const Index new_rows = Derived::RowsAtCompileTime == 1 ? 1 : size;
 1001|       |    const Index new_cols = Derived::RowsAtCompileTime == 1 ? size : 1;
 1002|       |    if (IsRelocatable)
 1003|       |      _this.derived().m_storage.conservativeResize(size, new_rows, new_cols);
 1004|       |    else
 1005|       |      Base::run(_this.derived(), new_rows, new_cols);
 1006|       |  }
 1007|       |
 1008|       |  static void run(DenseBase<Derived>& _this, const DenseBase<OtherDerived>& other) {
 1009|       |    if (_this.rows() == other.rows() && _this.cols() == other.cols()) return;
 1010|       |
 1011|       |    const Index num_new_elements = other.size() - _this.size();
 1012|       |
 1013|       |    const Index new_rows = Derived::RowsAtCompileTime == 1 ? 1 : other.rows();
 1014|       |    const Index new_cols = Derived::RowsAtCompileTime == 1 ? other.cols() : 1;
 1015|       |    if (IsRelocatable)
 1016|       |      _this.derived().m_storage.conservativeResize(other.size(), new_rows, new_cols);
 1017|       |    else
 1018|       |      Base::run(_this.derived(), new_rows, new_cols);
 1019|       |
 1020|       |    if (num_new_elements > 0) _this.tail(num_new_elements) = other.tail(num_new_elements);
 1021|       |  }
 1022|       |};
 1023|       |
 1024|       |template <typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers>
 1025|       |struct matrix_swap_impl {
 1026|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(MatrixTypeA& a, MatrixTypeB& b) { a.base().swap(b); }
 1027|       |};
 1028|       |
 1029|       |template <typename MatrixTypeA, typename MatrixTypeB>
 1030|       |struct matrix_swap_impl<MatrixTypeA, MatrixTypeB, true> {
 1031|       |  EIGEN_DEVICE_FUNC static inline void run(MatrixTypeA& a, MatrixTypeB& b) {
 1032|       |    static_cast<typename MatrixTypeA::Base&>(a).m_storage.swap(static_cast<typename MatrixTypeB::Base&>(b).m_storage);
 1033|       |  }
 1034|       |};
 1035|       |
 1036|       |}  // end namespace internal
 1037|       |
 1038|       |}  // end namespace Eigen
 1039|       |
 1040|       |#endif  // EIGEN_DENSESTORAGEBASE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Product.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2011 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_PRODUCT_H
   11|       |#define EIGEN_PRODUCT_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "./InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |template <typename Lhs, typename Rhs, int Option, typename StorageKind>
   19|       |class ProductImpl;
   20|       |
   21|       |namespace internal {
   22|       |
   23|       |template <typename Lhs, typename Rhs, int Option>
   24|       |struct traits<Product<Lhs, Rhs, Option>> {
   25|       |  typedef remove_all_t<Lhs> LhsCleaned;
   26|       |  typedef remove_all_t<Rhs> RhsCleaned;
   27|       |  typedef traits<LhsCleaned> LhsTraits;
   28|       |  typedef traits<RhsCleaned> RhsTraits;
   29|       |
   30|       |  typedef MatrixXpr XprKind;
   31|       |
   32|       |  typedef typename ScalarBinaryOpTraits<typename traits<LhsCleaned>::Scalar,
   33|       |                                        typename traits<RhsCleaned>::Scalar>::ReturnType Scalar;
   34|       |  typedef typename product_promote_storage_type<typename LhsTraits::StorageKind, typename RhsTraits::StorageKind,
   35|       |                                                internal::product_type<Lhs, Rhs>::ret>::ret StorageKind;
   36|       |  typedef typename promote_index_type<typename LhsTraits::StorageIndex, typename RhsTraits::StorageIndex>::type
   37|       |      StorageIndex;
   38|       |
   39|       |  enum {
   40|       |    RowsAtCompileTime = LhsTraits::RowsAtCompileTime,
   41|       |    ColsAtCompileTime = RhsTraits::ColsAtCompileTime,
   42|       |    MaxRowsAtCompileTime = LhsTraits::MaxRowsAtCompileTime,
   43|       |    MaxColsAtCompileTime = RhsTraits::MaxColsAtCompileTime,
   44|       |
   45|       |    // FIXME: only needed by GeneralMatrixMatrixTriangular
   46|       |    InnerSize = min_size_prefer_fixed(LhsTraits::ColsAtCompileTime, RhsTraits::RowsAtCompileTime),
   47|       |
   48|       |    // The storage order is somewhat arbitrary here. The correct one will be determined through the evaluator.
   49|       |    Flags = (MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1)   ? RowMajorBit
   50|       |            : (MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1) ? 0
   51|       |            : (((LhsTraits::Flags & NoPreferredStorageOrderBit) && (RhsTraits::Flags & RowMajorBit)) ||
   52|       |               ((RhsTraits::Flags & NoPreferredStorageOrderBit) && (LhsTraits::Flags & RowMajorBit)))
   53|       |                ? RowMajorBit
   54|       |                : NoPreferredStorageOrderBit
   55|       |  };
   56|       |};
   57|       |
   58|       |struct TransposeProductEnum {
   59|       |  // convenience enumerations to specialize transposed products
   60|       |  enum : int {
   61|       |    Default = 0x00,
   62|       |    Matrix = 0x01,
   63|       |    Permutation = 0x02,
   64|       |    MatrixMatrix = (Matrix << 8) | Matrix,
   65|       |    MatrixPermutation = (Matrix << 8) | Permutation,
   66|       |    PermutationMatrix = (Permutation << 8) | Matrix
   67|       |  };
   68|       |};
   69|       |template <typename Xpr>
   70|       |struct TransposeKind {
   71|       |  static constexpr int Kind = is_matrix_base_xpr<Xpr>::value        ? TransposeProductEnum::Matrix
   72|       |                              : is_permutation_base_xpr<Xpr>::value ? TransposeProductEnum::Permutation
   73|       |                                                                    : TransposeProductEnum::Default;
   74|       |};
   75|       |
   76|       |template <typename Lhs, typename Rhs>
   77|       |struct TransposeProductKind {
   78|       |  static constexpr int Kind = (TransposeKind<Lhs>::Kind << 8) | TransposeKind<Rhs>::Kind;
   79|       |};
   80|       |
   81|       |template <typename Lhs, typename Rhs, int Option, int Kind = TransposeProductKind<Lhs, Rhs>::Kind>
   82|       |struct product_transpose_helper {
   83|       |  // by default, don't optimize the transposed product
   84|       |  using Derived = Product<Lhs, Rhs, Option>;
   85|       |  using Scalar = typename Derived::Scalar;
   86|       |  using TransposeType = Transpose<const Derived>;
   87|       |  using ConjugateTransposeType = CwiseUnaryOp<scalar_conjugate_op<Scalar>, TransposeType>;
   88|       |  using AdjointType = std::conditional_t<NumTraits<Scalar>::IsComplex, ConjugateTransposeType, TransposeType>;
   89|       |
   90|       |  // return (lhs * rhs)^T
   91|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TransposeType run_transpose(const Derived& derived) {
   92|       |    return TransposeType(derived);
   93|       |  }
   94|       |  // return (lhs * rhs)^H
   95|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE AdjointType run_adjoint(const Derived& derived) {
   96|       |    return AdjointType(TransposeType(derived));
   97|       |  }
   98|       |};
   99|       |
  100|       |template <typename Lhs, typename Rhs, int Option>
  101|       |struct product_transpose_helper<Lhs, Rhs, Option, TransposeProductEnum::MatrixMatrix> {
  102|       |  // expand the transposed matrix-matrix product
  103|       |  using Derived = Product<Lhs, Rhs, Option>;
  104|       |
  105|       |  using LhsScalar = typename traits<Lhs>::Scalar;
  106|       |  using LhsTransposeType = typename DenseBase<Lhs>::ConstTransposeReturnType;
  107|       |  using LhsConjugateTransposeType = CwiseUnaryOp<scalar_conjugate_op<LhsScalar>, LhsTransposeType>;
  108|       |  using LhsAdjointType =
  109|       |      std::conditional_t<NumTraits<LhsScalar>::IsComplex, LhsConjugateTransposeType, LhsTransposeType>;
  110|       |
  111|       |  using RhsScalar = typename traits<Rhs>::Scalar;
  112|       |  using RhsTransposeType = typename DenseBase<Rhs>::ConstTransposeReturnType;
  113|       |  using RhsConjugateTransposeType = CwiseUnaryOp<scalar_conjugate_op<RhsScalar>, RhsTransposeType>;
  114|       |  using RhsAdjointType =
  115|       |      std::conditional_t<NumTraits<RhsScalar>::IsComplex, RhsConjugateTransposeType, RhsTransposeType>;
  116|       |
  117|       |  using TransposeType = Product<RhsTransposeType, LhsTransposeType, Option>;
  118|       |  using AdjointType = Product<RhsAdjointType, LhsAdjointType, Option>;
  119|       |
  120|       |  // return rhs^T * lhs^T
  121|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TransposeType run_transpose(const Derived& derived) {
  122|       |    return TransposeType(RhsTransposeType(derived.rhs()), LhsTransposeType(derived.lhs()));
  123|       |  }
  124|       |  // return rhs^H * lhs^H
  125|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE AdjointType run_adjoint(const Derived& derived) {
  126|       |    return AdjointType(RhsAdjointType(RhsTransposeType(derived.rhs())),
  127|       |                       LhsAdjointType(LhsTransposeType(derived.lhs())));
  128|       |  }
  129|       |};
  130|       |template <typename Lhs, typename Rhs, int Option>
  131|       |struct product_transpose_helper<Lhs, Rhs, Option, TransposeProductEnum::PermutationMatrix> {
  132|       |  // expand the transposed permutation-matrix product
  133|       |  using Derived = Product<Lhs, Rhs, Option>;
  134|       |
  135|       |  using LhsInverseType = typename PermutationBase<Lhs>::InverseReturnType;
  136|       |
  137|       |  using RhsScalar = typename traits<Rhs>::Scalar;
  138|       |  using RhsTransposeType = typename DenseBase<Rhs>::ConstTransposeReturnType;
  139|       |  using RhsConjugateTransposeType = CwiseUnaryOp<scalar_conjugate_op<RhsScalar>, RhsTransposeType>;
  140|       |  using RhsAdjointType =
  141|       |      std::conditional_t<NumTraits<RhsScalar>::IsComplex, RhsConjugateTransposeType, RhsTransposeType>;
  142|       |
  143|       |  using TransposeType = Product<RhsTransposeType, LhsInverseType, Option>;
  144|       |  using AdjointType = Product<RhsAdjointType, LhsInverseType, Option>;
  145|       |
  146|       |  // return rhs^T * lhs^-1
  147|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TransposeType run_transpose(const Derived& derived) {
  148|       |    return TransposeType(RhsTransposeType(derived.rhs()), LhsInverseType(derived.lhs()));
  149|       |  }
  150|       |  // return rhs^H * lhs^-1
  151|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE AdjointType run_adjoint(const Derived& derived) {
  152|       |    return AdjointType(RhsAdjointType(RhsTransposeType(derived.rhs())), LhsInverseType(derived.lhs()));
  153|       |  }
  154|       |};
  155|       |template <typename Lhs, typename Rhs, int Option>
  156|       |struct product_transpose_helper<Lhs, Rhs, Option, TransposeProductEnum::MatrixPermutation> {
  157|       |  // expand the transposed matrix-permutation product
  158|       |  using Derived = Product<Lhs, Rhs, Option>;
  159|       |
  160|       |  using LhsScalar = typename traits<Lhs>::Scalar;
  161|       |  using LhsTransposeType = typename DenseBase<Lhs>::ConstTransposeReturnType;
  162|       |  using LhsConjugateTransposeType = CwiseUnaryOp<scalar_conjugate_op<LhsScalar>, LhsTransposeType>;
  163|       |  using LhsAdjointType =
  164|       |      std::conditional_t<NumTraits<LhsScalar>::IsComplex, LhsConjugateTransposeType, LhsTransposeType>;
  165|       |
  166|       |  using RhsInverseType = typename PermutationBase<Rhs>::InverseReturnType;
  167|       |
  168|       |  using TransposeType = Product<RhsInverseType, LhsTransposeType, Option>;
  169|       |  using AdjointType = Product<RhsInverseType, LhsAdjointType, Option>;
  170|       |
  171|       |  // return rhs^-1 * lhs^T
  172|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TransposeType run_transpose(const Derived& derived) {
  173|       |    return TransposeType(RhsInverseType(derived.rhs()), LhsTransposeType(derived.lhs()));
  174|       |  }
  175|       |  // return rhs^-1 * lhs^H
  176|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE AdjointType run_adjoint(const Derived& derived) {
  177|       |    return AdjointType(RhsInverseType(derived.rhs()), LhsAdjointType(LhsTransposeType(derived.lhs())));
  178|       |  }
  179|       |};
  180|       |
  181|       |}  // end namespace internal
  182|       |
  183|       |/** \class Product
  184|       | * \ingroup Core_Module
  185|       | *
  186|       | * \brief Expression of the product of two arbitrary matrices or vectors
  187|       | *
  188|       | * \tparam Lhs_ the type of the left-hand side expression
  189|       | * \tparam Rhs_ the type of the right-hand side expression
  190|       | *
  191|       | * This class represents an expression of the product of two arbitrary matrices.
  192|       | *
  193|       | * The other template parameters are:
  194|       | * \tparam Option     can be DefaultProduct, AliasFreeProduct, or LazyProduct
  195|       | *
  196|       | */
  197|       |template <typename Lhs_, typename Rhs_, int Option>
  198|       |class Product
  199|       |    : public ProductImpl<Lhs_, Rhs_, Option,
  200|       |                         typename internal::product_promote_storage_type<
  201|       |                             typename internal::traits<Lhs_>::StorageKind, typename internal::traits<Rhs_>::StorageKind,
  202|       |                             internal::product_type<Lhs_, Rhs_>::ret>::ret> {
  203|       | public:
  204|       |  typedef Lhs_ Lhs;
  205|       |  typedef Rhs_ Rhs;
  206|       |
  207|       |  typedef
  208|       |      typename ProductImpl<Lhs, Rhs, Option,
  209|       |                           typename internal::product_promote_storage_type<
  210|       |                               typename internal::traits<Lhs>::StorageKind, typename internal::traits<Rhs>::StorageKind,
  211|       |                               internal::product_type<Lhs, Rhs>::ret>::ret>::Base Base;
  212|       |  EIGEN_GENERIC_PUBLIC_INTERFACE(Product)
  213|       |
  214|       |  typedef typename internal::ref_selector<Lhs>::type LhsNested;
  215|       |  typedef typename internal::ref_selector<Rhs>::type RhsNested;
  216|       |  typedef internal::remove_all_t<LhsNested> LhsNestedCleaned;
  217|       |  typedef internal::remove_all_t<RhsNested> RhsNestedCleaned;
  218|       |
  219|       |  using TransposeReturnType = typename internal::product_transpose_helper<Lhs, Rhs, Option>::TransposeType;
  220|       |  using AdjointReturnType = typename internal::product_transpose_helper<Lhs, Rhs, Option>::AdjointType;
  221|       |
  222|      4|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Product(const Lhs& lhs, const Rhs& rhs) : m_lhs(lhs), m_rhs(rhs) {
  223|      4|    eigen_assert(lhs.cols() == rhs.rows() && "invalid matrix product" &&
  224|      4|                 "if you wanted a coeff-wise or a dot product use the respective explicit functions");
  225|      4|  }
  ------------------
  | _ZN5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEC2ERKS3_S6_:
  |  222|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Product(const Lhs& lhs, const Rhs& rhs) : m_lhs(lhs), m_rhs(rhs) {
  |  223|      2|    eigen_assert(lhs.cols() == rhs.rows() && "invalid matrix product" &&
  |  224|      2|                 "if you wanted a coeff-wise or a dot product use the respective explicit functions");
  |  225|      2|  }
  ------------------
  | _ZN5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEENS1_IS2_Lin1ELi1ELi0ELin1ELi1EEELi0EEC2ERKS4_RKS5_:
  |  222|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Product(const Lhs& lhs, const Rhs& rhs) : m_lhs(lhs), m_rhs(rhs) {
  |  223|      1|    eigen_assert(lhs.cols() == rhs.rows() && "invalid matrix product" &&
  |  224|      1|                 "if you wanted a coeff-wise or a dot product use the respective explicit functions");
  |  225|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li1EEC2ERKS3_S6_
  ------------------
  | _ZN5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li0EEC2ERKS4_RKS3_:
  |  222|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Product(const Lhs& lhs, const Rhs& rhs) : m_lhs(lhs), m_rhs(rhs) {
  |  223|      1|    eigen_assert(lhs.cols() == rhs.rows() && "invalid matrix product" &&
  |  224|      1|                 "if you wanted a coeff-wise or a dot product use the respective explicit functions");
  |  225|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li1EEC2ERKS4_RKS3_
  ------------------
  226|       |
  227|     12|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
  ------------------
  | _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEENS1_IS2_Lin1ELi1ELi0ELin1ELi1EEELi0EE4rowsEv:
  |  227|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
  ------------------
  | _ZNK5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EE4rowsEv:
  |  227|     10|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li1EE4rowsEv
  ------------------
  | _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li0EE4rowsEv:
  |  227|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li1EE4rowsEv
  ------------------
  228|     10|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
  ------------------
  | _ZNK5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EE4colsEv:
  |  228|      8|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
  ------------------
  | _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEENS1_IS2_Lin1ELi1ELi0ELin1ELi1EEELi0EE4colsEv:
  |  228|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li1EE4colsEv
  ------------------
  | _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li0EE4colsEv:
  |  228|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li1EE4colsEv
  ------------------
  229|       |
  230|      4|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const LhsNestedCleaned& lhs() const { return m_lhs; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li1EE3lhsEv
  ------------------
  | _ZNK5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EE3lhsEv:
  |  230|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const LhsNestedCleaned& lhs() const { return m_lhs; }
  ------------------
  | _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEENS1_IS2_Lin1ELi1ELi0ELin1ELi1EEELi0EE3lhsEv:
  |  230|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const LhsNestedCleaned& lhs() const { return m_lhs; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li1EE3lhsEv
  ------------------
  | _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li0EE3lhsEv:
  |  230|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const LhsNestedCleaned& lhs() const { return m_lhs; }
  ------------------
  231|      4|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const RhsNestedCleaned& rhs() const { return m_rhs; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li1EE3rhsEv
  ------------------
  | _ZNK5Eigen7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EE3rhsEv:
  |  231|      2|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const RhsNestedCleaned& rhs() const { return m_rhs; }
  ------------------
  | _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEENS1_IS2_Lin1ELi1ELi0ELin1ELi1EEELi0EE3rhsEv:
  |  231|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const RhsNestedCleaned& rhs() const { return m_rhs; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li1EE3rhsEv
  ------------------
  | _ZNK5Eigen7ProductINS0_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES3_Li0EEES3_Li0EE3rhsEv:
  |  231|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const RhsNestedCleaned& rhs() const { return m_rhs; }
  ------------------
  232|       |
  233|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TransposeReturnType transpose() const {
  234|       |    return internal::product_transpose_helper<Lhs, Rhs, Option>::run_transpose(*this);
  235|       |  }
  236|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE AdjointReturnType adjoint() const {
  237|       |    return internal::product_transpose_helper<Lhs, Rhs, Option>::run_adjoint(*this);
  238|       |  }
  239|       |
  240|       | protected:
  241|       |  LhsNested m_lhs;
  242|       |  RhsNested m_rhs;
  243|       |};
  244|       |
  245|       |namespace internal {
  246|       |
  247|       |template <typename Lhs, typename Rhs, int Option, int ProductTag = internal::product_type<Lhs, Rhs>::ret>
  248|       |class dense_product_base : public internal::dense_xpr_base<Product<Lhs, Rhs, Option>>::type {};
  249|       |
  250|       |/** Conversion to scalar for inner-products */
  251|       |template <typename Lhs, typename Rhs, int Option>
  252|       |class dense_product_base<Lhs, Rhs, Option, InnerProduct>
  253|       |    : public internal::dense_xpr_base<Product<Lhs, Rhs, Option>>::type {
  254|       |  typedef Product<Lhs, Rhs, Option> ProductXpr;
  255|       |  typedef typename internal::dense_xpr_base<ProductXpr>::type Base;
  256|       |
  257|       | public:
  258|       |  using Base::derived;
  259|       |  typedef typename Base::Scalar Scalar;
  260|       |
  261|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE operator const Scalar() const {
  262|       |    return internal::evaluator<ProductXpr>(derived()).coeff(0, 0);
  263|       |  }
  264|       |};
  265|       |
  266|       |}  // namespace internal
  267|       |
  268|       |// Generic API dispatcher
  269|       |template <typename Lhs, typename Rhs, int Option, typename StorageKind>
  270|       |class ProductImpl : public internal::generic_xpr_base<Product<Lhs, Rhs, Option>, MatrixXpr, StorageKind>::type {
  271|       | public:
  272|       |  typedef typename internal::generic_xpr_base<Product<Lhs, Rhs, Option>, MatrixXpr, StorageKind>::type Base;
  273|       |};
  274|       |
  275|       |template <typename Lhs, typename Rhs, int Option>
  276|       |class ProductImpl<Lhs, Rhs, Option, Dense> : public internal::dense_product_base<Lhs, Rhs, Option> {
  277|       |  typedef Product<Lhs, Rhs, Option> Derived;
  278|       |
  279|       | public:
  280|       |  typedef typename internal::dense_product_base<Lhs, Rhs, Option> Base;
  281|       |  EIGEN_DENSE_PUBLIC_INTERFACE(Derived)
  282|       | protected:
  283|       |  enum {
  284|       |    IsOneByOne = (RowsAtCompileTime == 1 || RowsAtCompileTime == Dynamic) &&
  285|       |                 (ColsAtCompileTime == 1 || ColsAtCompileTime == Dynamic),
  286|       |    EnableCoeff = IsOneByOne || Option == LazyProduct
  287|       |  };
  288|       |
  289|       | public:
  290|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(Index row, Index col) const {
  291|       |    EIGEN_STATIC_ASSERT(EnableCoeff, THIS_METHOD_IS_ONLY_FOR_INNER_OR_LAZY_PRODUCTS);
  292|       |    eigen_assert((Option == LazyProduct) || (this->rows() == 1 && this->cols() == 1));
  293|       |
  294|       |    return internal::evaluator<Derived>(derived()).coeff(row, col);
  295|       |  }
  296|       |
  297|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(Index i) const {
  298|       |    EIGEN_STATIC_ASSERT(EnableCoeff, THIS_METHOD_IS_ONLY_FOR_INNER_OR_LAZY_PRODUCTS);
  299|       |    eigen_assert((Option == LazyProduct) || (this->rows() == 1 && this->cols() == 1));
  300|       |
  301|       |    return internal::evaluator<Derived>(derived()).coeff(i);
  302|       |  }
  303|       |};
  304|       |
  305|       |}  // end namespace Eigen
  306|       |
  307|       |#endif  // EIGEN_PRODUCT_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/ProductEvaluators.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2008-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |// Copyright (C) 2011 Jitse Niesen <jitse@maths.leeds.ac.uk>
    7|       |//
    8|       |// This Source Code Form is subject to the terms of the Mozilla
    9|       |// Public License v. 2.0. If a copy of the MPL was not distributed
   10|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   11|       |
   12|       |#ifndef EIGEN_PRODUCTEVALUATORS_H
   13|       |#define EIGEN_PRODUCTEVALUATORS_H
   14|       |
   15|       |// IWYU pragma: private
   16|       |#include "./InternalHeaderCheck.h"
   17|       |
   18|       |namespace Eigen {
   19|       |
   20|       |namespace internal {
   21|       |
   22|       |/** \internal
   23|       | * Evaluator of a product expression.
   24|       | * Since products require special treatments to handle all possible cases,
   25|       | * we simply defer the evaluation logic to a product_evaluator class
   26|       | * which offers more partial specialization possibilities.
   27|       | *
   28|       | * \sa class product_evaluator
   29|       | */
   30|       |template <typename Lhs, typename Rhs, int Options>
   31|       |struct evaluator<Product<Lhs, Rhs, Options>> : public product_evaluator<Product<Lhs, Rhs, Options>> {
   32|       |  typedef Product<Lhs, Rhs, Options> XprType;
   33|       |  typedef product_evaluator<XprType> Base;
   34|       |
   35|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr) : Base(xpr) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEEEC2ERKS6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li1EEEEC2ERKS6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal9evaluatorINS_7ProductINS2_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_Li1EEEEC2ERKS7_
  ------------------
   36|       |};
   37|       |
   38|       |// Catch "scalar * ( A * B )" and transform it to "(A*scalar) * B"
   39|       |// TODO we should apply that rule only if that's really helpful
   40|       |template <typename Lhs, typename Rhs, typename Scalar1, typename Scalar2, typename Plain1>
   41|       |struct evaluator_assume_aliasing<CwiseBinaryOp<internal::scalar_product_op<Scalar1, Scalar2>,
   42|       |                                               const CwiseNullaryOp<internal::scalar_constant_op<Scalar1>, Plain1>,
   43|       |                                               const Product<Lhs, Rhs, DefaultProduct>>> {
   44|       |  static const bool value = true;
   45|       |};
   46|       |template <typename Lhs, typename Rhs, typename Scalar1, typename Scalar2, typename Plain1>
   47|       |struct evaluator<CwiseBinaryOp<internal::scalar_product_op<Scalar1, Scalar2>,
   48|       |                               const CwiseNullaryOp<internal::scalar_constant_op<Scalar1>, Plain1>,
   49|       |                               const Product<Lhs, Rhs, DefaultProduct>>>
   50|       |    : public evaluator<Product<EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(Scalar1, Lhs, product), Rhs, DefaultProduct>> {
   51|       |  typedef CwiseBinaryOp<internal::scalar_product_op<Scalar1, Scalar2>,
   52|       |                        const CwiseNullaryOp<internal::scalar_constant_op<Scalar1>, Plain1>,
   53|       |                        const Product<Lhs, Rhs, DefaultProduct>>
   54|       |      XprType;
   55|       |  typedef evaluator<Product<EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(Scalar1, Lhs, product), Rhs, DefaultProduct>> Base;
   56|       |
   57|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr)
   58|       |      : Base(xpr.lhs().functor().m_other * xpr.rhs().lhs() * xpr.rhs().rhs()) {}
   59|       |};
   60|       |
   61|       |template <typename Lhs, typename Rhs, int DiagIndex>
   62|       |struct evaluator<Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex>>
   63|       |    : public evaluator<Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex>> {
   64|       |  typedef Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex> XprType;
   65|       |  typedef evaluator<Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex>> Base;
   66|       |
   67|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr)
   68|       |      : Base(Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex>(
   69|       |            Product<Lhs, Rhs, LazyProduct>(xpr.nestedExpression().lhs(), xpr.nestedExpression().rhs()), xpr.index())) {}
   70|       |};
   71|       |
   72|       |// Helper class to perform a matrix product with the destination at hand.
   73|       |// Depending on the sizes of the factors, there are different evaluation strategies
   74|       |// as controlled by internal::product_type.
   75|       |template <typename Lhs, typename Rhs, typename LhsShape = typename evaluator_traits<Lhs>::Shape,
   76|       |          typename RhsShape = typename evaluator_traits<Rhs>::Shape,
   77|       |          int ProductType = internal::product_type<Lhs, Rhs>::value>
   78|       |struct generic_product_impl;
   79|       |
   80|       |template <typename Lhs, typename Rhs>
   81|       |struct evaluator_assume_aliasing<Product<Lhs, Rhs, DefaultProduct>> {
   82|       |  static const bool value = true;
   83|       |};
   84|       |
   85|       |// This is the default evaluator implementation for products:
   86|       |// It creates a temporary and call generic_product_impl
   87|       |template <typename Lhs, typename Rhs, int Options, int ProductTag, typename LhsShape, typename RhsShape>
   88|       |struct product_evaluator<Product<Lhs, Rhs, Options>, ProductTag, LhsShape, RhsShape>
   89|       |    : public evaluator<typename Product<Lhs, Rhs, Options>::PlainObject> {
   90|       |  typedef Product<Lhs, Rhs, Options> XprType;
   91|       |  typedef typename XprType::PlainObject PlainObject;
   92|       |  typedef evaluator<PlainObject> Base;
   93|       |  enum { Flags = Base::Flags | EvalBeforeNestingBit };
   94|       |
   95|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit product_evaluator(const XprType& xpr)
   96|      0|      : m_result(xpr.rows(), xpr.cols()) {
   97|      0|    internal::construct_at<Base>(this, m_result);
   98|       |
   99|       |    // FIXME shall we handle nested_eval here?,
  100|       |    // if so, then we must take care at removing the call to nested_eval in the specializations (e.g., in
  101|       |    // permutation_matrix_product, transposition_matrix_product, etc.)
  102|       |    //     typedef typename internal::nested_eval<Lhs,Rhs::ColsAtCompileTime>::type LhsNested;
  103|       |    //     typedef typename internal::nested_eval<Rhs,Lhs::RowsAtCompileTime>::type RhsNested;
  104|       |    //     typedef internal::remove_all_t<LhsNested> LhsNestedCleaned;
  105|       |    //     typedef internal::remove_all_t<RhsNested> RhsNestedCleaned;
  106|       |    //
  107|       |    //     const LhsNested lhs(xpr.lhs());
  108|       |    //     const RhsNested rhs(xpr.rhs());
  109|       |    //
  110|       |    //     generic_product_impl<LhsNestedCleaned, RhsNestedCleaned>::evalTo(m_result, lhs, rhs);
  111|       |
  112|      0|    generic_product_impl<Lhs, Rhs, LhsShape, RhsShape, ProductTag>::evalTo(m_result, xpr.lhs(), xpr.rhs());
  113|      0|  }
  114|       |
  115|       | protected:
  116|       |  PlainObject m_result;
  117|       |};
  118|       |
  119|       |// The following three shortcuts are enabled only if the scalar types match exactly.
  120|       |// TODO: we could enable them for different scalar types when the product is not vectorized.
  121|       |
  122|       |// Dense = Product
  123|       |template <typename DstXprType, typename Lhs, typename Rhs, int Options, typename Scalar>
  124|       |struct Assignment<DstXprType, Product<Lhs, Rhs, Options>, internal::assign_op<Scalar, Scalar>, Dense2Dense,
  125|       |                  std::enable_if_t<(Options == DefaultProduct || Options == AliasFreeProduct)>> {
  126|       |  typedef Product<Lhs, Rhs, Options> SrcXprType;
  127|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(DstXprType& dst, const SrcXprType& src,
  128|      4|                                                        const internal::assign_op<Scalar, Scalar>&) {
  129|      4|    Index dstRows = src.rows();
  130|      4|    Index dstCols = src.cols();
  131|      4|    if ((dst.rows() != dstRows) || (dst.cols() != dstCols)) dst.resize(dstRows, dstCols);
  132|       |    // FIXME shall we handle nested_eval here?
  133|      4|    generic_product_impl<Lhs, Rhs>::evalTo(dst, src.lhs(), src.rhs());
  134|      4|  }
  ------------------
  | _ZN5Eigen8internal10AssignmentINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_7ProductINS5_INS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES6_Li0EEES4_Li0EEENS0_9assign_opIS3_S3_EENS0_11Dense2DenseEvE3runERS4_RKS8_RKSA_:
  |  128|      1|                                                        const internal::assign_op<Scalar, Scalar>&) {
  |  129|      1|    Index dstRows = src.rows();
  |  130|      1|    Index dstCols = src.cols();
  |  131|      1|    if ((dst.rows() != dstRows) || (dst.cols() != dstCols)) dst.resize(dstRows, dstCols);
  |  132|       |    // FIXME shall we handle nested_eval here?
  |  133|      1|    generic_product_impl<Lhs, Rhs>::evalTo(dst, src.lhs(), src.rhs());
  |  134|      1|  }
  ------------------
  | _ZN5Eigen8internal10AssignmentINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductIS4_S4_Li0EEENS0_9assign_opIS3_S3_EENS0_11Dense2DenseEvE3runERS4_RKS6_RKS8_:
  |  128|      2|                                                        const internal::assign_op<Scalar, Scalar>&) {
  |  129|      2|    Index dstRows = src.rows();
  |  130|      2|    Index dstCols = src.cols();
  |  131|      2|    if ((dst.rows() != dstRows) || (dst.cols() != dstCols)) dst.resize(dstRows, dstCols);
  |  132|       |    // FIXME shall we handle nested_eval here?
  |  133|      2|    generic_product_impl<Lhs, Rhs>::evalTo(dst, src.lhs(), src.rhs());
  |  134|      2|  }
  ------------------
  | _ZN5Eigen8internal10AssignmentINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_7ProductINS5_IS4_S4_Li0EEES4_Li0EEENS0_9assign_opIS3_S3_EENS0_11Dense2DenseEvE3runERS4_RKS7_RKS9_:
  |  128|      1|                                                        const internal::assign_op<Scalar, Scalar>&) {
  |  129|      1|    Index dstRows = src.rows();
  |  130|      1|    Index dstCols = src.cols();
  |  131|      1|    if ((dst.rows() != dstRows) || (dst.cols() != dstCols)) dst.resize(dstRows, dstCols);
  |  132|       |    // FIXME shall we handle nested_eval here?
  |  133|      1|    generic_product_impl<Lhs, Rhs>::evalTo(dst, src.lhs(), src.rhs());
  |  134|      1|  }
  ------------------
  135|       |};
  136|       |
  137|       |// Dense += Product
  138|       |template <typename DstXprType, typename Lhs, typename Rhs, int Options, typename Scalar>
  139|       |struct Assignment<DstXprType, Product<Lhs, Rhs, Options>, internal::add_assign_op<Scalar, Scalar>, Dense2Dense,
  140|       |                  std::enable_if_t<(Options == DefaultProduct || Options == AliasFreeProduct)>> {
  141|       |  typedef Product<Lhs, Rhs, Options> SrcXprType;
  142|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(DstXprType& dst, const SrcXprType& src,
  143|       |                                                        const internal::add_assign_op<Scalar, Scalar>&) {
  144|       |    eigen_assert(dst.rows() == src.rows() && dst.cols() == src.cols());
  145|       |    // FIXME shall we handle nested_eval here?
  146|       |    generic_product_impl<Lhs, Rhs>::addTo(dst, src.lhs(), src.rhs());
  147|       |  }
  148|       |};
  149|       |
  150|       |// Dense -= Product
  151|       |template <typename DstXprType, typename Lhs, typename Rhs, int Options, typename Scalar>
  152|       |struct Assignment<DstXprType, Product<Lhs, Rhs, Options>, internal::sub_assign_op<Scalar, Scalar>, Dense2Dense,
  153|       |                  std::enable_if_t<(Options == DefaultProduct || Options == AliasFreeProduct)>> {
  154|       |  typedef Product<Lhs, Rhs, Options> SrcXprType;
  155|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(DstXprType& dst, const SrcXprType& src,
  156|       |                                                        const internal::sub_assign_op<Scalar, Scalar>&) {
  157|       |    eigen_assert(dst.rows() == src.rows() && dst.cols() == src.cols());
  158|       |    // FIXME shall we handle nested_eval here?
  159|       |    generic_product_impl<Lhs, Rhs>::subTo(dst, src.lhs(), src.rhs());
  160|       |  }
  161|       |};
  162|       |
  163|       |// Dense ?= scalar * Product
  164|       |// TODO we should apply that rule if that's really helpful
  165|       |// for instance, this is not good for inner products
  166|       |template <typename DstXprType, typename Lhs, typename Rhs, typename AssignFunc, typename Scalar, typename ScalarBis,
  167|       |          typename Plain>
  168|       |struct Assignment<DstXprType,
  169|       |                  CwiseBinaryOp<internal::scalar_product_op<ScalarBis, Scalar>,
  170|       |                                const CwiseNullaryOp<internal::scalar_constant_op<ScalarBis>, Plain>,
  171|       |                                const Product<Lhs, Rhs, DefaultProduct>>,
  172|       |                  AssignFunc, Dense2Dense> {
  173|       |  typedef CwiseBinaryOp<internal::scalar_product_op<ScalarBis, Scalar>,
  174|       |                        const CwiseNullaryOp<internal::scalar_constant_op<ScalarBis>, Plain>,
  175|       |                        const Product<Lhs, Rhs, DefaultProduct>>
  176|       |      SrcXprType;
  177|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(DstXprType& dst, const SrcXprType& src,
  178|       |                                                        const AssignFunc& func) {
  179|       |    call_assignment_no_alias(dst, (src.lhs().functor().m_other * src.rhs().lhs()) * src.rhs().rhs(), func);
  180|       |  }
  181|       |};
  182|       |
  183|       |//----------------------------------------
  184|       |// Catch "Dense ?= xpr + Product<>" expression to save one temporary
  185|       |// FIXME we could probably enable these rules for any product, i.e., not only Dense and DefaultProduct
  186|       |
  187|       |template <typename OtherXpr, typename Lhs, typename Rhs>
  188|       |struct evaluator_assume_aliasing<
  189|       |    CwiseBinaryOp<
  190|       |        internal::scalar_sum_op<typename OtherXpr::Scalar, typename Product<Lhs, Rhs, DefaultProduct>::Scalar>,
  191|       |        const OtherXpr, const Product<Lhs, Rhs, DefaultProduct>>,
  192|       |    DenseShape> {
  193|       |  static const bool value = true;
  194|       |};
  195|       |
  196|       |template <typename OtherXpr, typename Lhs, typename Rhs>
  197|       |struct evaluator_assume_aliasing<
  198|       |    CwiseBinaryOp<
  199|       |        internal::scalar_difference_op<typename OtherXpr::Scalar, typename Product<Lhs, Rhs, DefaultProduct>::Scalar>,
  200|       |        const OtherXpr, const Product<Lhs, Rhs, DefaultProduct>>,
  201|       |    DenseShape> {
  202|       |  static const bool value = true;
  203|       |};
  204|       |
  205|       |template <typename DstXprType, typename OtherXpr, typename ProductType, typename Func1, typename Func2>
  206|       |struct assignment_from_xpr_op_product {
  207|       |  template <typename SrcXprType, typename InitialFunc>
  208|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(DstXprType& dst, const SrcXprType& src,
  209|       |                                                        const InitialFunc& /*func*/) {
  210|       |    call_assignment_no_alias(dst, src.lhs(), Func1());
  211|       |    call_assignment_no_alias(dst, src.rhs(), Func2());
  212|       |  }
  213|       |};
  214|       |
  215|       |#define EIGEN_CATCH_ASSIGN_XPR_OP_PRODUCT(ASSIGN_OP, BINOP, ASSIGN_OP2)                             \
  216|       |  template <typename DstXprType, typename OtherXpr, typename Lhs, typename Rhs, typename DstScalar, \
  217|       |            typename SrcScalar, typename OtherScalar, typename ProdScalar>                          \
  218|       |  struct Assignment<DstXprType,                                                                     \
  219|       |                    CwiseBinaryOp<internal::BINOP<OtherScalar, ProdScalar>, const OtherXpr,         \
  220|       |                                  const Product<Lhs, Rhs, DefaultProduct>>,                         \
  221|       |                    internal::ASSIGN_OP<DstScalar, SrcScalar>, Dense2Dense>                         \
  222|       |      : assignment_from_xpr_op_product<DstXprType, OtherXpr, Product<Lhs, Rhs, DefaultProduct>,     \
  223|       |                                       internal::ASSIGN_OP<DstScalar, OtherScalar>,                 \
  224|       |                                       internal::ASSIGN_OP2<DstScalar, ProdScalar>> {}
  225|       |
  226|       |EIGEN_CATCH_ASSIGN_XPR_OP_PRODUCT(assign_op, scalar_sum_op, add_assign_op);
  227|       |EIGEN_CATCH_ASSIGN_XPR_OP_PRODUCT(add_assign_op, scalar_sum_op, add_assign_op);
  228|       |EIGEN_CATCH_ASSIGN_XPR_OP_PRODUCT(sub_assign_op, scalar_sum_op, sub_assign_op);
  229|       |
  230|       |EIGEN_CATCH_ASSIGN_XPR_OP_PRODUCT(assign_op, scalar_difference_op, sub_assign_op);
  231|       |EIGEN_CATCH_ASSIGN_XPR_OP_PRODUCT(add_assign_op, scalar_difference_op, sub_assign_op);
  232|       |EIGEN_CATCH_ASSIGN_XPR_OP_PRODUCT(sub_assign_op, scalar_difference_op, add_assign_op);
  233|       |
  234|       |//----------------------------------------
  235|       |
  236|       |template <typename Lhs, typename Rhs>
  237|       |struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, InnerProduct> {
  238|       |  using impl = default_inner_product_impl<Lhs, Rhs, false>;
  239|       |  template <typename Dst>
  240|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  241|       |    dst.coeffRef(0, 0) = impl::run(lhs, rhs);
  242|       |  }
  243|       |
  244|       |  template <typename Dst>
  245|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  246|       |    dst.coeffRef(0, 0) += impl::run(lhs, rhs);
  247|       |  }
  248|       |
  249|       |  template <typename Dst>
  250|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  251|       |    dst.coeffRef(0, 0) -= impl::run(lhs, rhs);
  252|       |  }
  253|       |};
  254|       |
  255|       |/***********************************************************************
  256|       | *  Implementation of outer dense * dense vector product
  257|       | ***********************************************************************/
  258|       |
  259|       |// Column major result
  260|       |template <typename Dst, typename Lhs, typename Rhs, typename Func>
  261|       |void EIGEN_DEVICE_FUNC outer_product_selector_run(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Func& func,
  262|       |                                                  const false_type&) {
  263|       |  evaluator<Rhs> rhsEval(rhs);
  264|       |  ei_declare_local_nested_eval(Lhs, lhs, Rhs::SizeAtCompileTime, actual_lhs);
  265|       |  // FIXME if cols is large enough, then it might be useful to make sure that lhs is sequentially stored
  266|       |  // FIXME not very good if rhs is real and lhs complex while alpha is real too
  267|       |  const Index cols = dst.cols();
  268|       |  for (Index j = 0; j < cols; ++j) func(dst.col(j), rhsEval.coeff(Index(0), j) * actual_lhs);
  269|       |}
  270|       |
  271|       |// Row major result
  272|       |template <typename Dst, typename Lhs, typename Rhs, typename Func>
  273|       |void EIGEN_DEVICE_FUNC outer_product_selector_run(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Func& func,
  274|       |                                                  const true_type&) {
  275|       |  evaluator<Lhs> lhsEval(lhs);
  276|       |  ei_declare_local_nested_eval(Rhs, rhs, Lhs::SizeAtCompileTime, actual_rhs);
  277|       |  // FIXME if rows is large enough, then it might be useful to make sure that rhs is sequentially stored
  278|       |  // FIXME not very good if lhs is real and rhs complex while alpha is real too
  279|       |  const Index rows = dst.rows();
  280|       |  for (Index i = 0; i < rows; ++i) func(dst.row(i), lhsEval.coeff(i, Index(0)) * actual_rhs);
  281|       |}
  282|       |
  283|       |template <typename Lhs, typename Rhs>
  284|       |struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, OuterProduct> {
  285|       |  template <typename T>
  286|       |  struct is_row_major : std::conditional_t<(int(T::Flags) & RowMajorBit), internal::true_type, internal::false_type> {};
  287|       |  typedef typename Product<Lhs, Rhs>::Scalar Scalar;
  288|       |
  289|       |  // TODO it would be nice to be able to exploit our *_assign_op functors for that purpose
  290|       |  struct set {
  291|       |    template <typename Dst, typename Src>
  292|       |    EIGEN_DEVICE_FUNC void operator()(const Dst& dst, const Src& src) const {
  293|       |      dst.const_cast_derived() = src;
  294|       |    }
  295|       |  };
  296|       |  struct add {
  297|       |    template <typename Dst, typename Src>
  298|       |    EIGEN_DEVICE_FUNC void operator()(const Dst& dst, const Src& src) const {
  299|       |      dst.const_cast_derived() += src;
  300|       |    }
  301|       |  };
  302|       |  struct sub {
  303|       |    template <typename Dst, typename Src>
  304|       |    EIGEN_DEVICE_FUNC void operator()(const Dst& dst, const Src& src) const {
  305|       |      dst.const_cast_derived() -= src;
  306|       |    }
  307|       |  };
  308|       |  struct adds {
  309|       |    Scalar m_scale;
  310|       |    explicit adds(const Scalar& s) : m_scale(s) {}
  311|       |    template <typename Dst, typename Src>
  312|       |    void EIGEN_DEVICE_FUNC operator()(const Dst& dst, const Src& src) const {
  313|       |      dst.const_cast_derived() += m_scale * src;
  314|       |    }
  315|       |  };
  316|       |
  317|       |  template <typename Dst>
  318|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  319|       |    internal::outer_product_selector_run(dst, lhs, rhs, set(), is_row_major<Dst>());
  320|       |  }
  321|       |
  322|       |  template <typename Dst>
  323|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  324|       |    internal::outer_product_selector_run(dst, lhs, rhs, add(), is_row_major<Dst>());
  325|       |  }
  326|       |
  327|       |  template <typename Dst>
  328|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  329|       |    internal::outer_product_selector_run(dst, lhs, rhs, sub(), is_row_major<Dst>());
  330|       |  }
  331|       |
  332|       |  template <typename Dst>
  333|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void scaleAndAddTo(Dst& dst, const Lhs& lhs, const Rhs& rhs,
  334|       |                                                                  const Scalar& alpha) {
  335|       |    internal::outer_product_selector_run(dst, lhs, rhs, adds(alpha), is_row_major<Dst>());
  336|       |  }
  337|       |};
  338|       |
  339|       |// This base class provides default implementations for evalTo, addTo, subTo, in terms of scaleAndAddTo
  340|       |template <typename Lhs, typename Rhs, typename Derived>
  341|       |struct generic_product_impl_base {
  342|       |  typedef typename Product<Lhs, Rhs>::Scalar Scalar;
  343|       |
  344|       |  template <typename Dst>
  345|      1|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  346|      1|    dst.setZero();
  347|      1|    scaleAndAddTo(dst, lhs, rhs, Scalar(1));
  348|      1|  }
  349|       |
  350|       |  template <typename Dst>
  351|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  352|       |    scaleAndAddTo(dst, lhs, rhs, Scalar(1));
  353|       |  }
  354|       |
  355|       |  template <typename Dst>
  356|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  357|       |    scaleAndAddTo(dst, lhs, rhs, Scalar(-1));
  358|       |  }
  359|       |
  360|       |  template <typename Dst>
  361|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void scaleAndAddTo(Dst& dst, const Lhs& lhs, const Rhs& rhs,
  362|      1|                                                                  const Scalar& alpha) {
  363|      1|    Derived::scaleAndAddTo(dst, lhs, rhs, alpha);
  364|      1|  }
  365|       |};
  366|       |
  367|       |template <typename Lhs, typename Rhs>
  368|       |struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, GemvProduct>
  369|       |    : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, GemvProduct>> {
  370|       |  typedef typename nested_eval<Lhs, 1>::type LhsNested;
  371|       |  typedef typename nested_eval<Rhs, 1>::type RhsNested;
  372|       |  typedef typename Product<Lhs, Rhs>::Scalar Scalar;
  373|       |  enum { Side = Lhs::IsVectorAtCompileTime ? OnTheLeft : OnTheRight };
  374|       |  typedef internal::remove_all_t<std::conditional_t<int(Side) == OnTheRight, LhsNested, RhsNested>> MatrixType;
  375|       |
  376|       |  template <typename Dest>
  377|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs,
  378|      1|                                                                  const Scalar& alpha) {
  379|       |    // Fallback to inner product if both the lhs and rhs is a runtime vector.
  380|      1|    if (lhs.rows() == 1 && rhs.cols() == 1) {
  381|      0|      dst.coeffRef(0, 0) += alpha * lhs.row(0).conjugate().dot(rhs.col(0));
  382|      0|      return;
  383|      0|    }
  384|      1|    LhsNested actual_lhs(lhs);
  385|      1|    RhsNested actual_rhs(rhs);
  386|      1|    internal::gemv_dense_selector<Side, (int(MatrixType::Flags) & RowMajorBit) ? RowMajor : ColMajor,
  387|      1|                                  bool(internal::blas_traits<MatrixType>::HasUsableDirectAccess)>::run(actual_lhs,
  388|      1|                                                                                                       actual_rhs, dst,
  389|      1|                                                                                                       alpha);
  390|      1|  }
  ------------------
  | _ZN5Eigen8internal20generic_product_implINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEENS3_IS4_Lin1ELi1ELi0ELin1ELi1EEENS_10DenseShapeES8_Li7EE13scaleAndAddToIS7_EEvRT_RKS6_RKS7_RKS4_:
  |  378|      1|                                                                  const Scalar& alpha) {
  |  379|       |    // Fallback to inner product if both the lhs and rhs is a runtime vector.
  |  380|      1|    if (lhs.rows() == 1 && rhs.cols() == 1) {
  |  381|      0|      dst.coeffRef(0, 0) += alpha * lhs.row(0).conjugate().dot(rhs.col(0));
  |  382|      0|      return;
  |  383|      0|    }
  |  384|      1|    LhsNested actual_lhs(lhs);
  |  385|      1|    RhsNested actual_rhs(rhs);
  |  386|      1|    internal::gemv_dense_selector<Side, (int(MatrixType::Flags) & RowMajorBit) ? RowMajor : ColMajor,
  |  387|      1|                                  bool(internal::blas_traits<MatrixType>::HasUsableDirectAccess)>::run(actual_lhs,
  |  388|      1|                                                                                                       actual_rhs, dst,
  |  389|      1|                                                                                                       alpha);
  |  390|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20generic_product_implINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEKNS_5BlockIKS4_Lin1ELi1ELb1EEENS_10DenseShapeES9_Li7EE13scaleAndAddToINS5_IS4_Lin1ELi1ELb1EEEEEvRT_RS6_RS8_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20generic_product_implIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEES5_NS_10DenseShapeES9_Li7EE13scaleAndAddToINS2_IS5_Li1ELin1ELb0EEEEEvRT_RS8_RS6_RKS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20generic_product_implINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEEKNS_5BlockIKS5_Lin1ELi1ELb1EEENS_10DenseShapeESB_Li7EE13scaleAndAddToINS7_IS5_Lin1ELi1ELb1EEEEEvRT_RKS6_RSA_RKS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20generic_product_implIKNS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEES6_NS_10DenseShapeESB_Li7EE13scaleAndAddToINS2_IS6_Li1ELin1ELb0EEEEEvRT_RSA_RKS6_RKS5_
  ------------------
  391|       |};
  392|       |
  393|       |template <typename Lhs, typename Rhs>
  394|       |struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, CoeffBasedProductMode> {
  395|       |  typedef typename Product<Lhs, Rhs>::Scalar Scalar;
  396|       |
  397|       |  template <typename Dst>
  398|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  399|       |    // Same as: dst.noalias() = lhs.lazyProduct(rhs);
  400|       |    // but easier on the compiler side
  401|       |    call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::assign_op<typename Dst::Scalar, Scalar>());
  402|       |  }
  403|       |
  404|       |  template <typename Dst>
  405|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  406|       |    // dst.noalias() += lhs.lazyProduct(rhs);
  407|       |    call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::add_assign_op<typename Dst::Scalar, Scalar>());
  408|       |  }
  409|       |
  410|       |  template <typename Dst>
  411|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  412|       |    // dst.noalias() -= lhs.lazyProduct(rhs);
  413|       |    call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::sub_assign_op<typename Dst::Scalar, Scalar>());
  414|       |  }
  415|       |
  416|       |  // This is a special evaluation path called from generic_product_impl<...,GemmProduct> in file GeneralMatrixMatrix.h
  417|       |  // This variant tries to extract scalar multiples from both the LHS and RHS and factor them out. For instance:
  418|       |  //   dst {,+,-}= (s1*A)*(B*s2)
  419|       |  // will be rewritten as:
  420|       |  //   dst {,+,-}= (s1*s2) * (A.lazyProduct(B))
  421|       |  // There are at least four benefits of doing so:
  422|       |  //  1 - huge performance gain for heap-allocated matrix types as it save costly allocations.
  423|       |  //  2 - it is faster than simply by-passing the heap allocation through stack allocation.
  424|       |  //  3 - it makes this fallback consistent with the heavy GEMM routine.
  425|       |  //  4 - it fully by-passes huge stack allocation attempts when multiplying huge fixed-size matrices.
  426|       |  //      (see https://stackoverflow.com/questions/54738495)
  427|       |  // For small fixed sizes matrices, however, the gains are less obvious, it is sometimes x2 faster, but sometimes x3
  428|       |  // slower, and the behavior depends also a lot on the compiler... This is why this re-writing strategy is currently
  429|       |  // enabled only when falling back from the main GEMM.
  430|       |  template <typename Dst, typename Func>
  431|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void eval_dynamic(Dst& dst, const Lhs& lhs, const Rhs& rhs,
  432|      0|                                                                 const Func& func) {
  433|      0|    enum {
  434|      0|      HasScalarFactor = blas_traits<Lhs>::HasScalarFactor || blas_traits<Rhs>::HasScalarFactor,
  435|      0|      ConjLhs = blas_traits<Lhs>::NeedToConjugate,
  436|      0|      ConjRhs = blas_traits<Rhs>::NeedToConjugate
  437|      0|    };
  438|       |    // FIXME: in c++11 this should be auto, and extractScalarFactor should also return auto
  439|       |    //        this is important for real*complex_mat
  440|      0|    Scalar actualAlpha = combine_scalar_factors<Scalar>(lhs, rhs);
  441|       |
  442|      0|    eval_dynamic_impl(dst, blas_traits<Lhs>::extract(lhs).template conjugateIf<ConjLhs>(),
  443|      0|                      blas_traits<Rhs>::extract(rhs).template conjugateIf<ConjRhs>(), func, actualAlpha,
  444|      0|                      std::conditional_t<HasScalarFactor, true_type, false_type>());
  445|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20generic_product_implINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_NS_10DenseShapeES5_Li3EE12eval_dynamicIS4_NS0_9assign_opIS3_S3_EEEEvRT_RKS4_SD_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20generic_product_implINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_NS_10DenseShapeES7_Li3EE12eval_dynamicIS5_NS0_9assign_opIS4_S4_EEEEvRT_RKS6_RKS5_RKT0_
  ------------------
  446|       |
  447|       | protected:
  448|       |  template <typename Dst, typename LhsT, typename RhsT, typename Func, typename Scalar>
  449|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void eval_dynamic_impl(Dst& dst, const LhsT& lhs, const RhsT& rhs,
  450|       |                                                                      const Func& func, const Scalar& s /* == 1 */,
  451|      0|                                                                      false_type) {
  452|      0|    EIGEN_UNUSED_VARIABLE(s);
  453|      0|    eigen_internal_assert(numext::is_exactly_one(s));
  454|      0|    call_restricted_packet_assignment_no_alias(dst, lhs.lazyProduct(rhs), func);
  455|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20generic_product_implINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_NS_10DenseShapeES5_Li3EE17eval_dynamic_implIS4_S4_S4_NS0_9assign_opIS3_S3_EES3_EEvRT_RKT0_RKT1_RKT2_RKT3_NS0_10false_typeE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal20generic_product_implINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_NS_10DenseShapeES7_Li3EE17eval_dynamic_implIS5_S6_S5_NS0_9assign_opIS4_S4_EES4_EEvRT_RKT0_RKT1_RKT2_RKT3_NS0_10false_typeE
  ------------------
  456|       |
  457|       |  template <typename Dst, typename LhsT, typename RhsT, typename Func, typename Scalar>
  458|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void eval_dynamic_impl(Dst& dst, const LhsT& lhs, const RhsT& rhs,
  459|       |                                                                      const Func& func, const Scalar& s, true_type) {
  460|       |    call_restricted_packet_assignment_no_alias(dst, s * lhs.lazyProduct(rhs), func);
  461|       |  }
  462|       |};
  463|       |
  464|       |// This specialization enforces the use of a coefficient-based evaluation strategy
  465|       |template <typename Lhs, typename Rhs>
  466|       |struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, LazyCoeffBasedProductMode>
  467|       |    : generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, CoeffBasedProductMode> {};
  468|       |
  469|       |// Case 2: Evaluate coeff by coeff
  470|       |//
  471|       |// This is mostly taken from CoeffBasedProduct.h
  472|       |// The main difference is that we add an extra argument to the etor_product_*_impl::run() function
  473|       |// for the inner dimension of the product, because evaluator object do not know their size.
  474|       |
  475|       |template <int Traversal, int UnrollingIndex, typename Lhs, typename Rhs, typename RetScalar>
  476|       |struct etor_product_coeff_impl;
  477|       |
  478|       |template <int StorageOrder, int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
  479|       |struct etor_product_packet_impl;
  480|       |
  481|       |template <typename Lhs, typename Rhs, int ProductTag>
  482|       |struct product_evaluator<Product<Lhs, Rhs, LazyProduct>, ProductTag, DenseShape, DenseShape>
  483|       |    : evaluator_base<Product<Lhs, Rhs, LazyProduct>> {
  484|       |  typedef Product<Lhs, Rhs, LazyProduct> XprType;
  485|       |  typedef typename XprType::Scalar Scalar;
  486|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
  487|       |
  488|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit product_evaluator(const XprType& xpr)
  489|       |      : m_lhs(xpr.lhs()),
  490|       |        m_rhs(xpr.rhs()),
  491|       |        m_lhsImpl(m_lhs),  // FIXME the creation of the evaluator objects should result in a no-op, but check that!
  492|       |        m_rhsImpl(m_rhs),  //       Moreover, they are only useful for the packet path, so we could completely disable
  493|       |                           //       them when not needed, or perhaps declare them on the fly on the packet method... We
  494|       |                           //       have experiment to check what's best.
  495|      0|        m_innerDim(xpr.lhs().cols()) {
  496|      0|    EIGEN_INTERNAL_CHECK_COST_VALUE(NumTraits<Scalar>::MulCost);
  497|      0|    EIGEN_INTERNAL_CHECK_COST_VALUE(NumTraits<Scalar>::AddCost);
  498|      0|    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  499|       |#if 0
  500|       |    std::cerr << "LhsOuterStrideBytes=  " << LhsOuterStrideBytes << "\n";
  501|       |    std::cerr << "RhsOuterStrideBytes=  " << RhsOuterStrideBytes << "\n";
  502|       |    std::cerr << "LhsAlignment=         " << LhsAlignment << "\n";
  503|       |    std::cerr << "RhsAlignment=         " << RhsAlignment << "\n";
  504|       |    std::cerr << "CanVectorizeLhs=      " << CanVectorizeLhs << "\n";
  505|       |    std::cerr << "CanVectorizeRhs=      " << CanVectorizeRhs << "\n";
  506|       |    std::cerr << "CanVectorizeInner=    " << CanVectorizeInner << "\n";
  507|       |    std::cerr << "EvalToRowMajor=       " << EvalToRowMajor << "\n";
  508|       |    std::cerr << "Alignment=            " << Alignment << "\n";
  509|       |    std::cerr << "Flags=                " << Flags << "\n";
  510|       |#endif
  511|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17product_evaluatorINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li1EEELi8ENS_10DenseShapeES7_S4_S4_EC2ERKS6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17product_evaluatorINS_7ProductINS2_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_Li1EEELi8ENS_10DenseShapeES8_S4_S4_EC2ERKS7_
  ------------------
  512|       |
  513|       |  // Everything below here is taken from CoeffBasedProduct.h
  514|       |
  515|       |  typedef typename internal::nested_eval<Lhs, Rhs::ColsAtCompileTime>::type LhsNested;
  516|       |  typedef typename internal::nested_eval<Rhs, Lhs::RowsAtCompileTime>::type RhsNested;
  517|       |
  518|       |  typedef internal::remove_all_t<LhsNested> LhsNestedCleaned;
  519|       |  typedef internal::remove_all_t<RhsNested> RhsNestedCleaned;
  520|       |
  521|       |  typedef evaluator<LhsNestedCleaned> LhsEtorType;
  522|       |  typedef evaluator<RhsNestedCleaned> RhsEtorType;
  523|       |
  524|       |  enum {
  525|       |    RowsAtCompileTime = LhsNestedCleaned::RowsAtCompileTime,
  526|       |    ColsAtCompileTime = RhsNestedCleaned::ColsAtCompileTime,
  527|       |    InnerSize = min_size_prefer_fixed(LhsNestedCleaned::ColsAtCompileTime, RhsNestedCleaned::RowsAtCompileTime),
  528|       |    MaxRowsAtCompileTime = LhsNestedCleaned::MaxRowsAtCompileTime,
  529|       |    MaxColsAtCompileTime = RhsNestedCleaned::MaxColsAtCompileTime
  530|       |  };
  531|       |
  532|       |  typedef typename find_best_packet<Scalar, RowsAtCompileTime>::type LhsVecPacketType;
  533|       |  typedef typename find_best_packet<Scalar, ColsAtCompileTime>::type RhsVecPacketType;
  534|       |
  535|       |  enum {
  536|       |
  537|       |    LhsCoeffReadCost = LhsEtorType::CoeffReadCost,
  538|       |    RhsCoeffReadCost = RhsEtorType::CoeffReadCost,
  539|       |    CoeffReadCost = InnerSize == 0 ? NumTraits<Scalar>::ReadCost
  540|       |                    : InnerSize == Dynamic
  541|       |                        ? HugeCost
  542|       |                        : InnerSize * (NumTraits<Scalar>::MulCost + int(LhsCoeffReadCost) + int(RhsCoeffReadCost)) +
  543|       |                              (InnerSize - 1) * NumTraits<Scalar>::AddCost,
  544|       |
  545|       |    Unroll = CoeffReadCost <= EIGEN_UNROLLING_LIMIT,
  546|       |
  547|       |    LhsFlags = LhsEtorType::Flags,
  548|       |    RhsFlags = RhsEtorType::Flags,
  549|       |
  550|       |    LhsRowMajor = LhsFlags & RowMajorBit,
  551|       |    RhsRowMajor = RhsFlags & RowMajorBit,
  552|       |
  553|       |    LhsVecPacketSize = unpacket_traits<LhsVecPacketType>::size,
  554|       |    RhsVecPacketSize = unpacket_traits<RhsVecPacketType>::size,
  555|       |
  556|       |    // Here, we don't care about alignment larger than the usable packet size.
  557|       |    LhsAlignment =
  558|       |        plain_enum_min(LhsEtorType::Alignment, LhsVecPacketSize* int(sizeof(typename LhsNestedCleaned::Scalar))),
  559|       |    RhsAlignment =
  560|       |        plain_enum_min(RhsEtorType::Alignment, RhsVecPacketSize* int(sizeof(typename RhsNestedCleaned::Scalar))),
  561|       |
  562|       |    SameType = is_same<typename LhsNestedCleaned::Scalar, typename RhsNestedCleaned::Scalar>::value,
  563|       |
  564|       |    CanVectorizeRhs = bool(RhsRowMajor) && (RhsFlags & PacketAccessBit) && (ColsAtCompileTime != 1),
  565|       |    CanVectorizeLhs = (!LhsRowMajor) && (LhsFlags & PacketAccessBit) && (RowsAtCompileTime != 1),
  566|       |
  567|       |    EvalToRowMajor = (MaxRowsAtCompileTime == 1 && MaxColsAtCompileTime != 1) ? 1
  568|       |                     : (MaxColsAtCompileTime == 1 && MaxRowsAtCompileTime != 1)
  569|       |                         ? 0
  570|       |                         : (bool(RhsRowMajor) && !CanVectorizeLhs),
  571|       |
  572|       |    Flags = ((int(LhsFlags) | int(RhsFlags)) & HereditaryBits & ~RowMajorBit) |
  573|       |            (EvalToRowMajor ? RowMajorBit : 0)
  574|       |            // TODO enable vectorization for mixed types
  575|       |            | (SameType && (CanVectorizeLhs || CanVectorizeRhs) ? PacketAccessBit : 0) |
  576|       |            (XprType::IsVectorAtCompileTime ? LinearAccessBit : 0),
  577|       |
  578|       |    LhsOuterStrideBytes =
  579|       |        int(LhsNestedCleaned::OuterStrideAtCompileTime) * int(sizeof(typename LhsNestedCleaned::Scalar)),
  580|       |    RhsOuterStrideBytes =
  581|       |        int(RhsNestedCleaned::OuterStrideAtCompileTime) * int(sizeof(typename RhsNestedCleaned::Scalar)),
  582|       |
  583|       |    Alignment = bool(CanVectorizeLhs)
  584|       |                    ? (LhsOuterStrideBytes <= 0 || (int(LhsOuterStrideBytes) % plain_enum_max(1, LhsAlignment)) != 0
  585|       |                           ? 0
  586|       |                           : LhsAlignment)
  587|       |                : bool(CanVectorizeRhs)
  588|       |                    ? (RhsOuterStrideBytes <= 0 || (int(RhsOuterStrideBytes) % plain_enum_max(1, RhsAlignment)) != 0
  589|       |                           ? 0
  590|       |                           : RhsAlignment)
  591|       |                    : 0,
  592|       |
  593|       |    /* CanVectorizeInner deserves special explanation. It does not affect the product flags. It is not used outside
  594|       |     * of Product. If the Product itself is not a packet-access expression, there is still a chance that the inner
  595|       |     * loop of the product might be vectorized. This is the meaning of CanVectorizeInner. Since it doesn't affect
  596|       |     * the Flags, it is safe to make this value depend on ActualPacketAccessBit, that doesn't affect the ABI.
  597|       |     */
  598|       |    CanVectorizeInner = SameType && LhsRowMajor && (!RhsRowMajor) &&
  599|       |                        (int(LhsFlags) & int(RhsFlags) & ActualPacketAccessBit) &&
  600|       |                        (int(InnerSize) % packet_traits<Scalar>::size == 0)
  601|       |  };
  602|       |
  603|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CoeffReturnType coeff(Index row, Index col) const {
  604|      0|    return (m_lhs.row(row).transpose().cwiseProduct(m_rhs.col(col))).sum();
  605|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal17product_evaluatorINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li1EEELi8ENS_10DenseShapeES7_S4_S4_E5coeffEll
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal17product_evaluatorINS_7ProductINS2_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_Li1EEELi8ENS_10DenseShapeES8_S4_S4_E5coeffEll
  ------------------
  606|       |
  607|       |  /* Allow index-based non-packet access. It is impossible though to allow index-based packed access,
  608|       |   * which is why we don't set the LinearAccessBit.
  609|       |   * TODO: this seems possible when the result is a vector
  610|       |   */
  611|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CoeffReturnType coeff(Index index) const {
  612|       |    const Index row = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime == 1) ? 0 : index;
  613|       |    const Index col = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime == 1) ? index : 0;
  614|       |    return (m_lhs.row(row).transpose().cwiseProduct(m_rhs.col(col))).sum();
  615|       |  }
  616|       |
  617|       |  template <int LoadMode, typename PacketType>
  618|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const PacketType packet(Index row, Index col) const {
  619|       |    PacketType res;
  620|       |    typedef etor_product_packet_impl<bool(int(Flags) & RowMajorBit) ? RowMajor : ColMajor,
  621|       |                                     Unroll ? int(InnerSize) : Dynamic, LhsEtorType, RhsEtorType, PacketType, LoadMode>
  622|       |        PacketImpl;
  623|       |    PacketImpl::run(row, col, m_lhsImpl, m_rhsImpl, m_innerDim, res);
  624|       |    return res;
  625|       |  }
  626|       |
  627|       |  template <int LoadMode, typename PacketType>
  628|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const PacketType packet(Index index) const {
  629|       |    const Index row = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime == 1) ? 0 : index;
  630|       |    const Index col = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime == 1) ? index : 0;
  631|       |    return packet<LoadMode, PacketType>(row, col);
  632|       |  }
  633|       |
  634|       | protected:
  635|       |  add_const_on_value_type_t<LhsNested> m_lhs;
  636|       |  add_const_on_value_type_t<RhsNested> m_rhs;
  637|       |
  638|       |  LhsEtorType m_lhsImpl;
  639|       |  RhsEtorType m_rhsImpl;
  640|       |
  641|       |  // TODO: Get rid of m_innerDim if known at compile time
  642|       |  Index m_innerDim;
  643|       |};
  644|       |
  645|       |template <typename Lhs, typename Rhs>
  646|       |struct product_evaluator<Product<Lhs, Rhs, DefaultProduct>, LazyCoeffBasedProductMode, DenseShape, DenseShape>
  647|       |    : product_evaluator<Product<Lhs, Rhs, LazyProduct>, CoeffBasedProductMode, DenseShape, DenseShape> {
  648|       |  typedef Product<Lhs, Rhs, DefaultProduct> XprType;
  649|       |  typedef Product<Lhs, Rhs, LazyProduct> BaseProduct;
  650|       |  typedef product_evaluator<BaseProduct, CoeffBasedProductMode, DenseShape, DenseShape> Base;
  651|       |  enum { Flags = Base::Flags | EvalBeforeNestingBit };
  652|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit product_evaluator(const XprType& xpr)
  653|       |      : Base(BaseProduct(xpr.lhs(), xpr.rhs())) {}
  654|       |};
  655|       |
  656|       |/****************************************
  657|       |*** Coeff based product, Packet path  ***
  658|       |****************************************/
  659|       |
  660|       |template <int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
  661|       |struct etor_product_packet_impl<RowMajor, UnrollingIndex, Lhs, Rhs, Packet, LoadMode> {
  662|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs,
  663|       |                                                        Index innerDim, Packet& res) {
  664|       |    etor_product_packet_impl<RowMajor, UnrollingIndex - 1, Lhs, Rhs, Packet, LoadMode>::run(row, col, lhs, rhs,
  665|       |                                                                                            innerDim, res);
  666|       |    res = pmadd(pset1<Packet>(lhs.coeff(row, Index(UnrollingIndex - 1))),
  667|       |                rhs.template packet<LoadMode, Packet>(Index(UnrollingIndex - 1), col), res);
  668|       |  }
  669|       |};
  670|       |
  671|       |template <int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
  672|       |struct etor_product_packet_impl<ColMajor, UnrollingIndex, Lhs, Rhs, Packet, LoadMode> {
  673|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs,
  674|       |                                                        Index innerDim, Packet& res) {
  675|       |    etor_product_packet_impl<ColMajor, UnrollingIndex - 1, Lhs, Rhs, Packet, LoadMode>::run(row, col, lhs, rhs,
  676|       |                                                                                            innerDim, res);
  677|       |    res = pmadd(lhs.template packet<LoadMode, Packet>(row, Index(UnrollingIndex - 1)),
  678|       |                pset1<Packet>(rhs.coeff(Index(UnrollingIndex - 1), col)), res);
  679|       |  }
  680|       |};
  681|       |
  682|       |template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
  683|       |struct etor_product_packet_impl<RowMajor, 1, Lhs, Rhs, Packet, LoadMode> {
  684|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs,
  685|       |                                                        Index /*innerDim*/, Packet& res) {
  686|       |    res = pmul(pset1<Packet>(lhs.coeff(row, Index(0))), rhs.template packet<LoadMode, Packet>(Index(0), col));
  687|       |  }
  688|       |};
  689|       |
  690|       |template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
  691|       |struct etor_product_packet_impl<ColMajor, 1, Lhs, Rhs, Packet, LoadMode> {
  692|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs,
  693|       |                                                        Index /*innerDim*/, Packet& res) {
  694|       |    res = pmul(lhs.template packet<LoadMode, Packet>(row, Index(0)), pset1<Packet>(rhs.coeff(Index(0), col)));
  695|       |  }
  696|       |};
  697|       |
  698|       |template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
  699|       |struct etor_product_packet_impl<RowMajor, 0, Lhs, Rhs, Packet, LoadMode> {
  700|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/,
  701|       |                                                        const Rhs& /*rhs*/, Index /*innerDim*/, Packet& res) {
  702|       |    res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
  703|       |  }
  704|       |};
  705|       |
  706|       |template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
  707|       |struct etor_product_packet_impl<ColMajor, 0, Lhs, Rhs, Packet, LoadMode> {
  708|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/,
  709|       |                                                        const Rhs& /*rhs*/, Index /*innerDim*/, Packet& res) {
  710|       |    res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
  711|       |  }
  712|       |};
  713|       |
  714|       |template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
  715|       |struct etor_product_packet_impl<RowMajor, Dynamic, Lhs, Rhs, Packet, LoadMode> {
  716|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs,
  717|       |                                                        Index innerDim, Packet& res) {
  718|       |    res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
  719|       |    for (Index i = 0; i < innerDim; ++i)
  720|       |      res = pmadd(pset1<Packet>(lhs.coeff(row, i)), rhs.template packet<LoadMode, Packet>(i, col), res);
  721|       |  }
  722|       |};
  723|       |
  724|       |template <typename Lhs, typename Rhs, typename Packet, int LoadMode>
  725|       |struct etor_product_packet_impl<ColMajor, Dynamic, Lhs, Rhs, Packet, LoadMode> {
  726|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs,
  727|       |                                                        Index innerDim, Packet& res) {
  728|       |    res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
  729|       |    for (Index i = 0; i < innerDim; ++i)
  730|       |      res = pmadd(lhs.template packet<LoadMode, Packet>(row, i), pset1<Packet>(rhs.coeff(i, col)), res);
  731|       |  }
  732|       |};
  733|       |
  734|       |/***************************************************************************
  735|       | * Triangular products
  736|       | ***************************************************************************/
  737|       |template <int Mode, bool LhsIsTriangular, typename Lhs, bool LhsIsVector, typename Rhs, bool RhsIsVector>
  738|       |struct triangular_product_impl;
  739|       |
  740|       |template <typename Lhs, typename Rhs, int ProductTag>
  741|       |struct generic_product_impl<Lhs, Rhs, TriangularShape, DenseShape, ProductTag>
  742|       |    : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, TriangularShape, DenseShape, ProductTag>> {
  743|       |  typedef typename Product<Lhs, Rhs>::Scalar Scalar;
  744|       |
  745|       |  template <typename Dest>
  746|       |  static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
  747|       |    triangular_product_impl<Lhs::Mode, true, typename Lhs::MatrixType, false, Rhs, Rhs::ColsAtCompileTime == 1>::run(
  748|       |        dst, lhs.nestedExpression(), rhs, alpha);
  749|       |  }
  750|       |};
  751|       |
  752|       |template <typename Lhs, typename Rhs, int ProductTag>
  753|       |struct generic_product_impl<Lhs, Rhs, DenseShape, TriangularShape, ProductTag>
  754|       |    : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, DenseShape, TriangularShape, ProductTag>> {
  755|       |  typedef typename Product<Lhs, Rhs>::Scalar Scalar;
  756|       |
  757|       |  template <typename Dest>
  758|       |  static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
  759|       |    triangular_product_impl<Rhs::Mode, false, Lhs, Lhs::RowsAtCompileTime == 1, typename Rhs::MatrixType, false>::run(
  760|       |        dst, lhs, rhs.nestedExpression(), alpha);
  761|       |  }
  762|       |};
  763|       |
  764|       |/***************************************************************************
  765|       | * SelfAdjoint products
  766|       | ***************************************************************************/
  767|       |template <typename Lhs, int LhsMode, bool LhsIsVector, typename Rhs, int RhsMode, bool RhsIsVector>
  768|       |struct selfadjoint_product_impl;
  769|       |
  770|       |template <typename Lhs, typename Rhs, int ProductTag>
  771|       |struct generic_product_impl<Lhs, Rhs, SelfAdjointShape, DenseShape, ProductTag>
  772|       |    : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, SelfAdjointShape, DenseShape, ProductTag>> {
  773|       |  typedef typename Product<Lhs, Rhs>::Scalar Scalar;
  774|       |
  775|       |  template <typename Dest>
  776|       |  static EIGEN_DEVICE_FUNC void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
  777|       |    selfadjoint_product_impl<typename Lhs::MatrixType, Lhs::Mode, false, Rhs, 0, Rhs::IsVectorAtCompileTime>::run(
  778|       |        dst, lhs.nestedExpression(), rhs, alpha);
  779|       |  }
  780|       |};
  781|       |
  782|       |template <typename Lhs, typename Rhs, int ProductTag>
  783|       |struct generic_product_impl<Lhs, Rhs, DenseShape, SelfAdjointShape, ProductTag>
  784|       |    : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, DenseShape, SelfAdjointShape, ProductTag>> {
  785|       |  typedef typename Product<Lhs, Rhs>::Scalar Scalar;
  786|       |
  787|       |  template <typename Dest>
  788|       |  static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha) {
  789|       |    selfadjoint_product_impl<Lhs, 0, Lhs::IsVectorAtCompileTime, typename Rhs::MatrixType, Rhs::Mode, false>::run(
  790|       |        dst, lhs, rhs.nestedExpression(), alpha);
  791|       |  }
  792|       |};
  793|       |
  794|       |/***************************************************************************
  795|       | * Diagonal products
  796|       | ***************************************************************************/
  797|       |
  798|       |template <typename MatrixType, typename DiagonalType, typename Derived, int ProductOrder>
  799|       |struct diagonal_product_evaluator_base : evaluator_base<Derived> {
  800|       |  typedef typename ScalarBinaryOpTraits<typename MatrixType::Scalar, typename DiagonalType::Scalar>::ReturnType Scalar;
  801|       |
  802|       | public:
  803|       |  enum {
  804|       |    CoeffReadCost = int(NumTraits<Scalar>::MulCost) + int(evaluator<MatrixType>::CoeffReadCost) +
  805|       |                    int(evaluator<DiagonalType>::CoeffReadCost),
  806|       |
  807|       |    MatrixFlags = evaluator<MatrixType>::Flags,
  808|       |    DiagFlags = evaluator<DiagonalType>::Flags,
  809|       |
  810|       |    StorageOrder_ = (Derived::MaxRowsAtCompileTime == 1 && Derived::MaxColsAtCompileTime != 1)   ? RowMajor
  811|       |                    : (Derived::MaxColsAtCompileTime == 1 && Derived::MaxRowsAtCompileTime != 1) ? ColMajor
  812|       |                    : MatrixFlags & RowMajorBit                                                  ? RowMajor
  813|       |                                                                                                 : ColMajor,
  814|       |    SameStorageOrder_ = int(StorageOrder_) == ((MatrixFlags & RowMajorBit) ? RowMajor : ColMajor),
  815|       |
  816|       |    ScalarAccessOnDiag_ = !((int(StorageOrder_) == ColMajor && int(ProductOrder) == OnTheLeft) ||
  817|       |                            (int(StorageOrder_) == RowMajor && int(ProductOrder) == OnTheRight)),
  818|       |    SameTypes_ = is_same<typename MatrixType::Scalar, typename DiagonalType::Scalar>::value,
  819|       |    // FIXME currently we need same types, but in the future the next rule should be the one
  820|       |    // Vectorizable_ = bool(int(MatrixFlags)&PacketAccessBit) && ((!_PacketOnDiag) || (SameTypes_ &&
  821|       |    // bool(int(DiagFlags)&PacketAccessBit))),
  822|       |    Vectorizable_ = bool(int(MatrixFlags) & PacketAccessBit) && SameTypes_ &&
  823|       |                    (SameStorageOrder_ || (MatrixFlags & LinearAccessBit) == LinearAccessBit) &&
  824|       |                    (ScalarAccessOnDiag_ || (bool(int(DiagFlags) & PacketAccessBit))),
  825|       |    LinearAccessMask_ =
  826|       |        (MatrixType::RowsAtCompileTime == 1 || MatrixType::ColsAtCompileTime == 1) ? LinearAccessBit : 0,
  827|       |    Flags =
  828|       |        ((HereditaryBits | LinearAccessMask_) & (unsigned int)(MatrixFlags)) | (Vectorizable_ ? PacketAccessBit : 0),
  829|       |    Alignment = evaluator<MatrixType>::Alignment,
  830|       |
  831|       |    AsScalarProduct =
  832|       |        (DiagonalType::SizeAtCompileTime == 1) ||
  833|       |        (DiagonalType::SizeAtCompileTime == Dynamic && MatrixType::RowsAtCompileTime == 1 &&
  834|       |         ProductOrder == OnTheLeft) ||
  835|       |        (DiagonalType::SizeAtCompileTime == Dynamic && MatrixType::ColsAtCompileTime == 1 && ProductOrder == OnTheRight)
  836|       |  };
  837|       |
  838|       |  EIGEN_DEVICE_FUNC diagonal_product_evaluator_base(const MatrixType& mat, const DiagonalType& diag)
  839|       |      : m_diagImpl(diag), m_matImpl(mat) {
  840|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(NumTraits<Scalar>::MulCost);
  841|       |    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  842|       |  }
  843|       |
  844|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar coeff(Index idx) const {
  845|       |    if (AsScalarProduct)
  846|       |      return m_diagImpl.coeff(0) * m_matImpl.coeff(idx);
  847|       |    else
  848|       |      return m_diagImpl.coeff(idx) * m_matImpl.coeff(idx);
  849|       |  }
  850|       |
  851|       | protected:
  852|       |  template <int LoadMode, typename PacketType>
  853|       |  EIGEN_STRONG_INLINE PacketType packet_impl(Index row, Index col, Index id, internal::true_type) const {
  854|       |    return internal::pmul(m_matImpl.template packet<LoadMode, PacketType>(row, col),
  855|       |                          internal::pset1<PacketType>(m_diagImpl.coeff(id)));
  856|       |  }
  857|       |
  858|       |  template <int LoadMode, typename PacketType>
  859|       |  EIGEN_STRONG_INLINE PacketType packet_impl(Index row, Index col, Index id, internal::false_type) const {
  860|       |    enum {
  861|       |      InnerSize = (MatrixType::Flags & RowMajorBit) ? MatrixType::ColsAtCompileTime : MatrixType::RowsAtCompileTime,
  862|       |      DiagonalPacketLoadMode = plain_enum_min(
  863|       |          LoadMode,
  864|       |          ((InnerSize % 16) == 0) ? int(Aligned16) : int(evaluator<DiagonalType>::Alignment))  // FIXME hardcoded 16!!
  865|       |    };
  866|       |    return internal::pmul(m_matImpl.template packet<LoadMode, PacketType>(row, col),
  867|       |                          m_diagImpl.template packet<DiagonalPacketLoadMode, PacketType>(id));
  868|       |  }
  869|       |
  870|       |  evaluator<DiagonalType> m_diagImpl;
  871|       |  evaluator<MatrixType> m_matImpl;
  872|       |};
  873|       |
  874|       |// diagonal * dense
  875|       |template <typename Lhs, typename Rhs, int ProductKind, int ProductTag>
  876|       |struct product_evaluator<Product<Lhs, Rhs, ProductKind>, ProductTag, DiagonalShape, DenseShape>
  877|       |    : diagonal_product_evaluator_base<Rhs, typename Lhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>,
  878|       |                                      OnTheLeft> {
  879|       |  typedef diagonal_product_evaluator_base<Rhs, typename Lhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>,
  880|       |                                          OnTheLeft>
  881|       |      Base;
  882|       |  using Base::coeff;
  883|       |  using Base::m_diagImpl;
  884|       |  using Base::m_matImpl;
  885|       |  typedef typename Base::Scalar Scalar;
  886|       |
  887|       |  typedef Product<Lhs, Rhs, ProductKind> XprType;
  888|       |  typedef typename XprType::PlainObject PlainObject;
  889|       |  typedef typename Lhs::DiagonalVectorType DiagonalType;
  890|       |
  891|       |  enum { StorageOrder = Base::StorageOrder_ };
  892|       |
  893|       |  EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr) : Base(xpr.rhs(), xpr.lhs().diagonal()) {}
  894|       |
  895|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar coeff(Index row, Index col) const {
  896|       |    return m_diagImpl.coeff(row) * m_matImpl.coeff(row, col);
  897|       |  }
  898|       |
  899|       |#ifndef EIGEN_GPUCC
  900|       |  template <int LoadMode, typename PacketType>
  901|       |  EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
  902|       |    // FIXME: NVCC used to complain about the template keyword, but we have to check whether this is still the case.
  903|       |    // See also similar calls below.
  904|       |    return this->template packet_impl<LoadMode, PacketType>(
  905|       |        row, col, row, std::conditional_t<int(StorageOrder) == RowMajor, internal::true_type, internal::false_type>());
  906|       |  }
  907|       |
  908|       |  template <int LoadMode, typename PacketType>
  909|       |  EIGEN_STRONG_INLINE PacketType packet(Index idx) const {
  910|       |    return packet<LoadMode, PacketType>(int(StorageOrder) == ColMajor ? idx : 0,
  911|       |                                        int(StorageOrder) == ColMajor ? 0 : idx);
  912|       |  }
  913|       |#endif
  914|       |};
  915|       |
  916|       |// dense * diagonal
  917|       |template <typename Lhs, typename Rhs, int ProductKind, int ProductTag>
  918|       |struct product_evaluator<Product<Lhs, Rhs, ProductKind>, ProductTag, DenseShape, DiagonalShape>
  919|       |    : diagonal_product_evaluator_base<Lhs, typename Rhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>,
  920|       |                                      OnTheRight> {
  921|       |  typedef diagonal_product_evaluator_base<Lhs, typename Rhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>,
  922|       |                                          OnTheRight>
  923|       |      Base;
  924|       |  using Base::coeff;
  925|       |  using Base::m_diagImpl;
  926|       |  using Base::m_matImpl;
  927|       |  typedef typename Base::Scalar Scalar;
  928|       |
  929|       |  typedef Product<Lhs, Rhs, ProductKind> XprType;
  930|       |  typedef typename XprType::PlainObject PlainObject;
  931|       |
  932|       |  enum { StorageOrder = Base::StorageOrder_ };
  933|       |
  934|       |  EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr) : Base(xpr.lhs(), xpr.rhs().diagonal()) {}
  935|       |
  936|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar coeff(Index row, Index col) const {
  937|       |    return m_matImpl.coeff(row, col) * m_diagImpl.coeff(col);
  938|       |  }
  939|       |
  940|       |#ifndef EIGEN_GPUCC
  941|       |  template <int LoadMode, typename PacketType>
  942|       |  EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const {
  943|       |    return this->template packet_impl<LoadMode, PacketType>(
  944|       |        row, col, col, std::conditional_t<int(StorageOrder) == ColMajor, internal::true_type, internal::false_type>());
  945|       |  }
  946|       |
  947|       |  template <int LoadMode, typename PacketType>
  948|       |  EIGEN_STRONG_INLINE PacketType packet(Index idx) const {
  949|       |    return packet<LoadMode, PacketType>(int(StorageOrder) == ColMajor ? idx : 0,
  950|       |                                        int(StorageOrder) == ColMajor ? 0 : idx);
  951|       |  }
  952|       |#endif
  953|       |};
  954|       |
  955|       |/***************************************************************************
  956|       | * Products with permutation matrices
  957|       | ***************************************************************************/
  958|       |
  959|       |/** \internal
  960|       | * \class permutation_matrix_product
  961|       | * Internal helper class implementing the product between a permutation matrix and a matrix.
  962|       | * This class is specialized for DenseShape below and for SparseShape in SparseCore/SparsePermutation.h
  963|       | */
  964|       |template <typename ExpressionType, int Side, bool Transposed, typename ExpressionShape>
  965|       |struct permutation_matrix_product;
  966|       |
  967|       |template <typename ExpressionType, int Side, bool Transposed>
  968|       |struct permutation_matrix_product<ExpressionType, Side, Transposed, DenseShape> {
  969|       |  typedef typename nested_eval<ExpressionType, 1>::type MatrixType;
  970|       |  typedef remove_all_t<MatrixType> MatrixTypeCleaned;
  971|       |
  972|       |  template <typename Dest, typename PermutationType>
  973|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Dest& dst, const PermutationType& perm,
  974|       |                                                        const ExpressionType& xpr) {
  975|       |    MatrixType mat(xpr);
  976|       |    const Index n = Side == OnTheLeft ? mat.rows() : mat.cols();
  977|       |    // FIXME we need an is_same for expression that is not sensitive to constness. For instance
  978|       |    // is_same_xpr<Block<const Matrix>, Block<Matrix> >::value should be true.
  979|       |    // if(is_same<MatrixTypeCleaned,Dest>::value && extract_data(dst) == extract_data(mat))
  980|       |    if (is_same_dense(dst, mat)) {
  981|       |      // apply the permutation inplace
  982|       |      Matrix<bool, PermutationType::RowsAtCompileTime, 1, 0, PermutationType::MaxRowsAtCompileTime> mask(perm.size());
  983|       |      mask.fill(false);
  984|       |      Index r = 0;
  985|       |      while (r < perm.size()) {
  986|       |        // search for the next seed
  987|       |        while (r < perm.size() && mask[r]) r++;
  988|       |        if (r >= perm.size()) break;
  989|       |        // we got one, let's follow it until we are back to the seed
  990|       |        Index k0 = r++;
  991|       |        Index kPrev = k0;
  992|       |        mask.coeffRef(k0) = true;
  993|       |        for (Index k = perm.indices().coeff(k0); k != k0; k = perm.indices().coeff(k)) {
  994|       |          Block<Dest, Side == OnTheLeft ? 1 : Dest::RowsAtCompileTime,
  995|       |                Side == OnTheRight ? 1 : Dest::ColsAtCompileTime>(dst, k)
  996|       |              .swap(Block < Dest, Side == OnTheLeft ? 1 : Dest::RowsAtCompileTime,
  997|       |                    Side == OnTheRight
  998|       |                        ? 1
  999|       |                        : Dest::ColsAtCompileTime > (dst, ((Side == OnTheLeft) ^ Transposed) ? k0 : kPrev));
 1000|       |
 1001|       |          mask.coeffRef(k) = true;
 1002|       |          kPrev = k;
 1003|       |        }
 1004|       |      }
 1005|       |    } else {
 1006|       |      for (Index i = 0; i < n; ++i) {
 1007|       |        Block<Dest, Side == OnTheLeft ? 1 : Dest::RowsAtCompileTime, Side == OnTheRight ? 1 : Dest::ColsAtCompileTime>(
 1008|       |            dst, ((Side == OnTheLeft) ^ Transposed) ? perm.indices().coeff(i) : i)
 1009|       |
 1010|       |            =
 1011|       |
 1012|       |                Block < const MatrixTypeCleaned,
 1013|       |            Side == OnTheLeft ? 1 : MatrixTypeCleaned::RowsAtCompileTime,
 1014|       |            Side == OnTheRight ? 1
 1015|       |                               : MatrixTypeCleaned::ColsAtCompileTime >
 1016|       |                                     (mat, ((Side == OnTheRight) ^ Transposed) ? perm.indices().coeff(i) : i);
 1017|       |      }
 1018|       |    }
 1019|       |  }
 1020|       |};
 1021|       |
 1022|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1023|       |struct generic_product_impl<Lhs, Rhs, PermutationShape, MatrixShape, ProductTag> {
 1024|       |  template <typename Dest>
 1025|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
 1026|       |    permutation_matrix_product<Rhs, OnTheLeft, false, MatrixShape>::run(dst, lhs, rhs);
 1027|       |  }
 1028|       |};
 1029|       |
 1030|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1031|       |struct generic_product_impl<Lhs, Rhs, MatrixShape, PermutationShape, ProductTag> {
 1032|       |  template <typename Dest>
 1033|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
 1034|       |    permutation_matrix_product<Lhs, OnTheRight, false, MatrixShape>::run(dst, rhs, lhs);
 1035|       |  }
 1036|       |};
 1037|       |
 1038|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1039|       |struct generic_product_impl<Inverse<Lhs>, Rhs, PermutationShape, MatrixShape, ProductTag> {
 1040|       |  template <typename Dest>
 1041|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Inverse<Lhs>& lhs, const Rhs& rhs) {
 1042|       |    permutation_matrix_product<Rhs, OnTheLeft, true, MatrixShape>::run(dst, lhs.nestedExpression(), rhs);
 1043|       |  }
 1044|       |};
 1045|       |
 1046|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1047|       |struct generic_product_impl<Lhs, Inverse<Rhs>, MatrixShape, PermutationShape, ProductTag> {
 1048|       |  template <typename Dest>
 1049|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Inverse<Rhs>& rhs) {
 1050|       |    permutation_matrix_product<Lhs, OnTheRight, true, MatrixShape>::run(dst, rhs.nestedExpression(), lhs);
 1051|       |  }
 1052|       |};
 1053|       |
 1054|       |/***************************************************************************
 1055|       | * Products with transpositions matrices
 1056|       | ***************************************************************************/
 1057|       |
 1058|       |// FIXME could we unify Transpositions and Permutation into a single "shape"??
 1059|       |
 1060|       |/** \internal
 1061|       | * \class transposition_matrix_product
 1062|       | * Internal helper class implementing the product between a permutation matrix and a matrix.
 1063|       | */
 1064|       |template <typename ExpressionType, int Side, bool Transposed, typename ExpressionShape>
 1065|       |struct transposition_matrix_product {
 1066|       |  typedef typename nested_eval<ExpressionType, 1>::type MatrixType;
 1067|       |  typedef remove_all_t<MatrixType> MatrixTypeCleaned;
 1068|       |
 1069|       |  template <typename Dest, typename TranspositionType>
 1070|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Dest& dst, const TranspositionType& tr,
 1071|       |                                                        const ExpressionType& xpr) {
 1072|       |    MatrixType mat(xpr);
 1073|       |    typedef typename TranspositionType::StorageIndex StorageIndex;
 1074|       |    const Index size = tr.size();
 1075|       |    StorageIndex j = 0;
 1076|       |
 1077|       |    if (!is_same_dense(dst, mat)) dst = mat;
 1078|       |
 1079|       |    for (Index k = (Transposed ? size - 1 : 0); Transposed ? k >= 0 : k < size; Transposed ? --k : ++k)
 1080|       |      if (Index(j = tr.coeff(k)) != k) {
 1081|       |        if (Side == OnTheLeft)
 1082|       |          dst.row(k).swap(dst.row(j));
 1083|       |        else if (Side == OnTheRight)
 1084|       |          dst.col(k).swap(dst.col(j));
 1085|       |      }
 1086|       |  }
 1087|       |};
 1088|       |
 1089|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1090|       |struct generic_product_impl<Lhs, Rhs, TranspositionsShape, MatrixShape, ProductTag> {
 1091|       |  template <typename Dest>
 1092|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
 1093|       |    transposition_matrix_product<Rhs, OnTheLeft, false, MatrixShape>::run(dst, lhs, rhs);
 1094|       |  }
 1095|       |};
 1096|       |
 1097|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1098|       |struct generic_product_impl<Lhs, Rhs, MatrixShape, TranspositionsShape, ProductTag> {
 1099|       |  template <typename Dest>
 1100|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
 1101|       |    transposition_matrix_product<Lhs, OnTheRight, false, MatrixShape>::run(dst, rhs, lhs);
 1102|       |  }
 1103|       |};
 1104|       |
 1105|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1106|       |struct generic_product_impl<Transpose<Lhs>, Rhs, TranspositionsShape, MatrixShape, ProductTag> {
 1107|       |  template <typename Dest>
 1108|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Transpose<Lhs>& lhs, const Rhs& rhs) {
 1109|       |    transposition_matrix_product<Rhs, OnTheLeft, true, MatrixShape>::run(dst, lhs.nestedExpression(), rhs);
 1110|       |  }
 1111|       |};
 1112|       |
 1113|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1114|       |struct generic_product_impl<Lhs, Transpose<Rhs>, MatrixShape, TranspositionsShape, ProductTag> {
 1115|       |  template <typename Dest>
 1116|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Transpose<Rhs>& rhs) {
 1117|       |    transposition_matrix_product<Lhs, OnTheRight, true, MatrixShape>::run(dst, rhs.nestedExpression(), lhs);
 1118|       |  }
 1119|       |};
 1120|       |
 1121|       |/***************************************************************************
 1122|       | * skew symmetric products
 1123|       | * for now we just call the generic implementation
 1124|       | ***************************************************************************/
 1125|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1126|       |struct generic_product_impl<Lhs, Rhs, SkewSymmetricShape, MatrixShape, ProductTag> {
 1127|       |  template <typename Dest>
 1128|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
 1129|       |    generic_product_impl<typename Lhs::DenseMatrixType, Rhs, DenseShape, MatrixShape, ProductTag>::evalTo(dst, lhs,
 1130|       |                                                                                                          rhs);
 1131|       |  }
 1132|       |};
 1133|       |
 1134|       |template <typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 1135|       |struct generic_product_impl<Lhs, Rhs, MatrixShape, SkewSymmetricShape, ProductTag> {
 1136|       |  template <typename Dest>
 1137|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
 1138|       |    generic_product_impl<Lhs, typename Rhs::DenseMatrixType, MatrixShape, DenseShape, ProductTag>::evalTo(dst, lhs,
 1139|       |                                                                                                          rhs);
 1140|       |  }
 1141|       |};
 1142|       |
 1143|       |template <typename Lhs, typename Rhs, int ProductTag>
 1144|       |struct generic_product_impl<Lhs, Rhs, SkewSymmetricShape, SkewSymmetricShape, ProductTag> {
 1145|       |  template <typename Dest>
 1146|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs) {
 1147|       |    generic_product_impl<typename Lhs::DenseMatrixType, typename Rhs::DenseMatrixType, DenseShape, DenseShape,
 1148|       |                         ProductTag>::evalTo(dst, lhs, rhs);
 1149|       |  }
 1150|       |};
 1151|       |
 1152|       |}  // end namespace internal
 1153|       |
 1154|       |}  // end namespace Eigen
 1155|       |
 1156|       |#endif  // EIGEN_PRODUCT_EVALUATORS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/RandomImpl.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2024 Charles Schlosser <cs.schlosser@gmail.com>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_RANDOM_IMPL_H
   11|       |#define EIGEN_RANDOM_IMPL_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "./InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |/****************************************************************************
   21|       | * Implementation of random                                               *
   22|       | ****************************************************************************/
   23|       |
   24|       |template <typename Scalar, bool IsComplex, bool IsInteger>
   25|       |struct random_default_impl {};
   26|       |
   27|       |template <typename Scalar>
   28|       |struct random_impl : random_default_impl<Scalar, NumTraits<Scalar>::IsComplex, NumTraits<Scalar>::IsInteger> {};
   29|       |
   30|       |template <typename Scalar>
   31|       |struct random_retval {
   32|       |  typedef Scalar type;
   33|       |};
   34|       |
   35|       |template <typename Scalar>
   36|       |inline EIGEN_MATHFUNC_RETVAL(random, Scalar) random(const Scalar& x, const Scalar& y) {
   37|       |  return EIGEN_MATHFUNC_IMPL(random, Scalar)::run(x, y);
   38|       |}
   39|       |
   40|       |template <typename Scalar>
   41|  43.5k|inline EIGEN_MATHFUNC_RETVAL(random, Scalar) random() {
   42|  43.5k|  return EIGEN_MATHFUNC_IMPL(random, Scalar)::run();
   43|  43.5k|}
   44|       |
   45|       |// TODO: replace or provide alternatives to this, e.g. std::random_device
   46|       |struct eigen_random_device {
   47|       |  using ReturnType = int;
   48|       |  static constexpr int Entropy = meta_floor_log2<(unsigned int)(RAND_MAX) + 1>::value;
   49|       |  static constexpr ReturnType Highest = RAND_MAX;
   50|  43.5k|  static EIGEN_DEVICE_FUNC inline ReturnType run() { return std::rand(); }
   51|       |};
   52|       |
   53|       |// Fill a built-in unsigned integer with numRandomBits beginning with the least significant bit
   54|       |template <typename Scalar>
   55|       |struct random_bits_impl {
   56|       |  EIGEN_STATIC_ASSERT(std::is_unsigned<Scalar>::value, SCALAR MUST BE A BUILT - IN UNSIGNED INTEGER)
   57|       |  using RandomDevice = eigen_random_device;
   58|       |  using RandomReturnType = typename RandomDevice::ReturnType;
   59|       |  static constexpr int kEntropy = RandomDevice::Entropy;
   60|       |  static constexpr int kTotalBits = sizeof(Scalar) * CHAR_BIT;
   61|       |  // return a Scalar filled with numRandomBits beginning from the least significant bit
   62|  43.5k|  static EIGEN_DEVICE_FUNC inline Scalar run(int numRandomBits) {
   63|  43.5k|    eigen_assert((numRandomBits >= 0) && (numRandomBits <= kTotalBits));
   64|  43.5k|    const Scalar mask = Scalar(-1) >> ((kTotalBits - numRandomBits) & (kTotalBits - 1));
   65|  43.5k|    Scalar randomBits = 0;
   66|  87.0k|    for (int shift = 0; shift < numRandomBits; shift += kEntropy) {
   67|  43.5k|      RandomReturnType r = RandomDevice::run();
   68|  43.5k|      randomBits |= static_cast<Scalar>(r) << shift;
   69|  43.5k|    }
   70|       |    // clear the excess bits
   71|  43.5k|    randomBits &= mask;
   72|  43.5k|    return randomBits;
   73|  43.5k|  }
  ------------------
  | _ZN5Eigen8internal16random_bits_implIjE3runEi:
  |   62|  43.5k|  static EIGEN_DEVICE_FUNC inline Scalar run(int numRandomBits) {
  |   63|  43.5k|    eigen_assert((numRandomBits >= 0) && (numRandomBits <= kTotalBits));
  |   64|  43.5k|    const Scalar mask = Scalar(-1) >> ((kTotalBits - numRandomBits) & (kTotalBits - 1));
  |   65|  43.5k|    Scalar randomBits = 0;
  |   66|  87.0k|    for (int shift = 0; shift < numRandomBits; shift += kEntropy) {
  |   67|  43.5k|      RandomReturnType r = RandomDevice::run();
  |   68|  43.5k|      randomBits |= static_cast<Scalar>(r) << shift;
  |   69|  43.5k|    }
  |   70|       |    // clear the excess bits
  |   71|  43.5k|    randomBits &= mask;
  |   72|  43.5k|    return randomBits;
  |   73|  43.5k|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal16random_bits_implImE3runEi
  ------------------
   74|       |};
   75|       |
   76|       |template <typename BitsType>
   77|  43.5k|EIGEN_DEVICE_FUNC inline BitsType getRandomBits(int numRandomBits) {
   78|  43.5k|  return random_bits_impl<BitsType>::run(numRandomBits);
   79|  43.5k|}
  ------------------
  | _ZN5Eigen8internal13getRandomBitsIjEET_i:
  |   77|  43.5k|EIGEN_DEVICE_FUNC inline BitsType getRandomBits(int numRandomBits) {
  |   78|  43.5k|  return random_bits_impl<BitsType>::run(numRandomBits);
  |   79|  43.5k|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13getRandomBitsImEET_i
  ------------------
   80|       |
   81|       |// random implementation for a built-in floating point type
   82|       |template <typename Scalar, bool BuiltIn = std::is_floating_point<Scalar>::value>
   83|       |struct random_float_impl {
   84|       |  using BitsType = typename numext::get_integer_by_size<sizeof(Scalar)>::unsigned_type;
   85|      0|  static constexpr EIGEN_DEVICE_FUNC inline int mantissaBits() {
   86|      0|    const int digits = NumTraits<Scalar>::digits();
   87|      0|    return digits - 1;
   88|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17random_float_implIdLb1EE12mantissaBitsEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17random_float_implIfLb1EE12mantissaBitsEv
  ------------------
   89|      0|  static EIGEN_DEVICE_FUNC inline Scalar run(int numRandomBits) {
   90|      0|    eigen_assert(numRandomBits >= 0 && numRandomBits <= mantissaBits());
   91|      0|    BitsType randomBits = getRandomBits<BitsType>(numRandomBits);
   92|      0|    // if fewer than MantissaBits is requested, shift them to the left
   93|      0|    randomBits <<= (mantissaBits() - numRandomBits);
   94|      0|    // randomBits is in the half-open interval [2,4)
   95|      0|    randomBits |= numext::bit_cast<BitsType>(Scalar(2));
   96|      0|    // result is in the half-open interval [-1,1)
   97|      0|    Scalar result = numext::bit_cast<Scalar>(randomBits) - Scalar(3);
   98|      0|    return result;
   99|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17random_float_implIdLb1EE3runEi
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal17random_float_implIfLb1EE3runEi
  ------------------
  100|       |};
  101|       |// random implementation for a custom floating point type
  102|       |// uses double as the implementation with a mantissa with a size equal to either the target scalar's mantissa or that of
  103|       |// double, whichever is smaller
  104|       |template <typename Scalar>
  105|       |struct random_float_impl<Scalar, false> {
  106|       |  static EIGEN_DEVICE_FUNC inline int mantissaBits() {
  107|       |    const int digits = NumTraits<Scalar>::digits();
  108|       |    constexpr int kDoubleDigits = NumTraits<double>::digits();
  109|       |    return numext::mini(digits, kDoubleDigits) - 1;
  110|       |  }
  111|       |  static EIGEN_DEVICE_FUNC inline Scalar run(int numRandomBits) {
  112|       |    eigen_assert(numRandomBits >= 0 && numRandomBits <= mantissaBits());
  113|       |    Scalar result = static_cast<Scalar>(random_float_impl<double>::run(numRandomBits));
  114|       |    return result;
  115|       |  }
  116|       |};
  117|       |
  118|       |#if !EIGEN_COMP_NVCC
  119|       |// random implementation for long double
  120|       |// this specialization is not compatible with double-double scalars
  121|       |template <bool Specialize = (sizeof(long double) == 2 * sizeof(uint64_t)) &&
  122|       |                            ((std::numeric_limits<long double>::digits != (2 * std::numeric_limits<double>::digits)))>
  123|       |struct random_longdouble_impl {
  124|       |  static constexpr int Size = sizeof(long double);
  125|       |  static constexpr EIGEN_DEVICE_FUNC inline int mantissaBits() { return NumTraits<long double>::digits() - 1; }
  126|       |  static EIGEN_DEVICE_FUNC inline long double run(int numRandomBits) {
  127|       |    eigen_assert(numRandomBits >= 0 && numRandomBits <= mantissaBits());
  128|       |    EIGEN_USING_STD(memcpy);
  129|       |    int numLowBits = numext::mini(numRandomBits, 64);
  130|       |    int numHighBits = numext::maxi(numRandomBits - 64, 0);
  131|       |    uint64_t randomBits[2];
  132|       |    long double result = 2.0L;
  133|       |    memcpy(&randomBits, &result, Size);
  134|       |    randomBits[0] |= getRandomBits<uint64_t>(numLowBits);
  135|       |    randomBits[1] |= getRandomBits<uint64_t>(numHighBits);
  136|       |    memcpy(&result, &randomBits, Size);
  137|       |    result -= 3.0L;
  138|       |    return result;
  139|       |  }
  140|       |};
  141|       |template <>
  142|       |struct random_longdouble_impl<false> {
  143|      0|  static constexpr EIGEN_DEVICE_FUNC inline int mantissaBits() { return NumTraits<double>::digits() - 1; }
  144|      0|  static EIGEN_DEVICE_FUNC inline long double run(int numRandomBits) {
  145|      0|    return static_cast<long double>(random_float_impl<double>::run(numRandomBits));
  146|      0|  }
  147|       |};
  148|       |template <>
  149|       |struct random_float_impl<long double> : random_longdouble_impl<> {};
  150|       |#endif
  151|       |
  152|       |template <typename Scalar>
  153|       |struct random_default_impl<Scalar, false, false> {
  154|       |  using Impl = random_float_impl<Scalar>;
  155|      0|  static EIGEN_DEVICE_FUNC inline Scalar run(const Scalar& x, const Scalar& y, int numRandomBits) {
  156|      0|    Scalar half_x = Scalar(0.5) * x;
  157|      0|    Scalar half_y = Scalar(0.5) * y;
  158|      0|    Scalar result = (half_x + half_y) + (half_y - half_x) * run(numRandomBits);
  159|      0|    // result is in the half-open interval [x, y) -- provided that x < y
  160|      0|    return result;
  161|      0|  }
  162|       |  static EIGEN_DEVICE_FUNC inline Scalar run(const Scalar& x, const Scalar& y) {
  163|       |    return run(x, y, Impl::mantissaBits());
  164|       |  }
  165|      0|  static EIGEN_DEVICE_FUNC inline Scalar run(int numRandomBits) { return Impl::run(numRandomBits); }
  166|       |  static EIGEN_DEVICE_FUNC inline Scalar run() { return run(Impl::mantissaBits()); }
  167|       |};
  168|       |
  169|       |template <typename Scalar, bool IsSigned = NumTraits<Scalar>::IsSigned, bool BuiltIn = std::is_integral<Scalar>::value>
  170|       |struct random_int_impl;
  171|       |
  172|       |// random implementation for a built-in unsigned integer type
  173|       |template <typename Scalar>
  174|       |struct random_int_impl<Scalar, false, true> {
  175|       |  static constexpr int kTotalBits = sizeof(Scalar) * CHAR_BIT;
  176|       |  static EIGEN_DEVICE_FUNC inline Scalar run(const Scalar& x, const Scalar& y) {
  177|       |    if (y <= x) return x;
  178|       |    Scalar range = y - x;
  179|       |    // handle edge case where [x,y] spans the entire range of Scalar
  180|       |    if (range == NumTraits<Scalar>::highest()) return run();
  181|       |    Scalar count = range + 1;
  182|       |    // calculate the number of random bits needed to fill range
  183|       |    int numRandomBits = log2_ceil(count);
  184|       |    Scalar randomBits;
  185|       |    do {
  186|       |      randomBits = getRandomBits<Scalar>(numRandomBits);
  187|       |      // if the random draw is outside [0, range), try again (rejection sampling)
  188|       |      // in the worst-case scenario, the probability of rejection is: 1/2 - 1/2^numRandomBits < 50%
  189|       |    } while (randomBits >= count);
  190|       |    Scalar result = x + randomBits;
  191|       |    return result;
  192|       |  }
  193|       |  static EIGEN_DEVICE_FUNC inline Scalar run() { return getRandomBits<Scalar>(kTotalBits); }
  194|       |};
  195|       |
  196|       |// random implementation for a built-in signed integer type
  197|       |template <typename Scalar>
  198|       |struct random_int_impl<Scalar, true, true> {
  199|       |  static constexpr int kTotalBits = sizeof(Scalar) * CHAR_BIT;
  200|       |  using BitsType = typename make_unsigned<Scalar>::type;
  201|       |  static EIGEN_DEVICE_FUNC inline Scalar run(const Scalar& x, const Scalar& y) {
  202|       |    if (y <= x) return x;
  203|       |    // Avoid overflow by representing `range` as an unsigned type
  204|       |    BitsType range = static_cast<BitsType>(y) - static_cast<BitsType>(x);
  205|       |    BitsType randomBits = random_int_impl<BitsType>::run(0, range);
  206|       |    // Avoid overflow in the case where `x` is negative and there is a large range so
  207|       |    // `randomBits` would also be negative if cast to `Scalar` first.
  208|       |    Scalar result = static_cast<Scalar>(static_cast<BitsType>(x) + randomBits);
  209|       |    return result;
  210|       |  }
  211|       |  static EIGEN_DEVICE_FUNC inline Scalar run() { return static_cast<Scalar>(getRandomBits<BitsType>(kTotalBits)); }
  212|       |};
  213|       |
  214|       |// todo: custom integers
  215|       |template <typename Scalar, bool IsSigned>
  216|       |struct random_int_impl<Scalar, IsSigned, false> {
  217|       |  static EIGEN_DEVICE_FUNC inline Scalar run(const Scalar&, const Scalar&) { return run(); }
  218|       |  static EIGEN_DEVICE_FUNC inline Scalar run() {
  219|       |    eigen_assert(std::false_type::value && "RANDOM FOR CUSTOM INTEGERS NOT YET SUPPORTED");
  220|       |    return Scalar(0);
  221|       |  }
  222|       |};
  223|       |
  224|       |template <typename Scalar>
  225|       |struct random_default_impl<Scalar, false, true> : random_int_impl<Scalar> {};
  226|       |
  227|       |template <>
  228|       |struct random_impl<bool> {
  229|      0|  static EIGEN_DEVICE_FUNC inline bool run(const bool& x, const bool& y) {
  230|      0|    if (y <= x) return x;
  231|      0|    return run();
  232|      0|  }
  233|  43.5k|  static EIGEN_DEVICE_FUNC inline bool run() { return getRandomBits<unsigned>(1) ? true : false; }
  234|       |};
  235|       |
  236|       |template <typename Scalar>
  237|       |struct random_default_impl<Scalar, true, false> {
  238|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  239|       |  using Impl = random_impl<RealScalar>;
  240|       |  static EIGEN_DEVICE_FUNC inline Scalar run(const Scalar& x, const Scalar& y, int numRandomBits) {
  241|       |    return Scalar(Impl::run(x.real(), y.real(), numRandomBits), Impl::run(x.imag(), y.imag(), numRandomBits));
  242|       |  }
  243|       |  static EIGEN_DEVICE_FUNC inline Scalar run(const Scalar& x, const Scalar& y) {
  244|       |    return Scalar(Impl::run(x.real(), y.real()), Impl::run(x.imag(), y.imag()));
  245|       |  }
  246|       |  static EIGEN_DEVICE_FUNC inline Scalar run(int numRandomBits) {
  247|       |    return Scalar(Impl::run(numRandomBits), Impl::run(numRandomBits));
  248|       |  }
  249|       |  static EIGEN_DEVICE_FUNC inline Scalar run() { return Scalar(Impl::run(), Impl::run()); }
  250|       |};
  251|       |
  252|       |}  // namespace internal
  253|       |}  // namespace Eigen
  254|       |
  255|       |#endif  // EIGEN_RANDOM_IMPL_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Redux.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_REDUX_H
   12|       |#define EIGEN_REDUX_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |
   21|       |// TODO
   22|       |//  * implement other kind of vectorization
   23|       |//  * factorize code
   24|       |
   25|       |/***************************************************************************
   26|       | * Part 1 : the logic deciding a strategy for vectorization and unrolling
   27|       | ***************************************************************************/
   28|       |
   29|       |template <typename Func, typename Evaluator>
   30|       |struct redux_traits {
   31|       | public:
   32|       |  typedef typename find_best_packet<typename Evaluator::Scalar, Evaluator::SizeAtCompileTime>::type PacketType;
   33|       |  enum {
   34|       |    PacketSize = unpacket_traits<PacketType>::size,
   35|       |    InnerMaxSize = int(Evaluator::IsRowMajor) ? Evaluator::MaxColsAtCompileTime : Evaluator::MaxRowsAtCompileTime,
   36|       |    OuterMaxSize = int(Evaluator::IsRowMajor) ? Evaluator::MaxRowsAtCompileTime : Evaluator::MaxColsAtCompileTime,
   37|       |    SliceVectorizedWork = int(InnerMaxSize) == Dynamic   ? Dynamic
   38|       |                          : int(OuterMaxSize) == Dynamic ? (int(InnerMaxSize) >= int(PacketSize) ? Dynamic : 0)
   39|       |                                                         : (int(InnerMaxSize) / int(PacketSize)) * int(OuterMaxSize)
   40|       |  };
   41|       |
   42|       |  enum {
   43|       |    MayLinearize = (int(Evaluator::Flags) & LinearAccessBit),
   44|       |    MightVectorize = (int(Evaluator::Flags) & ActualPacketAccessBit) && (functor_traits<Func>::PacketAccess),
   45|       |    MayLinearVectorize = bool(MightVectorize) && bool(MayLinearize),
   46|       |    MaySliceVectorize = bool(MightVectorize) && (int(SliceVectorizedWork) == Dynamic || int(SliceVectorizedWork) >= 3)
   47|       |  };
   48|       |
   49|       | public:
   50|       |  enum {
   51|       |    Traversal = int(MayLinearVectorize)  ? int(LinearVectorizedTraversal)
   52|       |                : int(MaySliceVectorize) ? int(SliceVectorizedTraversal)
   53|       |                : int(MayLinearize)      ? int(LinearTraversal)
   54|       |                                         : int(DefaultTraversal)
   55|       |  };
   56|       |
   57|       | public:
   58|       |  enum {
   59|       |    Cost = Evaluator::SizeAtCompileTime == Dynamic
   60|       |               ? HugeCost
   61|       |               : int(Evaluator::SizeAtCompileTime) * int(Evaluator::CoeffReadCost) +
   62|       |                     (Evaluator::SizeAtCompileTime - 1) * functor_traits<Func>::Cost,
   63|       |    UnrollingLimit = EIGEN_UNROLLING_LIMIT * (int(Traversal) == int(DefaultTraversal) ? 1 : int(PacketSize))
   64|       |  };
   65|       |
   66|       | public:
   67|       |  enum { Unrolling = Cost <= UnrollingLimit ? CompleteUnrolling : NoUnrolling };
   68|       |
   69|       |#ifdef EIGEN_DEBUG_ASSIGN
   70|       |  static void debug() {
   71|       |    std::cerr << "Xpr: " << typeid(typename Evaluator::XprType).name() << std::endl;
   72|       |    std::cerr.setf(std::ios::hex, std::ios::basefield);
   73|       |    EIGEN_DEBUG_VAR(Evaluator::Flags)
   74|       |    std::cerr.unsetf(std::ios::hex);
   75|       |    EIGEN_DEBUG_VAR(InnerMaxSize)
   76|       |    EIGEN_DEBUG_VAR(OuterMaxSize)
   77|       |    EIGEN_DEBUG_VAR(SliceVectorizedWork)
   78|       |    EIGEN_DEBUG_VAR(PacketSize)
   79|       |    EIGEN_DEBUG_VAR(MightVectorize)
   80|       |    EIGEN_DEBUG_VAR(MayLinearVectorize)
   81|       |    EIGEN_DEBUG_VAR(MaySliceVectorize)
   82|       |    std::cerr << "Traversal"
   83|       |              << " = " << Traversal << " (" << demangle_traversal(Traversal) << ")" << std::endl;
   84|       |    EIGEN_DEBUG_VAR(UnrollingLimit)
   85|       |    std::cerr << "Unrolling"
   86|       |              << " = " << Unrolling << " (" << demangle_unrolling(Unrolling) << ")" << std::endl;
   87|       |    std::cerr << std::endl;
   88|       |  }
   89|       |#endif
   90|       |};
   91|       |
   92|       |/***************************************************************************
   93|       | * Part 2 : unrollers
   94|       | ***************************************************************************/
   95|       |
   96|       |/*** no vectorization ***/
   97|       |
   98|       |template <typename Func, typename Evaluator, Index Start, Index Length>
   99|       |struct redux_novec_unroller {
  100|       |  static constexpr Index HalfLength = Length / 2;
  101|       |
  102|       |  typedef typename Evaluator::Scalar Scalar;
  103|       |
  104|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval, const Func& func) {
  105|       |    return func(redux_novec_unroller<Func, Evaluator, Start, HalfLength>::run(eval, func),
  106|       |                redux_novec_unroller<Func, Evaluator, Start + HalfLength, Length - HalfLength>::run(eval, func));
  107|       |  }
  108|       |};
  109|       |
  110|       |template <typename Func, typename Evaluator, Index Start>
  111|       |struct redux_novec_unroller<Func, Evaluator, Start, 1> {
  112|       |  static constexpr Index outer = Start / Evaluator::InnerSizeAtCompileTime;
  113|       |  static constexpr Index inner = Start % Evaluator::InnerSizeAtCompileTime;
  114|       |
  115|       |  typedef typename Evaluator::Scalar Scalar;
  116|       |
  117|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval, const Func&) {
  118|       |    return eval.coeffByOuterInner(outer, inner);
  119|       |  }
  120|       |};
  121|       |
  122|       |// This is actually dead code and will never be called. It is required
  123|       |// to prevent false warnings regarding failed inlining though
  124|       |// for 0 length run() will never be called at all.
  125|       |template <typename Func, typename Evaluator, Index Start>
  126|       |struct redux_novec_unroller<Func, Evaluator, Start, 0> {
  127|       |  typedef typename Evaluator::Scalar Scalar;
  128|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator&, const Func&) { return Scalar(); }
  129|       |};
  130|       |
  131|       |template <typename Func, typename Evaluator, Index Start, Index Length>
  132|       |struct redux_novec_linear_unroller {
  133|       |  static constexpr Index HalfLength = Length / 2;
  134|       |
  135|       |  typedef typename Evaluator::Scalar Scalar;
  136|       |
  137|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval, const Func& func) {
  138|       |    return func(redux_novec_linear_unroller<Func, Evaluator, Start, HalfLength>::run(eval, func),
  139|       |                redux_novec_linear_unroller<Func, Evaluator, Start + HalfLength, Length - HalfLength>::run(eval, func));
  140|       |  }
  141|       |};
  142|       |
  143|       |template <typename Func, typename Evaluator, Index Start>
  144|       |struct redux_novec_linear_unroller<Func, Evaluator, Start, 1> {
  145|       |  typedef typename Evaluator::Scalar Scalar;
  146|       |
  147|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval, const Func&) {
  148|       |    return eval.coeff(Start);
  149|       |  }
  150|       |};
  151|       |
  152|       |// This is actually dead code and will never be called. It is required
  153|       |// to prevent false warnings regarding failed inlining though
  154|       |// for 0 length run() will never be called at all.
  155|       |template <typename Func, typename Evaluator, Index Start>
  156|       |struct redux_novec_linear_unroller<Func, Evaluator, Start, 0> {
  157|       |  typedef typename Evaluator::Scalar Scalar;
  158|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator&, const Func&) { return Scalar(); }
  159|       |};
  160|       |
  161|       |/*** vectorization ***/
  162|       |
  163|       |template <typename Func, typename Evaluator, Index Start, Index Length>
  164|       |struct redux_vec_unroller {
  165|       |  template <typename PacketType>
  166|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE PacketType run(const Evaluator& eval, const Func& func) {
  167|       |    constexpr Index HalfLength = Length / 2;
  168|       |
  169|       |    return func.packetOp(
  170|       |        redux_vec_unroller<Func, Evaluator, Start, HalfLength>::template run<PacketType>(eval, func),
  171|       |        redux_vec_unroller<Func, Evaluator, Start + HalfLength, Length - HalfLength>::template run<PacketType>(eval,
  172|       |                                                                                                               func));
  173|       |  }
  174|       |};
  175|       |
  176|       |template <typename Func, typename Evaluator, Index Start>
  177|       |struct redux_vec_unroller<Func, Evaluator, Start, 1> {
  178|       |  template <typename PacketType>
  179|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE PacketType run(const Evaluator& eval, const Func&) {
  180|       |    constexpr Index PacketSize = unpacket_traits<PacketType>::size;
  181|       |    constexpr Index index = Start * PacketSize;
  182|       |    constexpr Index outer = index / int(Evaluator::InnerSizeAtCompileTime);
  183|       |    constexpr Index inner = index % int(Evaluator::InnerSizeAtCompileTime);
  184|       |    constexpr int alignment = Evaluator::Alignment;
  185|       |
  186|       |    return eval.template packetByOuterInner<alignment, PacketType>(outer, inner);
  187|       |  }
  188|       |};
  189|       |
  190|       |template <typename Func, typename Evaluator, Index Start, Index Length>
  191|       |struct redux_vec_linear_unroller {
  192|       |  template <typename PacketType>
  193|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE PacketType run(const Evaluator& eval, const Func& func) {
  194|       |    constexpr Index HalfLength = Length / 2;
  195|       |
  196|       |    return func.packetOp(
  197|       |        redux_vec_linear_unroller<Func, Evaluator, Start, HalfLength>::template run<PacketType>(eval, func),
  198|       |        redux_vec_linear_unroller<Func, Evaluator, Start + HalfLength, Length - HalfLength>::template run<PacketType>(
  199|       |            eval, func));
  200|       |  }
  201|       |};
  202|       |
  203|       |template <typename Func, typename Evaluator, Index Start>
  204|       |struct redux_vec_linear_unroller<Func, Evaluator, Start, 1> {
  205|       |  template <typename PacketType>
  206|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE PacketType run(const Evaluator& eval, const Func&) {
  207|       |    constexpr Index PacketSize = unpacket_traits<PacketType>::size;
  208|       |    constexpr Index index = (Start * PacketSize);
  209|       |    constexpr int alignment = Evaluator::Alignment;
  210|       |    return eval.template packet<alignment, PacketType>(index);
  211|       |  }
  212|       |};
  213|       |
  214|       |/***************************************************************************
  215|       | * Part 3 : implementation of all cases
  216|       | ***************************************************************************/
  217|       |
  218|       |template <typename Func, typename Evaluator, int Traversal = redux_traits<Func, Evaluator>::Traversal,
  219|       |          int Unrolling = redux_traits<Func, Evaluator>::Unrolling>
  220|       |struct redux_impl;
  221|       |
  222|       |template <typename Func, typename Evaluator>
  223|       |struct redux_impl<Func, Evaluator, DefaultTraversal, NoUnrolling> {
  224|       |  typedef typename Evaluator::Scalar Scalar;
  225|       |
  226|       |  template <typename XprType>
  227|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval, const Func& func, const XprType& xpr) {
  228|       |    eigen_assert(xpr.rows() > 0 && xpr.cols() > 0 && "you are using an empty matrix");
  229|       |    Scalar res = eval.coeffByOuterInner(0, 0);
  230|       |    for (Index i = 1; i < xpr.innerSize(); ++i) res = func(res, eval.coeffByOuterInner(0, i));
  231|       |    for (Index i = 1; i < xpr.outerSize(); ++i)
  232|       |      for (Index j = 0; j < xpr.innerSize(); ++j) res = func(res, eval.coeffByOuterInner(i, j));
  233|       |    return res;
  234|       |  }
  235|       |};
  236|       |
  237|       |template <typename Func, typename Evaluator>
  238|       |struct redux_impl<Func, Evaluator, LinearTraversal, NoUnrolling> {
  239|       |  typedef typename Evaluator::Scalar Scalar;
  240|       |
  241|       |  template <typename XprType>
  242|      0|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval, const Func& func, const XprType& xpr) {
  243|      0|    eigen_assert(xpr.size() > 0 && "you are using an empty matrix");
  244|      0|    Scalar res = eval.coeff(0);
  245|      0|    for (Index k = 1; k < xpr.size(); ++k) res = func(res, eval.coeff(k));
  246|      0|    return res;
  247|      0|  }
  248|       |};
  249|       |
  250|       |template <typename Func, typename Evaluator>
  251|       |struct redux_impl<Func, Evaluator, DefaultTraversal, CompleteUnrolling>
  252|       |    : redux_novec_unroller<Func, Evaluator, 0, Evaluator::SizeAtCompileTime> {
  253|       |  typedef redux_novec_unroller<Func, Evaluator, 0, Evaluator::SizeAtCompileTime> Base;
  254|       |  typedef typename Evaluator::Scalar Scalar;
  255|       |  template <typename XprType>
  256|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval, const Func& func,
  257|       |                                                          const XprType& /*xpr*/) {
  258|       |    return Base::run(eval, func);
  259|       |  }
  260|       |};
  261|       |
  262|       |template <typename Func, typename Evaluator>
  263|       |struct redux_impl<Func, Evaluator, LinearTraversal, CompleteUnrolling>
  264|       |    : redux_novec_linear_unroller<Func, Evaluator, 0, Evaluator::SizeAtCompileTime> {
  265|       |  typedef redux_novec_linear_unroller<Func, Evaluator, 0, Evaluator::SizeAtCompileTime> Base;
  266|       |  typedef typename Evaluator::Scalar Scalar;
  267|       |  template <typename XprType>
  268|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval, const Func& func,
  269|       |                                                          const XprType& /*xpr*/) {
  270|       |    return Base::run(eval, func);
  271|       |  }
  272|       |};
  273|       |
  274|       |template <typename Func, typename Evaluator>
  275|       |struct redux_impl<Func, Evaluator, LinearVectorizedTraversal, NoUnrolling> {
  276|       |  typedef typename Evaluator::Scalar Scalar;
  277|       |  typedef typename redux_traits<Func, Evaluator>::PacketType PacketScalar;
  278|       |
  279|       |  template <typename XprType>
  280|       |  static Scalar run(const Evaluator& eval, const Func& func, const XprType& xpr) {
  281|       |    const Index size = xpr.size();
  282|       |
  283|       |    constexpr Index packetSize = redux_traits<Func, Evaluator>::PacketSize;
  284|       |    constexpr int packetAlignment = unpacket_traits<PacketScalar>::alignment;
  285|       |    constexpr int alignment0 =
  286|       |        (bool(Evaluator::Flags & DirectAccessBit) && bool(packet_traits<Scalar>::AlignedOnScalar))
  287|       |            ? int(packetAlignment)
  288|       |            : int(Unaligned);
  289|       |    constexpr int alignment = plain_enum_max(alignment0, Evaluator::Alignment);
  290|       |    const Index alignedStart = internal::first_default_aligned(xpr);
  291|       |    const Index alignedSize2 = ((size - alignedStart) / (2 * packetSize)) * (2 * packetSize);
  292|       |    const Index alignedSize = ((size - alignedStart) / (packetSize)) * (packetSize);
  293|       |    const Index alignedEnd2 = alignedStart + alignedSize2;
  294|       |    const Index alignedEnd = alignedStart + alignedSize;
  295|       |    Scalar res;
  296|       |    if (alignedSize) {
  297|       |      PacketScalar packet_res0 = eval.template packet<alignment, PacketScalar>(alignedStart);
  298|       |      if (alignedSize > packetSize)  // we have at least two packets to partly unroll the loop
  299|       |      {
  300|       |        PacketScalar packet_res1 = eval.template packet<alignment, PacketScalar>(alignedStart + packetSize);
  301|       |        for (Index index = alignedStart + 2 * packetSize; index < alignedEnd2; index += 2 * packetSize) {
  302|       |          packet_res0 = func.packetOp(packet_res0, eval.template packet<alignment, PacketScalar>(index));
  303|       |          packet_res1 = func.packetOp(packet_res1, eval.template packet<alignment, PacketScalar>(index + packetSize));
  304|       |        }
  305|       |
  306|       |        packet_res0 = func.packetOp(packet_res0, packet_res1);
  307|       |        if (alignedEnd > alignedEnd2)
  308|       |          packet_res0 = func.packetOp(packet_res0, eval.template packet<alignment, PacketScalar>(alignedEnd2));
  309|       |      }
  310|       |      res = func.predux(packet_res0);
  311|       |
  312|       |      for (Index index = 0; index < alignedStart; ++index) res = func(res, eval.coeff(index));
  313|       |
  314|       |      for (Index index = alignedEnd; index < size; ++index) res = func(res, eval.coeff(index));
  315|       |    } else  // too small to vectorize anything.
  316|       |            // since this is dynamic-size hence inefficient anyway for such small sizes, don't try to optimize.
  317|       |    {
  318|       |      res = eval.coeff(0);
  319|       |      for (Index index = 1; index < size; ++index) res = func(res, eval.coeff(index));
  320|       |    }
  321|       |
  322|       |    return res;
  323|       |  }
  324|       |};
  325|       |
  326|       |// NOTE: for SliceVectorizedTraversal we simply bypass unrolling
  327|       |template <typename Func, typename Evaluator, int Unrolling>
  328|       |struct redux_impl<Func, Evaluator, SliceVectorizedTraversal, Unrolling> {
  329|       |  typedef typename Evaluator::Scalar Scalar;
  330|       |  typedef typename redux_traits<Func, Evaluator>::PacketType PacketType;
  331|       |
  332|       |  template <typename XprType>
  333|       |  EIGEN_DEVICE_FUNC static Scalar run(const Evaluator& eval, const Func& func, const XprType& xpr) {
  334|       |    eigen_assert(xpr.rows() > 0 && xpr.cols() > 0 && "you are using an empty matrix");
  335|       |    constexpr Index packetSize = redux_traits<Func, Evaluator>::PacketSize;
  336|       |    const Index innerSize = xpr.innerSize();
  337|       |    const Index outerSize = xpr.outerSize();
  338|       |    const Index packetedInnerSize = ((innerSize) / packetSize) * packetSize;
  339|       |    Scalar res;
  340|       |    if (packetedInnerSize) {
  341|       |      PacketType packet_res = eval.template packet<Unaligned, PacketType>(0, 0);
  342|       |      for (Index j = 0; j < outerSize; ++j)
  343|       |        for (Index i = (j == 0 ? packetSize : 0); i < packetedInnerSize; i += Index(packetSize))
  344|       |          packet_res = func.packetOp(packet_res, eval.template packetByOuterInner<Unaligned, PacketType>(j, i));
  345|       |
  346|       |      res = func.predux(packet_res);
  347|       |      for (Index j = 0; j < outerSize; ++j)
  348|       |        for (Index i = packetedInnerSize; i < innerSize; ++i) res = func(res, eval.coeffByOuterInner(j, i));
  349|       |    } else  // too small to vectorize anything.
  350|       |            // since this is dynamic-size hence inefficient anyway for such small sizes, don't try to optimize.
  351|       |    {
  352|       |      res = redux_impl<Func, Evaluator, DefaultTraversal, NoUnrolling>::run(eval, func, xpr);
  353|       |    }
  354|       |
  355|       |    return res;
  356|       |  }
  357|       |};
  358|       |
  359|       |template <typename Func, typename Evaluator>
  360|       |struct redux_impl<Func, Evaluator, LinearVectorizedTraversal, CompleteUnrolling> {
  361|       |  typedef typename Evaluator::Scalar Scalar;
  362|       |
  363|       |  typedef typename redux_traits<Func, Evaluator>::PacketType PacketType;
  364|       |  static constexpr Index PacketSize = redux_traits<Func, Evaluator>::PacketSize;
  365|       |  static constexpr Index Size = Evaluator::SizeAtCompileTime;
  366|       |  static constexpr Index VectorizedSize = (int(Size) / int(PacketSize)) * int(PacketSize);
  367|       |
  368|       |  template <typename XprType>
  369|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Scalar run(const Evaluator& eval, const Func& func, const XprType& xpr) {
  370|       |    EIGEN_ONLY_USED_FOR_DEBUG(xpr)
  371|       |    eigen_assert(xpr.rows() > 0 && xpr.cols() > 0 && "you are using an empty matrix");
  372|       |    if (VectorizedSize > 0) {
  373|       |      Scalar res = func.predux(
  374|       |          redux_vec_linear_unroller<Func, Evaluator, 0, Size / PacketSize>::template run<PacketType>(eval, func));
  375|       |      if (VectorizedSize != Size)
  376|       |        res = func(
  377|       |            res, redux_novec_linear_unroller<Func, Evaluator, VectorizedSize, Size - VectorizedSize>::run(eval, func));
  378|       |      return res;
  379|       |    } else {
  380|       |      return redux_novec_linear_unroller<Func, Evaluator, 0, Size>::run(eval, func);
  381|       |    }
  382|       |  }
  383|       |};
  384|       |
  385|       |// evaluator adaptor
  386|       |template <typename XprType_>
  387|       |class redux_evaluator : public internal::evaluator<XprType_> {
  388|       |  typedef internal::evaluator<XprType_> Base;
  389|       |
  390|       | public:
  391|       |  typedef XprType_ XprType;
  392|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit redux_evaluator(const XprType& xpr) : Base(xpr) {}
  393|       |
  394|       |  typedef typename XprType::Scalar Scalar;
  395|       |  typedef typename XprType::CoeffReturnType CoeffReturnType;
  396|       |  typedef typename XprType::PacketScalar PacketScalar;
  397|       |
  398|       |  enum {
  399|       |    MaxRowsAtCompileTime = XprType::MaxRowsAtCompileTime,
  400|       |    MaxColsAtCompileTime = XprType::MaxColsAtCompileTime,
  401|       |    // TODO we should not remove DirectAccessBit and rather find an elegant way to query the alignment offset at runtime
  402|       |    // from the evaluator
  403|       |    Flags = Base::Flags & ~DirectAccessBit,
  404|       |    IsRowMajor = XprType::IsRowMajor,
  405|       |    SizeAtCompileTime = XprType::SizeAtCompileTime,
  406|       |    InnerSizeAtCompileTime = XprType::InnerSizeAtCompileTime
  407|       |  };
  408|       |
  409|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE CoeffReturnType coeffByOuterInner(Index outer, Index inner) const {
  410|       |    return Base::coeff(IsRowMajor ? outer : inner, IsRowMajor ? inner : outer);
  411|       |  }
  412|       |
  413|       |  template <int LoadMode, typename PacketType>
  414|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PacketType packetByOuterInner(Index outer, Index inner) const {
  415|       |    return Base::template packet<LoadMode, PacketType>(IsRowMajor ? outer : inner, IsRowMajor ? inner : outer);
  416|       |  }
  417|       |};
  418|       |
  419|       |}  // end namespace internal
  420|       |
  421|       |/***************************************************************************
  422|       | * Part 4 : public API
  423|       | ***************************************************************************/
  424|       |
  425|       |/** \returns the result of a full redux operation on the whole matrix or vector using \a func
  426|       | *
  427|       | * The template parameter \a BinaryOp is the type of the functor \a func which must be
  428|       | * an associative operator. Both current C++98 and C++11 functor styles are handled.
  429|       | *
  430|       | * \warning the matrix must be not empty, otherwise an assertion is triggered.
  431|       | *
  432|       | * \sa DenseBase::sum(), DenseBase::minCoeff(), DenseBase::maxCoeff(), MatrixBase::colwise(), MatrixBase::rowwise()
  433|       | */
  434|       |template <typename Derived>
  435|       |template <typename Func>
  436|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar DenseBase<Derived>::redux(
  437|      0|    const Func& func) const {
  438|      0|  eigen_assert(this->rows() > 0 && this->cols() > 0 && "you are using an empty matrix");
  439|       |
  440|      0|  typedef typename internal::redux_evaluator<Derived> ThisEvaluator;
  441|      0|  ThisEvaluator thisEval(derived());
  442|       |
  443|       |  // The initial expression is passed to the reducer as an additional argument instead of
  444|       |  // passing it as a member of redux_evaluator to help
  445|      0|  return internal::redux_impl<Func, ThisEvaluator>::run(thisEval, func, derived());
  446|      0|}
  447|       |
  448|       |/** \returns the minimum of all coefficients of \c *this.
  449|       | * In case \c *this contains NaN, NaNPropagation determines the behavior:
  450|       | *   NaNPropagation == PropagateFast : undefined
  451|       | *   NaNPropagation == PropagateNaN : result is NaN
  452|       | *   NaNPropagation == PropagateNumbers : result is minimum of elements that are not NaN
  453|       | * \warning the matrix must be not empty, otherwise an assertion is triggered.
  454|       | */
  455|       |template <typename Derived>
  456|       |template <int NaNPropagation>
  457|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar DenseBase<Derived>::minCoeff() const {
  458|       |  return derived().redux(Eigen::internal::scalar_min_op<Scalar, Scalar, NaNPropagation>());
  459|       |}
  460|       |
  461|       |/** \returns the maximum of all coefficients of \c *this.
  462|       | * In case \c *this contains NaN, NaNPropagation determines the behavior:
  463|       | *   NaNPropagation == PropagateFast : undefined
  464|       | *   NaNPropagation == PropagateNaN : result is NaN
  465|       | *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
  466|       | * \warning the matrix must be not empty, otherwise an assertion is triggered.
  467|       | */
  468|       |template <typename Derived>
  469|       |template <int NaNPropagation>
  470|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar DenseBase<Derived>::maxCoeff() const {
  471|       |  return derived().redux(Eigen::internal::scalar_max_op<Scalar, Scalar, NaNPropagation>());
  472|       |}
  473|       |
  474|       |/** \returns the sum of all coefficients of \c *this
  475|       | *
  476|       | * If \c *this is empty, then the value 0 is returned.
  477|       | *
  478|       | * \sa trace(), prod(), mean()
  479|       | */
  480|       |template <typename Derived>
  481|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar DenseBase<Derived>::sum() const {
  482|      0|  if (SizeAtCompileTime == 0 || (SizeAtCompileTime == Dynamic && size() == 0)) return Scalar(0);
  483|      0|  return derived().redux(Eigen::internal::scalar_sum_op<Scalar, Scalar>());
  484|      0|}
  485|       |
  486|       |/** \returns the mean of all coefficients of *this
  487|       | *
  488|       | * \sa trace(), prod(), sum()
  489|       | */
  490|       |template <typename Derived>
  491|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar DenseBase<Derived>::mean() const {
  492|       |#ifdef __INTEL_COMPILER
  493|       |#pragma warning push
  494|       |#pragma warning(disable : 2259)
  495|       |#endif
  496|       |  return Scalar(derived().redux(Eigen::internal::scalar_sum_op<Scalar, Scalar>())) / Scalar(this->size());
  497|       |#ifdef __INTEL_COMPILER
  498|       |#pragma warning pop
  499|       |#endif
  500|       |}
  501|       |
  502|       |/** \returns the product of all coefficients of *this
  503|       | *
  504|       | * Example: \include MatrixBase_prod.cpp
  505|       | * Output: \verbinclude MatrixBase_prod.out
  506|       | *
  507|       | * \sa sum(), mean(), trace()
  508|       | */
  509|       |template <typename Derived>
  510|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar DenseBase<Derived>::prod() const {
  511|       |  if (SizeAtCompileTime == 0 || (SizeAtCompileTime == Dynamic && size() == 0)) return Scalar(1);
  512|       |  return derived().redux(Eigen::internal::scalar_product_op<Scalar>());
  513|       |}
  514|       |
  515|       |/** \returns the trace of \c *this, i.e. the sum of the coefficients on the main diagonal.
  516|       | *
  517|       | * \c *this can be any matrix, not necessarily square.
  518|       | *
  519|       | * \sa diagonal(), sum()
  520|       | */
  521|       |template <typename Derived>
  522|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar MatrixBase<Derived>::trace() const {
  523|       |  return derived().diagonal().sum();
  524|       |}
  525|       |
  526|       |}  // end namespace Eigen
  527|       |
  528|       |#endif  // EIGEN_REDUX_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Stride.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_STRIDE_H
   11|       |#define EIGEN_STRIDE_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "./InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |/** \class Stride
   19|       | * \ingroup Core_Module
   20|       | *
   21|       | * \brief Holds strides information for Map
   22|       | *
   23|       | * This class holds the strides information for mapping arrays with strides with class Map.
   24|       | *
   25|       | * It holds two values: the inner stride and the outer stride.
   26|       | *
   27|       | * The inner stride is the pointer increment between two consecutive entries within a given row of a
   28|       | * row-major matrix or within a given column of a column-major matrix.
   29|       | *
   30|       | * The outer stride is the pointer increment between two consecutive rows of a row-major matrix or
   31|       | * between two consecutive columns of a column-major matrix.
   32|       | *
   33|       | * These two values can be passed either at compile-time as template parameters, or at runtime as
   34|       | * arguments to the constructor.
   35|       | *
   36|       | * Indeed, this class takes two template parameters:
   37|       | *  \tparam OuterStrideAtCompileTime_ the outer stride, or Dynamic if you want to specify it at runtime.
   38|       | *  \tparam InnerStrideAtCompileTime_ the inner stride, or Dynamic if you want to specify it at runtime.
   39|       | *
   40|       | * Here is an example:
   41|       | * \include Map_general_stride.cpp
   42|       | * Output: \verbinclude Map_general_stride.out
   43|       | *
   44|       | * Both strides can be negative. However, a negative stride of -1 cannot be specified at compile time
   45|       | * because of the ambiguity with Dynamic which is defined to -1 (historically, negative strides were
   46|       | * not allowed).
   47|       | *
   48|       | * Note that for compile-time vectors (ColsAtCompileTime==1 or RowsAtCompile==1),
   49|       | * the inner stride is the pointer increment between two consecutive elements,
   50|       | * regardless of storage layout.
   51|       | *
   52|       | * \sa class InnerStride, class OuterStride, \ref TopicStorageOrders
   53|       | */
   54|       |template <int OuterStrideAtCompileTime_, int InnerStrideAtCompileTime_>
   55|       |class Stride {
   56|       | public:
   57|       |  typedef Eigen::Index Index;  ///< \deprecated since Eigen 3.3
   58|       |  enum { InnerStrideAtCompileTime = InnerStrideAtCompileTime_, OuterStrideAtCompileTime = OuterStrideAtCompileTime_ };
   59|       |
   60|       |  /** Default constructor, for use when strides are fixed at compile time */
   61|      0|  EIGEN_DEVICE_FUNC Stride() : m_outer(OuterStrideAtCompileTime), m_inner(InnerStrideAtCompileTime) {
   62|       |    // FIXME: for Eigen 4 we should use DynamicIndex instead of Dynamic.
   63|       |    // FIXME: for Eigen 4 we should also unify this API with fix<>
   64|      0|    eigen_assert(InnerStrideAtCompileTime != Dynamic && OuterStrideAtCompileTime != Dynamic);
   65|      0|  }
   66|       |
   67|       |  /** Constructor allowing to pass the strides at runtime */
   68|       |  EIGEN_DEVICE_FUNC Stride(Index outerStride, Index innerStride) : m_outer(outerStride), m_inner(innerStride) {}
   69|       |
   70|       |  /** Copy constructor */
   71|      0|  EIGEN_DEVICE_FUNC Stride(const Stride& other) : m_outer(other.outer()), m_inner(other.inner()) {}
   72|       |
   73|       |  /** Copy assignment operator */
   74|       |  EIGEN_DEVICE_FUNC Stride& operator=(const Stride& other) {
   75|       |    m_outer.setValue(other.outer());
   76|       |    m_inner.setValue(other.inner());
   77|       |    return *this;
   78|       |  }
   79|       |
   80|       |  /** \returns the outer stride */
   81|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outer() const { return m_outer.value(); }
   82|       |  /** \returns the inner stride */
   83|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index inner() const { return m_inner.value(); }
   84|       |
   85|       | protected:
   86|       |  internal::variable_if_dynamic<Index, OuterStrideAtCompileTime> m_outer;
   87|       |  internal::variable_if_dynamic<Index, InnerStrideAtCompileTime> m_inner;
   88|       |};
   89|       |
   90|       |/** \brief Convenience specialization of Stride to specify only an inner stride
   91|       | * See class Map for some examples */
   92|       |template <int Value>
   93|       |class InnerStride : public Stride<0, Value> {
   94|       |  typedef Stride<0, Value> Base;
   95|       |
   96|       | public:
   97|       |  EIGEN_DEVICE_FUNC InnerStride() : Base() {}
   98|       |  EIGEN_DEVICE_FUNC InnerStride(Index v) : Base(0, v) {}  // FIXME making this explicit could break valid code
   99|       |};
  100|       |
  101|       |/** \brief Convenience specialization of Stride to specify only an outer stride
  102|       | * See class Map for some examples */
  103|       |template <int Value>
  104|       |class OuterStride : public Stride<Value, 0> {
  105|       |  typedef Stride<Value, 0> Base;
  106|       |
  107|       | public:
  108|       |  EIGEN_DEVICE_FUNC OuterStride() : Base() {}
  109|       |  EIGEN_DEVICE_FUNC OuterStride(Index v) : Base(v, 0) {}  // FIXME making this explicit could break valid code
  110|       |};
  111|       |
  112|       |}  // end namespace Eigen
  113|       |
  114|       |#endif  // EIGEN_STRIDE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/Transpose.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2009-2014 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_TRANSPOSE_H
   12|       |#define EIGEN_TRANSPOSE_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "./InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |template <typename MatrixType>
   21|       |struct traits<Transpose<MatrixType> > : public traits<MatrixType> {
   22|       |  typedef typename ref_selector<MatrixType>::type MatrixTypeNested;
   23|       |  typedef std::remove_reference_t<MatrixTypeNested> MatrixTypeNestedPlain;
   24|       |  enum {
   25|       |    RowsAtCompileTime = MatrixType::ColsAtCompileTime,
   26|       |    ColsAtCompileTime = MatrixType::RowsAtCompileTime,
   27|       |    MaxRowsAtCompileTime = MatrixType::MaxColsAtCompileTime,
   28|       |    MaxColsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
   29|       |    FlagsLvalueBit = is_lvalue<MatrixType>::value ? LvalueBit : 0,
   30|       |    Flags0 = traits<MatrixTypeNestedPlain>::Flags & ~(LvalueBit | NestByRefBit),
   31|       |    Flags1 = Flags0 | FlagsLvalueBit,
   32|       |    Flags = Flags1 ^ RowMajorBit,
   33|       |    InnerStrideAtCompileTime = inner_stride_at_compile_time<MatrixType>::ret,
   34|       |    OuterStrideAtCompileTime = outer_stride_at_compile_time<MatrixType>::ret
   35|       |  };
   36|       |};
   37|       |}  // namespace internal
   38|       |
   39|       |template <typename MatrixType, typename StorageKind>
   40|       |class TransposeImpl;
   41|       |
   42|       |/** \class Transpose
   43|       | * \ingroup Core_Module
   44|       | *
   45|       | * \brief Expression of the transpose of a matrix
   46|       | *
   47|       | * \tparam MatrixType the type of the object of which we are taking the transpose
   48|       | *
   49|       | * This class represents an expression of the transpose of a matrix.
   50|       | * It is the return type of MatrixBase::transpose() and MatrixBase::adjoint()
   51|       | * and most of the time this is the only way it is used.
   52|       | *
   53|       | * \sa MatrixBase::transpose(), MatrixBase::adjoint()
   54|       | */
   55|       |template <typename MatrixType>
   56|       |class Transpose : public TransposeImpl<MatrixType, typename internal::traits<MatrixType>::StorageKind> {
   57|       | public:
   58|       |  typedef typename internal::ref_selector<MatrixType>::non_const_type MatrixTypeNested;
   59|       |
   60|       |  typedef typename TransposeImpl<MatrixType, typename internal::traits<MatrixType>::StorageKind>::Base Base;
   61|       |  EIGEN_GENERIC_PUBLIC_INTERFACE(Transpose)
   62|       |  typedef internal::remove_all_t<MatrixType> NestedExpression;
   63|       |
   64|      0|  EIGEN_DEVICE_FUNC explicit EIGEN_STRONG_INLINE Transpose(MatrixType& matrix) : m_matrix(matrix) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEC2ERS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEC2ERS5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEC2ERS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEC2ERS4_
  ------------------
   65|       |
   66|       |  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Transpose)
   67|       |
   68|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE4rowsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE4rowsEv
  ------------------
   69|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE4colsEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE4colsEv
  ------------------
   70|       |
   71|       |  /** \returns the nested expression */
   72|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const internal::remove_all_t<MatrixTypeNested>& nestedExpression() const {
   73|      0|    return m_matrix;
   74|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE16nestedExpressionEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE16nestedExpressionEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE16nestedExpressionEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE16nestedExpressionEv
  ------------------
   75|       |
   76|       |  /** \returns the nested expression */
   77|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE std::remove_reference_t<MatrixTypeNested>& nestedExpression() {
   78|      0|    return m_matrix;
   79|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE16nestedExpressionEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE16nestedExpressionEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE16nestedExpressionEv
  ------------------
   80|       |
   81|       |  /** \internal */
   82|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index nrows, Index ncols) { m_matrix.resize(ncols, nrows); }
   83|       |
   84|       | protected:
   85|       |  typename internal::ref_selector<MatrixType>::non_const_type m_matrix;
   86|       |};
   87|       |
   88|       |namespace internal {
   89|       |
   90|       |template <typename MatrixType, bool HasDirectAccess = has_direct_access<MatrixType>::ret>
   91|       |struct TransposeImpl_base {
   92|       |  typedef typename dense_xpr_base<Transpose<MatrixType> >::type type;
   93|       |};
   94|       |
   95|       |template <typename MatrixType>
   96|       |struct TransposeImpl_base<MatrixType, false> {
   97|       |  typedef typename dense_xpr_base<Transpose<MatrixType> >::type type;
   98|       |};
   99|       |
  100|       |}  // end namespace internal
  101|       |
  102|       |// Generic API dispatcher
  103|       |template <typename XprType, typename StorageKind>
  104|       |class TransposeImpl : public internal::generic_xpr_base<Transpose<XprType> >::type {
  105|       | public:
  106|       |  typedef typename internal::generic_xpr_base<Transpose<XprType> >::type Base;
  107|       |};
  108|       |
  109|       |template <typename MatrixType>
  110|       |class TransposeImpl<MatrixType, Dense> : public internal::TransposeImpl_base<MatrixType>::type {
  111|       | public:
  112|       |  typedef typename internal::TransposeImpl_base<MatrixType>::type Base;
  113|       |  using Base::coeffRef;
  114|       |  EIGEN_DENSE_PUBLIC_INTERFACE(Transpose<MatrixType>)
  115|       |  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(TransposeImpl)
  116|       |
  117|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index innerStride() const { return derived().nestedExpression().innerStride(); }
  118|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index outerStride() const { return derived().nestedExpression().outerStride(); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13TransposeImplIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_5DenseEE11outerStrideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13TransposeImplINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS_5DenseEE11outerStrideEv
  ------------------
  119|       |
  120|       |  typedef std::conditional_t<internal::is_lvalue<MatrixType>::value, Scalar, const Scalar> ScalarWithConstIfNotLvalue;
  121|       |
  122|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr ScalarWithConstIfNotLvalue* data() {
  123|      0|    return derived().nestedExpression().data();
  124|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13TransposeImplINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS_5DenseEE4dataEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13TransposeImplIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS_5DenseEE4dataEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13TransposeImplIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS_5DenseEE4dataEv
  ------------------
  125|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const Scalar* data() const {
  126|      0|    return derived().nestedExpression().data();
  127|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13TransposeImplIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_5DenseEE4dataEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13TransposeImplIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS_5DenseEE4dataEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen13TransposeImplIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS_5DenseEE4dataEv
  ------------------
  128|       |
  129|       |  // FIXME: shall we keep the const version of coeffRef?
  130|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar& coeffRef(Index rowId, Index colId) const {
  131|       |    return derived().nestedExpression().coeffRef(colId, rowId);
  132|       |  }
  133|       |
  134|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar& coeffRef(Index index) const {
  135|       |    return derived().nestedExpression().coeffRef(index);
  136|       |  }
  137|       |
  138|       | protected:
  139|       |  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(TransposeImpl)
  140|       |};
  141|       |
  142|       |/** \returns an expression of the transpose of *this.
  143|       | *
  144|       | * Example: \include MatrixBase_transpose.cpp
  145|       | * Output: \verbinclude MatrixBase_transpose.out
  146|       | *
  147|       | * \warning If you want to replace a matrix by its own transpose, do \b NOT do this:
  148|       | * \code
  149|       | * m = m.transpose(); // bug!!! caused by aliasing effect
  150|       | * \endcode
  151|       | * Instead, use the transposeInPlace() method:
  152|       | * \code
  153|       | * m.transposeInPlace();
  154|       | * \endcode
  155|       | * which gives Eigen good opportunities for optimization, or alternatively you can also do:
  156|       | * \code
  157|       | * m = m.transpose().eval();
  158|       | * \endcode
  159|       | *
  160|       | * \sa transposeInPlace(), adjoint() */
  161|       |template <typename Derived>
  162|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename DenseBase<Derived>::TransposeReturnType DenseBase<Derived>::transpose() {
  163|       |  return TransposeReturnType(derived());
  164|       |}
  165|       |
  166|       |/** This is the const version of transpose().
  167|       | *
  168|       | * Make sure you read the warning for transpose() !
  169|       | *
  170|       | * \sa transposeInPlace(), adjoint() */
  171|       |template <typename Derived>
  172|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename DenseBase<Derived>::ConstTransposeReturnType
  173|      0|DenseBase<Derived>::transpose() const {
  174|      0|  return ConstTransposeReturnType(derived());
  175|      0|}
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE9transposeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE9transposeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE9transposeEv
  ------------------
  176|       |
  177|       |/** \returns an expression of the adjoint (i.e. conjugate transpose) of *this.
  178|       | *
  179|       | * Example: \include MatrixBase_adjoint.cpp
  180|       | * Output: \verbinclude MatrixBase_adjoint.out
  181|       | *
  182|       | * \warning If you want to replace a matrix by its own adjoint, do \b NOT do this:
  183|       | * \code
  184|       | * m = m.adjoint(); // bug!!! caused by aliasing effect
  185|       | * \endcode
  186|       | * Instead, use the adjointInPlace() method:
  187|       | * \code
  188|       | * m.adjointInPlace();
  189|       | * \endcode
  190|       | * which gives Eigen good opportunities for optimization, or alternatively you can also do:
  191|       | * \code
  192|       | * m = m.adjoint().eval();
  193|       | * \endcode
  194|       | *
  195|       | * \sa adjointInPlace(), transpose(), conjugate(), class Transpose, class internal::scalar_conjugate_op */
  196|       |template <typename Derived>
  197|       |EIGEN_DEVICE_FUNC inline const typename MatrixBase<Derived>::AdjointReturnType MatrixBase<Derived>::adjoint() const {
  198|       |  return AdjointReturnType(this->transpose());
  199|       |}
  200|       |
  201|       |/***************************************************************************
  202|       | * "in place" transpose implementation
  203|       | ***************************************************************************/
  204|       |
  205|       |namespace internal {
  206|       |
  207|       |template <typename MatrixType,
  208|       |          bool IsSquare = (MatrixType::RowsAtCompileTime == MatrixType::ColsAtCompileTime) &&
  209|       |                          MatrixType::RowsAtCompileTime != Dynamic,
  210|       |          bool MatchPacketSize =
  211|       |              (int(MatrixType::RowsAtCompileTime) == int(internal::packet_traits<typename MatrixType::Scalar>::size)) &&
  212|       |              (internal::evaluator<MatrixType>::Flags & PacketAccessBit)>
  213|       |struct inplace_transpose_selector;
  214|       |
  215|       |template <typename MatrixType>
  216|       |struct inplace_transpose_selector<MatrixType, true, false> {  // square matrix
  217|       |  static void run(MatrixType& m) {
  218|       |    m.matrix().template triangularView<StrictlyUpper>().swap(
  219|       |        m.matrix().transpose().template triangularView<StrictlyUpper>());
  220|       |  }
  221|       |};
  222|       |
  223|       |template <typename MatrixType>
  224|       |struct inplace_transpose_selector<MatrixType, true, true> {  // PacketSize x PacketSize
  225|       |  static void run(MatrixType& m) {
  226|       |    typedef typename MatrixType::Scalar Scalar;
  227|       |    typedef typename internal::packet_traits<typename MatrixType::Scalar>::type Packet;
  228|       |    const Index PacketSize = internal::packet_traits<Scalar>::size;
  229|       |    const Index Alignment = internal::evaluator<MatrixType>::Alignment;
  230|       |    PacketBlock<Packet> A;
  231|       |    for (Index i = 0; i < PacketSize; ++i) A.packet[i] = m.template packetByOuterInner<Alignment>(i, 0);
  232|       |    internal::ptranspose(A);
  233|       |    for (Index i = 0; i < PacketSize; ++i)
  234|       |      m.template writePacket<Alignment>(m.rowIndexByOuterInner(i, 0), m.colIndexByOuterInner(i, 0), A.packet[i]);
  235|       |  }
  236|       |};
  237|       |
  238|       |template <typename MatrixType, Index Alignment>
  239|       |void BlockedInPlaceTranspose(MatrixType& m) {
  240|       |  typedef typename MatrixType::Scalar Scalar;
  241|       |  typedef typename internal::packet_traits<typename MatrixType::Scalar>::type Packet;
  242|       |  const Index PacketSize = internal::packet_traits<Scalar>::size;
  243|       |  eigen_assert(m.rows() == m.cols());
  244|       |  int row_start = 0;
  245|       |  for (; row_start + PacketSize <= m.rows(); row_start += PacketSize) {
  246|       |    for (int col_start = row_start; col_start + PacketSize <= m.cols(); col_start += PacketSize) {
  247|       |      PacketBlock<Packet> A;
  248|       |      if (row_start == col_start) {
  249|       |        for (Index i = 0; i < PacketSize; ++i)
  250|       |          A.packet[i] = m.template packetByOuterInner<Alignment>(row_start + i, col_start);
  251|       |        internal::ptranspose(A);
  252|       |        for (Index i = 0; i < PacketSize; ++i)
  253|       |          m.template writePacket<Alignment>(m.rowIndexByOuterInner(row_start + i, col_start),
  254|       |                                            m.colIndexByOuterInner(row_start + i, col_start), A.packet[i]);
  255|       |      } else {
  256|       |        PacketBlock<Packet> B;
  257|       |        for (Index i = 0; i < PacketSize; ++i) {
  258|       |          A.packet[i] = m.template packetByOuterInner<Alignment>(row_start + i, col_start);
  259|       |          B.packet[i] = m.template packetByOuterInner<Alignment>(col_start + i, row_start);
  260|       |        }
  261|       |        internal::ptranspose(A);
  262|       |        internal::ptranspose(B);
  263|       |        for (Index i = 0; i < PacketSize; ++i) {
  264|       |          m.template writePacket<Alignment>(m.rowIndexByOuterInner(row_start + i, col_start),
  265|       |                                            m.colIndexByOuterInner(row_start + i, col_start), B.packet[i]);
  266|       |          m.template writePacket<Alignment>(m.rowIndexByOuterInner(col_start + i, row_start),
  267|       |                                            m.colIndexByOuterInner(col_start + i, row_start), A.packet[i]);
  268|       |        }
  269|       |      }
  270|       |    }
  271|       |  }
  272|       |  for (Index row = row_start; row < m.rows(); ++row) {
  273|       |    m.matrix().row(row).head(row).swap(m.matrix().col(row).head(row).transpose());
  274|       |  }
  275|       |}
  276|       |
  277|       |template <typename MatrixType, bool MatchPacketSize>
  278|       |struct inplace_transpose_selector<MatrixType, false, MatchPacketSize> {  // non square or dynamic matrix
  279|       |  static void run(MatrixType& m) {
  280|       |    typedef typename MatrixType::Scalar Scalar;
  281|       |    if (m.rows() == m.cols()) {
  282|       |      const Index PacketSize = internal::packet_traits<Scalar>::size;
  283|       |      if (!NumTraits<Scalar>::IsComplex && m.rows() >= PacketSize) {
  284|       |        if ((m.rows() % PacketSize) == 0)
  285|       |          BlockedInPlaceTranspose<MatrixType, internal::evaluator<MatrixType>::Alignment>(m);
  286|       |        else
  287|       |          BlockedInPlaceTranspose<MatrixType, Unaligned>(m);
  288|       |      } else {
  289|       |        m.matrix().template triangularView<StrictlyUpper>().swap(
  290|       |            m.matrix().transpose().template triangularView<StrictlyUpper>());
  291|       |      }
  292|       |    } else {
  293|       |      m = m.transpose().eval();
  294|       |    }
  295|       |  }
  296|       |};
  297|       |
  298|       |}  // end namespace internal
  299|       |
  300|       |/** This is the "in place" version of transpose(): it replaces \c *this by its own transpose.
  301|       | * Thus, doing
  302|       | * \code
  303|       | * m.transposeInPlace();
  304|       | * \endcode
  305|       | * has the same effect on m as doing
  306|       | * \code
  307|       | * m = m.transpose().eval();
  308|       | * \endcode
  309|       | * and is faster and also safer because in the latter line of code, forgetting the eval() results
  310|       | * in a bug caused by \ref TopicAliasing "aliasing".
  311|       | *
  312|       | * Notice however that this method is only useful if you want to replace a matrix by its own transpose.
  313|       | * If you just need the transpose of a matrix, use transpose().
  314|       | *
  315|       | * \note if the matrix is not square, then \c *this must be a resizable matrix.
  316|       | * This excludes (non-square) fixed-size matrices, block-expressions and maps.
  317|       | *
  318|       | * \sa transpose(), adjoint(), adjointInPlace() */
  319|       |template <typename Derived>
  320|       |EIGEN_DEVICE_FUNC inline void DenseBase<Derived>::transposeInPlace() {
  321|       |  eigen_assert((rows() == cols() || (RowsAtCompileTime == Dynamic && ColsAtCompileTime == Dynamic)) &&
  322|       |               "transposeInPlace() called on a non-square non-resizable matrix");
  323|       |  internal::inplace_transpose_selector<Derived>::run(derived());
  324|       |}
  325|       |
  326|       |/***************************************************************************
  327|       | * "in place" adjoint implementation
  328|       | ***************************************************************************/
  329|       |
  330|       |/** This is the "in place" version of adjoint(): it replaces \c *this by its own transpose.
  331|       | * Thus, doing
  332|       | * \code
  333|       | * m.adjointInPlace();
  334|       | * \endcode
  335|       | * has the same effect on m as doing
  336|       | * \code
  337|       | * m = m.adjoint().eval();
  338|       | * \endcode
  339|       | * and is faster and also safer because in the latter line of code, forgetting the eval() results
  340|       | * in a bug caused by aliasing.
  341|       | *
  342|       | * Notice however that this method is only useful if you want to replace a matrix by its own adjoint.
  343|       | * If you just need the adjoint of a matrix, use adjoint().
  344|       | *
  345|       | * \note if the matrix is not square, then \c *this must be a resizable matrix.
  346|       | * This excludes (non-square) fixed-size matrices, block-expressions and maps.
  347|       | *
  348|       | * \sa transpose(), adjoint(), transposeInPlace() */
  349|       |template <typename Derived>
  350|       |EIGEN_DEVICE_FUNC inline void MatrixBase<Derived>::adjointInPlace() {
  351|       |  derived() = adjoint().eval();
  352|       |}
  353|       |
  354|       |#ifndef EIGEN_NO_DEBUG
  355|       |
  356|       |// The following is to detect aliasing problems in most common cases.
  357|       |
  358|       |namespace internal {
  359|       |
  360|       |template <bool DestIsTransposed, typename OtherDerived>
  361|       |struct check_transpose_aliasing_compile_time_selector {
  362|       |  enum { ret = bool(blas_traits<OtherDerived>::IsTransposed) != DestIsTransposed };
  363|       |};
  364|       |
  365|       |template <bool DestIsTransposed, typename BinOp, typename DerivedA, typename DerivedB>
  366|       |struct check_transpose_aliasing_compile_time_selector<DestIsTransposed, CwiseBinaryOp<BinOp, DerivedA, DerivedB> > {
  367|       |  enum {
  368|       |    ret = bool(blas_traits<DerivedA>::IsTransposed) != DestIsTransposed ||
  369|       |          bool(blas_traits<DerivedB>::IsTransposed) != DestIsTransposed
  370|       |  };
  371|       |};
  372|       |
  373|       |template <typename Scalar, bool DestIsTransposed, typename OtherDerived>
  374|       |struct check_transpose_aliasing_run_time_selector {
  375|      0|  EIGEN_DEVICE_FUNC static bool run(const Scalar* dest, const OtherDerived& src) {
  376|      0|    return (bool(blas_traits<OtherDerived>::IsTransposed) != DestIsTransposed) &&
  377|      0|           (dest != 0 && dest == (const Scalar*)extract_data(src));
  378|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal42check_transpose_aliasing_run_time_selectorI14AnnoyingScalarLb0ENS_9TransposeIKNS_5BlockIKNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE3runEPKS2_RKSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal42check_transpose_aliasing_run_time_selectorI14AnnoyingScalarLb0ENS_9TransposeIKNS_6MatrixIS2_Li1ELin1ELi1ELi1ELin1EEEEEE3runEPKS2_RKS7_
  ------------------
  379|       |};
  380|       |
  381|       |template <typename Scalar, bool DestIsTransposed, typename BinOp, typename DerivedA, typename DerivedB>
  382|       |struct check_transpose_aliasing_run_time_selector<Scalar, DestIsTransposed, CwiseBinaryOp<BinOp, DerivedA, DerivedB> > {
  383|       |  EIGEN_DEVICE_FUNC static bool run(const Scalar* dest, const CwiseBinaryOp<BinOp, DerivedA, DerivedB>& src) {
  384|       |    return ((blas_traits<DerivedA>::IsTransposed != DestIsTransposed) &&
  385|       |            (dest != 0 && dest == (const Scalar*)extract_data(src.lhs()))) ||
  386|       |           ((blas_traits<DerivedB>::IsTransposed != DestIsTransposed) &&
  387|       |            (dest != 0 && dest == (const Scalar*)extract_data(src.rhs())));
  388|       |  }
  389|       |};
  390|       |
  391|       |// the following selector, checkTransposeAliasing_impl, based on MightHaveTransposeAliasing,
  392|       |// is because when the condition controlling the assert is known at compile time, ICC emits a warning.
  393|       |// This is actually a good warning: in expressions that don't have any transposing, the condition is
  394|       |// known at compile time to be false, and using that, we can avoid generating the code of the assert again
  395|       |// and again for all these expressions that don't need it.
  396|       |
  397|       |template <typename Derived, typename OtherDerived,
  398|       |          bool MightHaveTransposeAliasing =
  399|       |              check_transpose_aliasing_compile_time_selector<blas_traits<Derived>::IsTransposed, OtherDerived>::ret>
  400|       |struct checkTransposeAliasing_impl {
  401|      0|  EIGEN_DEVICE_FUNC static void run(const Derived& dst, const OtherDerived& other) {
  402|      0|    eigen_assert(
  403|      0|        (!check_transpose_aliasing_run_time_selector<typename Derived::Scalar, blas_traits<Derived>::IsTransposed,
  404|      0|                                                     OtherDerived>::run(extract_data(dst), other)) &&
  405|      0|        "aliasing detected during transposition, use transposeInPlace() "
  406|      0|        "or evaluate the rhs into a temporary using .eval()");
  407|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS_5BlockIKNS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELb1EE3runERKS8_RKSF_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEELb1EE3runERKS8_RKSC_
  ------------------
  408|       |};
  409|       |
  410|       |template <typename Derived, typename OtherDerived>
  411|       |struct checkTransposeAliasing_impl<Derived, OtherDerived, false> {
  412|      0|  EIGEN_DEVICE_FUNC static void run(const Derived&, const OtherDerived&) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Lb0EE3runERKS4_S7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_5BlockINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELb0EE3runERKS8_RKSB_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS4_S4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKNS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISD_Li1ENS_6StrideILi0ELi0EEEEEEELb0EE3runERKS6_RKSM_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_3MapINS3_IS4_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEELb0EE3runERKS6_RKSB_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_Lb0EE3runERKS8_RKS5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS3_S3_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS3_EEKS4_EEKNS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEEEELb0EE3runERSB_RKSJ_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEELb0EE3runERKS4_RKS8_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEES4_Lb0EE3runERKS4_S7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27checkTransposeAliasing_implINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS_5BlockIKNS_7ProductINS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEELb0EE3runERKS4_RKSA_
  ------------------
  413|       |};
  414|       |
  415|       |template <typename Dst, typename Src>
  416|      0|EIGEN_DEVICE_FUNC inline void check_for_aliasing(const Dst& dst, const Src& src) {
  417|      0|  if ((!Dst::IsVectorAtCompileTime) && dst.rows() > 1 && dst.cols() > 1)
  418|      0|    internal::checkTransposeAliasing_impl<Dst, Src>::run(dst, src);
  419|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS_5BlockIKNS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEES4_EEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS_5BlockIKNS_7ProductINS2_IS3_Lin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEEEEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_EEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEENS_5BlockINS3_IS4_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS4_S4_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS4_EEKNS3_IS4_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISD_Li1ENS_6StrideILi0ELi0EEEEEEEEEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEENS_3MapINS3_IS4_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEES5_EEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_13CwiseBinaryOpINS0_17scalar_product_opIS3_S3_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS3_EEKS4_EEKNS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEEEEEEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEENS_3MapIS4_Li1ENS_6StrideILi0ELi0EEEEEEEvRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18check_for_aliasingINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEENS_9TransposeIKNS3_IS4_Li1ELin1ELi1ELi1ELin1EEEEEEEvRKT_RKT0_
  ------------------
  420|       |
  421|       |}  // end namespace internal
  422|       |
  423|       |#endif  // EIGEN_NO_DEBUG
  424|       |
  425|       |}  // end namespace Eigen
  426|       |
  427|       |#endif  // EIGEN_TRANSPOSE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/arch/Default/BFloat16.h:
    1|       |/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.
    2|       |
    3|       |Licensed under the Apache License, Version 2.0 (the "License");
    4|       |you may not use this file except in compliance with the License.
    5|       |You may obtain a copy of the License at
    6|       |
    7|       |    http://www.apache.org/licenses/LICENSE-2.0
    8|       |
    9|       |Unless required by applicable law or agreed to in writing, software
   10|       |distributed under the License is distributed on an "AS IS" BASIS,
   11|       |WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   12|       |See the License for the specific language governing permissions and
   13|       |limitations under the License.
   14|       |==============================================================================*/
   15|       |
   16|       |#ifndef EIGEN_BFLOAT16_H
   17|       |#define EIGEN_BFLOAT16_H
   18|       |
   19|       |// IWYU pragma: private
   20|       |#include "../../InternalHeaderCheck.h"
   21|       |
   22|       |#if defined(EIGEN_HAS_HIP_BF16)
   23|       |// When compiling with GPU support, the "hip_bfloat16" base class as well as
   24|       |// some other routines are defined in the GPU compiler header files
   25|       |// (hip_bfloat16.h), and they are not tagged constexpr
   26|       |// As a consequence, we get compile failures when compiling Eigen with
   27|       |// GPU support. Hence the need to disable EIGEN_CONSTEXPR when building
   28|       |// Eigen with GPU support
   29|       |#pragma push_macro("EIGEN_CONSTEXPR")
   30|       |#undef EIGEN_CONSTEXPR
   31|       |#define EIGEN_CONSTEXPR
   32|       |#endif
   33|       |
   34|       |#define BF16_PACKET_FUNCTION(PACKET_F, PACKET_BF16, METHOD)                                         \
   35|       |  template <>                                                                                       \
   36|       |  EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED PACKET_BF16 METHOD<PACKET_BF16>( \
   37|       |      const PACKET_BF16& _x) {                                                                      \
   38|       |    return F32ToBf16(METHOD<PACKET_F>(Bf16ToF32(_x)));                                              \
   39|       |  }
   40|       |
   41|       |// Only use HIP GPU bf16 in kernels
   42|       |#if defined(EIGEN_HAS_HIP_BF16) && defined(EIGEN_GPU_COMPILE_PHASE)
   43|       |#define EIGEN_USE_HIP_BF16
   44|       |#endif
   45|       |
   46|       |namespace Eigen {
   47|       |
   48|       |struct bfloat16;
   49|       |
   50|       |namespace numext {
   51|       |template <>
   52|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Eigen::bfloat16 bit_cast<Eigen::bfloat16, uint16_t>(const uint16_t& src);
   53|       |
   54|       |template <>
   55|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC uint16_t bit_cast<uint16_t, Eigen::bfloat16>(const Eigen::bfloat16& src);
   56|       |}  // namespace numext
   57|       |namespace bfloat16_impl {
   58|       |
   59|       |#if defined(EIGEN_USE_HIP_BF16)
   60|       |
   61|       |struct __bfloat16_raw : public hip_bfloat16 {
   62|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw() {}
   63|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw(hip_bfloat16 hb) : hip_bfloat16(hb) {}
   64|       |  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw(unsigned short raw) : hip_bfloat16(raw) {}
   65|       |};
   66|       |
   67|       |#else
   68|       |
   69|       |// Make our own __bfloat16_raw definition.
   70|       |struct __bfloat16_raw {
   71|       |#if defined(EIGEN_HAS_HIP_BF16) && !defined(EIGEN_GPU_COMPILE_PHASE)
   72|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw() {}
   73|       |#else
   74|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw() : value(0) {}
   75|       |#endif
   76|      0|  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw(unsigned short raw) : value(raw) {}
   77|       |  unsigned short value;
   78|       |};
   79|       |
   80|       |#endif  // defined(EIGEN_USE_HIP_BF16)
   81|       |
   82|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw raw_uint16_to_bfloat16(unsigned short value);
   83|       |template <bool AssumeArgumentIsNormalOrInfinityOrZero>
   84|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne(float ff);
   85|       |// Forward declarations of template specializations, to avoid Visual C++ 2019 errors, saying:
   86|       |// > error C2908: explicit specialization; 'float_to_bfloat16_rtne' has already been instantiated
   87|       |template <>
   88|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne<false>(float ff);
   89|       |template <>
   90|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne<true>(float ff);
   91|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float bfloat16_to_float(__bfloat16_raw h);
   92|       |
   93|       |struct bfloat16_base : public __bfloat16_raw {
   94|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16_base() {}
   95|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16_base(const __bfloat16_raw& h) : __bfloat16_raw(h) {}
   96|       |};
   97|       |
   98|       |}  // namespace bfloat16_impl
   99|       |
  100|       |// Class definition.
  101|       |struct bfloat16 : public bfloat16_impl::bfloat16_base {
  102|       |  typedef bfloat16_impl::__bfloat16_raw __bfloat16_raw;
  103|       |
  104|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16() {}
  105|       |
  106|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(const __bfloat16_raw& h) : bfloat16_impl::bfloat16_base(h) {}
  107|       |
  108|       |  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(bool b)
  109|      0|      : bfloat16_impl::bfloat16_base(bfloat16_impl::raw_uint16_to_bfloat16(b ? 0x3f80 : 0)) {}
  110|       |
  111|       |  template <class T>
  112|       |  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(T val)
  113|       |      : bfloat16_impl::bfloat16_base(
  114|       |            bfloat16_impl::float_to_bfloat16_rtne<internal::is_integral<T>::value>(static_cast<float>(val))) {}
  115|       |
  116|       |  explicit EIGEN_DEVICE_FUNC bfloat16(float f)
  117|      0|      : bfloat16_impl::bfloat16_base(bfloat16_impl::float_to_bfloat16_rtne<false>(f)) {}
  118|       |
  119|       |  // Following the convention of numpy, converting between complex and
  120|       |  // float will lead to loss of imag value.
  121|       |  template <typename RealScalar>
  122|       |  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(const std::complex<RealScalar>& val)
  123|       |      : bfloat16_impl::bfloat16_base(bfloat16_impl::float_to_bfloat16_rtne<false>(static_cast<float>(val.real()))) {}
  124|       |
  125|      0|  EIGEN_DEVICE_FUNC operator float() const {  // NOLINT: Allow implicit conversion to float, because it is lossless.
  126|      0|    return bfloat16_impl::bfloat16_to_float(*this);
  127|      0|  }
  128|       |};
  129|       |
  130|       |// TODO(majnemer): Get rid of this once we can rely on C++17 inline variables do
  131|       |// solve the ODR issue.
  132|       |namespace bfloat16_impl {
  133|       |template <typename = void>
  134|       |struct numeric_limits_bfloat16_impl {
  135|       |  static EIGEN_CONSTEXPR const bool is_specialized = true;
  136|       |  static EIGEN_CONSTEXPR const bool is_signed = true;
  137|       |  static EIGEN_CONSTEXPR const bool is_integer = false;
  138|       |  static EIGEN_CONSTEXPR const bool is_exact = false;
  139|       |  static EIGEN_CONSTEXPR const bool has_infinity = true;
  140|       |  static EIGEN_CONSTEXPR const bool has_quiet_NaN = true;
  141|       |  static EIGEN_CONSTEXPR const bool has_signaling_NaN = true;
  142|       |  EIGEN_DIAGNOSTICS(push)
  143|       |  EIGEN_DISABLE_DEPRECATED_WARNING
  144|       |  static EIGEN_CONSTEXPR const std::float_denorm_style has_denorm = std::denorm_present;
  145|       |  static EIGEN_CONSTEXPR const bool has_denorm_loss = false;
  146|       |  EIGEN_DIAGNOSTICS(pop)
  147|       |  static EIGEN_CONSTEXPR const std::float_round_style round_style = std::numeric_limits<float>::round_style;
  148|       |  static EIGEN_CONSTEXPR const bool is_iec559 = true;
  149|       |  // The C++ standard defines this as "true if the set of values representable
  150|       |  // by the type is finite." BFloat16 has finite precision.
  151|       |  static EIGEN_CONSTEXPR const bool is_bounded = true;
  152|       |  static EIGEN_CONSTEXPR const bool is_modulo = false;
  153|       |  static EIGEN_CONSTEXPR const int digits = 8;
  154|       |  static EIGEN_CONSTEXPR const int digits10 = 2;
  155|       |  static EIGEN_CONSTEXPR const int max_digits10 = 4;
  156|       |  static EIGEN_CONSTEXPR const int radix = std::numeric_limits<float>::radix;
  157|       |  static EIGEN_CONSTEXPR const int min_exponent = std::numeric_limits<float>::min_exponent;
  158|       |  static EIGEN_CONSTEXPR const int min_exponent10 = std::numeric_limits<float>::min_exponent10;
  159|       |  static EIGEN_CONSTEXPR const int max_exponent = std::numeric_limits<float>::max_exponent;
  160|       |  static EIGEN_CONSTEXPR const int max_exponent10 = std::numeric_limits<float>::max_exponent10;
  161|       |  static EIGEN_CONSTEXPR const bool traps = std::numeric_limits<float>::traps;
  162|       |  // IEEE754: "The implementer shall choose how tininess is detected, but shall
  163|       |  // detect tininess in the same way for all operations in radix two"
  164|       |  static EIGEN_CONSTEXPR const bool tinyness_before = std::numeric_limits<float>::tinyness_before;
  165|       |
  166|       |  static EIGEN_CONSTEXPR Eigen::bfloat16(min)() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x0080); }
  167|       |  static EIGEN_CONSTEXPR Eigen::bfloat16 lowest() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0xff7f); }
  168|       |  static EIGEN_CONSTEXPR Eigen::bfloat16(max)() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7f7f); }
  169|       |  static EIGEN_CONSTEXPR Eigen::bfloat16 epsilon() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x3c00); }
  170|       |  static EIGEN_CONSTEXPR Eigen::bfloat16 round_error() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x3f00); }
  171|       |  static EIGEN_CONSTEXPR Eigen::bfloat16 infinity() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7f80); }
  172|       |  static EIGEN_CONSTEXPR Eigen::bfloat16 quiet_NaN() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7fc0); }
  173|       |  static EIGEN_CONSTEXPR Eigen::bfloat16 signaling_NaN() {
  174|       |    return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7fa0);
  175|       |  }
  176|       |  static EIGEN_CONSTEXPR Eigen::bfloat16 denorm_min() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x0001); }
  177|       |};
  178|       |
  179|       |template <typename T>
  180|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::is_specialized;
  181|       |template <typename T>
  182|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::is_signed;
  183|       |template <typename T>
  184|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::is_integer;
  185|       |template <typename T>
  186|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::is_exact;
  187|       |template <typename T>
  188|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::has_infinity;
  189|       |template <typename T>
  190|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::has_quiet_NaN;
  191|       |template <typename T>
  192|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::has_signaling_NaN;
  193|       |EIGEN_DIAGNOSTICS(push)
  194|       |EIGEN_DISABLE_DEPRECATED_WARNING
  195|       |template <typename T>
  196|       |EIGEN_CONSTEXPR const std::float_denorm_style numeric_limits_bfloat16_impl<T>::has_denorm;
  197|       |template <typename T>
  198|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::has_denorm_loss;
  199|       |EIGEN_DIAGNOSTICS(pop)
  200|       |template <typename T>
  201|       |EIGEN_CONSTEXPR const std::float_round_style numeric_limits_bfloat16_impl<T>::round_style;
  202|       |template <typename T>
  203|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::is_iec559;
  204|       |template <typename T>
  205|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::is_bounded;
  206|       |template <typename T>
  207|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::is_modulo;
  208|       |template <typename T>
  209|       |EIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl<T>::digits;
  210|       |template <typename T>
  211|       |EIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl<T>::digits10;
  212|       |template <typename T>
  213|       |EIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl<T>::max_digits10;
  214|       |template <typename T>
  215|       |EIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl<T>::radix;
  216|       |template <typename T>
  217|       |EIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl<T>::min_exponent;
  218|       |template <typename T>
  219|       |EIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl<T>::min_exponent10;
  220|       |template <typename T>
  221|       |EIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl<T>::max_exponent;
  222|       |template <typename T>
  223|       |EIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl<T>::max_exponent10;
  224|       |template <typename T>
  225|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::traps;
  226|       |template <typename T>
  227|       |EIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl<T>::tinyness_before;
  228|       |}  // end namespace bfloat16_impl
  229|       |}  // end namespace Eigen
  230|       |
  231|       |namespace std {
  232|       |// If std::numeric_limits<T> is specialized, should also specialize
  233|       |// std::numeric_limits<const T>, std::numeric_limits<volatile T>, and
  234|       |// std::numeric_limits<const volatile T>
  235|       |// https://stackoverflow.com/a/16519653/
  236|       |template <>
  237|       |class numeric_limits<Eigen::bfloat16> : public Eigen::bfloat16_impl::numeric_limits_bfloat16_impl<> {};
  238|       |template <>
  239|       |class numeric_limits<const Eigen::bfloat16> : public numeric_limits<Eigen::bfloat16> {};
  240|       |template <>
  241|       |class numeric_limits<volatile Eigen::bfloat16> : public numeric_limits<Eigen::bfloat16> {};
  242|       |template <>
  243|       |class numeric_limits<const volatile Eigen::bfloat16> : public numeric_limits<Eigen::bfloat16> {};
  244|       |}  // end namespace std
  245|       |
  246|       |namespace Eigen {
  247|       |
  248|       |namespace bfloat16_impl {
  249|       |
  250|       |// We need to distinguish clang as the CUDA compiler from clang as the host compiler,
  251|       |// invoked by NVCC (e.g. on MacOS). The former needs to see both host and device implementation
  252|       |// of the functions, while the latter can only deal with one of them.
  253|       |#if !defined(EIGEN_HAS_NATIVE_BF16) || (EIGEN_COMP_CLANG && !EIGEN_COMP_NVCC)  // Emulate support for bfloat16 floats
  254|       |
  255|       |#if EIGEN_COMP_CLANG && defined(EIGEN_CUDACC)
  256|       |// We need to provide emulated *host-side* BF16 operators for clang.
  257|       |#pragma push_macro("EIGEN_DEVICE_FUNC")
  258|       |#undef EIGEN_DEVICE_FUNC
  259|       |#if (defined(EIGEN_HAS_GPU_BF16) && defined(EIGEN_HAS_NATIVE_BF16))
  260|       |#define EIGEN_DEVICE_FUNC __host__
  261|       |#else  // both host and device need emulated ops.
  262|       |#define EIGEN_DEVICE_FUNC __host__ __device__
  263|       |#endif
  264|       |#endif
  265|       |
  266|       |// Definitions for CPUs, mostly working through conversion
  267|       |// to/from fp32.
  268|       |
  269|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator+(const bfloat16& a, const bfloat16& b) {
  270|      0|  return bfloat16(float(a) + float(b));
  271|      0|}
  272|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator+(const bfloat16& a, const int& b) {
  273|      0|  return bfloat16(float(a) + static_cast<float>(b));
  274|      0|}
  275|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator+(const int& a, const bfloat16& b) {
  276|      0|  return bfloat16(static_cast<float>(a) + float(b));
  277|      0|}
  278|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator*(const bfloat16& a, const bfloat16& b) {
  279|      0|  return bfloat16(float(a) * float(b));
  280|      0|}
  281|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator-(const bfloat16& a, const bfloat16& b) {
  282|      0|  return bfloat16(float(a) - float(b));
  283|      0|}
  284|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator/(const bfloat16& a, const bfloat16& b) {
  285|      0|  return bfloat16(float(a) / float(b));
  286|      0|}
  287|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator-(const bfloat16& a) {
  288|      0|  numext::uint16_t x = numext::bit_cast<uint16_t>(a) ^ 0x8000;
  289|      0|  return numext::bit_cast<bfloat16>(x);
  290|      0|}
  291|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16& operator+=(bfloat16& a, const bfloat16& b) {
  292|      0|  a = bfloat16(float(a) + float(b));
  293|      0|  return a;
  294|      0|}
  295|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16& operator*=(bfloat16& a, const bfloat16& b) {
  296|      0|  a = bfloat16(float(a) * float(b));
  297|      0|  return a;
  298|      0|}
  299|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16& operator-=(bfloat16& a, const bfloat16& b) {
  300|      0|  a = bfloat16(float(a) - float(b));
  301|      0|  return a;
  302|      0|}
  303|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16& operator/=(bfloat16& a, const bfloat16& b) {
  304|      0|  a = bfloat16(float(a) / float(b));
  305|      0|  return a;
  306|      0|}
  307|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator++(bfloat16& a) {
  308|      0|  a += bfloat16(1);
  309|      0|  return a;
  310|      0|}
  311|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator--(bfloat16& a) {
  312|      0|  a -= bfloat16(1);
  313|      0|  return a;
  314|      0|}
  315|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator++(bfloat16& a, int) {
  316|      0|  bfloat16 original_value = a;
  317|      0|  ++a;
  318|      0|  return original_value;
  319|      0|}
  320|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator--(bfloat16& a, int) {
  321|      0|  bfloat16 original_value = a;
  322|      0|  --a;
  323|      0|  return original_value;
  324|      0|}
  325|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator==(const bfloat16& a, const bfloat16& b) {
  326|      0|  return numext::equal_strict(float(a), float(b));
  327|      0|}
  328|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator!=(const bfloat16& a, const bfloat16& b) {
  329|      0|  return numext::not_equal_strict(float(a), float(b));
  330|      0|}
  331|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator<(const bfloat16& a, const bfloat16& b) {
  332|      0|  return float(a) < float(b);
  333|      0|}
  334|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator<=(const bfloat16& a, const bfloat16& b) {
  335|      0|  return float(a) <= float(b);
  336|      0|}
  337|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator>(const bfloat16& a, const bfloat16& b) {
  338|      0|  return float(a) > float(b);
  339|      0|}
  340|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator>=(const bfloat16& a, const bfloat16& b) {
  341|      0|  return float(a) >= float(b);
  342|      0|}
  343|       |
  344|       |#if EIGEN_COMP_CLANG && defined(EIGEN_CUDACC)
  345|       |#pragma pop_macro("EIGEN_DEVICE_FUNC")
  346|       |#endif
  347|       |#endif  // Emulate support for bfloat16 floats
  348|       |
  349|       |// Division by an index. Do it in full float precision to avoid accuracy
  350|       |// issues in converting the denominator to bfloat16.
  351|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator/(const bfloat16& a, Index b) {
  352|      0|  return bfloat16(static_cast<float>(a) / static_cast<float>(b));
  353|      0|}
  354|       |
  355|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw truncate_to_bfloat16(const float v) {
  356|      0|#if defined(EIGEN_USE_HIP_BF16)
  357|      0|  return __bfloat16_raw(__bfloat16_raw::round_to_bfloat16(v, __bfloat16_raw::truncate));
  358|      0|#else
  359|      0|  __bfloat16_raw output;
  360|      0|  if (numext::isnan EIGEN_NOT_A_MACRO(v)) {
  361|      0|    output.value = std::signbit(v) ? 0xFFC0 : 0x7FC0;
  362|      0|    return output;
  363|      0|  }
  364|      0|  output.value = static_cast<numext::uint16_t>(numext::bit_cast<numext::uint32_t>(v) >> 16);
  365|      0|  return output;
  366|      0|#endif
  367|      0|}
  368|       |
  369|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw raw_uint16_to_bfloat16(numext::uint16_t value) {
  370|      0|#if defined(EIGEN_USE_HIP_BF16)
  371|      0|  __bfloat16_raw bf;
  372|      0|  bf.data = value;
  373|      0|  return bf;
  374|      0|#else
  375|      0|  return __bfloat16_raw(value);
  376|      0|#endif
  377|      0|}
  378|       |
  379|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR numext::uint16_t raw_bfloat16_as_uint16(
  380|      0|    const __bfloat16_raw& bf) {
  381|      0|#if defined(EIGEN_USE_HIP_BF16)
  382|      0|  return bf.data;
  383|      0|#else
  384|      0|  return bf.value;
  385|      0|#endif
  386|      0|}
  387|       |
  388|       |// float_to_bfloat16_rtne template specialization that does not make any
  389|       |// assumption about the value of its function argument (ff).
  390|       |template <>
  391|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne<false>(float ff) {
  392|      0|#if defined(EIGEN_USE_HIP_BF16)
  393|      0|  return __bfloat16_raw(__bfloat16_raw::round_to_bfloat16(ff));
  394|      0|#else
  395|      0|  __bfloat16_raw output;
  396|      0|
  397|      0|  if (numext::isnan EIGEN_NOT_A_MACRO(ff)) {
  398|      0|    // If the value is a NaN, squash it to a qNaN with msb of fraction set,
  399|      0|    // this makes sure after truncation we don't end up with an inf.
  400|      0|    //
  401|      0|    // qNaN magic: All exponent bits set + most significant bit of fraction
  402|      0|    // set.
  403|      0|    output.value = std::signbit(ff) ? 0xFFC0 : 0x7FC0;
  404|      0|  } else {
  405|      0|    // Fast rounding algorithm that rounds a half value to nearest even. This
  406|      0|    // reduces expected error when we convert a large number of floats. Here
  407|      0|    // is how it works:
  408|      0|    //
  409|      0|    // Definitions:
  410|      0|    // To convert a float 32 to bfloat16, a float 32 can be viewed as 32 bits
  411|      0|    // with the following tags:
  412|      0|    //
  413|      0|    // Sign |  Exp (8 bits) | Frac (23 bits)
  414|      0|    //  S     EEEEEEEE         FFFFFFLRTTTTTTTTTTTTTTT
  415|      0|    //
  416|      0|    //  S: Sign bit.
  417|      0|    //  E: Exponent bits.
  418|      0|    //  F: First 6 bits of fraction.
  419|      0|    //  L: Least significant bit of resulting bfloat16 if we truncate away the
  420|      0|    //  rest of the float32. This is also the 7th bit of fraction
  421|      0|    //  R: Rounding bit, 8th bit of fraction.
  422|      0|    //  T: Sticky bits, rest of fraction, 15 bits.
  423|      0|    //
  424|      0|    // To round half to nearest even, there are 3 cases where we want to round
  425|      0|    // down (simply truncate the result of the bits away, which consists of
  426|      0|    // rounding bit and sticky bits) and two cases where we want to round up
  427|      0|    // (truncate then add one to the result).
  428|      0|    //
  429|      0|    // The fast converting algorithm simply adds lsb (L) to 0x7fff (15 bits of
  430|      0|    // 1s) as the rounding bias, adds the rounding bias to the input, then
  431|      0|    // truncates the last 16 bits away.
  432|      0|    //
  433|      0|    // To understand how it works, we can analyze this algorithm case by case:
  434|      0|    //
  435|      0|    // 1. L = 0, R = 0:
  436|      0|    //   Expect: round down, this is less than half value.
  437|      0|    //
  438|      0|    //   Algorithm:
  439|      0|    //   - Rounding bias: 0x7fff + 0 = 0x7fff
  440|      0|    //   - Adding rounding bias to input may create any carry, depending on
  441|      0|    //   whether there is any value set to 1 in T bits.
  442|      0|    //   - R may be set to 1 if there is a carry.
  443|      0|    //   - L remains 0.
  444|      0|    //   - Note that this case also handles Inf and -Inf, where all fraction
  445|      0|    //   bits, including L, R and Ts are all 0. The output remains Inf after
  446|      0|    //   this algorithm.
  447|      0|    //
  448|      0|    // 2. L = 1, R = 0:
  449|      0|    //   Expect: round down, this is less than half value.
  450|      0|    //
  451|      0|    //   Algorithm:
  452|      0|    //   - Rounding bias: 0x7fff + 1 = 0x8000
  453|      0|    //   - Adding rounding bias to input doesn't change sticky bits but
  454|      0|    //   adds 1 to rounding bit.
  455|      0|    //   - L remains 1.
  456|      0|    //
  457|      0|    // 3. L = 0, R = 1, all of T are 0:
  458|      0|    //   Expect: round down, this is exactly at half, the result is already
  459|      0|    //   even (L=0).
  460|      0|    //
  461|      0|    //   Algorithm:
  462|      0|    //   - Rounding bias: 0x7fff + 0 = 0x7fff
  463|      0|    //   - Adding rounding bias to input sets all sticky bits to 1, but
  464|      0|    //   doesn't create a carry.
  465|      0|    //   - R remains 1.
  466|      0|    //   - L remains 0.
  467|      0|    //
  468|      0|    // 4. L = 1, R = 1:
  469|      0|    //   Expect: round up, this is exactly at half, the result needs to be
  470|      0|    //   round to the next even number.
  471|      0|    //
  472|      0|    //   Algorithm:
  473|      0|    //   - Rounding bias: 0x7fff + 1 = 0x8000
  474|      0|    //   - Adding rounding bias to input doesn't change sticky bits, but
  475|      0|    //   creates a carry from rounding bit.
  476|      0|    //   - The carry sets L to 0, creates another carry bit and propagate
  477|      0|    //   forward to F bits.
  478|      0|    //   - If all the F bits are 1, a carry then propagates to the exponent
  479|      0|    //   bits, which then creates the minimum value with the next exponent
  480|      0|    //   value. Note that we won't have the case where exponents are all 1,
  481|      0|    //   since that's either a NaN (handled in the other if condition) or inf
  482|      0|    //   (handled in case 1).
  483|      0|    //
  484|      0|    // 5. L = 0, R = 1, any of T is 1:
  485|      0|    //   Expect: round up, this is greater than half.
  486|      0|    //
  487|      0|    //   Algorithm:
  488|      0|    //   - Rounding bias: 0x7fff + 0 = 0x7fff
  489|      0|    //   - Adding rounding bias to input creates a carry from sticky bits,
  490|      0|    //   sets rounding bit to 0, then create another carry.
  491|      0|    //   - The second carry sets L to 1.
  492|      0|    //
  493|      0|    // Examples:
  494|      0|    //
  495|      0|    //  Exact half value that is already even:
  496|      0|    //    Input:
  497|      0|    //    Sign |  Exp (8 bit)     | Frac (first 7 bit) | Frac (last 16 bit)
  498|      0|    //     S     E E E E E E E E      F F F F F F L     RTTTTTTTTTTTTTTT
  499|      0|    //     0     0 0 0 0 0 0 0 0      0 0 0 0 0 1 0     1000000000000000
  500|      0|    //
  501|      0|    //     This falls into case 3. We truncate the rest of 16 bits and no
  502|      0|    //     carry is created into F and L:
  503|      0|    //
  504|      0|    //    Output:
  505|      0|    //    Sign |  Exp (8 bit)     | Frac (first 7 bit)
  506|      0|    //     S     E E E E E E E E      F F F F F F L
  507|      0|    //     0     0 0 0 0 0 0 0 0      0 0 0 0 0 1 0
  508|      0|    //
  509|      0|    //  Exact half value, round to next even number:
  510|      0|    //    Input:
  511|      0|    //    Sign |  Exp (8 bit)     | Frac (first 7 bit) | Frac (last 16 bit)
  512|      0|    //     S     E E E E E E E E      F F F F F F L     RTTTTTTTTTTTTTTT
  513|      0|    //     0     0 0 0 0 0 0 0 0      0 0 0 0 0 0 1     1000000000000000
  514|      0|    //
  515|      0|    //     This falls into case 4. We create a carry from R and T,
  516|      0|    //     which then propagates into L and F:
  517|      0|    //
  518|      0|    //    Output:
  519|      0|    //    Sign |  Exp (8 bit)     | Frac (first 7 bit)
  520|      0|    //     S     E E E E E E E E      F F F F F F L
  521|      0|    //     0     0 0 0 0 0 0 0 0      0 0 0 0 0 1 0
  522|      0|    //
  523|      0|    //
  524|      0|    //  Max denormal value round to min normal value:
  525|      0|    //    Input:
  526|      0|    //    Sign |  Exp (8 bit)     | Frac (first 7 bit) | Frac (last 16 bit)
  527|      0|    //     S     E E E E E E E E      F F F F F F L     RTTTTTTTTTTTTTTT
  528|      0|    //     0     0 0 0 0 0 0 0 0      1 1 1 1 1 1 1     1111111111111111
  529|      0|    //
  530|      0|    //     This falls into case 4. We create a carry from R and T,
  531|      0|    //     propagate into L and F, which then propagates into exponent
  532|      0|    //     bits:
  533|      0|    //
  534|      0|    //    Output:
  535|      0|    //    Sign |  Exp (8 bit)     | Frac (first 7 bit)
  536|      0|    //     S     E E E E E E E E      F F F F F F L
  537|      0|    //     0     0 0 0 0 0 0 0 1      0 0 0 0 0 0 0
  538|      0|    //
  539|      0|    //  Max normal value round to Inf:
  540|      0|    //    Input:
  541|      0|    //    Sign |  Exp (8 bit)     | Frac (first 7 bit) | Frac (last 16 bit)
  542|      0|    //     S     E E E E E E E E      F F F F F F L     RTTTTTTTTTTTTTTT
  543|      0|    //     0     1 1 1 1 1 1 1 0      1 1 1 1 1 1 1     1111111111111111
  544|      0|    //
  545|      0|    //     This falls into case 4. We create a carry from R and T,
  546|      0|    //     propagate into L and F, which then propagates into exponent
  547|      0|    //     bits:
  548|      0|    //
  549|      0|    //    Sign |  Exp (8 bit)     | Frac (first 7 bit)
  550|      0|    //     S     E E E E E E E E      F F F F F F L
  551|      0|    //     0     1 1 1 1 1 1 1 1      0 0 0 0 0 0 0
  552|      0|
  553|      0|    // At this point, ff must be either a normal float, or +/-infinity.
  554|      0|    output = float_to_bfloat16_rtne<true>(ff);
  555|      0|  }
  556|      0|  return output;
  557|      0|#endif
  558|      0|}
  559|       |
  560|       |// float_to_bfloat16_rtne template specialization that assumes that its function
  561|       |// argument (ff) is either a normal floating point number, or +/-infinity, or
  562|       |// zero. Used to improve the runtime performance of conversion from an integer
  563|       |// type to bfloat16.
  564|       |template <>
  565|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne<true>(float ff) {
  566|      0|#if defined(EIGEN_USE_HIP_BF16)
  567|      0|  return __bfloat16_raw(__bfloat16_raw::round_to_bfloat16(ff));
  568|      0|#else
  569|      0|  numext::uint32_t input = numext::bit_cast<numext::uint32_t>(ff);
  570|      0|  __bfloat16_raw output;
  571|      0|
  572|      0|  // Least significant bit of resulting bfloat.
  573|      0|  numext::uint32_t lsb = (input >> 16) & 1;
  574|      0|  numext::uint32_t rounding_bias = 0x7fff + lsb;
  575|      0|  input += rounding_bias;
  576|      0|  output.value = static_cast<numext::uint16_t>(input >> 16);
  577|      0|  return output;
  578|      0|#endif
  579|      0|}
  580|       |
  581|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float bfloat16_to_float(__bfloat16_raw h) {
  582|      0|#if defined(EIGEN_USE_HIP_BF16)
  583|      0|  return static_cast<float>(h);
  584|      0|#else
  585|      0|  return numext::bit_cast<float>(static_cast<numext::uint32_t>(h.value) << 16);
  586|      0|#endif
  587|      0|}
  588|       |
  589|       |// --- standard functions ---
  590|       |
  591|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isinf)(const bfloat16& a) {
  592|      0|  EIGEN_USING_STD(isinf);
  593|      0|#if defined(EIGEN_USE_HIP_BF16)
  594|      0|  return (isinf)(a);  // Uses HIP hip_bfloat16 isinf operator
  595|      0|#else
  596|      0|  return (isinf)(float(a));
  597|      0|#endif
  598|      0|}
  599|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isnan)(const bfloat16& a) {
  600|      0|  EIGEN_USING_STD(isnan);
  601|      0|#if defined(EIGEN_USE_HIP_BF16)
  602|      0|  return (isnan)(a);  // Uses HIP hip_bfloat16 isnan operator
  603|      0|#else
  604|      0|  return (isnan)(float(a));
  605|      0|#endif
  606|      0|}
  607|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isfinite)(const bfloat16& a) {
  608|      0|  return !(isinf EIGEN_NOT_A_MACRO(a)) && !(isnan EIGEN_NOT_A_MACRO(a));
  609|      0|}
  610|       |
  611|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 abs(const bfloat16& a) {
  612|      0|  numext::uint16_t x = numext::bit_cast<numext::uint16_t>(a) & 0x7FFF;
  613|      0|  return numext::bit_cast<bfloat16>(x);
  614|      0|}
  615|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 exp(const bfloat16& a) { return bfloat16(::expf(float(a))); }
  616|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 exp2(const bfloat16& a) { return bfloat16(::exp2f(float(a))); }
  617|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 expm1(const bfloat16& a) { return bfloat16(numext::expm1(float(a))); }
  618|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log(const bfloat16& a) { return bfloat16(::logf(float(a))); }
  619|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log1p(const bfloat16& a) { return bfloat16(numext::log1p(float(a))); }
  620|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log10(const bfloat16& a) { return bfloat16(::log10f(float(a))); }
  621|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log2(const bfloat16& a) {
  622|      0|  return bfloat16(static_cast<float>(EIGEN_LOG2E) * ::logf(float(a)));
  623|      0|}
  624|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 sqrt(const bfloat16& a) { return bfloat16(::sqrtf(float(a))); }
  625|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 pow(const bfloat16& a, const bfloat16& b) {
  626|      0|  return bfloat16(::powf(float(a), float(b)));
  627|      0|}
  628|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 atan2(const bfloat16& a, const bfloat16& b) {
  629|      0|  return bfloat16(::atan2f(float(a), float(b)));
  630|      0|}
  631|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 sin(const bfloat16& a) { return bfloat16(::sinf(float(a))); }
  632|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 cos(const bfloat16& a) { return bfloat16(::cosf(float(a))); }
  633|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 tan(const bfloat16& a) { return bfloat16(::tanf(float(a))); }
  634|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 asin(const bfloat16& a) { return bfloat16(::asinf(float(a))); }
  635|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 acos(const bfloat16& a) { return bfloat16(::acosf(float(a))); }
  636|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 atan(const bfloat16& a) { return bfloat16(::atanf(float(a))); }
  637|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 sinh(const bfloat16& a) { return bfloat16(::sinhf(float(a))); }
  638|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 cosh(const bfloat16& a) { return bfloat16(::coshf(float(a))); }
  639|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 tanh(const bfloat16& a) { return bfloat16(::tanhf(float(a))); }
  640|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 asinh(const bfloat16& a) { return bfloat16(::asinhf(float(a))); }
  641|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 acosh(const bfloat16& a) { return bfloat16(::acoshf(float(a))); }
  642|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 atanh(const bfloat16& a) { return bfloat16(::atanhf(float(a))); }
  643|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 floor(const bfloat16& a) { return bfloat16(::floorf(float(a))); }
  644|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 ceil(const bfloat16& a) { return bfloat16(::ceilf(float(a))); }
  645|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 rint(const bfloat16& a) { return bfloat16(::rintf(float(a))); }
  646|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 round(const bfloat16& a) { return bfloat16(::roundf(float(a))); }
  647|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 trunc(const bfloat16& a) { return bfloat16(::truncf(float(a))); }
  648|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 fmod(const bfloat16& a, const bfloat16& b) {
  649|      0|  return bfloat16(::fmodf(float(a), float(b)));
  650|      0|}
  651|       |
  652|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16(min)(const bfloat16& a, const bfloat16& b) {
  653|      0|  const float f1 = static_cast<float>(a);
  654|      0|  const float f2 = static_cast<float>(b);
  655|      0|  return f2 < f1 ? b : a;
  656|      0|}
  657|       |
  658|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16(max)(const bfloat16& a, const bfloat16& b) {
  659|      0|  const float f1 = static_cast<float>(a);
  660|      0|  const float f2 = static_cast<float>(b);
  661|      0|  return f1 < f2 ? b : a;
  662|      0|}
  663|       |
  664|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 fmin(const bfloat16& a, const bfloat16& b) {
  665|      0|  const float f1 = static_cast<float>(a);
  666|      0|  const float f2 = static_cast<float>(b);
  667|      0|  return bfloat16(::fminf(f1, f2));
  668|      0|}
  669|       |
  670|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 fmax(const bfloat16& a, const bfloat16& b) {
  671|      0|  const float f1 = static_cast<float>(a);
  672|      0|  const float f2 = static_cast<float>(b);
  673|      0|  return bfloat16(::fmaxf(f1, f2));
  674|      0|}
  675|       |
  676|       |#ifndef EIGEN_NO_IO
  677|      0|EIGEN_ALWAYS_INLINE std::ostream& operator<<(std::ostream& os, const bfloat16& v) {
  678|      0|  os << static_cast<float>(v);
  679|      0|  return os;
  680|      0|}
  681|       |#endif
  682|       |
  683|       |}  // namespace bfloat16_impl
  684|       |
  685|       |namespace internal {
  686|       |
  687|       |template <>
  688|       |struct is_arithmetic<bfloat16> {
  689|       |  enum { value = true };
  690|       |};
  691|       |
  692|       |template <>
  693|       |struct random_impl<bfloat16> {
  694|       |  enum : int { MantissaBits = 7 };
  695|       |  using Impl = random_impl<float>;
  696|      0|  static EIGEN_DEVICE_FUNC inline bfloat16 run(const bfloat16& x, const bfloat16& y) {
  697|      0|    float result = Impl::run(x, y, MantissaBits);
  698|      0|    return bfloat16(result);
  699|      0|  }
  700|      0|  static EIGEN_DEVICE_FUNC inline bfloat16 run() {
  701|      0|    float result = Impl::run(MantissaBits);
  702|      0|    return bfloat16(result);
  703|      0|  }
  704|       |};
  705|       |
  706|       |}  // namespace internal
  707|       |
  708|       |template <>
  709|       |struct NumTraits<Eigen::bfloat16> : GenericNumTraits<Eigen::bfloat16> {
  710|       |  enum { IsSigned = true, IsInteger = false, IsComplex = false, RequireInitialization = false };
  711|       |
  712|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 epsilon() {
  713|      0|    return bfloat16_impl::raw_uint16_to_bfloat16(0x3c00);
  714|      0|  }
  715|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 dummy_precision() {
  716|      0|    return bfloat16_impl::raw_uint16_to_bfloat16(0x3D4D);  // bfloat16(5e-2f);
  717|      0|  }
  718|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 highest() {
  719|      0|    return bfloat16_impl::raw_uint16_to_bfloat16(0x7F7F);
  720|      0|  }
  721|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 lowest() {
  722|      0|    return bfloat16_impl::raw_uint16_to_bfloat16(0xFF7F);
  723|      0|  }
  724|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 infinity() {
  725|      0|    return bfloat16_impl::raw_uint16_to_bfloat16(0x7f80);
  726|      0|  }
  727|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 quiet_NaN() {
  728|      0|    return bfloat16_impl::raw_uint16_to_bfloat16(0x7fc0);
  729|      0|  }
  730|       |};
  731|       |
  732|       |}  // namespace Eigen
  733|       |
  734|       |#if defined(EIGEN_HAS_HIP_BF16)
  735|       |#pragma pop_macro("EIGEN_CONSTEXPR")
  736|       |#endif
  737|       |
  738|       |namespace Eigen {
  739|       |namespace numext {
  740|       |
  741|       |template <>
  742|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isnan)(const Eigen::bfloat16& h) {
  743|      0|  return (bfloat16_impl::isnan)(h);
  744|      0|}
  745|       |
  746|       |template <>
  747|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isinf)(const Eigen::bfloat16& h) {
  748|      0|  return (bfloat16_impl::isinf)(h);
  749|      0|}
  750|       |
  751|       |template <>
  752|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isfinite)(const Eigen::bfloat16& h) {
  753|      0|  return (bfloat16_impl::isfinite)(h);
  754|      0|}
  755|       |
  756|       |template <>
  757|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Eigen::bfloat16 bit_cast<Eigen::bfloat16, uint16_t>(const uint16_t& src) {
  758|      0|  return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(src);
  759|      0|}
  760|       |
  761|       |template <>
  762|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC uint16_t bit_cast<uint16_t, Eigen::bfloat16>(const Eigen::bfloat16& src) {
  763|      0|  return Eigen::bfloat16_impl::raw_bfloat16_as_uint16(src);
  764|      0|}
  765|       |
  766|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 nextafter(const bfloat16& from, const bfloat16& to) {
  767|      0|  if (numext::isnan EIGEN_NOT_A_MACRO(from)) {
  768|      0|    return from;
  769|      0|  }
  770|      0|  if (numext::isnan EIGEN_NOT_A_MACRO(to)) {
  771|      0|    return to;
  772|      0|  }
  773|      0|  if (from == to) {
  774|      0|    return to;
  775|      0|  }
  776|      0|  uint16_t from_bits = numext::bit_cast<uint16_t>(from);
  777|      0|  bool from_sign = from_bits >> 15;
  778|      0|  // Whether we are adjusting toward the infinity with the same sign as from.
  779|      0|  bool toward_inf = (to > from) == !from_sign;
  780|      0|  if (toward_inf) {
  781|      0|    ++from_bits;
  782|      0|  } else if ((from_bits & 0x7fff) == 0) {
  783|      0|    // Adjusting away from inf, but from is zero, so just toggle the sign.
  784|      0|    from_bits ^= 0x8000;
  785|      0|  } else {
  786|      0|    --from_bits;
  787|      0|  }
  788|      0|  return numext::bit_cast<bfloat16>(from_bits);
  789|      0|}
  790|       |
  791|       |}  // namespace numext
  792|       |}  // namespace Eigen
  793|       |
  794|       |#if EIGEN_HAS_STD_HASH
  795|       |namespace std {
  796|       |template <>
  797|       |struct hash<Eigen::bfloat16> {
  798|      0|  EIGEN_STRONG_INLINE std::size_t operator()(const Eigen::bfloat16& a) const {
  799|      0|    return static_cast<std::size_t>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(a));
  800|      0|  }
  801|       |};
  802|       |}  // namespace std
  803|       |#endif
  804|       |
  805|       |// Add the missing shfl* intrinsics.
  806|       |// The __shfl* functions are only valid on HIP or _CUDA_ARCH_ >= 300.
  807|       |//   CUDA defines them for (__CUDA_ARCH__ >= 300 || !defined(__CUDA_ARCH__))
  808|       |//
  809|       |// HIP and CUDA prior to SDK 9.0 define
  810|       |//    __shfl, __shfl_up, __shfl_down, __shfl_xor for int and float
  811|       |// CUDA since 9.0 deprecates those and instead defines
  812|       |//    __shfl_sync, __shfl_up_sync, __shfl_down_sync, __shfl_xor_sync,
  813|       |//    with native support for __half and __nv_bfloat16
  814|       |//
  815|       |// Note that the following are __device__ - only functions.
  816|       |#if defined(EIGEN_HIPCC)
  817|       |
  818|       |#if defined(EIGEN_HAS_HIP_BF16)
  819|       |
  820|       |__device__ EIGEN_STRONG_INLINE Eigen::bfloat16 __shfl(Eigen::bfloat16 var, int srcLane, int width = warpSize) {
  821|       |  const int ivar = static_cast<int>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(var));
  822|       |  return Eigen::numext::bit_cast<Eigen::bfloat16>(static_cast<Eigen::numext::uint16_t>(__shfl(ivar, srcLane, width)));
  823|       |}
  824|       |
  825|       |__device__ EIGEN_STRONG_INLINE Eigen::bfloat16 __shfl_up(Eigen::bfloat16 var, unsigned int delta,
  826|       |                                                         int width = warpSize) {
  827|       |  const int ivar = static_cast<int>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(var));
  828|       |  return Eigen::numext::bit_cast<Eigen::bfloat16>(static_cast<Eigen::numext::uint16_t>(__shfl_up(ivar, delta, width)));
  829|       |}
  830|       |
  831|       |__device__ EIGEN_STRONG_INLINE Eigen::bfloat16 __shfl_down(Eigen::bfloat16 var, unsigned int delta,
  832|       |                                                           int width = warpSize) {
  833|       |  const int ivar = static_cast<int>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(var));
  834|       |  return Eigen::numext::bit_cast<Eigen::bfloat16>(
  835|       |      static_cast<Eigen::numext::uint16_t>(__shfl_down(ivar, delta, width)));
  836|       |}
  837|       |
  838|       |__device__ EIGEN_STRONG_INLINE Eigen::bfloat16 __shfl_xor(Eigen::bfloat16 var, int laneMask, int width = warpSize) {
  839|       |  const int ivar = static_cast<int>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(var));
  840|       |  return Eigen::numext::bit_cast<Eigen::bfloat16>(
  841|       |      static_cast<Eigen::numext::uint16_t>(__shfl_xor(ivar, laneMask, width)));
  842|       |}
  843|       |
  844|       |#endif  // HIP
  845|       |
  846|       |#endif  // __shfl*
  847|       |
  848|       |#if defined(EIGEN_HIPCC)
  849|       |EIGEN_STRONG_INLINE __device__ Eigen::bfloat16 __ldg(const Eigen::bfloat16* ptr) {
  850|       |  return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(
  851|       |      __ldg(Eigen::numext::bit_cast<const Eigen::numext::uint16_t*>(ptr)));
  852|       |}
  853|       |#endif  // __ldg
  854|       |
  855|       |#endif  // EIGEN_BFLOAT16_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/arch/Default/ConjHelper.h:
    1|       |
    2|       |// This file is part of Eigen, a lightweight C++ template library
    3|       |// for linear algebra.
    4|       |//
    5|       |// Copyright (C) 2017 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_ARCH_CONJ_HELPER_H
   12|       |#define EIGEN_ARCH_CONJ_HELPER_H
   13|       |
   14|       |#define EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(PACKET_CPLX, PACKET_REAL)                                                  \
   15|       |  template <>                                                                                                       \
   16|       |  struct conj_helper<PACKET_REAL, PACKET_CPLX, false, false> {                                                      \
   17|      0|    EIGEN_STRONG_INLINE PACKET_CPLX pmadd(const PACKET_REAL& x, const PACKET_CPLX& y, const PACKET_CPLX& c) const { \
   18|      0|      return padd(c, this->pmul(x, y));                                                                             \
   19|      0|    }                                                                                                               \
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11conj_helperIDv4_fNS0_9Packet2cfELb0ELb0EE5pmaddERKS2_RKS3_S8_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11conj_helperIDv2_dNS0_9Packet1cdELb0ELb0EE5pmaddERKS2_RKS3_S8_
  ------------------
   20|      0|    EIGEN_STRONG_INLINE PACKET_CPLX pmul(const PACKET_REAL& x, const PACKET_CPLX& y) const {                        \
   21|      0|      return PACKET_CPLX(Eigen::internal::pmul<PACKET_REAL>(x, y.v));                                               \
   22|      0|    }                                                                                                               \
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11conj_helperIDv4_fNS0_9Packet2cfELb0ELb0EE4pmulERKS2_RKS3_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11conj_helperIDv2_dNS0_9Packet1cdELb0ELb0EE4pmulERKS2_RKS3_
  ------------------
   23|       |  };                                                                                                                \
   24|       |                                                                                                                    \
   25|       |  template <>                                                                                                       \
   26|       |  struct conj_helper<PACKET_CPLX, PACKET_REAL, false, false> {                                                      \
   27|      0|    EIGEN_STRONG_INLINE PACKET_CPLX pmadd(const PACKET_CPLX& x, const PACKET_REAL& y, const PACKET_CPLX& c) const { \
   28|      0|      return padd(c, this->pmul(x, y));                                                                             \
   29|      0|    }                                                                                                               \
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11conj_helperINS0_9Packet2cfEDv4_fLb0ELb0EE5pmaddERKS2_RKS3_S6_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11conj_helperINS0_9Packet1cdEDv2_dLb0ELb0EE5pmaddERKS2_RKS3_S6_
  ------------------
   30|      0|    EIGEN_STRONG_INLINE PACKET_CPLX pmul(const PACKET_CPLX& x, const PACKET_REAL& y) const {                        \
   31|      0|      return PACKET_CPLX(Eigen::internal::pmul<PACKET_REAL>(x.v, y));                                               \
   32|      0|    }                                                                                                               \
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11conj_helperINS0_9Packet2cfEDv4_fLb0ELb0EE4pmulERKS2_RKS3_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11conj_helperINS0_9Packet1cdEDv2_dLb0ELb0EE4pmulERKS2_RKS3_
  ------------------
   33|       |  };
   34|       |
   35|       |// IWYU pragma: private
   36|       |#include "../../InternalHeaderCheck.h"
   37|       |
   38|       |namespace Eigen {
   39|       |namespace internal {
   40|       |
   41|       |template <bool Conjugate>
   42|       |struct conj_if;
   43|       |
   44|       |template <>
   45|       |struct conj_if<true> {
   46|       |  template <typename T>
   47|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T operator()(const T& x) const {
   48|       |    return numext::conj(x);
   49|       |  }
   50|       |  template <typename T>
   51|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T pconj(const T& x) const {
   52|       |    return internal::pconj(x);
   53|       |  }
   54|       |};
   55|       |
   56|       |template <>
   57|       |struct conj_if<false> {
   58|       |  template <typename T>
   59|  5.00k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const T& operator()(const T& x) const {
   60|  5.00k|    return x;
   61|  5.00k|  }
   62|       |  template <typename T>
   63|  5.40k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const T& pconj(const T& x) const {
   64|  5.40k|    return x;
   65|  5.40k|  }
   66|       |};
   67|       |
   68|       |// Generic Implementation, assume scalars since the packet-version is
   69|       |// specialized below.
   70|       |template <typename LhsType, typename RhsType, bool ConjLhs, bool ConjRhs>
   71|       |struct conj_helper {
   72|       |  typedef typename ScalarBinaryOpTraits<LhsType, RhsType>::ReturnType ResultType;
   73|       |
   74|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType pmadd(const LhsType& x, const RhsType& y,
   75|       |                                                         const ResultType& c) const {
   76|       |    return this->pmul(x, y) + c;
   77|       |  }
   78|       |
   79|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType pmul(const LhsType& x, const RhsType& y) const {
   80|       |    return conj_if<ConjLhs>()(x) * conj_if<ConjRhs>()(y);
   81|       |  }
   82|       |};
   83|       |
   84|       |template <typename LhsScalar, typename RhsScalar>
   85|       |struct conj_helper<LhsScalar, RhsScalar, true, true> {
   86|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResultType;
   87|       |
   88|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType pmadd(const LhsScalar& x, const RhsScalar& y,
   89|       |                                                         const ResultType& c) const {
   90|       |    return this->pmul(x, y) + c;
   91|       |  }
   92|       |
   93|       |  // We save a conjuation by using the identity conj(a)*conj(b) = conj(a*b).
   94|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType pmul(const LhsScalar& x, const RhsScalar& y) const {
   95|       |    return numext::conj(x * y);
   96|       |  }
   97|       |};
   98|       |
   99|       |// Implementation with equal type, use packet operations.
  100|       |template <typename Packet, bool ConjLhs, bool ConjRhs>
  101|       |struct conj_helper<Packet, Packet, ConjLhs, ConjRhs> {
  102|       |  typedef Packet ResultType;
  103|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pmadd(const Packet& x, const Packet& y, const Packet& c) const {
  104|      0|    return Eigen::internal::pmadd(conj_if<ConjLhs>().pconj(x), conj_if<ConjRhs>().pconj(y), c);
  105|      0|  }
  106|       |
  107|    200|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pmul(const Packet& x, const Packet& y) const {
  108|    200|    return Eigen::internal::pmul(conj_if<ConjLhs>().pconj(x), conj_if<ConjRhs>().pconj(y));
  109|    200|  }
  110|       |};
  111|       |
  112|       |template <typename Packet>
  113|       |struct conj_helper<Packet, Packet, true, true> {
  114|       |  typedef Packet ResultType;
  115|       |
  116|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pmadd(const Packet& x, const Packet& y, const Packet& c) const {
  117|       |    return Eigen::internal::pmadd(pconj(x), pconj(y), c);
  118|       |  }
  119|       |  // We save a conjuation by using the identity conj(a)*conj(b) = conj(a*b).
  120|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pmul(const Packet& x, const Packet& y) const {
  121|       |    return pconj(Eigen::internal::pmul(x, y));
  122|       |  }
  123|       |};
  124|       |
  125|       |}  // namespace internal
  126|       |}  // namespace Eigen
  127|       |
  128|       |#endif  // EIGEN_ARCH_CONJ_HELPER_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2007 Julien Pommier
    5|       |// Copyright (C) 2014 Pedro Gonnet (pedro.gonnet@gmail.com)
    6|       |// Copyright (C) 2009-2019 Gael Guennebaud <gael.guennebaud@inria.fr>
    7|       |//
    8|       |// This Source Code Form is subject to the terms of the Mozilla
    9|       |// Public License v. 2.0. If a copy of the MPL was not distributed
   10|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   11|       |
   12|       |/* The exp and log functions of this file initially come from
   13|       | * Julien Pommier's sse math library: http://gruntthepeon.free.fr/ssemath/
   14|       | */
   15|       |
   16|       |#ifndef EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_H
   17|       |#define EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_H
   18|       |
   19|       |// IWYU pragma: private
   20|       |#include "../../InternalHeaderCheck.h"
   21|       |
   22|       |namespace Eigen {
   23|       |namespace internal {
   24|       |
   25|       |// Creates a Scalar integer type with same bit-width.
   26|       |template <typename T>
   27|       |struct make_integer;
   28|       |template <>
   29|       |struct make_integer<float> {
   30|       |  typedef numext::int32_t type;
   31|       |};
   32|       |template <>
   33|       |struct make_integer<double> {
   34|       |  typedef numext::int64_t type;
   35|       |};
   36|       |template <>
   37|       |struct make_integer<half> {
   38|       |  typedef numext::int16_t type;
   39|       |};
   40|       |template <>
   41|       |struct make_integer<bfloat16> {
   42|       |  typedef numext::int16_t type;
   43|       |};
   44|       |
   45|       |/* polevl (modified for Eigen)
   46|       | *
   47|       | *      Evaluate polynomial
   48|       | *
   49|       | *
   50|       | *
   51|       | * SYNOPSIS:
   52|       | *
   53|       | * int N;
   54|       | * Scalar x, y, coef[N+1];
   55|       | *
   56|       | * y = polevl<decltype(x), N>( x, coef);
   57|       | *
   58|       | *
   59|       | *
   60|       | * DESCRIPTION:
   61|       | *
   62|       | * Evaluates polynomial of degree N:
   63|       | *
   64|       | *                     2          N
   65|       | * y  =  C  + C x + C x  +...+ C x
   66|       | *        0    1     2          N
   67|       | *
   68|       | * Coefficients are stored in reverse order:
   69|       | *
   70|       | * coef[0] = C  , ..., coef[N] = C  .
   71|       | *            N                   0
   72|       | *
   73|       | *  The function p1evl() assumes that coef[N] = 1.0 and is
   74|       | * omitted from the array.  Its calling arguments are
   75|       | * otherwise the same as polevl().
   76|       | *
   77|       | *
   78|       | * The Eigen implementation is templatized.  For best speed, store
   79|       | * coef as a const array (constexpr), e.g.
   80|       | *
   81|       | * const double coef[] = {1.0, 2.0, 3.0, ...};
   82|       | *
   83|       | */
   84|       |template <typename Packet, int N>
   85|       |struct ppolevl {
   86|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& x,
   87|      0|                                                          const typename unpacket_traits<Packet>::type coeff[]) {
   88|      0|    EIGEN_STATIC_ASSERT((N > 0), YOU_MADE_A_PROGRAMMING_MISTAKE);
   89|      0|    return pmadd(ppolevl<Packet, N - 1>::run(x, coeff), x, pset1<Packet>(coeff[N]));
   90|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIfLi3EE3runERKfPS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIfLi2EE3runERKfPS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIfLi1EE3runERKfPS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIfLi4EE3runERKfPS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv4_fLi4EE3runERKS2_PKf
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv4_fLi3EE3runERKS2_PKf
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv4_fLi2EE3runERKS2_PKf
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv4_fLi1EE3runERKS2_PKf
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi4EE3runERKS2_PKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi3EE3runERKS2_PKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi2EE3runERKS2_PKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi1EE3runERKS2_PKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi5EE3runERKS2_PKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi8EE3runERKS2_PKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi7EE3runERKS2_PKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi6EE3runERKS2_PKd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi9EE3runERKS2_PKd
  ------------------
   91|       |};
   92|       |
   93|       |template <typename Packet>
   94|       |struct ppolevl<Packet, 0> {
   95|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& x,
   96|      0|                                                          const typename unpacket_traits<Packet>::type coeff[]) {
   97|      0|    EIGEN_UNUSED_VARIABLE(x);
   98|      0|    return pset1<Packet>(coeff[0]);
   99|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIfLi0EE3runERKfPS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv4_fLi0EE3runERKS2_PKf
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7ppolevlIDv2_dLi0EE3runERKS2_PKd
  ------------------
  100|       |};
  101|       |
  102|       |/* chbevl (modified for Eigen)
  103|       | *
  104|       | *     Evaluate Chebyshev series
  105|       | *
  106|       | *
  107|       | *
  108|       | * SYNOPSIS:
  109|       | *
  110|       | * int N;
  111|       | * Scalar x, y, coef[N], chebevl();
  112|       | *
  113|       | * y = chbevl( x, coef, N );
  114|       | *
  115|       | *
  116|       | *
  117|       | * DESCRIPTION:
  118|       | *
  119|       | * Evaluates the series
  120|       | *
  121|       | *        N-1
  122|       | *         - '
  123|       | *  y  =   >   coef[i] T (x/2)
  124|       | *         -            i
  125|       | *        i=0
  126|       | *
  127|       | * of Chebyshev polynomials Ti at argument x/2.
  128|       | *
  129|       | * Coefficients are stored in reverse order, i.e. the zero
  130|       | * order term is last in the array.  Note N is the number of
  131|       | * coefficients, not the order.
  132|       | *
  133|       | * If coefficients are for the interval a to b, x must
  134|       | * have been transformed to x -> 2(2x - b - a)/(b-a) before
  135|       | * entering the routine.  This maps x from (a, b) to (-1, 1),
  136|       | * over which the Chebyshev polynomials are defined.
  137|       | *
  138|       | * If the coefficients are for the inverted interval, in
  139|       | * which (a, b) is mapped to (1/b, 1/a), the transformation
  140|       | * required is x -> 2(2ab/x - b - a)/(b-a).  If b is infinity,
  141|       | * this becomes x -> 4a/x - 1.
  142|       | *
  143|       | *
  144|       | *
  145|       | * SPEED:
  146|       | *
  147|       | * Taking advantage of the recurrence properties of the
  148|       | * Chebyshev polynomials, the routine requires one more
  149|       | * addition per loop than evaluating a nested polynomial of
  150|       | * the same degree.
  151|       | *
  152|       | */
  153|       |
  154|       |template <typename Packet, int N>
  155|       |struct pchebevl {
  156|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Packet run(Packet x,
  157|       |                                                          const typename unpacket_traits<Packet>::type coef[]) {
  158|       |    typedef typename unpacket_traits<Packet>::type Scalar;
  159|       |    Packet b0 = pset1<Packet>(coef[0]);
  160|       |    Packet b1 = pset1<Packet>(static_cast<Scalar>(0.f));
  161|       |    Packet b2;
  162|       |
  163|       |    for (int i = 1; i < N; i++) {
  164|       |      b2 = b1;
  165|       |      b1 = b0;
  166|       |      b0 = psub(pmadd(x, b1, pset1<Packet>(coef[i])), b2);
  167|       |    }
  168|       |
  169|       |    return pmul(pset1<Packet>(static_cast<Scalar>(0.5f)), psub(b0, b2));
  170|       |  }
  171|       |};
  172|       |
  173|       |template <typename Packet>
  174|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pfrexp_generic_get_biased_exponent(const Packet& a) {
  175|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
  176|      0|  typedef typename unpacket_traits<Packet>::integer_packet PacketI;
  177|      0|  static constexpr int mantissa_bits = numext::numeric_limits<Scalar>::digits - 1;
  178|      0|  return pcast<PacketI, Packet>(plogical_shift_right<mantissa_bits>(preinterpret<PacketI>(pabs(a))));
  179|      0|}
  180|       |
  181|       |// Safely applies frexp, correctly handles denormals.
  182|       |// Assumes IEEE floating point format.
  183|       |template <typename Packet>
  184|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pfrexp_generic(const Packet& a, Packet& exponent) {
  185|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
  186|      0|  typedef typename make_unsigned<typename make_integer<Scalar>::type>::type ScalarUI;
  187|      0|  static constexpr int TotalBits = sizeof(Scalar) * CHAR_BIT, MantissaBits = numext::numeric_limits<Scalar>::digits - 1,
  188|      0|                       ExponentBits = TotalBits - MantissaBits - 1;
  189|      0|
  190|      0|  EIGEN_CONSTEXPR ScalarUI scalar_sign_mantissa_mask =
  191|      0|      ~(((ScalarUI(1) << ExponentBits) - ScalarUI(1)) << MantissaBits);  // ~0x7f800000
  192|      0|  const Packet sign_mantissa_mask = pset1frombits<Packet>(static_cast<ScalarUI>(scalar_sign_mantissa_mask));
  193|      0|  const Packet half = pset1<Packet>(Scalar(0.5));
  194|      0|  const Packet zero = pzero(a);
  195|      0|  const Packet normal_min = pset1<Packet>((numext::numeric_limits<Scalar>::min)());  // Minimum normal value, 2^-126
  196|      0|
  197|      0|  // To handle denormals, normalize by multiplying by 2^(int(MantissaBits)+1).
  198|      0|  const Packet is_denormal = pcmp_lt(pabs(a), normal_min);
  199|      0|  EIGEN_CONSTEXPR ScalarUI scalar_normalization_offset = ScalarUI(MantissaBits + 1);  // 24
  200|      0|  // The following cannot be constexpr because bfloat16(uint16_t) is not constexpr.
  201|      0|  const Scalar scalar_normalization_factor = Scalar(ScalarUI(1) << int(scalar_normalization_offset));  // 2^24
  202|      0|  const Packet normalization_factor = pset1<Packet>(scalar_normalization_factor);
  203|      0|  const Packet normalized_a = pselect(is_denormal, pmul(a, normalization_factor), a);
  204|      0|
  205|      0|  // Determine exponent offset: -126 if normal, -126-24 if denormal
  206|      0|  const Scalar scalar_exponent_offset = -Scalar((ScalarUI(1) << (ExponentBits - 1)) - ScalarUI(2));  // -126
  207|      0|  Packet exponent_offset = pset1<Packet>(scalar_exponent_offset);
  208|      0|  const Packet normalization_offset = pset1<Packet>(-Scalar(scalar_normalization_offset));  // -24
  209|      0|  exponent_offset = pselect(is_denormal, padd(exponent_offset, normalization_offset), exponent_offset);
  210|      0|
  211|      0|  // Determine exponent and mantissa from normalized_a.
  212|      0|  exponent = pfrexp_generic_get_biased_exponent(normalized_a);
  213|      0|  // Zero, Inf and NaN return 'a' unmodified, exponent is zero
  214|      0|  // (technically the exponent is unspecified for inf/NaN, but GCC/Clang set it to zero)
  215|      0|  const Scalar scalar_non_finite_exponent = Scalar((ScalarUI(1) << ExponentBits) - ScalarUI(1));  // 255
  216|      0|  const Packet non_finite_exponent = pset1<Packet>(scalar_non_finite_exponent);
  217|      0|  const Packet is_zero_or_not_finite = por(pcmp_eq(a, zero), pcmp_eq(exponent, non_finite_exponent));
  218|      0|  const Packet m = pselect(is_zero_or_not_finite, a, por(pand(normalized_a, sign_mantissa_mask), half));
  219|      0|  exponent = pselect(is_zero_or_not_finite, zero, padd(exponent, exponent_offset));
  220|      0|  return m;
  221|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14pfrexp_genericIDv4_fEET_RKS3_RS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14pfrexp_genericIDv2_dEET_RKS3_RS3_
  ------------------
  222|       |
  223|       |// Safely applies ldexp, correctly handles overflows, underflows and denormals.
  224|       |// Assumes IEEE floating point format.
  225|       |template <typename Packet>
  226|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pldexp_generic(const Packet& a, const Packet& exponent) {
  227|      0|  // We want to return a * 2^exponent, allowing for all possible integer
  228|      0|  // exponents without overflowing or underflowing in intermediate
  229|      0|  // computations.
  230|      0|  //
  231|      0|  // Since 'a' and the output can be denormal, the maximum range of 'exponent'
  232|      0|  // to consider for a float is:
  233|      0|  //   -255-23 -> 255+23
  234|      0|  // Below -278 any finite float 'a' will become zero, and above +278 any
  235|      0|  // finite float will become inf, including when 'a' is the smallest possible
  236|      0|  // denormal.
  237|      0|  //
  238|      0|  // Unfortunately, 2^(278) cannot be represented using either one or two
  239|      0|  // finite normal floats, so we must split the scale factor into at least
  240|      0|  // three parts. It turns out to be faster to split 'exponent' into four
  241|      0|  // factors, since [exponent>>2] is much faster to compute that [exponent/3].
  242|      0|  //
  243|      0|  // Set e = min(max(exponent, -278), 278);
  244|      0|  //     b = floor(e/4);
  245|      0|  //   out = ((((a * 2^(b)) * 2^(b)) * 2^(b)) * 2^(e-3*b))
  246|      0|  //
  247|      0|  // This will avoid any intermediate overflows and correctly handle 0, inf,
  248|      0|  // NaN cases.
  249|      0|  typedef typename unpacket_traits<Packet>::integer_packet PacketI;
  250|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
  251|      0|  typedef typename unpacket_traits<PacketI>::type ScalarI;
  252|      0|  static constexpr int TotalBits = sizeof(Scalar) * CHAR_BIT, MantissaBits = numext::numeric_limits<Scalar>::digits - 1,
  253|      0|                       ExponentBits = TotalBits - MantissaBits - 1;
  254|      0|
  255|      0|  const Packet max_exponent = pset1<Packet>(Scalar((ScalarI(1) << ExponentBits) + ScalarI(MantissaBits - 1)));  // 278
  256|      0|  const PacketI bias = pset1<PacketI>((ScalarI(1) << (ExponentBits - 1)) - ScalarI(1));                         // 127
  257|      0|  const PacketI e = pcast<Packet, PacketI>(pmin(pmax(exponent, pnegate(max_exponent)), max_exponent));
  258|      0|  PacketI b = parithmetic_shift_right<2>(e);                                          // floor(e/4);
  259|      0|  Packet c = preinterpret<Packet>(plogical_shift_left<MantissaBits>(padd(b, bias)));  // 2^b
  260|      0|  Packet out = pmul(pmul(pmul(a, c), c), c);                                          // a * 2^(3b)
  261|      0|  b = pnmadd(pset1<PacketI>(3), b, e);                                                // e - 3b
  262|      0|  c = preinterpret<Packet>(plogical_shift_left<MantissaBits>(padd(b, bias)));         // 2^(e-3*b)
  263|      0|  out = pmul(out, c);
  264|      0|  return out;
  265|      0|}
  266|       |
  267|       |// Explicitly multiplies
  268|       |//    a * (2^e)
  269|       |// clamping e to the range
  270|       |// [NumTraits<Scalar>::min_exponent()-2, NumTraits<Scalar>::max_exponent()]
  271|       |//
  272|       |// This is approx 7x faster than pldexp_impl, but will prematurely over/underflow
  273|       |// if 2^e doesn't fit into a normal floating-point Scalar.
  274|       |//
  275|       |// Assumes IEEE floating point format
  276|       |template <typename Packet>
  277|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pldexp_fast(const Packet& a, const Packet& exponent) {
  278|      0|  typedef typename unpacket_traits<Packet>::integer_packet PacketI;
  279|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
  280|      0|  typedef typename unpacket_traits<PacketI>::type ScalarI;
  281|      0|  static constexpr int TotalBits = sizeof(Scalar) * CHAR_BIT, MantissaBits = numext::numeric_limits<Scalar>::digits - 1,
  282|      0|                       ExponentBits = TotalBits - MantissaBits - 1;
  283|      0|
  284|      0|  const Packet bias = pset1<Packet>(Scalar((ScalarI(1) << (ExponentBits - 1)) - ScalarI(1)));  // 127
  285|      0|  const Packet limit = pset1<Packet>(Scalar((ScalarI(1) << ExponentBits) - ScalarI(1)));       // 255
  286|      0|  // restrict biased exponent between 0 and 255 for float.
  287|      0|  const PacketI e = pcast<Packet, PacketI>(pmin(pmax(padd(exponent, bias), pzero(limit)), limit));  // exponent + 127
  288|      0|  // return a * (2^e)
  289|      0|  return pmul(a, preinterpret<Packet>(plogical_shift_left<MantissaBits>(e)));
  290|      0|}
  291|       |
  292|       |// Natural or base 2 logarithm.
  293|       |// Computes log(x) as log(2^e * m) = C*e + log(m), where the constant C =log(2)
  294|       |// and m is in the range [sqrt(1/2),sqrt(2)). In this range, the logarithm can
  295|       |// be easily approximated by a polynomial centered on m=1 for stability.
  296|       |// TODO(gonnet): Further reduce the interval allowing for lower-degree
  297|       |//               polynomial interpolants -> ... -> profit!
  298|       |template <typename Packet, bool base2>
  299|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_impl_float(const Packet _x) {
  300|      0|  const Packet cst_1 = pset1<Packet>(1.0f);
  301|      0|  const Packet cst_minus_inf = pset1frombits<Packet>(static_cast<Eigen::numext::uint32_t>(0xff800000u));
  302|      0|  const Packet cst_pos_inf = pset1frombits<Packet>(static_cast<Eigen::numext::uint32_t>(0x7f800000u));
  303|      0|
  304|      0|  const Packet cst_cephes_SQRTHF = pset1<Packet>(0.707106781186547524f);
  305|      0|  Packet e, x;
  306|      0|  // extract significant in the range [0.5,1) and exponent
  307|      0|  x = pfrexp(_x, e);
  308|      0|
  309|      0|  // part2: Shift the inputs from the range [0.5,1) to [sqrt(1/2),sqrt(2))
  310|      0|  // and shift by -1. The values are then centered around 0, which improves
  311|      0|  // the stability of the polynomial evaluation.
  312|      0|  //   if( x < SQRTHF ) {
  313|      0|  //     e -= 1;
  314|      0|  //     x = x + x - 1.0;
  315|      0|  //   } else { x = x - 1.0; }
  316|      0|  Packet mask = pcmp_lt(x, cst_cephes_SQRTHF);
  317|      0|  Packet tmp = pand(x, mask);
  318|      0|  x = psub(x, cst_1);
  319|      0|  e = psub(e, pand(cst_1, mask));
  320|      0|  x = padd(x, tmp);
  321|      0|
  322|      0|  // Polynomial coefficients for rational r(x) = p(x)/q(x)
  323|      0|  // approximating log(1+x) on [sqrt(0.5)-1;sqrt(2)-1].
  324|      0|  constexpr float alpha[] = {0.18256296349849254f, 1.0000000190281063f, 1.0000000190281136f};
  325|      0|  constexpr float beta[] = {0.049616247954120038f, 0.59923249590823520f, 1.4999999999999927f, 1.0f};
  326|      0|
  327|      0|  Packet p = ppolevl<Packet, 2>::run(x, alpha);
  328|      0|  p = pmul(x, p);
  329|      0|  Packet q = ppolevl<Packet, 3>::run(x, beta);
  330|      0|  x = pdiv(p, q);
  331|      0|
  332|      0|  // Add the logarithm of the exponent back to the result of the interpolation.
  333|      0|  if (base2) {
  334|      0|    const Packet cst_log2e = pset1<Packet>(static_cast<float>(EIGEN_LOG2E));
  335|      0|    x = pmadd(x, cst_log2e, e);
  336|      0|  } else {
  337|      0|    const Packet cst_ln2 = pset1<Packet>(static_cast<float>(EIGEN_LN2));
  338|      0|    x = pmadd(e, cst_ln2, x);
  339|      0|  }
  340|      0|
  341|      0|  Packet invalid_mask = pcmp_lt_or_nan(_x, pzero(_x));
  342|      0|  Packet iszero_mask = pcmp_eq(_x, pzero(_x));
  343|      0|  Packet pos_inf_mask = pcmp_eq(_x, cst_pos_inf);
  344|      0|  // Filter out invalid inputs, i.e.:
  345|      0|  //  - negative arg will be NAN
  346|      0|  //  - 0 will be -INF
  347|      0|  //  - +INF will be +INF
  348|      0|  return pselect(iszero_mask, cst_minus_inf, por(pselect(pos_inf_mask, cst_pos_inf, x), invalid_mask));
  349|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15plog_impl_floatIDv4_fLb0EEET_S3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15plog_impl_floatIDv4_fLb1EEET_S3_
  ------------------
  350|       |
  351|       |template <typename Packet>
  352|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_float(const Packet _x) {
  353|      0|  return plog_impl_float<Packet, /* base2 */ false>(_x);
  354|      0|}
  355|       |
  356|       |template <typename Packet>
  357|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog2_float(const Packet _x) {
  358|      0|  return plog_impl_float<Packet, /* base2 */ true>(_x);
  359|      0|}
  360|       |
  361|       |/* Returns the base e (2.718...) or base 2 logarithm of x.
  362|       | * The argument is separated into its exponent and fractional parts.
  363|       | * The logarithm of the fraction in the interval [sqrt(1/2), sqrt(2)],
  364|       | * is approximated by
  365|       | *
  366|       | *     log(1+x) = x - 0.5 x**2 + x**3 P(x)/Q(x).
  367|       | *
  368|       | * for more detail see: http://www.netlib.org/cephes/
  369|       | */
  370|       |template <typename Packet, bool base2>
  371|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_impl_double(const Packet _x) {
  372|      0|  Packet x = _x;
  373|      0|
  374|      0|  const Packet cst_1 = pset1<Packet>(1.0);
  375|      0|  const Packet cst_neg_half = pset1<Packet>(-0.5);
  376|      0|  const Packet cst_minus_inf = pset1frombits<Packet>(static_cast<uint64_t>(0xfff0000000000000ull));
  377|      0|  const Packet cst_pos_inf = pset1frombits<Packet>(static_cast<uint64_t>(0x7ff0000000000000ull));
  378|      0|
  379|      0|  // Polynomial Coefficients for log(1+x) = x - x**2/2 + x**3 P(x)/Q(x)
  380|      0|  //                             1/sqrt(2) <= x < sqrt(2)
  381|      0|  const Packet cst_cephes_SQRTHF = pset1<Packet>(0.70710678118654752440E0);
  382|      0|  const Packet cst_cephes_log_p0 = pset1<Packet>(1.01875663804580931796E-4);
  383|      0|  const Packet cst_cephes_log_p1 = pset1<Packet>(4.97494994976747001425E-1);
  384|      0|  const Packet cst_cephes_log_p2 = pset1<Packet>(4.70579119878881725854E0);
  385|      0|  const Packet cst_cephes_log_p3 = pset1<Packet>(1.44989225341610930846E1);
  386|      0|  const Packet cst_cephes_log_p4 = pset1<Packet>(1.79368678507819816313E1);
  387|      0|  const Packet cst_cephes_log_p5 = pset1<Packet>(7.70838733755885391666E0);
  388|      0|
  389|      0|  const Packet cst_cephes_log_q0 = pset1<Packet>(1.0);
  390|      0|  const Packet cst_cephes_log_q1 = pset1<Packet>(1.12873587189167450590E1);
  391|      0|  const Packet cst_cephes_log_q2 = pset1<Packet>(4.52279145837532221105E1);
  392|      0|  const Packet cst_cephes_log_q3 = pset1<Packet>(8.29875266912776603211E1);
  393|      0|  const Packet cst_cephes_log_q4 = pset1<Packet>(7.11544750618563894466E1);
  394|      0|  const Packet cst_cephes_log_q5 = pset1<Packet>(2.31251620126765340583E1);
  395|      0|
  396|      0|  Packet e;
  397|      0|  // extract significant in the range [0.5,1) and exponent
  398|      0|  x = pfrexp(x, e);
  399|      0|
  400|      0|  // Shift the inputs from the range [0.5,1) to [sqrt(1/2),sqrt(2))
  401|      0|  // and shift by -1. The values are then centered around 0, which improves
  402|      0|  // the stability of the polynomial evaluation.
  403|      0|  //   if( x < SQRTHF ) {
  404|      0|  //     e -= 1;
  405|      0|  //     x = x + x - 1.0;
  406|      0|  //   } else { x = x - 1.0; }
  407|      0|  Packet mask = pcmp_lt(x, cst_cephes_SQRTHF);
  408|      0|  Packet tmp = pand(x, mask);
  409|      0|  x = psub(x, cst_1);
  410|      0|  e = psub(e, pand(cst_1, mask));
  411|      0|  x = padd(x, tmp);
  412|      0|
  413|      0|  Packet x2 = pmul(x, x);
  414|      0|  Packet x3 = pmul(x2, x);
  415|      0|
  416|      0|  // Evaluate the polynomial approximant , probably to improve instruction-level parallelism.
  417|      0|  // y = x - 0.5*x^2 + x^3 * polevl( x, P, 5 ) / p1evl( x, Q, 5 ) );
  418|      0|  Packet y, y1, y_;
  419|      0|  y = pmadd(cst_cephes_log_p0, x, cst_cephes_log_p1);
  420|      0|  y1 = pmadd(cst_cephes_log_p3, x, cst_cephes_log_p4);
  421|      0|  y = pmadd(y, x, cst_cephes_log_p2);
  422|      0|  y1 = pmadd(y1, x, cst_cephes_log_p5);
  423|      0|  y_ = pmadd(y, x3, y1);
  424|      0|
  425|      0|  y = pmadd(cst_cephes_log_q0, x, cst_cephes_log_q1);
  426|      0|  y1 = pmadd(cst_cephes_log_q3, x, cst_cephes_log_q4);
  427|      0|  y = pmadd(y, x, cst_cephes_log_q2);
  428|      0|  y1 = pmadd(y1, x, cst_cephes_log_q5);
  429|      0|  y = pmadd(y, x3, y1);
  430|      0|
  431|      0|  y_ = pmul(y_, x3);
  432|      0|  y = pdiv(y_, y);
  433|      0|
  434|      0|  y = pmadd(cst_neg_half, x2, y);
  435|      0|  x = padd(x, y);
  436|      0|
  437|      0|  // Add the logarithm of the exponent back to the result of the interpolation.
  438|      0|  if (base2) {
  439|      0|    const Packet cst_log2e = pset1<Packet>(static_cast<double>(EIGEN_LOG2E));
  440|      0|    x = pmadd(x, cst_log2e, e);
  441|      0|  } else {
  442|      0|    const Packet cst_ln2 = pset1<Packet>(static_cast<double>(EIGEN_LN2));
  443|      0|    x = pmadd(e, cst_ln2, x);
  444|      0|  }
  445|      0|
  446|      0|  Packet invalid_mask = pcmp_lt_or_nan(_x, pzero(_x));
  447|      0|  Packet iszero_mask = pcmp_eq(_x, pzero(_x));
  448|      0|  Packet pos_inf_mask = pcmp_eq(_x, cst_pos_inf);
  449|      0|  // Filter out invalid inputs, i.e.:
  450|      0|  //  - negative arg will be NAN
  451|      0|  //  - 0 will be -INF
  452|      0|  //  - +INF will be +INF
  453|      0|  return pselect(iszero_mask, cst_minus_inf, por(pselect(pos_inf_mask, cst_pos_inf, x), invalid_mask));
  454|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal16plog_impl_doubleIDv2_dLb0EEET_S3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal16plog_impl_doubleIDv2_dLb1EEET_S3_
  ------------------
  455|       |
  456|       |template <typename Packet>
  457|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_double(const Packet _x) {
  458|      0|  return plog_impl_double<Packet, /* base2 */ false>(_x);
  459|      0|}
  460|       |
  461|       |template <typename Packet>
  462|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog2_double(const Packet _x) {
  463|      0|  return plog_impl_double<Packet, /* base2 */ true>(_x);
  464|      0|}
  465|       |
  466|       |/** \internal \returns log(1 + x) computed using W. Kahan's formula.
  467|       |    See: http://www.plunk.org/~hatch/rightway.php
  468|       | */
  469|       |template <typename Packet>
  470|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_log1p(const Packet& x) {
  471|      0|  typedef typename unpacket_traits<Packet>::type ScalarType;
  472|      0|  const Packet one = pset1<Packet>(ScalarType(1));
  473|      0|  Packet xp1 = padd(x, one);
  474|      0|  Packet small_mask = pcmp_eq(xp1, one);
  475|      0|  Packet log1 = plog(xp1);
  476|      0|  Packet inf_mask = pcmp_eq(xp1, log1);
  477|      0|  Packet log_large = pmul(x, pdiv(log1, psub(xp1, one)));
  478|      0|  return pselect(por(small_mask, inf_mask), x, log_large);
  479|      0|}
  480|       |
  481|       |/** \internal \returns exp(x)-1 computed using W. Kahan's formula.
  482|       |    See: http://www.plunk.org/~hatch/rightway.php
  483|       | */
  484|       |template <typename Packet>
  485|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_expm1(const Packet& x) {
  486|      0|  typedef typename unpacket_traits<Packet>::type ScalarType;
  487|      0|  const Packet one = pset1<Packet>(ScalarType(1));
  488|      0|  const Packet neg_one = pset1<Packet>(ScalarType(-1));
  489|      0|  Packet u = pexp(x);
  490|      0|  Packet one_mask = pcmp_eq(u, one);
  491|      0|  Packet u_minus_one = psub(u, one);
  492|      0|  Packet neg_one_mask = pcmp_eq(u_minus_one, neg_one);
  493|      0|  Packet logu = plog(u);
  494|      0|  // The following comparison is to catch the case where
  495|      0|  // exp(x) = +inf. It is written in this way to avoid having
  496|      0|  // to form the constant +inf, which depends on the packet
  497|      0|  // type.
  498|      0|  Packet pos_inf_mask = pcmp_eq(logu, u);
  499|      0|  Packet expm1 = pmul(u_minus_one, pdiv(x, logu));
  500|      0|  expm1 = pselect(pos_inf_mask, u, expm1);
  501|      0|  return pselect(one_mask, x, pselect(neg_one_mask, neg_one, expm1));
  502|      0|}
  503|       |
  504|       |// Exponential function. Works by writing "x = m*log(2) + r" where
  505|       |// "m = floor(x/log(2)+1/2)" and "r" is the remainder. The result is then
  506|       |// "exp(x) = 2^m*exp(r)" where exp(r) is in the range [-1,1).
  507|       |// exp(r) is computed using a 6th order minimax polynomial approximation.
  508|       |template <typename Packet>
  509|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp_float(const Packet _x) {
  510|      0|  const Packet cst_zero = pset1<Packet>(0.0f);
  511|      0|  const Packet cst_one = pset1<Packet>(1.0f);
  512|      0|  const Packet cst_half = pset1<Packet>(0.5f);
  513|      0|  const Packet cst_exp_hi = pset1<Packet>(88.723f);
  514|      0|  const Packet cst_exp_lo = pset1<Packet>(-104.f);
  515|      0|  const Packet cst_pldexp_threshold = pset1<Packet>(87.0);
  516|      0|
  517|      0|  const Packet cst_cephes_LOG2EF = pset1<Packet>(1.44269504088896341f);
  518|      0|  const Packet cst_p2 = pset1<Packet>(0.49999988079071044921875f);
  519|      0|  const Packet cst_p3 = pset1<Packet>(0.16666518151760101318359375f);
  520|      0|  const Packet cst_p4 = pset1<Packet>(4.166965186595916748046875e-2f);
  521|      0|  const Packet cst_p5 = pset1<Packet>(8.36894474923610687255859375e-3f);
  522|      0|  const Packet cst_p6 = pset1<Packet>(1.37449637986719608306884765625e-3f);
  523|      0|
  524|      0|  // Clamp x.
  525|      0|  Packet zero_mask = pcmp_lt(_x, cst_exp_lo);
  526|      0|  Packet x = pmin(_x, cst_exp_hi);
  527|      0|
  528|      0|  // Express exp(x) as exp(m*ln(2) + r), start by extracting
  529|      0|  // m = floor(x/ln(2) + 0.5).
  530|      0|  Packet m = pfloor(pmadd(x, cst_cephes_LOG2EF, cst_half));
  531|      0|
  532|      0|  // Get r = x - m*ln(2). If no FMA instructions are available, m*ln(2) is
  533|      0|  // subtracted out in two parts, m*C1+m*C2 = m*ln(2), to avoid accumulating
  534|      0|  // truncation errors.
  535|      0|  const Packet cst_cephes_exp_C1 = pset1<Packet>(-0.693359375f);
  536|      0|  const Packet cst_cephes_exp_C2 = pset1<Packet>(2.12194440e-4f);
  537|      0|  Packet r = pmadd(m, cst_cephes_exp_C1, x);
  538|      0|  r = pmadd(m, cst_cephes_exp_C2, r);
  539|      0|
  540|      0|  // Evaluate the 6th order polynomial approximation to exp(r)
  541|      0|  // with r in the interval [-ln(2)/2;ln(2)/2].
  542|      0|  const Packet r2 = pmul(r, r);
  543|      0|  Packet p_even = pmadd(r2, cst_p6, cst_p4);
  544|      0|  const Packet p_odd = pmadd(r2, cst_p5, cst_p3);
  545|      0|  p_even = pmadd(r2, p_even, cst_p2);
  546|      0|  const Packet p_low = padd(r, cst_one);
  547|      0|  Packet y = pmadd(r, p_odd, p_even);
  548|      0|  y = pmadd(r2, y, p_low);
  549|      0|
  550|      0|  // Return 2^m * exp(r).
  551|      0|  const Packet fast_pldexp_unsafe = pcmp_lt(cst_pldexp_threshold, pabs(x));
  552|      0|  if (!predux_any(fast_pldexp_unsafe)) {
  553|      0|    // For |x| <= 87, we know the result is not zero or inf, and we can safely use
  554|      0|    // the fast version of pldexp.
  555|      0|    return pmax(pldexp_fast(y, m), _x);
  556|      0|  }
  557|      0|  return pselect(zero_mask, cst_zero, pmax(pldexp(y, m), _x));
  558|      0|}
  559|       |
  560|       |template <typename Packet>
  561|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp_double(const Packet _x) {
  562|      0|  Packet x = _x;
  563|      0|  const Packet cst_zero = pset1<Packet>(0.0);
  564|      0|  const Packet cst_1 = pset1<Packet>(1.0);
  565|      0|  const Packet cst_2 = pset1<Packet>(2.0);
  566|      0|  const Packet cst_half = pset1<Packet>(0.5);
  567|      0|
  568|      0|  const Packet cst_exp_hi = pset1<Packet>(709.784);
  569|      0|  const Packet cst_exp_lo = pset1<Packet>(-745.519);
  570|      0|  const Packet cst_pldexp_threshold = pset1<Packet>(708.0);
  571|      0|  const Packet cst_cephes_LOG2EF = pset1<Packet>(1.4426950408889634073599);
  572|      0|  const Packet cst_cephes_exp_p0 = pset1<Packet>(1.26177193074810590878e-4);
  573|      0|  const Packet cst_cephes_exp_p1 = pset1<Packet>(3.02994407707441961300e-2);
  574|      0|  const Packet cst_cephes_exp_p2 = pset1<Packet>(9.99999999999999999910e-1);
  575|      0|  const Packet cst_cephes_exp_q0 = pset1<Packet>(3.00198505138664455042e-6);
  576|      0|  const Packet cst_cephes_exp_q1 = pset1<Packet>(2.52448340349684104192e-3);
  577|      0|  const Packet cst_cephes_exp_q2 = pset1<Packet>(2.27265548208155028766e-1);
  578|      0|  const Packet cst_cephes_exp_q3 = pset1<Packet>(2.00000000000000000009e0);
  579|      0|  const Packet cst_cephes_exp_C1 = pset1<Packet>(0.693145751953125);
  580|      0|  const Packet cst_cephes_exp_C2 = pset1<Packet>(1.42860682030941723212e-6);
  581|      0|
  582|      0|  Packet tmp, fx;
  583|      0|
  584|      0|  // clamp x
  585|      0|  Packet zero_mask = pcmp_lt(_x, cst_exp_lo);
  586|      0|  x = pmin(x, cst_exp_hi);
  587|      0|  // Express exp(x) as exp(g + n*log(2)).
  588|      0|  fx = pmadd(cst_cephes_LOG2EF, x, cst_half);
  589|      0|
  590|      0|  // Get the integer modulus of log(2), i.e. the "n" described above.
  591|      0|  fx = pfloor(fx);
  592|      0|
  593|      0|  // Get the remainder modulo log(2), i.e. the "g" described above. Subtract
  594|      0|  // n*log(2) out in two steps, i.e. n*C1 + n*C2, C1+C2=log2 to get the last
  595|      0|  // digits right.
  596|      0|  tmp = pmul(fx, cst_cephes_exp_C1);
  597|      0|  Packet z = pmul(fx, cst_cephes_exp_C2);
  598|      0|  x = psub(x, tmp);
  599|      0|  x = psub(x, z);
  600|      0|
  601|      0|  Packet x2 = pmul(x, x);
  602|      0|
  603|      0|  // Evaluate the numerator polynomial of the rational interpolant.
  604|      0|  Packet px = cst_cephes_exp_p0;
  605|      0|  px = pmadd(px, x2, cst_cephes_exp_p1);
  606|      0|  px = pmadd(px, x2, cst_cephes_exp_p2);
  607|      0|  px = pmul(px, x);
  608|      0|
  609|      0|  // Evaluate the denominator polynomial of the rational interpolant.
  610|      0|  Packet qx = cst_cephes_exp_q0;
  611|      0|  qx = pmadd(qx, x2, cst_cephes_exp_q1);
  612|      0|  qx = pmadd(qx, x2, cst_cephes_exp_q2);
  613|      0|  qx = pmadd(qx, x2, cst_cephes_exp_q3);
  614|      0|
  615|      0|  // I don't really get this bit, copied from the SSE2 routines, so...
  616|      0|  // TODO(gonnet): Figure out what is going on here, perhaps find a better
  617|      0|  // rational interpolant?
  618|      0|  x = pdiv(px, psub(qx, px));
  619|      0|  x = pmadd(cst_2, x, cst_1);
  620|      0|
  621|      0|  // Construct the result 2^n * exp(g) = e * x. The max is used to catch
  622|      0|  // non-finite values in the input.
  623|      0|  const Packet fast_pldexp_unsafe = pcmp_lt(cst_pldexp_threshold, pabs(_x));
  624|      0|  if (!predux_any(fast_pldexp_unsafe)) {
  625|      0|    // For |x| <= 708, we know the result is not zero or inf, and we can safely use
  626|      0|    // the fast version of pldexp.
  627|      0|    return pmax(pldexp_fast(x, fx), _x);
  628|      0|  }
  629|      0|  return pselect(zero_mask, cst_zero, pmax(pldexp(x, fx), _x));
  630|      0|}
  631|       |
  632|       |// The following code is inspired by the following stack-overflow answer:
  633|       |//   https://stackoverflow.com/questions/30463616/payne-hanek-algorithm-implementation-in-c/30465751#30465751
  634|       |// It has been largely optimized:
  635|       |//  - By-pass calls to frexp.
  636|       |//  - Aligned loads of required 96 bits of 2/pi. This is accomplished by
  637|       |//    (1) balancing the mantissa and exponent to the required bits of 2/pi are
  638|       |//    aligned on 8-bits, and (2) replicating the storage of the bits of 2/pi.
  639|       |//  - Avoid a branch in rounding and extraction of the remaining fractional part.
  640|       |// Overall, I measured a speed up higher than x2 on x86-64.
  641|      0|inline float trig_reduce_huge(float xf, Eigen::numext::int32_t* quadrant) {
  642|      0|  using Eigen::numext::int32_t;
  643|      0|  using Eigen::numext::int64_t;
  644|      0|  using Eigen::numext::uint32_t;
  645|      0|  using Eigen::numext::uint64_t;
  646|      0|
  647|      0|  const double pio2_62 = 3.4061215800865545e-19;     // pi/2 * 2^-62
  648|      0|  const uint64_t zero_dot_five = uint64_t(1) << 61;  // 0.5 in 2.62-bit fixed-point format
  649|      0|
  650|      0|  // 192 bits of 2/pi for Payne-Hanek reduction
  651|      0|  // Bits are introduced by packet of 8 to enable aligned reads.
  652|      0|  static const uint32_t two_over_pi[] = {
  653|      0|      0x00000028, 0x000028be, 0x0028be60, 0x28be60db, 0xbe60db93, 0x60db9391, 0xdb939105, 0x9391054a, 0x91054a7f,
  654|      0|      0x054a7f09, 0x4a7f09d5, 0x7f09d5f4, 0x09d5f47d, 0xd5f47d4d, 0xf47d4d37, 0x7d4d3770, 0x4d377036, 0x377036d8,
  655|      0|      0x7036d8a5, 0x36d8a566, 0xd8a5664f, 0xa5664f10, 0x664f10e4, 0x4f10e410, 0x10e41000, 0xe4100000};
  656|      0|
  657|      0|  uint32_t xi = numext::bit_cast<uint32_t>(xf);
  658|      0|  // Below, -118 = -126 + 8.
  659|      0|  //   -126 is to get the exponent,
  660|      0|  //   +8 is to enable alignment of 2/pi's bits on 8 bits.
  661|      0|  // This is possible because the fractional part of x as only 24 meaningful bits.
  662|      0|  uint32_t e = (xi >> 23) - 118;
  663|      0|  // Extract the mantissa and shift it to align it wrt the exponent
  664|      0|  xi = ((xi & 0x007fffffu) | 0x00800000u) << (e & 0x7);
  665|      0|
  666|      0|  uint32_t i = e >> 3;
  667|      0|  uint32_t twoopi_1 = two_over_pi[i - 1];
  668|      0|  uint32_t twoopi_2 = two_over_pi[i + 3];
  669|      0|  uint32_t twoopi_3 = two_over_pi[i + 7];
  670|      0|
  671|      0|  // Compute x * 2/pi in 2.62-bit fixed-point format.
  672|      0|  uint64_t p;
  673|      0|  p = uint64_t(xi) * twoopi_3;
  674|      0|  p = uint64_t(xi) * twoopi_2 + (p >> 32);
  675|      0|  p = (uint64_t(xi * twoopi_1) << 32) + p;
  676|      0|
  677|      0|  // Round to nearest: add 0.5 and extract integral part.
  678|      0|  uint64_t q = (p + zero_dot_five) >> 62;
  679|      0|  *quadrant = int(q);
  680|      0|  // Now it remains to compute "r = x - q*pi/2" with high accuracy,
  681|      0|  // since we have p=x/(pi/2) with high accuracy, we can more efficiently compute r as:
  682|      0|  //   r = (p-q)*pi/2,
  683|      0|  // where the product can be be carried out with sufficient accuracy using double precision.
  684|      0|  p -= q << 62;
  685|      0|  return float(double(int64_t(p)) * pio2_62);
  686|      0|}
  687|       |
  688|       |template <bool ComputeSine, typename Packet, bool ComputeBoth = false>
  689|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
  690|       |#if EIGEN_COMP_GNUC_STRICT
  691|       |    __attribute__((optimize("-fno-unsafe-math-optimizations")))
  692|       |#endif
  693|       |    Packet
  694|      0|    psincos_float(const Packet& _x) {
  695|      0|  typedef typename unpacket_traits<Packet>::integer_packet PacketI;
  696|      0|
  697|      0|  const Packet cst_2oPI = pset1<Packet>(0.636619746685028076171875f);  // 2/PI
  698|      0|  const Packet cst_rounding_magic = pset1<Packet>(12582912);           // 2^23 for rounding
  699|      0|  const PacketI csti_1 = pset1<PacketI>(1);
  700|      0|  const Packet cst_sign_mask = pset1frombits<Packet>(static_cast<Eigen::numext::uint32_t>(0x80000000u));
  701|      0|
  702|      0|  Packet x = pabs(_x);
  703|      0|
  704|      0|  // Scale x by 2/Pi to find x's octant.
  705|      0|  Packet y = pmul(x, cst_2oPI);
  706|      0|
  707|      0|  // Rounding trick to find nearest integer:
  708|      0|  Packet y_round = padd(y, cst_rounding_magic);
  709|      0|  EIGEN_OPTIMIZATION_BARRIER(y_round)
  710|      0|  PacketI y_int = preinterpret<PacketI>(y_round);  // last 23 digits represent integer (if abs(x)<2^24)
  711|      0|  y = psub(y_round, cst_rounding_magic);           // nearest integer to x * (2/pi)
  712|      0|
  713|      0|// Subtract y * Pi/2 to reduce x to the interval -Pi/4 <= x <= +Pi/4
  714|      0|// using "Extended precision modular arithmetic"
  715|      0|#if defined(EIGEN_VECTORIZE_FMA)
  716|      0|  // This version requires true FMA for high accuracy.
  717|      0|  // It provides a max error of 1ULP up to (with absolute_error < 5.9605e-08):
  718|      0|  const float huge_th = ComputeSine ? 117435.992f : 71476.0625f;
  719|      0|  x = pmadd(y, pset1<Packet>(-1.57079601287841796875f), x);
  720|      0|  x = pmadd(y, pset1<Packet>(-3.1391647326017846353352069854736328125e-07f), x);
  721|      0|  x = pmadd(y, pset1<Packet>(-5.390302529957764765544681040410068817436695098876953125e-15f), x);
  722|      0|#else
  723|      0|  // Without true FMA, the previous set of coefficients maintain 1ULP accuracy
  724|      0|  // up to x<15.7 (for sin), but accuracy is immediately lost for x>15.7.
  725|      0|  // We thus use one more iteration to maintain 2ULPs up to reasonably large inputs.
  726|      0|
  727|      0|  // The following set of coefficients maintain 1ULP up to 9.43 and 14.16 for sin and cos respectively.
  728|      0|  // and 2 ULP up to:
  729|      0|  const float huge_th = ComputeSine ? 25966.f : 18838.f;
  730|      0|  x = pmadd(y, pset1<Packet>(-1.5703125), x);  // = 0xbfc90000
  731|      0|  EIGEN_OPTIMIZATION_BARRIER(x)
  732|      0|  x = pmadd(y, pset1<Packet>(-0.000483989715576171875), x);  // = 0xb9fdc000
  733|      0|  EIGEN_OPTIMIZATION_BARRIER(x)
  734|      0|  x = pmadd(y, pset1<Packet>(1.62865035235881805419921875e-07), x);                      // = 0x342ee000
  735|      0|  x = pmadd(y, pset1<Packet>(5.5644315544167710640977020375430583953857421875e-11), x);  // = 0x2e74b9ee
  736|      0|
  737|      0|// For the record, the following set of coefficients maintain 2ULP up
  738|      0|// to a slightly larger range:
  739|      0|// const float huge_th = ComputeSine ? 51981.f : 39086.125f;
  740|      0|// but it slightly fails to maintain 1ULP for two values of sin below pi.
  741|      0|// x = pmadd(y, pset1<Packet>(-3.140625/2.), x);
  742|      0|// x = pmadd(y, pset1<Packet>(-0.00048351287841796875), x);
  743|      0|// x = pmadd(y, pset1<Packet>(-3.13855707645416259765625e-07), x);
  744|      0|// x = pmadd(y, pset1<Packet>(-6.0771006282767103812147979624569416046142578125e-11), x);
  745|      0|
  746|      0|// For the record, with only 3 iterations it is possible to maintain
  747|      0|// 1 ULP up to 3PI (maybe more) and 2ULP up to 255.
  748|      0|// The coefficients are: 0xbfc90f80, 0xb7354480, 0x2e74b9ee
  749|      0|#endif
  750|      0|
  751|      0|  if (predux_any(pcmp_le(pset1<Packet>(huge_th), pabs(_x)))) {
  752|      0|    const int PacketSize = unpacket_traits<Packet>::size;
  753|      0|    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) float vals[PacketSize];
  754|      0|    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) float x_cpy[PacketSize];
  755|      0|    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Eigen::numext::int32_t y_int2[PacketSize];
  756|      0|    pstoreu(vals, pabs(_x));
  757|      0|    pstoreu(x_cpy, x);
  758|      0|    pstoreu(y_int2, y_int);
  759|      0|    for (int k = 0; k < PacketSize; ++k) {
  760|      0|      float val = vals[k];
  761|      0|      if (val >= huge_th && (numext::isfinite)(val)) x_cpy[k] = trig_reduce_huge(val, &y_int2[k]);
  762|      0|    }
  763|      0|    x = ploadu<Packet>(x_cpy);
  764|      0|    y_int = ploadu<PacketI>(y_int2);
  765|      0|  }
  766|      0|
  767|      0|  // Compute the sign to apply to the polynomial.
  768|      0|  // sin: sign = second_bit(y_int) xor signbit(_x)
  769|      0|  // cos: sign = second_bit(y_int+1)
  770|      0|  Packet sign_bit = ComputeSine ? pxor(_x, preinterpret<Packet>(plogical_shift_left<30>(y_int)))
  771|      0|                                : preinterpret<Packet>(plogical_shift_left<30>(padd(y_int, csti_1)));
  772|      0|  sign_bit = pand(sign_bit, cst_sign_mask);  // clear all but left most bit
  773|      0|
  774|      0|  // Get the polynomial selection mask from the second bit of y_int
  775|      0|  // We'll calculate both (sin and cos) polynomials and then select from the two.
  776|      0|  Packet poly_mask = preinterpret<Packet>(pcmp_eq(pand(y_int, csti_1), pzero(y_int)));
  777|      0|
  778|      0|  Packet x2 = pmul(x, x);
  779|      0|
  780|      0|  // Evaluate the cos(x) polynomial. (-Pi/4 <= x <= Pi/4)
  781|      0|  Packet y1 = pset1<Packet>(2.4372266125283204019069671630859375e-05f);
  782|      0|  y1 = pmadd(y1, x2, pset1<Packet>(-0.00138865201734006404876708984375f));
  783|      0|  y1 = pmadd(y1, x2, pset1<Packet>(0.041666619479656219482421875f));
  784|      0|  y1 = pmadd(y1, x2, pset1<Packet>(-0.5f));
  785|      0|  y1 = pmadd(y1, x2, pset1<Packet>(1.f));
  786|      0|
  787|      0|  // Evaluate the sin(x) polynomial. (Pi/4 <= x <= Pi/4)
  788|      0|  // octave/matlab code to compute those coefficients:
  789|      0|  //    x = (0:0.0001:pi/4)';
  790|      0|  //    A = [x.^3 x.^5 x.^7];
  791|      0|  //    w = ((1.-(x/(pi/4)).^2).^5)*2000+1;         # weights trading relative accuracy
  792|      0|  //    c = (A'*diag(w)*A)\(A'*diag(w)*(sin(x)-x)); # weighted LS, linear coeff forced to 1
  793|      0|  //    printf('%.64f\n %.64f\n%.64f\n', c(3), c(2), c(1))
  794|      0|  //
  795|      0|  Packet y2 = pset1<Packet>(-0.0001959234114083702898469196984621021329076029360294342041015625f);
  796|      0|  y2 = pmadd(y2, x2, pset1<Packet>(0.0083326873655616851693794799871284340042620897293090820312500000f));
  797|      0|  y2 = pmadd(y2, x2, pset1<Packet>(-0.1666666203982298255503735617821803316473960876464843750000000000f));
  798|      0|  y2 = pmul(y2, x2);
  799|      0|  y2 = pmadd(y2, x, x);
  800|      0|
  801|      0|  // Select the correct result from the two polynomials.
  802|      0|  if (ComputeBoth) {
  803|      0|    Packet peven = peven_mask(x);
  804|      0|    Packet ysin = pselect(poly_mask, y2, y1);
  805|      0|    Packet ycos = pselect(poly_mask, y1, y2);
  806|      0|    Packet sign_bit_sin = pxor(_x, preinterpret<Packet>(plogical_shift_left<30>(y_int)));
  807|      0|    Packet sign_bit_cos = preinterpret<Packet>(plogical_shift_left<30>(padd(y_int, csti_1)));
  808|      0|    sign_bit_sin = pand(sign_bit_sin, cst_sign_mask);  // clear all but left most bit
  809|      0|    sign_bit_cos = pand(sign_bit_cos, cst_sign_mask);  // clear all but left most bit
  810|      0|    y = pselect(peven, pxor(ysin, sign_bit_sin), pxor(ycos, sign_bit_cos));
  811|      0|  } else {
  812|      0|    y = ComputeSine ? pselect(poly_mask, y2, y1) : pselect(poly_mask, y1, y2);
  813|      0|    y = pxor(y, sign_bit);
  814|      0|  }
  815|      0|  // Update the sign and filter huge inputs
  816|      0|  return y;
  817|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13psincos_floatILb1EDv4_fLb0EEET0_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13psincos_floatILb0EDv4_fLb0EEET0_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13psincos_floatILb0EDv4_fLb1EEET0_RKS3_
  ------------------
  818|       |
  819|       |template <typename Packet>
  820|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psin_float(const Packet& x) {
  821|      0|  return psincos_float<true>(x);
  822|      0|}
  823|       |
  824|       |template <typename Packet>
  825|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcos_float(const Packet& x) {
  826|      0|  return psincos_float<false>(x);
  827|      0|}
  828|       |
  829|       |// Trigonometric argument reduction for double for inputs smaller than 15.
  830|       |// Reduces trigonometric arguments for double inputs where x < 15. Given an argument x and its corresponding quadrant
  831|       |// count n, the function computes and returns the reduced argument t such that x = n * pi/2 + t.
  832|       |template <typename Packet>
  833|      0|Packet trig_reduce_small_double(const Packet& x, const Packet& q) {
  834|      0|  // Pi/2 split into 2 values
  835|      0|  const Packet cst_pio2_a = pset1<Packet>(-1.570796325802803);
  836|      0|  const Packet cst_pio2_b = pset1<Packet>(-9.920935184482005e-10);
  837|      0|
  838|      0|  Packet t;
  839|      0|  t = pmadd(cst_pio2_a, q, x);
  840|      0|  t = pmadd(cst_pio2_b, q, t);
  841|      0|  return t;
  842|      0|}
  843|       |
  844|       |// Trigonometric argument reduction for double for inputs smaller than 1e14.
  845|       |// Reduces trigonometric arguments for double inputs where x < 1e14. Given an argument x and its corresponding quadrant
  846|       |// count n, the function computes and returns the reduced argument t such that x = n * pi/2 + t.
  847|       |template <typename Packet>
  848|      0|Packet trig_reduce_medium_double(const Packet& x, const Packet& q_high, const Packet& q_low) {
  849|      0|  // Pi/2 split into 4 values
  850|      0|  const Packet cst_pio2_a = pset1<Packet>(-1.570796325802803);
  851|      0|  const Packet cst_pio2_b = pset1<Packet>(-9.920935184482005e-10);
  852|      0|  const Packet cst_pio2_c = pset1<Packet>(-6.123234014771656e-17);
  853|      0|  const Packet cst_pio2_d = pset1<Packet>(1.903488962019325e-25);
  854|      0|
  855|      0|  Packet t;
  856|      0|  t = pmadd(cst_pio2_a, q_high, x);
  857|      0|  t = pmadd(cst_pio2_a, q_low, t);
  858|      0|  t = pmadd(cst_pio2_b, q_high, t);
  859|      0|  t = pmadd(cst_pio2_b, q_low, t);
  860|      0|  t = pmadd(cst_pio2_c, q_high, t);
  861|      0|  t = pmadd(cst_pio2_c, q_low, t);
  862|      0|  t = pmadd(cst_pio2_d, padd(q_low, q_high), t);
  863|      0|  return t;
  864|      0|}
  865|       |
  866|       |template <bool ComputeSine, typename Packet, bool ComputeBoth = false>
  867|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
  868|       |#if EIGEN_COMP_GNUC_STRICT
  869|       |    __attribute__((optimize("-fno-unsafe-math-optimizations")))
  870|       |#endif
  871|       |    Packet
  872|      0|    psincos_double(const Packet& x) {
  873|      0|  typedef typename unpacket_traits<Packet>::integer_packet PacketI;
  874|      0|  typedef typename unpacket_traits<PacketI>::type ScalarI;
  875|      0|
  876|      0|  const Packet cst_sign_mask = pset1frombits<Packet>(static_cast<Eigen::numext::uint64_t>(0x8000000000000000u));
  877|      0|
  878|      0|  // If the argument is smaller than this value, use a simpler argument reduction
  879|      0|  const double small_th = 15;
  880|      0|  // If the argument is bigger than this value, use the non-vectorized std version
  881|      0|  const double huge_th = 1e14;
  882|      0|
  883|      0|  const Packet cst_2oPI = pset1<Packet>(0.63661977236758134307553505349006);  // 2/PI
  884|      0|  // Integer Packet constants
  885|      0|  const PacketI cst_one = pset1<PacketI>(ScalarI(1));
  886|      0|  // Constant for splitting
  887|      0|  const Packet cst_split = pset1<Packet>(1 << 24);
  888|      0|
  889|      0|  Packet x_abs = pabs(x);
  890|      0|
  891|      0|  // Scale x by 2/Pi
  892|      0|  PacketI q_int;
  893|      0|  Packet s;
  894|      0|
  895|      0|  // TODO Implement huge angle argument reduction
  896|      0|  if (EIGEN_PREDICT_FALSE(predux_any(pcmp_le(pset1<Packet>(small_th), x_abs)))) {
  897|      0|    Packet q_high = pmul(pfloor(pmul(x_abs, pdiv(cst_2oPI, cst_split))), cst_split);
  898|      0|    Packet q_low_noround = psub(pmul(x_abs, cst_2oPI), q_high);
  899|      0|    q_int = pcast<Packet, PacketI>(padd(q_low_noround, pset1<Packet>(0.5)));
  900|      0|    Packet q_low = pcast<PacketI, Packet>(q_int);
  901|      0|    s = trig_reduce_medium_double(x_abs, q_high, q_low);
  902|      0|  } else {
  903|      0|    Packet qval_noround = pmul(x_abs, cst_2oPI);
  904|      0|    q_int = pcast<Packet, PacketI>(padd(qval_noround, pset1<Packet>(0.5)));
  905|      0|    Packet q = pcast<PacketI, Packet>(q_int);
  906|      0|    s = trig_reduce_small_double(x_abs, q);
  907|      0|  }
  908|      0|
  909|      0|  // All the upcoming approximating polynomials have even exponents
  910|      0|  Packet ss = pmul(s, s);
  911|      0|
  912|      0|  // Pad approximant of cos(x)
  913|      0|  // Assuring < 1 ULP error on the interval [-pi/4, pi/4]
  914|      0|  // cos(x) ~= (80737373*x^8 - 13853547000*x^6 + 727718024880*x^4 - 11275015752000*x^2 + 23594700729600)/(147173*x^8 +
  915|      0|  // 39328920*x^6 + 5772800880*x^4 + 522334612800*x^2 + 23594700729600)
  916|      0|  // MATLAB code to compute those coefficients:
  917|      0|  //    syms x;
  918|      0|  //    cosf = @(x) cos(x);
  919|      0|  //    pade_cosf = pade(cosf(x), x, 0, 'Order', 8)
  920|      0|  Packet sc1_num = pmadd(ss, pset1<Packet>(80737373), pset1<Packet>(-13853547000));
  921|      0|  Packet sc2_num = pmadd(sc1_num, ss, pset1<Packet>(727718024880));
  922|      0|  Packet sc3_num = pmadd(sc2_num, ss, pset1<Packet>(-11275015752000));
  923|      0|  Packet sc4_num = pmadd(sc3_num, ss, pset1<Packet>(23594700729600));
  924|      0|  Packet sc1_denum = pmadd(ss, pset1<Packet>(147173), pset1<Packet>(39328920));
  925|      0|  Packet sc2_denum = pmadd(sc1_denum, ss, pset1<Packet>(5772800880));
  926|      0|  Packet sc3_denum = pmadd(sc2_denum, ss, pset1<Packet>(522334612800));
  927|      0|  Packet sc4_denum = pmadd(sc3_denum, ss, pset1<Packet>(23594700729600));
  928|      0|  Packet scos = pdiv(sc4_num, sc4_denum);
  929|      0|
  930|      0|  // Pad approximant of sin(x)
  931|      0|  // Assuring < 1 ULP error on the interval [-pi/4, pi/4]
  932|      0|  // sin(x) ~= (x*(4585922449*x^8 - 1066023933480*x^6 + 83284044283440*x^4 - 2303682236856000*x^2 +
  933|      0|  // 15605159573203200))/(45*(1029037*x^8 + 345207016*x^6 + 61570292784*x^4 + 6603948711360*x^2 + 346781323848960))
  934|      0|  // MATLAB code to compute those coefficients:
  935|      0|  //    syms x;
  936|      0|  //    sinf = @(x) sin(x);
  937|      0|  //    pade_sinf = pade(sinf(x), x, 0, 'Order', 8, 'OrderMode', 'relative')
  938|      0|  Packet ss1_num = pmadd(ss, pset1<Packet>(4585922449), pset1<Packet>(-1066023933480));
  939|      0|  Packet ss2_num = pmadd(ss1_num, ss, pset1<Packet>(83284044283440));
  940|      0|  Packet ss3_num = pmadd(ss2_num, ss, pset1<Packet>(-2303682236856000));
  941|      0|  Packet ss4_num = pmadd(ss3_num, ss, pset1<Packet>(15605159573203200));
  942|      0|  Packet ss1_denum = pmadd(ss, pset1<Packet>(1029037), pset1<Packet>(345207016));
  943|      0|  Packet ss2_denum = pmadd(ss1_denum, ss, pset1<Packet>(61570292784));
  944|      0|  Packet ss3_denum = pmadd(ss2_denum, ss, pset1<Packet>(6603948711360));
  945|      0|  Packet ss4_denum = pmadd(ss3_denum, ss, pset1<Packet>(346781323848960));
  946|      0|  Packet ssin = pdiv(pmul(s, ss4_num), pmul(pset1<Packet>(45), ss4_denum));
  947|      0|
  948|      0|  Packet poly_mask = preinterpret<Packet>(pcmp_eq(pand(q_int, cst_one), pzero(q_int)));
  949|      0|
  950|      0|  Packet sign_sin = pxor(x, preinterpret<Packet>(plogical_shift_left<62>(q_int)));
  951|      0|  Packet sign_cos = preinterpret<Packet>(plogical_shift_left<62>(padd(q_int, cst_one)));
  952|      0|  Packet sign_bit, sFinalRes;
  953|      0|  if (ComputeBoth) {
  954|      0|    Packet peven = peven_mask(x);
  955|      0|    sign_bit = pselect((s), sign_sin, sign_cos);
  956|      0|    sFinalRes = pselect(pxor(peven, poly_mask), ssin, scos);
  957|      0|  } else {
  958|      0|    sign_bit = ComputeSine ? sign_sin : sign_cos;
  959|      0|    sFinalRes = ComputeSine ? pselect(poly_mask, ssin, scos) : pselect(poly_mask, scos, ssin);
  960|      0|  }
  961|      0|  sign_bit = pand(sign_bit, cst_sign_mask);  // clear all but left most bit
  962|      0|  sFinalRes = pxor(sFinalRes, sign_bit);
  963|      0|
  964|      0|  // If the inputs values are higher than that a value that the argument reduction can currently address, compute them
  965|      0|  // using std::sin and std::cos
  966|      0|  // TODO Remove it when huge angle argument reduction is implemented
  967|      0|  if (EIGEN_PREDICT_FALSE(predux_any(pcmp_le(pset1<Packet>(huge_th), x_abs)))) {
  968|      0|    const int PacketSize = unpacket_traits<Packet>::size;
  969|      0|    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) double sincos_vals[PacketSize];
  970|      0|    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) double x_cpy[PacketSize];
  971|      0|    pstoreu(x_cpy, x);
  972|      0|    pstoreu(sincos_vals, sFinalRes);
  973|      0|    for (int k = 0; k < PacketSize; ++k) {
  974|      0|      double val = x_cpy[k];
  975|      0|      if (std::abs(val) > huge_th && (numext::isfinite)(val)) {
  976|      0|        if (ComputeBoth)
  977|      0|          sincos_vals[k] = k % 2 == 0 ? std::sin(val) : std::cos(val);
  978|      0|        else
  979|      0|          sincos_vals[k] = ComputeSine ? std::sin(val) : std::cos(val);
  980|      0|      }
  981|      0|    }
  982|      0|    sFinalRes = ploadu<Packet>(sincos_vals);
  983|      0|  }
  984|      0|  return sFinalRes;
  985|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14psincos_doubleILb1EDv2_dLb0EEET0_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14psincos_doubleILb0EDv2_dLb0EEET0_RKS3_
  ------------------
  986|       |
  987|       |template <typename Packet>
  988|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psin_double(const Packet& x) {
  989|      0|  return psincos_double<true>(x);
  990|      0|}
  991|       |
  992|       |template <typename Packet>
  993|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcos_double(const Packet& x) {
  994|      0|  return psincos_double<false>(x);
  995|      0|}
  996|       |
  997|       |// Generic implementation of acos(x).
  998|       |template <typename Packet>
  999|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pacos_float(const Packet& x_in) {
 1000|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1001|      0|  static_assert(std::is_same<Scalar, float>::value, "Scalar type must be float");
 1002|      0|
 1003|      0|  const Packet cst_one = pset1<Packet>(Scalar(1));
 1004|      0|  const Packet cst_pi = pset1<Packet>(Scalar(EIGEN_PI));
 1005|      0|  const Packet p6 = pset1<Packet>(Scalar(2.36423197202384471893310546875e-3));
 1006|      0|  const Packet p5 = pset1<Packet>(Scalar(-1.1368644423782825469970703125e-2));
 1007|      0|  const Packet p4 = pset1<Packet>(Scalar(2.717843465507030487060546875e-2));
 1008|      0|  const Packet p3 = pset1<Packet>(Scalar(-4.8969544470310211181640625e-2));
 1009|      0|  const Packet p2 = pset1<Packet>(Scalar(8.8804088532924652099609375e-2));
 1010|      0|  const Packet p1 = pset1<Packet>(Scalar(-0.214591205120086669921875));
 1011|      0|  const Packet p0 = pset1<Packet>(Scalar(1.57079637050628662109375));
 1012|      0|
 1013|      0|  // For x in [0:1], we approximate acos(x)/sqrt(1-x), which is a smooth
 1014|      0|  // function, by a 6'th order polynomial.
 1015|      0|  // For x in [-1:0) we use that acos(-x) = pi - acos(x).
 1016|      0|  const Packet neg_mask = psignbit(x_in);
 1017|      0|  const Packet abs_x = pabs(x_in);
 1018|      0|
 1019|      0|  // Evaluate the polynomial using Horner's rule:
 1020|      0|  //   P(x) = p0 + x * (p1 +  x * (p2 + ... (p5 + x * p6)) ... ) .
 1021|      0|  // We evaluate even and odd terms independently to increase
 1022|      0|  // instruction level parallelism.
 1023|      0|  Packet x2 = pmul(x_in, x_in);
 1024|      0|  Packet p_even = pmadd(p6, x2, p4);
 1025|      0|  Packet p_odd = pmadd(p5, x2, p3);
 1026|      0|  p_even = pmadd(p_even, x2, p2);
 1027|      0|  p_odd = pmadd(p_odd, x2, p1);
 1028|      0|  p_even = pmadd(p_even, x2, p0);
 1029|      0|  Packet p = pmadd(p_odd, abs_x, p_even);
 1030|      0|
 1031|      0|  // The polynomial approximates acos(x)/sqrt(1-x), so
 1032|      0|  // multiply by sqrt(1-x) to get acos(x).
 1033|      0|  // Conveniently returns NaN for arguments outside [-1:1].
 1034|      0|  Packet denom = psqrt(psub(cst_one, abs_x));
 1035|      0|  Packet result = pmul(denom, p);
 1036|      0|  // Undo mapping for negative arguments.
 1037|      0|  return pselect(neg_mask, psub(cst_pi, result), result);
 1038|      0|}
 1039|       |
 1040|       |// Generic implementation of asin(x).
 1041|       |template <typename Packet>
 1042|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pasin_float(const Packet& x_in) {
 1043|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1044|      0|  static_assert(std::is_same<Scalar, float>::value, "Scalar type must be float");
 1045|      0|
 1046|      0|  constexpr float kPiOverTwo = static_cast<float>(EIGEN_PI / 2);
 1047|      0|
 1048|      0|  const Packet cst_half = pset1<Packet>(0.5f);
 1049|      0|  const Packet cst_one = pset1<Packet>(1.0f);
 1050|      0|  const Packet cst_two = pset1<Packet>(2.0f);
 1051|      0|  const Packet cst_pi_over_two = pset1<Packet>(kPiOverTwo);
 1052|      0|
 1053|      0|  const Packet abs_x = pabs(x_in);
 1054|      0|  const Packet sign_mask = pandnot(x_in, abs_x);
 1055|      0|  const Packet invalid_mask = pcmp_lt(cst_one, abs_x);
 1056|      0|
 1057|      0|  // For arguments |x| > 0.5, we map x back to [0:0.5] using
 1058|      0|  // the transformation x_large = sqrt(0.5*(1-x)), and use the
 1059|      0|  // identity
 1060|      0|  //   asin(x) = pi/2 - 2 * asin( sqrt( 0.5 * (1 - x)))
 1061|      0|
 1062|      0|  const Packet x_large = psqrt(pnmadd(cst_half, abs_x, cst_half));
 1063|      0|  const Packet large_mask = pcmp_lt(cst_half, abs_x);
 1064|      0|  const Packet x = pselect(large_mask, x_large, abs_x);
 1065|      0|  const Packet x2 = pmul(x, x);
 1066|      0|
 1067|      0|  // For |x| < 0.5 approximate asin(x)/x by an 8th order polynomial with
 1068|      0|  // even terms only.
 1069|      0|  constexpr float alpha[] = {5.08838854730129241943359375e-2f, 3.95139865577220916748046875e-2f,
 1070|      0|                             7.550220191478729248046875e-2f, 0.16664917767047882080078125f, 1.00000011920928955078125f};
 1071|      0|  Packet p = ppolevl<Packet, 4>::run(x2, alpha);
 1072|      0|  p = pmul(p, x);
 1073|      0|
 1074|      0|  const Packet p_large = pnmadd(cst_two, p, cst_pi_over_two);
 1075|      0|  p = pselect(large_mask, p_large, p);
 1076|      0|  // Flip the sign for negative arguments.
 1077|      0|  p = pxor(p, sign_mask);
 1078|      0|  // Return NaN for arguments outside [-1:1].
 1079|      0|  return por(invalid_mask, p);
 1080|      0|}
 1081|       |
 1082|       |template <typename Scalar>
 1083|       |struct patan_reduced {
 1084|       |  template <typename Packet>
 1085|       |  static EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet run(const Packet& x);
 1086|       |};
 1087|       |
 1088|       |template <>
 1089|       |template <typename Packet>
 1090|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patan_reduced<double>::run(const Packet& x) {
 1091|      0|  constexpr double alpha[] = {2.6667153866462208e-05, 3.0917513112462781e-03, 5.2574296781008604e-02,
 1092|      0|                              3.0409318473444424e-01, 7.5365702534987022e-01, 8.2704055405494614e-01,
 1093|      0|                              3.3004361289279920e-01};
 1094|      0|
 1095|      0|  constexpr double beta[] = {
 1096|      0|      2.7311202462436667e-04, 1.0899150928962708e-02, 1.1548932646420353e-01, 4.9716458728465573e-01, 1.0,
 1097|      0|      9.3705509168587852e-01, 3.3004361289279920e-01};
 1098|      0|
 1099|      0|  Packet x2 = pmul(x, x);
 1100|      0|  Packet p = ppolevl<Packet, 6>::run(x2, alpha);
 1101|      0|  Packet q = ppolevl<Packet, 6>::run(x2, beta);
 1102|      0|  return pmul(x, pdiv(p, q));
 1103|      0|}
 1104|       |
 1105|       |// Computes elementwise atan(x) for x in [-1:1] with 2 ulp accuracy.
 1106|       |template <>
 1107|       |template <typename Packet>
 1108|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patan_reduced<float>::run(const Packet& x) {
 1109|      0|  constexpr float alpha[] = {1.12026982009410858154296875e-01f, 7.296695709228515625e-01f, 8.109951019287109375e-01f};
 1110|      0|
 1111|      0|  constexpr float beta[] = {1.00917108356952667236328125e-02f, 2.8318560123443603515625e-01f, 1.0f,
 1112|      0|                            8.109951019287109375e-01f};
 1113|      0|
 1114|      0|  Packet x2 = pmul(x, x);
 1115|      0|  Packet p = ppolevl<Packet, 2>::run(x2, alpha);
 1116|      0|  Packet q = ppolevl<Packet, 3>::run(x2, beta);
 1117|      0|  return pmul(x, pdiv(p, q));
 1118|      0|}
 1119|       |
 1120|       |template <typename Packet>
 1121|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_atan(const Packet& x_in) {
 1122|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1123|      0|
 1124|      0|  constexpr Scalar kPiOverTwo = static_cast<Scalar>(EIGEN_PI / 2);
 1125|      0|
 1126|      0|  const Packet cst_signmask = pset1<Packet>(-Scalar(0));
 1127|      0|  const Packet cst_one = pset1<Packet>(Scalar(1));
 1128|      0|  const Packet cst_pi_over_two = pset1<Packet>(kPiOverTwo);
 1129|      0|
 1130|      0|  //   "Large": For |x| > 1, use atan(1/x) = sign(x)*pi/2 - atan(x).
 1131|      0|  //   "Small": For |x| <= 1, approximate atan(x) directly by a polynomial
 1132|      0|  //            calculated using Rminimax.
 1133|      0|
 1134|      0|  const Packet abs_x = pabs(x_in);
 1135|      0|  const Packet x_signmask = pand(x_in, cst_signmask);
 1136|      0|  const Packet large_mask = pcmp_lt(cst_one, abs_x);
 1137|      0|  const Packet x = pselect(large_mask, preciprocal(abs_x), abs_x);
 1138|      0|  const Packet p = patan_reduced<Scalar>::run(x);
 1139|      0|  // Apply transformations according to the range reduction masks.
 1140|      0|  Packet result = pselect(large_mask, psub(cst_pi_over_two, p), p);
 1141|      0|  // Return correct sign
 1142|      0|  return pxor(result, x_signmask);
 1143|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12generic_atanIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12generic_atanIDv2_dEET_RKS3_
  ------------------
 1144|       |
 1145|       |/** \internal \returns the hyperbolic tan of \a a (coeff-wise)
 1146|       |    Doesn't do anything fancy, just a 9/8-degree rational interpolant which
 1147|       |    is accurate up to a couple of ulps in the (approximate) range [-8, 8],
 1148|       |    outside of which tanh(x) = +/-1 in single precision. The input is clamped
 1149|       |    to the range [-c, c]. The value c is chosen as the smallest value where
 1150|       |    the approximation evaluates to exactly 1.
 1151|       |
 1152|       |    This implementation works on both scalars and packets.
 1153|       |*/
 1154|       |template <typename T>
 1155|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS T ptanh_float(const T& a_x) {
 1156|      0|  // Clamp the inputs to the range [-c, c] and set everything
 1157|      0|  // outside that range to 1.0. The value c is chosen as the smallest
 1158|      0|  // floating point argument such that the approximation is exactly 1.
 1159|      0|  // This saves clamping the value at the end.
 1160|      0|#ifdef EIGEN_VECTORIZE_FMA
 1161|      0|  const T plus_clamp = pset1<T>(8.01773357391357422f);
 1162|      0|  const T minus_clamp = pset1<T>(-8.01773357391357422f);
 1163|      0|#else
 1164|      0|  const T plus_clamp = pset1<T>(7.90738964080810547f);
 1165|      0|  const T minus_clamp = pset1<T>(-7.90738964080810547f);
 1166|      0|#endif
 1167|      0|  const T x = pmax(pmin(a_x, plus_clamp), minus_clamp);
 1168|      0|
 1169|      0|  // The following rational approximation was generated by rminimax
 1170|      0|  // (https://gitlab.inria.fr/sfilip/rminimax) using the following
 1171|      0|  // command:
 1172|      0|  // $ ratapprox --function="tanh(x)" --dom='[-8.67,8.67]' --num="odd"
 1173|      0|  //   --den="even" --type="[9,8]" --numF="[SG]" --denF="[SG]" --log
 1174|      0|  //   --output=tanhf.sollya --dispCoeff="dec"
 1175|      0|
 1176|      0|  // The monomial coefficients of the numerator polynomial (odd).
 1177|      0|  constexpr float alpha[] = {1.394553628e-8f, 2.102733560e-5f, 3.520756727e-3f, 1.340216100e-1f};
 1178|      0|
 1179|      0|  // The monomial coefficients of the denominator polynomial (even).
 1180|      0|  constexpr float beta[] = {8.015776984e-7f, 3.326951409e-4f, 2.597254514e-2f, 4.673548340e-1f, 1.0f};
 1181|      0|
 1182|      0|  // Since the polynomials are odd/even, we need x^2.
 1183|      0|  const T x2 = pmul(x, x);
 1184|      0|  const T x3 = pmul(x2, x);
 1185|      0|
 1186|      0|  T p = ppolevl<T, 3>::run(x2, alpha);
 1187|      0|  T q = ppolevl<T, 4>::run(x2, beta);
 1188|      0|  // Take advantage of the fact that the constant term in p is 1 to compute
 1189|      0|  // x*(x^2*p + 1) = x^3 * p + x.
 1190|      0|  p = pmadd(x3, p, x);
 1191|      0|
 1192|      0|  // Divide the numerator by the denominator.
 1193|      0|  return pdiv(p, q);
 1194|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11ptanh_floatIfEET_RKS2_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11ptanh_floatIDv4_fEET_RKS3_
  ------------------
 1195|       |
 1196|       |/** \internal \returns the hyperbolic tan of \a a (coeff-wise)
 1197|       |    This uses a 19/18-degree rational interpolant which
 1198|       |    is accurate up to a couple of ulps in the (approximate) range [-18.7, 18.7],
 1199|       |    outside of which tanh(x) = +/-1 in single precision. The input is clamped
 1200|       |    to the range [-c, c]. The value c is chosen as the smallest value where
 1201|       |    the approximation evaluates to exactly 1.
 1202|       |
 1203|       |    This implementation works on both scalars and packets.
 1204|       |*/
 1205|       |template <typename T>
 1206|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS T ptanh_double(const T& a_x) {
 1207|      0|  // Clamp the inputs to the range [-c, c] and set everything
 1208|      0|  // outside that range to 1.0. The value c is chosen as the smallest
 1209|      0|  // floating point argument such that the approximation is exactly 1.
 1210|      0|  // This saves clamping the value at the end.
 1211|      0|#ifdef EIGEN_VECTORIZE_FMA
 1212|      0|  const T plus_clamp = pset1<T>(17.6610191624600077);
 1213|      0|  const T minus_clamp = pset1<T>(-17.6610191624600077);
 1214|      0|#else
 1215|      0|  const T plus_clamp = pset1<T>(17.714196154005176);
 1216|      0|  const T minus_clamp = pset1<T>(-17.714196154005176);
 1217|      0|#endif
 1218|      0|  const T x = pmax(pmin(a_x, plus_clamp), minus_clamp);
 1219|      0|
 1220|      0|  // The following rational approximation was generated by rminimax
 1221|      0|  // (https://gitlab.inria.fr/sfilip/rminimax) using the following
 1222|      0|  // command:
 1223|      0|  // $ ./ratapprox --function="tanh(x)" --dom='[-18.72,18.72]'
 1224|      0|  //   --num="odd" --den="even" --type="[19,18]" --numF="[D]"
 1225|      0|  //   --denF="[D]" --log --output=tanh.sollya --dispCoeff="dec"
 1226|      0|
 1227|      0|  // The monomial coefficients of the numerator polynomial (odd).
 1228|      0|  constexpr double alpha[] = {2.6158007860482230e-23, 7.6534862268749319e-19, 3.1309488231386680e-15,
 1229|      0|                              4.2303918148209176e-12, 2.4618379131293676e-09, 6.8644367682497074e-07,
 1230|      0|                              9.3839087674268880e-05, 5.9809711724441161e-03, 1.5184719640284322e-01};
 1231|      0|
 1232|      0|  // The monomial coefficients of the denominator polynomial (even).
 1233|      0|  constexpr double beta[] = {6.463747022670968018e-21, 5.782506856739003571e-17,
 1234|      0|                             1.293019623712687916e-13, 1.123643448069621992e-10,
 1235|      0|                             4.492975677839633985e-08, 8.785185266237658698e-06,
 1236|      0|                             8.295161192716231542e-04, 3.437448108450402717e-02,
 1237|      0|                             4.851805297361760360e-01, 1.0};
 1238|      0|
 1239|      0|  // Since the polynomials are odd/even, we need x^2.
 1240|      0|  const T x2 = pmul(x, x);
 1241|      0|  const T x3 = pmul(x2, x);
 1242|      0|
 1243|      0|  // Interleave the evaluation of the numerator polynomial p and
 1244|      0|  // denominator polynomial q.
 1245|      0|  T p = ppolevl<T, 8>::run(x2, alpha);
 1246|      0|  T q = ppolevl<T, 9>::run(x2, beta);
 1247|      0|  // Take advantage of the fact that the constant term in p is 1 to compute
 1248|      0|  // x*(x^2*p + 1) = x^3 * p + x.
 1249|      0|  p = pmadd(x3, p, x);
 1250|      0|
 1251|      0|  // Divide the numerator by the denominator.
 1252|      0|  return pdiv(p, q);
 1253|      0|}
 1254|       |
 1255|       |template <typename Packet>
 1256|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patanh_float(const Packet& x) {
 1257|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1258|      0|  static_assert(std::is_same<Scalar, float>::value, "Scalar type must be float");
 1259|      0|
 1260|      0|  // For |x| in [0:0.5] we use a polynomial approximation of the form
 1261|      0|  // P(x) = x + x^3*(alpha[4] + x^2 * (alpha[3] + x^2 * (... x^2 * alpha[0]) ... )).
 1262|      0|  constexpr float alpha[] = {0.1819281280040740966796875f, 8.2311116158962249755859375e-2f,
 1263|      0|                             0.14672131836414337158203125f, 0.1997792422771453857421875f, 0.3333373963832855224609375f};
 1264|      0|  const Packet x2 = pmul(x, x);
 1265|      0|  const Packet x3 = pmul(x, x2);
 1266|      0|  Packet p = ppolevl<Packet, 4>::run(x2, alpha);
 1267|      0|  p = pmadd(x3, p, x);
 1268|      0|
 1269|      0|  // For |x| in ]0.5:1.0] we use atanh = 0.5*ln((1+x)/(1-x));
 1270|      0|  const Packet half = pset1<Packet>(0.5f);
 1271|      0|  const Packet one = pset1<Packet>(1.0f);
 1272|      0|  Packet r = pdiv(padd(one, x), psub(one, x));
 1273|      0|  r = pmul(half, plog(r));
 1274|      0|
 1275|      0|  const Packet x_gt_half = pcmp_le(half, pabs(x));
 1276|      0|  const Packet x_eq_one = pcmp_eq(one, pabs(x));
 1277|      0|  const Packet x_gt_one = pcmp_lt(one, pabs(x));
 1278|      0|  const Packet sign_mask = pset1<Packet>(-0.0f);
 1279|      0|  const Packet x_sign = pand(sign_mask, x);
 1280|      0|  const Packet inf = pset1<Packet>(std::numeric_limits<float>::infinity());
 1281|      0|  return por(x_gt_one, pselect(x_eq_one, por(x_sign, inf), pselect(x_gt_half, r, p)));
 1282|      0|}
 1283|       |
 1284|       |template <typename Packet>
 1285|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patanh_double(const Packet& x) {
 1286|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1287|      0|  static_assert(std::is_same<Scalar, double>::value, "Scalar type must be double");
 1288|      0|  // For x in [-0.5:0.5] we use a rational approximation of the form
 1289|      0|  // R(x) = x + x^3*P(x^2)/Q(x^2), where P is or order 4 and Q is of order 5.
 1290|      0|  constexpr double alpha[] = {3.3071338469301391e-03, -4.7129526768798737e-02, 1.8185306179826699e-01,
 1291|      0|                              -2.5949536095445679e-01, 1.2306328729812676e-01};
 1292|      0|
 1293|      0|  constexpr double beta[] = {-3.8679974580640881e-03, 7.6391885763341910e-02,  -4.2828141436397615e-01,
 1294|      0|                             9.8733495886883648e-01,  -1.0000000000000000e+00, 3.6918986189438030e-01};
 1295|      0|
 1296|      0|  const Packet x2 = pmul(x, x);
 1297|      0|  const Packet x3 = pmul(x, x2);
 1298|      0|  Packet p = ppolevl<Packet, 4>::run(x2, alpha);
 1299|      0|  Packet q = ppolevl<Packet, 5>::run(x2, beta);
 1300|      0|  Packet y_small = pmadd(x3, pdiv(p, q), x);
 1301|      0|
 1302|      0|  // For |x| in ]0.5:1.0] we use atanh = 0.5*ln((1+x)/(1-x));
 1303|      0|  const Packet half = pset1<Packet>(0.5);
 1304|      0|  const Packet one = pset1<Packet>(1.0);
 1305|      0|  Packet y_large = pdiv(padd(one, x), psub(one, x));
 1306|      0|  y_large = pmul(half, plog(y_large));
 1307|      0|
 1308|      0|  const Packet x_gt_half = pcmp_le(half, pabs(x));
 1309|      0|  const Packet x_eq_one = pcmp_eq(one, pabs(x));
 1310|      0|  const Packet x_gt_one = pcmp_lt(one, pabs(x));
 1311|      0|  const Packet sign_mask = pset1<Packet>(-0.0);
 1312|      0|  const Packet x_sign = pand(sign_mask, x);
 1313|      0|  const Packet inf = pset1<Packet>(std::numeric_limits<double>::infinity());
 1314|      0|  return por(x_gt_one, pselect(x_eq_one, por(x_sign, inf), pselect(x_gt_half, y_large, y_small)));
 1315|      0|}
 1316|       |
 1317|       |template <typename Packet>
 1318|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pdiv_complex(const Packet& x, const Packet& y) {
 1319|      0|  typedef typename unpacket_traits<Packet>::as_real RealPacket;
 1320|      0|  // In the following we annotate the code for the case where the inputs
 1321|      0|  // are a pair length-2 SIMD vectors representing a single pair of complex
 1322|      0|  // numbers x = a + i*b, y = c + i*d.
 1323|      0|  const RealPacket y_abs = pabs(y.v);                        // |c|, |d|
 1324|      0|  const RealPacket y_abs_flip = pcplxflip(Packet(y_abs)).v;  // |d|, |c|
 1325|      0|  const RealPacket y_max = pmax(y_abs, y_abs_flip);          // max(|c|, |d|), max(|c|, |d|)
 1326|      0|  const RealPacket y_scaled = pdiv(y.v, y_max);              // c / max(|c|, |d|), d / max(|c|, |d|)
 1327|      0|  // Compute scaled denominator.
 1328|      0|  const RealPacket y_scaled_sq = pmul(y_scaled, y_scaled);  // c'**2, d'**2
 1329|      0|  const RealPacket denom = padd(y_scaled_sq, pcplxflip(Packet(y_scaled_sq)).v);
 1330|      0|  Packet result_scaled = pmul(x, pconj(Packet(y_scaled)));  // a * c' + b * d', -a * d + b * c
 1331|      0|  // Divide elementwise by denom.
 1332|      0|  result_scaled = Packet(pdiv(result_scaled.v, denom));
 1333|      0|  // Rescale result
 1334|      0|  return Packet(pdiv(result_scaled.v, y_max));
 1335|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12pdiv_complexINS0_9Packet2cfEEET_RKS3_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12pdiv_complexINS0_9Packet1cdEEET_RKS3_S5_
  ------------------
 1336|       |
 1337|       |template <typename Packet>
 1338|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_complex(const Packet& x) {
 1339|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1340|      0|  typedef typename Scalar::value_type RealScalar;
 1341|      0|  typedef typename unpacket_traits<Packet>::as_real RealPacket;
 1342|      0|
 1343|      0|  RealPacket real_mask_rp = peven_mask(x.v);
 1344|      0|  Packet real_mask(real_mask_rp);
 1345|      0|
 1346|      0|  // Real part
 1347|      0|  RealPacket x_flip = pcplxflip(x).v;  // b, a
 1348|      0|  Packet x_norm = phypot_complex(x);   // sqrt(a^2 + b^2), sqrt(a^2 + b^2)
 1349|      0|  RealPacket xlogr = plog(x_norm.v);   // log(sqrt(a^2 + b^2)), log(sqrt(a^2 + b^2))
 1350|      0|
 1351|      0|  // Imag part
 1352|      0|  RealPacket ximg = patan2(x.v, x_flip);  // atan2(a, b), atan2(b, a)
 1353|      0|
 1354|      0|  const RealPacket cst_pos_inf = pset1<RealPacket>(NumTraits<RealScalar>::infinity());
 1355|      0|  RealPacket x_abs = pabs(x.v);
 1356|      0|  RealPacket is_x_pos_inf = pcmp_eq(x_abs, cst_pos_inf);
 1357|      0|  RealPacket is_y_pos_inf = pcplxflip(Packet(is_x_pos_inf)).v;
 1358|      0|  RealPacket is_any_inf = por(is_x_pos_inf, is_y_pos_inf);
 1359|      0|  RealPacket xreal = pselect(is_any_inf, cst_pos_inf, xlogr);
 1360|      0|
 1361|      0|  Packet xres = pselect(real_mask, Packet(xreal), Packet(ximg));  // log(sqrt(a^2 + b^2)), atan2(b, a)
 1362|      0|  return xres;
 1363|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12plog_complexINS0_9Packet1cdEEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12plog_complexINS0_9Packet2cfEEET_RKS3_
  ------------------
 1364|       |
 1365|       |template <typename Packet>
 1366|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp_complex(const Packet& a) {
 1367|      0|  typedef typename unpacket_traits<Packet>::as_real RealPacket;
 1368|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1369|      0|  typedef typename Scalar::value_type RealScalar;
 1370|      0|  const RealPacket even_mask = peven_mask(a.v);
 1371|      0|  const RealPacket odd_mask = pcplxflip(Packet(even_mask)).v;
 1372|      0|
 1373|      0|  // Let a = x + iy.
 1374|      0|  // exp(a) = exp(x) * cis(y), plus some special edge-case handling.
 1375|      0|
 1376|      0|  // exp(x):
 1377|      0|  RealPacket x = pand(a.v, even_mask);
 1378|      0|  x = por(x, pcplxflip(Packet(x)).v);
 1379|      0|  RealPacket expx = pexp(x);  // exp(x);
 1380|      0|
 1381|      0|  // cis(y):
 1382|      0|  RealPacket y = pand(odd_mask, a.v);
 1383|      0|  y = por(y, pcplxflip(Packet(y)).v);
 1384|      0|  RealPacket cisy = psincos_float<false, RealPacket, true>(y);
 1385|      0|  cisy = pcplxflip(Packet(cisy)).v;  // cos(y) + i * sin(y)
 1386|      0|
 1387|      0|  const RealPacket cst_pos_inf = pset1<RealPacket>(NumTraits<RealScalar>::infinity());
 1388|      0|  const RealPacket cst_neg_inf = pset1<RealPacket>(-NumTraits<RealScalar>::infinity());
 1389|      0|
 1390|      0|  // If x is -inf, we know that cossin(y) is bounded,
 1391|      0|  //   so the result is (0, +/-0), where the sign of the imaginary part comes
 1392|      0|  //   from the sign of cossin(y).
 1393|      0|  RealPacket cisy_sign = por(pandnot(cisy, pabs(cisy)), pset1<RealPacket>(RealScalar(1)));
 1394|      0|  cisy = pselect(pcmp_eq(x, cst_neg_inf), cisy_sign, cisy);
 1395|      0|
 1396|      0|  // If x is inf, and cos(y) has unknown sign (y is inf or NaN), the result
 1397|      0|  // is (+/-inf, NaN), where the signs are undetermined (take the sign of y).
 1398|      0|  RealPacket y_sign = por(pandnot(y, pabs(y)), pset1<RealPacket>(RealScalar(1)));
 1399|      0|  cisy = pselect(pand(pcmp_eq(x, cst_pos_inf), pisnan(cisy)), pand(y_sign, even_mask), cisy);
 1400|      0|  Packet result = Packet(pmul(expx, cisy));
 1401|      0|
 1402|      0|  // If y is +/- 0, the input is real, so take the real result for consistency.
 1403|      0|  result = pselect(Packet(pcmp_eq(y, pzero(y))), Packet(por(pand(expx, even_mask), pand(y, odd_mask))), result);
 1404|      0|
 1405|      0|  return result;
 1406|      0|}
 1407|       |
 1408|       |template <typename Packet>
 1409|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psqrt_complex(const Packet& a) {
 1410|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1411|      0|  typedef typename Scalar::value_type RealScalar;
 1412|      0|  typedef typename unpacket_traits<Packet>::as_real RealPacket;
 1413|      0|
 1414|      0|  // Computes the principal sqrt of the complex numbers in the input.
 1415|      0|  //
 1416|      0|  // For example, for packets containing 2 complex numbers stored in interleaved format
 1417|      0|  //    a = [a0, a1] = [x0, y0, x1, y1],
 1418|      0|  // where x0 = real(a0), y0 = imag(a0) etc., this function returns
 1419|      0|  //    b = [b0, b1] = [u0, v0, u1, v1],
 1420|      0|  // such that b0^2 = a0, b1^2 = a1.
 1421|      0|  //
 1422|      0|  // To derive the formula for the complex square roots, let's consider the equation for
 1423|      0|  // a single complex square root of the number x + i*y. We want to find real numbers
 1424|      0|  // u and v such that
 1425|      0|  //    (u + i*v)^2 = x + i*y  <=>
 1426|      0|  //    u^2 - v^2 + i*2*u*v = x + i*v.
 1427|      0|  // By equating the real and imaginary parts we get:
 1428|      0|  //    u^2 - v^2 = x
 1429|      0|  //    2*u*v = y.
 1430|      0|  //
 1431|      0|  // For x >= 0, this has the numerically stable solution
 1432|      0|  //    u = sqrt(0.5 * (x + sqrt(x^2 + y^2)))
 1433|      0|  //    v = 0.5 * (y / u)
 1434|      0|  // and for x < 0,
 1435|      0|  //    v = sign(y) * sqrt(0.5 * (-x + sqrt(x^2 + y^2)))
 1436|      0|  //    u = 0.5 * (y / v)
 1437|      0|  //
 1438|      0|  //  To avoid unnecessary over- and underflow, we compute sqrt(x^2 + y^2) as
 1439|      0|  //     l = max(|x|, |y|) * sqrt(1 + (min(|x|, |y|) / max(|x|, |y|))^2) ,
 1440|      0|
 1441|      0|  // In the following, without lack of generality, we have annotated the code, assuming
 1442|      0|  // that the input is a packet of 2 complex numbers.
 1443|      0|  //
 1444|      0|  // Step 1. Compute l = [l0, l0, l1, l1], where
 1445|      0|  //    l0 = sqrt(x0^2 + y0^2),  l1 = sqrt(x1^2 + y1^2)
 1446|      0|  // To avoid over- and underflow, we use the stable formula for each hypotenuse
 1447|      0|  //    l0 = (min0 == 0 ? max0 : max0 * sqrt(1 + (min0/max0)**2)),
 1448|      0|  // where max0 = max(|x0|, |y0|), min0 = min(|x0|, |y0|), and similarly for l1.
 1449|      0|
 1450|      0|  RealPacket a_abs = pabs(a.v);                        // [|x0|, |y0|, |x1|, |y1|]
 1451|      0|  RealPacket a_abs_flip = pcplxflip(Packet(a_abs)).v;  // [|y0|, |x0|, |y1|, |x1|]
 1452|      0|  RealPacket a_max = pmax(a_abs, a_abs_flip);
 1453|      0|  RealPacket a_min = pmin(a_abs, a_abs_flip);
 1454|      0|  RealPacket a_min_zero_mask = pcmp_eq(a_min, pzero(a_min));
 1455|      0|  RealPacket a_max_zero_mask = pcmp_eq(a_max, pzero(a_max));
 1456|      0|  RealPacket r = pdiv(a_min, a_max);
 1457|      0|  const RealPacket cst_one = pset1<RealPacket>(RealScalar(1));
 1458|      0|  RealPacket l = pmul(a_max, psqrt(padd(cst_one, pmul(r, r))));  // [l0, l0, l1, l1]
 1459|      0|  // Set l to a_max if a_min is zero.
 1460|      0|  l = pselect(a_min_zero_mask, a_max, l);
 1461|      0|
 1462|      0|  // Step 2. Compute [rho0, *, rho1, *], where
 1463|      0|  // rho0 = sqrt(0.5 * (l0 + |x0|)), rho1 =  sqrt(0.5 * (l1 + |x1|))
 1464|      0|  // We don't care about the imaginary parts computed here. They will be overwritten later.
 1465|      0|  const RealPacket cst_half = pset1<RealPacket>(RealScalar(0.5));
 1466|      0|  Packet rho;
 1467|      0|  rho.v = psqrt(pmul(cst_half, padd(a_abs, l)));
 1468|      0|
 1469|      0|  // Step 3. Compute [rho0, eta0, rho1, eta1], where
 1470|      0|  // eta0 = (y0 / l0) / 2, and eta1 = (y1 / l1) / 2.
 1471|      0|  // set eta = 0 of input is 0 + i0.
 1472|      0|  RealPacket eta = pandnot(pmul(cst_half, pdiv(a.v, pcplxflip(rho).v)), a_max_zero_mask);
 1473|      0|  RealPacket real_mask = peven_mask(a.v);
 1474|      0|  Packet positive_real_result;
 1475|      0|  // Compute result for inputs with positive real part.
 1476|      0|  positive_real_result.v = pselect(real_mask, rho.v, eta);
 1477|      0|
 1478|      0|  // Step 4. Compute solution for inputs with negative real part:
 1479|      0|  //         [|eta0|, sign(y0)*rho0, |eta1|, sign(y1)*rho1]
 1480|      0|  const RealPacket cst_imag_sign_mask = pset1<Packet>(Scalar(RealScalar(0.0), RealScalar(-0.0))).v;
 1481|      0|  RealPacket imag_signs = pand(a.v, cst_imag_sign_mask);
 1482|      0|  Packet negative_real_result;
 1483|      0|  // Notice that rho is positive, so taking it's absolute value is a noop.
 1484|      0|  negative_real_result.v = por(pabs(pcplxflip(positive_real_result).v), imag_signs);
 1485|      0|
 1486|      0|  // Step 5. Select solution branch based on the sign of the real parts.
 1487|      0|  Packet negative_real_mask;
 1488|      0|  negative_real_mask.v = pcmp_lt(pand(real_mask, a.v), pzero(a.v));
 1489|      0|  negative_real_mask.v = por(negative_real_mask.v, pcplxflip(negative_real_mask).v);
 1490|      0|  Packet result = pselect(negative_real_mask, negative_real_result, positive_real_result);
 1491|      0|
 1492|      0|  // Step 6. Handle special cases for infinities:
 1493|      0|  // * If z is (x,+), the result is (+,+) even if x is NaN
 1494|      0|  // * If z is (x,-), the result is (+,-) even if x is NaN
 1495|      0|  // * If z is (-,y), the result is (0*|y|,+) for finite or NaN y
 1496|      0|  // * If z is (+,y), the result is (+,0*|y|) for finite or NaN y
 1497|      0|  const RealPacket cst_pos_inf = pset1<RealPacket>(NumTraits<RealScalar>::infinity());
 1498|      0|  Packet is_inf;
 1499|      0|  is_inf.v = pcmp_eq(a_abs, cst_pos_inf);
 1500|      0|  Packet is_real_inf;
 1501|      0|  is_real_inf.v = pand(is_inf.v, real_mask);
 1502|      0|  is_real_inf = por(is_real_inf, pcplxflip(is_real_inf));
 1503|      0|  // prepare packet of (+,0*|y|) or (0*|y|,+), depending on the sign of the infinite real part.
 1504|      0|  Packet real_inf_result;
 1505|      0|  real_inf_result.v = pmul(a_abs, pset1<Packet>(Scalar(RealScalar(1.0), RealScalar(0.0))).v);
 1506|      0|  real_inf_result.v = pselect(negative_real_mask.v, pcplxflip(real_inf_result).v, real_inf_result.v);
 1507|      0|  // prepare packet of (+,+) or (+,-), depending on the sign of the infinite imaginary part.
 1508|      0|  Packet is_imag_inf;
 1509|      0|  is_imag_inf.v = pandnot(is_inf.v, real_mask);
 1510|      0|  is_imag_inf = por(is_imag_inf, pcplxflip(is_imag_inf));
 1511|      0|  Packet imag_inf_result;
 1512|      0|  imag_inf_result.v = por(pand(cst_pos_inf, real_mask), pandnot(a.v, real_mask));
 1513|      0|  // unless otherwise specified, if either the real or imaginary component is nan, the entire result is nan
 1514|      0|  Packet result_is_nan = pisnan(result);
 1515|      0|  result = por(result_is_nan, result);
 1516|      0|
 1517|      0|  return pselect(is_imag_inf, imag_inf_result, pselect(is_real_inf, real_inf_result, result));
 1518|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13psqrt_complexINS0_9Packet1cdEEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13psqrt_complexINS0_9Packet2cfEEET_RKS3_
  ------------------
 1519|       |
 1520|       |// \internal \returns the norm of a complex number z = x + i*y, defined as sqrt(x^2 + y^2).
 1521|       |// Implemented using the hypot(a,b) algorithm from https://doi.org/10.48550/arXiv.1904.09481
 1522|       |template <typename Packet>
 1523|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet phypot_complex(const Packet& a) {
 1524|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1525|      0|  typedef typename Scalar::value_type RealScalar;
 1526|      0|  typedef typename unpacket_traits<Packet>::as_real RealPacket;
 1527|      0|
 1528|      0|  const RealPacket cst_zero_rp = pset1<RealPacket>(static_cast<RealScalar>(0.0));
 1529|      0|  const RealPacket cst_minus_one_rp = pset1<RealPacket>(static_cast<RealScalar>(-1.0));
 1530|      0|  const RealPacket cst_two_rp = pset1<RealPacket>(static_cast<RealScalar>(2.0));
 1531|      0|  const RealPacket evenmask = peven_mask(a.v);
 1532|      0|
 1533|      0|  RealPacket a_abs = pabs(a.v);
 1534|      0|  RealPacket a_flip = pcplxflip(Packet(a_abs)).v;       // |b|, |a|
 1535|      0|  RealPacket a_all = pselect(evenmask, a_abs, a_flip);  // |a|, |a|
 1536|      0|  RealPacket b_all = pselect(evenmask, a_flip, a_abs);  // |b|, |b|
 1537|      0|
 1538|      0|  RealPacket a2 = pmul(a.v, a.v);                    // |a^2, b^2|
 1539|      0|  RealPacket a2_flip = pcplxflip(Packet(a2)).v;      // |b^2, a^2|
 1540|      0|  RealPacket h = psqrt(padd(a2, a2_flip));           // |sqrt(a^2 + b^2), sqrt(a^2 + b^2)|
 1541|      0|  RealPacket h_sq = pmul(h, h);                      // |a^2 + b^2, a^2 + b^2|
 1542|      0|  RealPacket a_sq = pselect(evenmask, a2, a2_flip);  // |a^2, a^2|
 1543|      0|  RealPacket m_h_sq = pmul(h_sq, cst_minus_one_rp);
 1544|      0|  RealPacket m_a_sq = pmul(a_sq, cst_minus_one_rp);
 1545|      0|  RealPacket x = psub(psub(pmadd(h, h, m_h_sq), pmadd(b_all, b_all, psub(a_sq, h_sq))), pmadd(a_all, a_all, m_a_sq));
 1546|      0|  h = psub(h, pdiv(x, pmul(cst_two_rp, h)));  // |h - x/(2*h), h - x/(2*h)|
 1547|      0|
 1548|      0|  // handle zero-case
 1549|      0|  RealPacket iszero = pcmp_eq(por(a_abs, a_flip), cst_zero_rp);
 1550|      0|
 1551|      0|  h = pandnot(h, iszero);  // |sqrt(a^2+b^2), sqrt(a^2+b^2)|
 1552|      0|  return Packet(h);        // |sqrt(a^2+b^2), sqrt(a^2+b^2)|
 1553|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14phypot_complexINS0_9Packet1cdEEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14phypot_complexINS0_9Packet2cfEEET_RKS3_
  ------------------
 1554|       |
 1555|       |template <typename Packet>
 1556|       |struct psign_impl<Packet, std::enable_if_t<!NumTraits<typename unpacket_traits<Packet>::type>::IsComplex &&
 1557|       |                                           !NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>> {
 1558|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a) {
 1559|       |    using Scalar = typename unpacket_traits<Packet>::type;
 1560|       |    const Packet cst_one = pset1<Packet>(Scalar(1));
 1561|       |    const Packet cst_zero = pzero(a);
 1562|       |
 1563|       |    const Packet abs_a = pabs(a);
 1564|       |    const Packet sign_mask = pandnot(a, abs_a);
 1565|       |    const Packet nonzero_mask = pcmp_lt(cst_zero, abs_a);
 1566|       |
 1567|       |    return pselect(nonzero_mask, por(sign_mask, cst_one), abs_a);
 1568|       |  }
 1569|       |};
 1570|       |
 1571|       |template <typename Packet>
 1572|       |struct psign_impl<Packet, std::enable_if_t<!NumTraits<typename unpacket_traits<Packet>::type>::IsComplex &&
 1573|       |                                           NumTraits<typename unpacket_traits<Packet>::type>::IsSigned &&
 1574|       |                                           NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>> {
 1575|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a) {
 1576|       |    using Scalar = typename unpacket_traits<Packet>::type;
 1577|       |    const Packet cst_one = pset1<Packet>(Scalar(1));
 1578|       |    const Packet cst_minus_one = pset1<Packet>(Scalar(-1));
 1579|       |    const Packet cst_zero = pzero(a);
 1580|       |
 1581|       |    const Packet positive_mask = pcmp_lt(cst_zero, a);
 1582|       |    const Packet positive = pand(positive_mask, cst_one);
 1583|       |    const Packet negative_mask = pcmp_lt(a, cst_zero);
 1584|       |    const Packet negative = pand(negative_mask, cst_minus_one);
 1585|       |
 1586|       |    return por(positive, negative);
 1587|       |  }
 1588|       |};
 1589|       |
 1590|       |template <typename Packet>
 1591|       |struct psign_impl<Packet, std::enable_if_t<!NumTraits<typename unpacket_traits<Packet>::type>::IsComplex &&
 1592|       |                                           !NumTraits<typename unpacket_traits<Packet>::type>::IsSigned &&
 1593|       |                                           NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>> {
 1594|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a) {
 1595|       |    using Scalar = typename unpacket_traits<Packet>::type;
 1596|       |    const Packet cst_one = pset1<Packet>(Scalar(1));
 1597|       |    const Packet cst_zero = pzero(a);
 1598|       |
 1599|       |    const Packet zero_mask = pcmp_eq(cst_zero, a);
 1600|       |    return pandnot(cst_one, zero_mask);
 1601|       |  }
 1602|       |};
 1603|       |
 1604|       |// \internal \returns the the sign of a complex number z, defined as z / abs(z).
 1605|       |template <typename Packet>
 1606|       |struct psign_impl<Packet, std::enable_if_t<NumTraits<typename unpacket_traits<Packet>::type>::IsComplex &&
 1607|       |                                           unpacket_traits<Packet>::vectorizable>> {
 1608|       |  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a) {
 1609|       |    typedef typename unpacket_traits<Packet>::type Scalar;
 1610|       |    typedef typename Scalar::value_type RealScalar;
 1611|       |    typedef typename unpacket_traits<Packet>::as_real RealPacket;
 1612|       |
 1613|       |    // Step 1. Compute (for each element z = x + i*y in a)
 1614|       |    //     l = abs(z) = sqrt(x^2 + y^2).
 1615|       |    // To avoid over- and underflow, we use the stable formula for each hypotenuse
 1616|       |    //    l = (zmin == 0 ? zmax : zmax * sqrt(1 + (zmin/zmax)**2)),
 1617|       |    // where zmax = max(|x|, |y|), zmin = min(|x|, |y|),
 1618|       |    RealPacket a_abs = pabs(a.v);
 1619|       |    RealPacket a_abs_flip = pcplxflip(Packet(a_abs)).v;
 1620|       |    RealPacket a_max = pmax(a_abs, a_abs_flip);
 1621|       |    RealPacket a_min = pmin(a_abs, a_abs_flip);
 1622|       |    RealPacket a_min_zero_mask = pcmp_eq(a_min, pzero(a_min));
 1623|       |    RealPacket a_max_zero_mask = pcmp_eq(a_max, pzero(a_max));
 1624|       |    RealPacket r = pdiv(a_min, a_max);
 1625|       |    const RealPacket cst_one = pset1<RealPacket>(RealScalar(1));
 1626|       |    RealPacket l = pmul(a_max, psqrt(padd(cst_one, pmul(r, r))));  // [l0, l0, l1, l1]
 1627|       |    // Set l to a_max if a_min is zero, since the roundtrip sqrt(a_max^2) may be
 1628|       |    // lossy.
 1629|       |    l = pselect(a_min_zero_mask, a_max, l);
 1630|       |    // Step 2 compute a / abs(a).
 1631|       |    RealPacket sign_as_real = pandnot(pdiv(a.v, l), a_max_zero_mask);
 1632|       |    Packet sign;
 1633|       |    sign.v = sign_as_real;
 1634|       |    return sign;
 1635|       |  }
 1636|       |};
 1637|       |
 1638|       |// TODO(rmlarsen): The following set of utilities for double word arithmetic
 1639|       |// should perhaps be refactored as a separate file, since it would be generally
 1640|       |// useful for special function implementation etc. Writing the algorithms in
 1641|       |// terms if a double word type would also make the code more readable.
 1642|       |
 1643|       |// This function splits x into the nearest integer n and fractional part r,
 1644|       |// such that x = n + r holds exactly.
 1645|       |template <typename Packet>
 1646|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void absolute_split(const Packet& x, Packet& n, Packet& r) {
 1647|       |  n = pround(x);
 1648|       |  r = psub(x, n);
 1649|       |}
 1650|       |
 1651|       |// This function computes the sum {s, r}, such that x + y = s_hi + s_lo
 1652|       |// holds exactly, and s_hi = fl(x+y), if |x| >= |y|.
 1653|       |template <typename Packet>
 1654|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void fast_twosum(const Packet& x, const Packet& y, Packet& s_hi, Packet& s_lo) {
 1655|       |  s_hi = padd(x, y);
 1656|       |  const Packet t = psub(s_hi, x);
 1657|       |  s_lo = psub(y, t);
 1658|       |}
 1659|       |
 1660|       |#ifdef EIGEN_VECTORIZE_FMA
 1661|       |// This function implements the extended precision product of
 1662|       |// a pair of floating point numbers. Given {x, y}, it computes the pair
 1663|       |// {p_hi, p_lo} such that x * y = p_hi + p_lo holds exactly and
 1664|       |// p_hi = fl(x * y).
 1665|       |template <typename Packet>
 1666|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twoprod(const Packet& x, const Packet& y, Packet& p_hi, Packet& p_lo) {
 1667|       |  p_hi = pmul(x, y);
 1668|       |  p_lo = pmsub(x, y, p_hi);
 1669|       |}
 1670|       |
 1671|       |// A version of twoprod that takes x, y, and fl(x*y) as input and returns the p_lo such that
 1672|       |// x * y = xy + p_lo holds exactly.
 1673|       |template <typename Packet>
 1674|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet twoprod_low(const Packet& x, const Packet& y, const Packet& xy) {
 1675|       |  return pmsub(x, y, xy);
 1676|       |}
 1677|       |
 1678|       |#else
 1679|       |
 1680|       |// This function implements the Veltkamp splitting. Given a floating point
 1681|       |// number x it returns the pair {x_hi, x_lo} such that x_hi + x_lo = x holds
 1682|       |// exactly and that half of the significant of x fits in x_hi.
 1683|       |// This is Algorithm 3 from Jean-Michel Muller, "Elementary Functions",
 1684|       |// 3rd edition, Birkh\"auser, 2016.
 1685|       |template <typename Packet>
 1686|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void veltkamp_splitting(const Packet& x, Packet& x_hi, Packet& x_lo) {
 1687|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 1688|      0|  EIGEN_CONSTEXPR int shift = (NumTraits<Scalar>::digits() + 1) / 2;
 1689|      0|  const Scalar shift_scale = Scalar(uint64_t(1) << shift);  // Scalar constructor not necessarily constexpr.
 1690|      0|  const Packet gamma = pmul(pset1<Packet>(shift_scale + Scalar(1)), x);
 1691|      0|  Packet rho = psub(x, gamma);
 1692|      0|  x_hi = padd(rho, gamma);
 1693|      0|  x_lo = psub(x, x_hi);
 1694|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18veltkamp_splittingIDv4_fEEvRKT_RS3_S6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18veltkamp_splittingIDv2_dEEvRKT_RS3_S6_
  ------------------
 1695|       |
 1696|       |// This function implements Dekker's algorithm for products x * y.
 1697|       |// Given floating point numbers {x, y} computes the pair
 1698|       |// {p_hi, p_lo} such that x * y = p_hi + p_lo holds exactly and
 1699|       |// p_hi = fl(x * y).
 1700|       |template <typename Packet>
 1701|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twoprod(const Packet& x, const Packet& y, Packet& p_hi, Packet& p_lo) {
 1702|      0|  Packet x_hi, x_lo, y_hi, y_lo;
 1703|      0|  veltkamp_splitting(x, x_hi, x_lo);
 1704|      0|  veltkamp_splitting(y, y_hi, y_lo);
 1705|      0|
 1706|      0|  p_hi = pmul(x, y);
 1707|      0|  p_lo = pmadd(x_hi, y_hi, pnegate(p_hi));
 1708|      0|  p_lo = pmadd(x_hi, y_lo, p_lo);
 1709|      0|  p_lo = pmadd(x_lo, y_hi, p_lo);
 1710|      0|  p_lo = pmadd(x_lo, y_lo, p_lo);
 1711|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7twoprodIDv4_fEEvRKT_S5_RS3_S6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal7twoprodIDv2_dEEvRKT_S5_RS3_S6_
  ------------------
 1712|       |
 1713|       |// A version of twoprod that takes x, y, and fl(x*y) as input and returns the p_lo such that
 1714|       |// x * y = xy + p_lo holds exactly.
 1715|       |template <typename Packet>
 1716|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet twoprod_low(const Packet& x, const Packet& y, const Packet& xy) {
 1717|       |  Packet x_hi, x_lo, y_hi, y_lo;
 1718|       |  veltkamp_splitting(x, x_hi, x_lo);
 1719|       |  veltkamp_splitting(y, y_hi, y_lo);
 1720|       |
 1721|       |  Packet p_lo = pmadd(x_hi, y_hi, pnegate(xy));
 1722|       |  p_lo = pmadd(x_hi, y_lo, p_lo);
 1723|       |  p_lo = pmadd(x_lo, y_hi, p_lo);
 1724|       |  p_lo = pmadd(x_lo, y_lo, p_lo);
 1725|       |  return p_lo;
 1726|       |}
 1727|       |
 1728|       |#endif  // EIGEN_VECTORIZE_FMA
 1729|       |
 1730|       |// This function implements Dekker's algorithm for the addition
 1731|       |// of two double word numbers represented by {x_hi, x_lo} and {y_hi, y_lo}.
 1732|       |// It returns the result as a pair {s_hi, s_lo} such that
 1733|       |// x_hi + x_lo + y_hi + y_lo = s_hi + s_lo holds exactly.
 1734|       |// This is Algorithm 5 from Jean-Michel Muller, "Elementary Functions",
 1735|       |// 3rd edition, Birkh\"auser, 2016.
 1736|       |template <typename Packet>
 1737|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twosum(const Packet& x_hi, const Packet& x_lo, const Packet& y_hi,
 1738|       |                                                  const Packet& y_lo, Packet& s_hi, Packet& s_lo) {
 1739|       |  const Packet x_greater_mask = pcmp_lt(pabs(y_hi), pabs(x_hi));
 1740|       |  Packet r_hi_1, r_lo_1;
 1741|       |  fast_twosum(x_hi, y_hi, r_hi_1, r_lo_1);
 1742|       |  Packet r_hi_2, r_lo_2;
 1743|       |  fast_twosum(y_hi, x_hi, r_hi_2, r_lo_2);
 1744|       |  const Packet r_hi = pselect(x_greater_mask, r_hi_1, r_hi_2);
 1745|       |
 1746|       |  const Packet s1 = padd(padd(y_lo, r_lo_1), x_lo);
 1747|       |  const Packet s2 = padd(padd(x_lo, r_lo_2), y_lo);
 1748|       |  const Packet s = pselect(x_greater_mask, s1, s2);
 1749|       |
 1750|       |  fast_twosum(r_hi, s, s_hi, s_lo);
 1751|       |}
 1752|       |
 1753|       |// This is a version of twosum for double word numbers,
 1754|       |// which assumes that |x_hi| >= |y_hi|.
 1755|       |template <typename Packet>
 1756|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void fast_twosum(const Packet& x_hi, const Packet& x_lo, const Packet& y_hi,
 1757|       |                                                       const Packet& y_lo, Packet& s_hi, Packet& s_lo) {
 1758|       |  Packet r_hi, r_lo;
 1759|       |  fast_twosum(x_hi, y_hi, r_hi, r_lo);
 1760|       |  const Packet s = padd(padd(y_lo, r_lo), x_lo);
 1761|       |  fast_twosum(r_hi, s, s_hi, s_lo);
 1762|       |}
 1763|       |
 1764|       |// This is a version of twosum for adding a floating point number x to
 1765|       |// double word number {y_hi, y_lo} number, with the assumption
 1766|       |// that |x| >= |y_hi|.
 1767|       |template <typename Packet>
 1768|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void fast_twosum(const Packet& x, const Packet& y_hi, const Packet& y_lo,
 1769|       |                                                       Packet& s_hi, Packet& s_lo) {
 1770|       |  Packet r_hi, r_lo;
 1771|       |  fast_twosum(x, y_hi, r_hi, r_lo);
 1772|       |  const Packet s = padd(y_lo, r_lo);
 1773|       |  fast_twosum(r_hi, s, s_hi, s_lo);
 1774|       |}
 1775|       |
 1776|       |// This function implements the multiplication of a double word
 1777|       |// number represented by {x_hi, x_lo} by a floating point number y.
 1778|       |// It returns the result as a pair {p_hi, p_lo} such that
 1779|       |// (x_hi + x_lo) * y = p_hi + p_lo hold with a relative error
 1780|       |// of less than 2*2^{-2p}, where p is the number of significand bit
 1781|       |// in the floating point type.
 1782|       |// This is Algorithm 7 from Jean-Michel Muller, "Elementary Functions",
 1783|       |// 3rd edition, Birkh\"auser, 2016.
 1784|       |template <typename Packet>
 1785|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twoprod(const Packet& x_hi, const Packet& x_lo, const Packet& y,
 1786|       |                                                   Packet& p_hi, Packet& p_lo) {
 1787|       |  Packet c_hi, c_lo1;
 1788|       |  twoprod(x_hi, y, c_hi, c_lo1);
 1789|       |  const Packet c_lo2 = pmul(x_lo, y);
 1790|       |  Packet t_hi, t_lo1;
 1791|       |  fast_twosum(c_hi, c_lo2, t_hi, t_lo1);
 1792|       |  const Packet t_lo2 = padd(t_lo1, c_lo1);
 1793|       |  fast_twosum(t_hi, t_lo2, p_hi, p_lo);
 1794|       |}
 1795|       |
 1796|       |// This function implements the multiplication of two double word
 1797|       |// numbers represented by {x_hi, x_lo} and {y_hi, y_lo}.
 1798|       |// It returns the result as a pair {p_hi, p_lo} such that
 1799|       |// (x_hi + x_lo) * (y_hi + y_lo) = p_hi + p_lo holds with a relative error
 1800|       |// of less than 2*2^{-2p}, where p is the number of significand bit
 1801|       |// in the floating point type.
 1802|       |template <typename Packet>
 1803|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twoprod(const Packet& x_hi, const Packet& x_lo, const Packet& y_hi,
 1804|       |                                                   const Packet& y_lo, Packet& p_hi, Packet& p_lo) {
 1805|       |  Packet p_hi_hi, p_hi_lo;
 1806|       |  twoprod(x_hi, x_lo, y_hi, p_hi_hi, p_hi_lo);
 1807|       |  Packet p_lo_hi, p_lo_lo;
 1808|       |  twoprod(x_hi, x_lo, y_lo, p_lo_hi, p_lo_lo);
 1809|       |  fast_twosum(p_hi_hi, p_hi_lo, p_lo_hi, p_lo_lo, p_hi, p_lo);
 1810|       |}
 1811|       |
 1812|       |// This function implements the division of double word {x_hi, x_lo}
 1813|       |// by float y. This is Algorithm 15 from "Tight and rigorous error bounds
 1814|       |// for basic building blocks of double-word arithmetic", Joldes, Muller, & Popescu,
 1815|       |// 2017. https://hal.archives-ouvertes.fr/hal-01351529
 1816|       |template <typename Packet>
 1817|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void doubleword_div_fp(const Packet& x_hi, const Packet& x_lo, const Packet& y,
 1818|       |                                                             Packet& z_hi, Packet& z_lo) {
 1819|       |  const Packet t_hi = pdiv(x_hi, y);
 1820|       |  Packet pi_hi, pi_lo;
 1821|       |  twoprod(t_hi, y, pi_hi, pi_lo);
 1822|       |  const Packet delta_hi = psub(x_hi, pi_hi);
 1823|       |  const Packet delta_t = psub(delta_hi, pi_lo);
 1824|       |  const Packet delta = padd(delta_t, x_lo);
 1825|       |  const Packet t_lo = pdiv(delta, y);
 1826|       |  fast_twosum(t_hi, t_lo, z_hi, z_lo);
 1827|       |}
 1828|       |
 1829|       |// This function computes log2(x) and returns the result as a double word.
 1830|       |template <typename Scalar>
 1831|       |struct accurate_log2 {
 1832|       |  template <typename Packet>
 1833|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void operator()(const Packet& x, Packet& log2_x_hi, Packet& log2_x_lo) {
 1834|       |    log2_x_hi = plog2(x);
 1835|       |    log2_x_lo = pzero(x);
 1836|       |  }
 1837|       |};
 1838|       |
 1839|       |// This specialization uses a more accurate algorithm to compute log2(x) for
 1840|       |// floats in [1/sqrt(2);sqrt(2)] with a relative accuracy of ~6.56508e-10.
 1841|       |// This additional accuracy is needed to counter the error-magnification
 1842|       |// inherent in multiplying by a potentially large exponent in pow(x,y).
 1843|       |// The minimax polynomial used was calculated using the Rminimax tool,
 1844|       |// see https://gitlab.inria.fr/sfilip/rminimax.
 1845|       |// Command line:
 1846|       |//   $ ratapprox --function="log2(1+x)/x"  --dom='[-0.2929,0.41422]'
 1847|       |//   --type=[10,0]
 1848|       |//       --numF="[D,D,SG]" --denF="[SG]" --log --dispCoeff="dec"
 1849|       |//
 1850|       |// The resulting implementation of pow(x,y) is accurate to 3 ulps.
 1851|       |template <>
 1852|       |struct accurate_log2<float> {
 1853|       |  template <typename Packet>
 1854|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void operator()(const Packet& z, Packet& log2_x_hi, Packet& log2_x_lo) {
 1855|       |    // Split the two lowest order constant coefficient into double-word representation.
 1856|       |    constexpr double kC0 = 1.442695041742110273474963832995854318141937255859375e+00;
 1857|       |    constexpr float kC0_hi = static_cast<float>(kC0);
 1858|       |    constexpr float kC0_lo = static_cast<float>(kC0 - static_cast<double>(kC0_hi));
 1859|       |    const Packet c0_hi = pset1<Packet>(kC0_hi);
 1860|       |    const Packet c0_lo = pset1<Packet>(kC0_lo);
 1861|       |
 1862|       |    constexpr double kC1 = -7.2134751588268664068692714863573201000690460205078125e-01;
 1863|       |    constexpr float kC1_hi = static_cast<float>(kC1);
 1864|       |    constexpr float kC1_lo = static_cast<float>(kC1 - static_cast<double>(kC1_hi));
 1865|       |    const Packet c1_hi = pset1<Packet>(kC1_hi);
 1866|       |    const Packet c1_lo = pset1<Packet>(kC1_lo);
 1867|       |
 1868|       |    constexpr float c[] = {
 1869|       |        9.7010828554630279541015625e-02,  -1.6896486282348632812500000e-01, 1.7200836539268493652343750e-01,
 1870|       |        -1.7892272770404815673828125e-01, 2.0505344867706298828125000e-01,  -2.4046677350997924804687500e-01,
 1871|       |        2.8857553005218505859375000e-01,  -3.6067414283752441406250000e-01, 4.8089790344238281250000000e-01};
 1872|       |
 1873|       |    // Evaluate the higher order terms in the polynomial using
 1874|       |    // standard arithmetic.
 1875|       |    const Packet one = pset1<Packet>(1.0f);
 1876|       |    const Packet x = psub(z, one);
 1877|       |    Packet p = ppolevl<Packet, 8>::run(x, c);
 1878|       |    // Evaluate the final two step in Horner's rule using double-word
 1879|       |    // arithmetic.
 1880|       |    Packet p_hi, p_lo;
 1881|       |    twoprod(x, p, p_hi, p_lo);
 1882|       |    fast_twosum(c1_hi, c1_lo, p_hi, p_lo, p_hi, p_lo);
 1883|       |    twoprod(p_hi, p_lo, x, p_hi, p_lo);
 1884|       |    fast_twosum(c0_hi, c0_lo, p_hi, p_lo, p_hi, p_lo);
 1885|       |    // Multiply by x to recover log2(z).
 1886|       |    twoprod(p_hi, p_lo, x, log2_x_hi, log2_x_lo);
 1887|       |  }
 1888|       |};
 1889|       |
 1890|       |// This specialization uses a more accurate algorithm to compute log2(x) for
 1891|       |// floats in [1/sqrt(2);sqrt(2)] with a relative accuracy of ~1.27e-18.
 1892|       |// This additional accuracy is needed to counter the error-magnification
 1893|       |// inherent in multiplying by a potentially large exponent in pow(x,y).
 1894|       |// The minimax polynomial used was calculated using the Sollya tool.
 1895|       |// See sollya.org.
 1896|       |
 1897|       |template <>
 1898|       |struct accurate_log2<double> {
 1899|       |  template <typename Packet>
 1900|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void operator()(const Packet& x, Packet& log2_x_hi, Packet& log2_x_lo) {
 1901|       |    // We use a transformation of variables:
 1902|       |    //    r = c * (x-1) / (x+1),
 1903|       |    // such that
 1904|       |    //    log2(x) = log2((1 + r/c) / (1 - r/c)) = f(r).
 1905|       |    // The function f(r) can be approximated well using an odd polynomial
 1906|       |    // of the form
 1907|       |    //   P(r) = ((Q(r^2) * r^2 + C) * r^2 + 1) * r,
 1908|       |    // For the implementation of log2<double> here, Q is of degree 6 with
 1909|       |    // coefficient represented in working precision (double), while C is a
 1910|       |    // constant represented in extra precision as a double word to achieve
 1911|       |    // full accuracy.
 1912|       |    //
 1913|       |    // The polynomial coefficients were computed by the Sollya script:
 1914|       |    //
 1915|       |    // c = 2 / log(2);
 1916|       |    // trans = c * (x-1)/(x+1);
 1917|       |    // itrans = (1+x/c)/(1-x/c);
 1918|       |    // interval=[trans(sqrt(0.5)); trans(sqrt(2))];
 1919|       |    // print(interval);
 1920|       |    // f = log2(itrans(x));
 1921|       |    // p=fpminimax(f,[|1,3,5,7,9,11,13,15,17|],[|1,DD,double...|],interval,relative,floating);
 1922|       |    const Packet q12 = pset1<Packet>(2.87074255468000586e-9);
 1923|       |    const Packet q10 = pset1<Packet>(2.38957980901884082e-8);
 1924|       |    const Packet q8 = pset1<Packet>(2.31032094540014656e-7);
 1925|       |    const Packet q6 = pset1<Packet>(2.27279857398537278e-6);
 1926|       |    const Packet q4 = pset1<Packet>(2.31271023278625638e-5);
 1927|       |    const Packet q2 = pset1<Packet>(2.47556738444535513e-4);
 1928|       |    const Packet q0 = pset1<Packet>(2.88543873228900172e-3);
 1929|       |    const Packet C_hi = pset1<Packet>(0.0400377511598501157);
 1930|       |    const Packet C_lo = pset1<Packet>(-4.77726582251425391e-19);
 1931|       |    const Packet one = pset1<Packet>(1.0);
 1932|       |
 1933|       |    const Packet cst_2_log2e_hi = pset1<Packet>(2.88539008177792677);
 1934|       |    const Packet cst_2_log2e_lo = pset1<Packet>(4.07660016854549667e-17);
 1935|       |    // c * (x - 1)
 1936|       |    Packet t_hi, t_lo;
 1937|       |    // t = c * (x-1)
 1938|       |    twoprod(cst_2_log2e_hi, cst_2_log2e_lo, psub(x, one), t_hi, t_lo);
 1939|       |    // r = c * (x-1) / (x+1),
 1940|       |    Packet r_hi, r_lo;
 1941|       |    doubleword_div_fp(t_hi, t_lo, padd(x, one), r_hi, r_lo);
 1942|       |
 1943|       |    // r2 = r * r
 1944|       |    Packet r2_hi, r2_lo;
 1945|       |    twoprod(r_hi, r_lo, r_hi, r_lo, r2_hi, r2_lo);
 1946|       |    // r4 = r2 * r2
 1947|       |    Packet r4_hi, r4_lo;
 1948|       |    twoprod(r2_hi, r2_lo, r2_hi, r2_lo, r4_hi, r4_lo);
 1949|       |
 1950|       |    // Evaluate Q(r^2) in working precision. We evaluate it in two parts
 1951|       |    // (even and odd in r^2) to improve instruction level parallelism.
 1952|       |    Packet q_even = pmadd(q12, r4_hi, q8);
 1953|       |    Packet q_odd = pmadd(q10, r4_hi, q6);
 1954|       |    q_even = pmadd(q_even, r4_hi, q4);
 1955|       |    q_odd = pmadd(q_odd, r4_hi, q2);
 1956|       |    q_even = pmadd(q_even, r4_hi, q0);
 1957|       |    Packet q = pmadd(q_odd, r2_hi, q_even);
 1958|       |
 1959|       |    // Now evaluate the low order terms of P(x) in double word precision.
 1960|       |    // In the following, due to the increasing magnitude of the coefficients
 1961|       |    // and r being constrained to [-0.5, 0.5] we can use fast_twosum instead
 1962|       |    // of the slower twosum.
 1963|       |    // Q(r^2) * r^2
 1964|       |    Packet p_hi, p_lo;
 1965|       |    twoprod(r2_hi, r2_lo, q, p_hi, p_lo);
 1966|       |    // Q(r^2) * r^2 + C
 1967|       |    Packet p1_hi, p1_lo;
 1968|       |    fast_twosum(C_hi, C_lo, p_hi, p_lo, p1_hi, p1_lo);
 1969|       |    // (Q(r^2) * r^2 + C) * r^2
 1970|       |    Packet p2_hi, p2_lo;
 1971|       |    twoprod(r2_hi, r2_lo, p1_hi, p1_lo, p2_hi, p2_lo);
 1972|       |    // ((Q(r^2) * r^2 + C) * r^2 + 1)
 1973|       |    Packet p3_hi, p3_lo;
 1974|       |    fast_twosum(one, p2_hi, p2_lo, p3_hi, p3_lo);
 1975|       |
 1976|       |    // log(z) ~= ((Q(r^2) * r^2 + C) * r^2 + 1) * r
 1977|       |    twoprod(p3_hi, p3_lo, r_hi, r_lo, log2_x_hi, log2_x_lo);
 1978|       |  }
 1979|       |};
 1980|       |
 1981|       |// This function implements the non-trivial case of pow(x,y) where x is
 1982|       |// positive and y is (possibly) non-integer.
 1983|       |// Formally, pow(x,y) = exp2(y * log2(x)), where exp2(x) is shorthand for 2^x.
 1984|       |// TODO(rmlarsen): We should probably add this as a packet up 'ppow', to make it
 1985|       |// easier to specialize or turn off for specific types and/or backends.x
 1986|       |template <typename Packet>
 1987|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_pow_impl(const Packet& x, const Packet& y) {
 1988|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 1989|       |  // Split x into exponent e_x and mantissa m_x.
 1990|       |  Packet e_x;
 1991|       |  Packet m_x = pfrexp(x, e_x);
 1992|       |
 1993|       |  // Adjust m_x to lie in [1/sqrt(2):sqrt(2)] to minimize absolute error in log2(m_x).
 1994|       |  EIGEN_CONSTEXPR Scalar sqrt_half = Scalar(0.70710678118654752440);
 1995|       |  const Packet m_x_scale_mask = pcmp_lt(m_x, pset1<Packet>(sqrt_half));
 1996|       |  m_x = pselect(m_x_scale_mask, pmul(pset1<Packet>(Scalar(2)), m_x), m_x);
 1997|       |  e_x = pselect(m_x_scale_mask, psub(e_x, pset1<Packet>(Scalar(1))), e_x);
 1998|       |
 1999|       |  // Compute log2(m_x) with 6 extra bits of accuracy.
 2000|       |  Packet rx_hi, rx_lo;
 2001|       |  accurate_log2<Scalar>()(m_x, rx_hi, rx_lo);
 2002|       |
 2003|       |  // Compute the two terms {y * e_x, y * r_x} in f = y * log2(x) with doubled
 2004|       |  // precision using double word arithmetic.
 2005|       |  Packet f1_hi, f1_lo, f2_hi, f2_lo;
 2006|       |  twoprod(e_x, y, f1_hi, f1_lo);
 2007|       |  twoprod(rx_hi, rx_lo, y, f2_hi, f2_lo);
 2008|       |  // Sum the two terms in f using double word arithmetic. We know
 2009|       |  // that |e_x| > |log2(m_x)|, except for the case where e_x==0.
 2010|       |  // This means that we can use fast_twosum(f1,f2).
 2011|       |  // In the case e_x == 0, e_x * y = f1 = 0, so we don't lose any
 2012|       |  // accuracy by violating the assumption of fast_twosum, because
 2013|       |  // it's a no-op.
 2014|       |  Packet f_hi, f_lo;
 2015|       |  fast_twosum(f1_hi, f1_lo, f2_hi, f2_lo, f_hi, f_lo);
 2016|       |
 2017|       |  // Split f into integer and fractional parts.
 2018|       |  Packet n_z, r_z;
 2019|       |  absolute_split(f_hi, n_z, r_z);
 2020|       |  r_z = padd(r_z, f_lo);
 2021|       |  Packet n_r;
 2022|       |  absolute_split(r_z, n_r, r_z);
 2023|       |  n_z = padd(n_z, n_r);
 2024|       |
 2025|       |  // We now have an accurate split of f = n_z + r_z and can compute
 2026|       |  //   x^y = 2**{n_z + r_z) = exp2(r_z) * 2**{n_z}.
 2027|       |  // Multiplication by the second factor can be done exactly using pldexp(), since
 2028|       |  // it is an integer power of 2.
 2029|       |  const Packet e_r = generic_exp2(r_z);
 2030|       |
 2031|       |  // Since we know that e_r is in [1/sqrt(2); sqrt(2)], we can use the fast version
 2032|       |  // of pldexp to multiply by 2**{n_z} when |n_z| is sufficiently small.
 2033|       |  constexpr Scalar kPldExpThresh = std::numeric_limits<Scalar>::max_exponent - 2;
 2034|       |  const Packet pldexp_fast_unsafe = pcmp_lt(pset1<Packet>(kPldExpThresh), pabs(n_z));
 2035|       |  if (predux_any(pldexp_fast_unsafe)) {
 2036|       |    return pldexp(e_r, n_z);
 2037|       |  }
 2038|       |  return pldexp_fast(e_r, n_z);
 2039|       |}
 2040|       |
 2041|       |// Generic implementation of pow(x,y).
 2042|       |template <typename Packet>
 2043|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_pow(const Packet& x, const Packet& y) {
 2044|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 2045|       |
 2046|       |  const Packet cst_inf = pset1<Packet>(NumTraits<Scalar>::infinity());
 2047|       |  const Packet cst_zero = pset1<Packet>(Scalar(0));
 2048|       |  const Packet cst_one = pset1<Packet>(Scalar(1));
 2049|       |  const Packet cst_nan = pset1<Packet>(NumTraits<Scalar>::quiet_NaN());
 2050|       |
 2051|       |  const Packet x_abs = pabs(x);
 2052|       |  Packet pow = generic_pow_impl(x_abs, y);
 2053|       |
 2054|       |  // In the following we enforce the special case handling prescribed in
 2055|       |  // https://en.cppreference.com/w/cpp/numeric/math/pow.
 2056|       |
 2057|       |  // Predicates for sign and magnitude of x.
 2058|       |  const Packet x_is_negative = pcmp_lt(x, cst_zero);
 2059|       |  const Packet x_is_zero = pcmp_eq(x, cst_zero);
 2060|       |  const Packet x_is_one = pcmp_eq(x, cst_one);
 2061|       |  const Packet x_has_signbit = psignbit(x);
 2062|       |  const Packet x_abs_gt_one = pcmp_lt(cst_one, x_abs);
 2063|       |  const Packet x_abs_is_inf = pcmp_eq(x_abs, cst_inf);
 2064|       |
 2065|       |  // Predicates for sign and magnitude of y.
 2066|       |  const Packet y_abs = pabs(y);
 2067|       |  const Packet y_abs_is_inf = pcmp_eq(y_abs, cst_inf);
 2068|       |  const Packet y_is_negative = pcmp_lt(y, cst_zero);
 2069|       |  const Packet y_is_zero = pcmp_eq(y, cst_zero);
 2070|       |  const Packet y_is_one = pcmp_eq(y, cst_one);
 2071|       |  // Predicates for whether y is integer and odd/even.
 2072|       |  const Packet y_is_int = pandnot(pcmp_eq(pfloor(y), y), y_abs_is_inf);
 2073|       |  const Packet y_div_2 = pmul(y, pset1<Packet>(Scalar(0.5)));
 2074|       |  const Packet y_is_even = pcmp_eq(pround(y_div_2), y_div_2);
 2075|       |  const Packet y_is_odd_int = pandnot(y_is_int, y_is_even);
 2076|       |  // Smallest exponent for which (1 + epsilon) overflows to infinity.
 2077|       |  EIGEN_CONSTEXPR Scalar huge_exponent =
 2078|       |      (NumTraits<Scalar>::max_exponent() * Scalar(EIGEN_LN2)) / NumTraits<Scalar>::epsilon();
 2079|       |  const Packet y_abs_is_huge = pcmp_le(pset1<Packet>(huge_exponent), y_abs);
 2080|       |
 2081|       |  // *  pow(base, exp) returns NaN if base is finite and negative
 2082|       |  //    and exp is finite and non-integer.
 2083|       |  pow = pselect(pandnot(x_is_negative, y_is_int), cst_nan, pow);
 2084|       |
 2085|       |  // * pow(0, exp), where exp is negative, finite, and is an even integer or
 2086|       |  // a non-integer, returns +
 2087|       |  // * pow(0, exp), where exp is positive non-integer or a positive even
 2088|       |  // integer, returns +0
 2089|       |  // * pow(+0, exp), where exp is a negative odd integer, returns +
 2090|       |  // * pow(-0, exp), where exp is a negative odd integer, returns -
 2091|       |  // * pow(+0, exp), where exp is a positive odd integer, returns +0
 2092|       |  // * pow(-0, exp), where exp is a positive odd integer, returns -0
 2093|       |  // Sign is flipped by the rule below.
 2094|       |  pow = pselect(x_is_zero, pselect(y_is_negative, cst_inf, cst_zero), pow);
 2095|       |
 2096|       |  // pow(base, exp) returns -pow(abs(base), exp) if base has the sign bit set,
 2097|       |  // and exp is an odd integer exponent.
 2098|       |  pow = pselect(pand(x_has_signbit, y_is_odd_int), pnegate(pow), pow);
 2099|       |
 2100|       |  // * pow(base, -) returns + for any |base|<1
 2101|       |  // * pow(base, -) returns +0 for any |base|>1
 2102|       |  // * pow(base, +) returns +0 for any |base|<1
 2103|       |  // * pow(base, +) returns + for any |base|>1
 2104|       |  // * pow(0, -) returns +
 2105|       |  // * pow(-1, +-) = 1
 2106|       |  Packet inf_y_val = pselect(por(pand(y_is_negative, x_is_zero), pxor(y_is_negative, x_abs_gt_one)), cst_inf, cst_zero);
 2107|       |  inf_y_val = pselect(pcmp_eq(x, pset1<Packet>(Scalar(-1.0))), cst_one, inf_y_val);
 2108|       |  pow = pselect(y_abs_is_huge, inf_y_val, pow);
 2109|       |
 2110|       |  // * pow(+, exp) returns +0 for any negative exp
 2111|       |  // * pow(+, exp) returns + for any positive exp
 2112|       |  // * pow(-, exp) returns -0 if exp is a negative odd integer.
 2113|       |  // * pow(-, exp) returns +0 if exp is a negative non-integer or negative
 2114|       |  //     even integer.
 2115|       |  // * pow(-, exp) returns - if exp is a positive odd integer.
 2116|       |  // * pow(-, exp) returns + if exp is a positive non-integer or positive
 2117|       |  //     even integer.
 2118|       |  auto x_pos_inf_value = pselect(y_is_negative, cst_zero, cst_inf);
 2119|       |  auto x_neg_inf_value = pselect(y_is_odd_int, pnegate(x_pos_inf_value), x_pos_inf_value);
 2120|       |  pow = pselect(x_abs_is_inf, pselect(x_is_negative, x_neg_inf_value, x_pos_inf_value), pow);
 2121|       |
 2122|       |  // All cases of NaN inputs return NaN, except the two below.
 2123|       |  pow = pselect(por(pisnan(x), pisnan(y)), cst_nan, pow);
 2124|       |
 2125|       |  // * pow(base, 1) returns base.
 2126|       |  // * pow(base, +/-0) returns 1, regardless of base, even NaN.
 2127|       |  // * pow(+1, exp) returns 1, regardless of exponent, even NaN.
 2128|       |  pow = pselect(y_is_one, x, pselect(por(x_is_one, y_is_zero), cst_one, pow));
 2129|       |
 2130|       |  return pow;
 2131|       |}
 2132|       |
 2133|       |namespace unary_pow {
 2134|       |
 2135|       |template <typename ScalarExponent, bool IsInteger = NumTraits<ScalarExponent>::IsInteger>
 2136|       |struct exponent_helper {
 2137|       |  using safe_abs_type = ScalarExponent;
 2138|       |  static constexpr ScalarExponent one_half = ScalarExponent(0.5);
 2139|       |  // these routines assume that exp is an integer stored as a floating point type
 2140|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ScalarExponent safe_abs(const ScalarExponent& exp) {
 2141|       |    return numext::abs(exp);
 2142|       |  }
 2143|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool is_odd(const ScalarExponent& exp) {
 2144|       |    eigen_assert(((numext::isfinite)(exp) && exp == numext::floor(exp)) && "exp must be an integer");
 2145|       |    ScalarExponent exp_div_2 = exp * one_half;
 2146|       |    ScalarExponent floor_exp_div_2 = numext::floor(exp_div_2);
 2147|       |    return exp_div_2 != floor_exp_div_2;
 2148|       |  }
 2149|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ScalarExponent floor_div_two(const ScalarExponent& exp) {
 2150|       |    ScalarExponent exp_div_2 = exp * one_half;
 2151|       |    return numext::floor(exp_div_2);
 2152|       |  }
 2153|       |};
 2154|       |
 2155|       |template <typename ScalarExponent>
 2156|       |struct exponent_helper<ScalarExponent, true> {
 2157|       |  // if `exp` is a signed integer type, cast it to its unsigned counterpart to safely store its absolute value
 2158|       |  // consider the (rare) case where `exp` is an int32_t: abs(-2147483648) != 2147483648
 2159|       |  using safe_abs_type = typename numext::get_integer_by_size<sizeof(ScalarExponent)>::unsigned_type;
 2160|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE safe_abs_type safe_abs(const ScalarExponent& exp) {
 2161|       |    ScalarExponent mask = numext::signbit(exp);
 2162|       |    safe_abs_type result = safe_abs_type(exp ^ mask);
 2163|       |    return result + safe_abs_type(ScalarExponent(1) & mask);
 2164|       |  }
 2165|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool is_odd(const safe_abs_type& exp) {
 2166|       |    return exp % safe_abs_type(2) != safe_abs_type(0);
 2167|       |  }
 2168|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE safe_abs_type floor_div_two(const safe_abs_type& exp) {
 2169|       |    return exp >> safe_abs_type(1);
 2170|       |  }
 2171|       |};
 2172|       |
 2173|       |template <typename Packet, typename ScalarExponent,
 2174|       |          bool ReciprocateIfExponentIsNegative =
 2175|       |              !NumTraits<typename unpacket_traits<Packet>::type>::IsInteger && NumTraits<ScalarExponent>::IsSigned>
 2176|       |struct reciprocate {
 2177|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& x, const ScalarExponent& exponent) {
 2178|       |    using Scalar = typename unpacket_traits<Packet>::type;
 2179|       |    const Packet cst_pos_one = pset1<Packet>(Scalar(1));
 2180|       |    return exponent < 0 ? pdiv(cst_pos_one, x) : x;
 2181|       |  }
 2182|       |};
 2183|       |
 2184|       |template <typename Packet, typename ScalarExponent>
 2185|       |struct reciprocate<Packet, ScalarExponent, false> {
 2186|       |  // pdiv not defined, nor necessary for integer base types
 2187|       |  // if the exponent is unsigned, then the exponent cannot be negative
 2188|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& x, const ScalarExponent&) { return x; }
 2189|       |};
 2190|       |
 2191|       |template <typename Packet, typename ScalarExponent>
 2192|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet int_pow(const Packet& x, const ScalarExponent& exponent) {
 2193|       |  using Scalar = typename unpacket_traits<Packet>::type;
 2194|       |  using ExponentHelper = exponent_helper<ScalarExponent>;
 2195|       |  using AbsExponentType = typename ExponentHelper::safe_abs_type;
 2196|       |  const Packet cst_pos_one = pset1<Packet>(Scalar(1));
 2197|       |  if (exponent == ScalarExponent(0)) return cst_pos_one;
 2198|       |
 2199|       |  Packet result = reciprocate<Packet, ScalarExponent>::run(x, exponent);
 2200|       |  Packet y = cst_pos_one;
 2201|       |  AbsExponentType m = ExponentHelper::safe_abs(exponent);
 2202|       |
 2203|       |  while (m > 1) {
 2204|       |    bool odd = ExponentHelper::is_odd(m);
 2205|       |    if (odd) y = pmul(y, result);
 2206|       |    result = pmul(result, result);
 2207|       |    m = ExponentHelper::floor_div_two(m);
 2208|       |  }
 2209|       |
 2210|       |  return pmul(y, result);
 2211|       |}
 2212|       |
 2213|       |template <typename Packet>
 2214|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet gen_pow(const Packet& x,
 2215|       |                                                     const typename unpacket_traits<Packet>::type& exponent) {
 2216|       |  const Packet exponent_packet = pset1<Packet>(exponent);
 2217|       |  return generic_pow_impl(x, exponent_packet);
 2218|       |}
 2219|       |
 2220|       |template <typename Packet, typename ScalarExponent>
 2221|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet handle_nonint_nonint_errors(const Packet& x, const Packet& powx,
 2222|       |                                                                         const ScalarExponent& exponent) {
 2223|       |  using Scalar = typename unpacket_traits<Packet>::type;
 2224|       |
 2225|       |  // non-integer base and exponent case
 2226|       |
 2227|       |  const Scalar pos_zero = Scalar(0);
 2228|       |  const Scalar all_ones = ptrue<Scalar>(Scalar());
 2229|       |  const Scalar pos_one = Scalar(1);
 2230|       |  const Scalar pos_inf = NumTraits<Scalar>::infinity();
 2231|       |
 2232|       |  const Packet cst_pos_zero = pzero(x);
 2233|       |  const Packet cst_pos_one = pset1<Packet>(pos_one);
 2234|       |  const Packet cst_pos_inf = pset1<Packet>(pos_inf);
 2235|       |
 2236|       |  const bool exponent_is_not_fin = !(numext::isfinite)(exponent);
 2237|       |  const bool exponent_is_neg = exponent < ScalarExponent(0);
 2238|       |  const bool exponent_is_pos = exponent > ScalarExponent(0);
 2239|       |
 2240|       |  const Packet exp_is_not_fin = pset1<Packet>(exponent_is_not_fin ? all_ones : pos_zero);
 2241|       |  const Packet exp_is_neg = pset1<Packet>(exponent_is_neg ? all_ones : pos_zero);
 2242|       |  const Packet exp_is_pos = pset1<Packet>(exponent_is_pos ? all_ones : pos_zero);
 2243|       |  const Packet exp_is_inf = pand(exp_is_not_fin, por(exp_is_neg, exp_is_pos));
 2244|       |  const Packet exp_is_nan = pandnot(exp_is_not_fin, por(exp_is_neg, exp_is_pos));
 2245|       |
 2246|       |  const Packet x_is_le_zero = pcmp_le(x, cst_pos_zero);
 2247|       |  const Packet x_is_ge_zero = pcmp_le(cst_pos_zero, x);
 2248|       |  const Packet x_is_zero = pand(x_is_le_zero, x_is_ge_zero);
 2249|       |
 2250|       |  const Packet abs_x = pabs(x);
 2251|       |  const Packet abs_x_is_le_one = pcmp_le(abs_x, cst_pos_one);
 2252|       |  const Packet abs_x_is_ge_one = pcmp_le(cst_pos_one, abs_x);
 2253|       |  const Packet abs_x_is_inf = pcmp_eq(abs_x, cst_pos_inf);
 2254|       |  const Packet abs_x_is_one = pand(abs_x_is_le_one, abs_x_is_ge_one);
 2255|       |
 2256|       |  Packet pow_is_inf_if_exp_is_neg = por(x_is_zero, pand(abs_x_is_le_one, exp_is_inf));
 2257|       |  Packet pow_is_inf_if_exp_is_pos = por(abs_x_is_inf, pand(abs_x_is_ge_one, exp_is_inf));
 2258|       |  Packet pow_is_one = pand(abs_x_is_one, por(exp_is_inf, x_is_ge_zero));
 2259|       |
 2260|       |  Packet result = powx;
 2261|       |  result = por(x_is_le_zero, result);
 2262|       |  result = pselect(pow_is_inf_if_exp_is_neg, pand(cst_pos_inf, exp_is_neg), result);
 2263|       |  result = pselect(pow_is_inf_if_exp_is_pos, pand(cst_pos_inf, exp_is_pos), result);
 2264|       |  result = por(exp_is_nan, result);
 2265|       |  result = pselect(pow_is_one, cst_pos_one, result);
 2266|       |  return result;
 2267|       |}
 2268|       |
 2269|       |template <typename Packet, typename ScalarExponent,
 2270|       |          std::enable_if_t<NumTraits<typename unpacket_traits<Packet>::type>::IsSigned, bool> = true>
 2271|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet handle_negative_exponent(const Packet& x, const ScalarExponent& exponent) {
 2272|       |  using Scalar = typename unpacket_traits<Packet>::type;
 2273|       |
 2274|       |  // signed integer base, signed integer exponent case
 2275|       |
 2276|       |  // This routine handles negative exponents.
 2277|       |  // The return value is either 0, 1, or -1.
 2278|       |
 2279|       |  const Scalar pos_zero = Scalar(0);
 2280|       |  const Scalar all_ones = ptrue<Scalar>(Scalar());
 2281|       |  const Scalar pos_one = Scalar(1);
 2282|       |
 2283|       |  const Packet cst_pos_one = pset1<Packet>(pos_one);
 2284|       |
 2285|       |  const bool exponent_is_odd = exponent % ScalarExponent(2) != ScalarExponent(0);
 2286|       |
 2287|       |  const Packet exp_is_odd = pset1<Packet>(exponent_is_odd ? all_ones : pos_zero);
 2288|       |
 2289|       |  const Packet abs_x = pabs(x);
 2290|       |  const Packet abs_x_is_one = pcmp_eq(abs_x, cst_pos_one);
 2291|       |
 2292|       |  Packet result = pselect(exp_is_odd, x, abs_x);
 2293|       |  result = pand(abs_x_is_one, result);
 2294|       |  return result;
 2295|       |}
 2296|       |
 2297|       |template <typename Packet, typename ScalarExponent,
 2298|       |          std::enable_if_t<!NumTraits<typename unpacket_traits<Packet>::type>::IsSigned, bool> = true>
 2299|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet handle_negative_exponent(const Packet& x, const ScalarExponent&) {
 2300|       |  using Scalar = typename unpacket_traits<Packet>::type;
 2301|       |
 2302|       |  // unsigned integer base, signed integer exponent case
 2303|       |
 2304|       |  // This routine handles negative exponents.
 2305|       |  // The return value is either 0 or 1
 2306|       |
 2307|       |  const Scalar pos_one = Scalar(1);
 2308|       |
 2309|       |  const Packet cst_pos_one = pset1<Packet>(pos_one);
 2310|       |
 2311|       |  const Packet x_is_one = pcmp_eq(x, cst_pos_one);
 2312|       |
 2313|       |  return pand(x_is_one, x);
 2314|       |}
 2315|       |
 2316|       |}  // end namespace unary_pow
 2317|       |
 2318|       |template <typename Packet, typename ScalarExponent,
 2319|       |          bool BaseIsIntegerType = NumTraits<typename unpacket_traits<Packet>::type>::IsInteger,
 2320|       |          bool ExponentIsIntegerType = NumTraits<ScalarExponent>::IsInteger,
 2321|       |          bool ExponentIsSigned = NumTraits<ScalarExponent>::IsSigned>
 2322|       |struct unary_pow_impl;
 2323|       |
 2324|       |template <typename Packet, typename ScalarExponent, bool ExponentIsSigned>
 2325|       |struct unary_pow_impl<Packet, ScalarExponent, false, false, ExponentIsSigned> {
 2326|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 2327|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& x, const ScalarExponent& exponent) {
 2328|       |    const bool exponent_is_integer = (numext::isfinite)(exponent) && numext::round(exponent) == exponent;
 2329|       |    if (exponent_is_integer) {
 2330|       |      // The simple recursive doubling implementation is only accurate to 3 ulps
 2331|       |      // for integer exponents in [-3:7]. Since this is a common case, we
 2332|       |      // specialize it here.
 2333|       |      bool use_repeated_squaring =
 2334|       |          (exponent <= ScalarExponent(7) && (!ExponentIsSigned || exponent >= ScalarExponent(-3)));
 2335|       |      return use_repeated_squaring ? unary_pow::int_pow(x, exponent) : generic_pow(x, pset1<Packet>(exponent));
 2336|       |    } else {
 2337|       |      Packet result = unary_pow::gen_pow(x, exponent);
 2338|       |      result = unary_pow::handle_nonint_nonint_errors(x, result, exponent);
 2339|       |      return result;
 2340|       |    }
 2341|       |  }
 2342|       |};
 2343|       |
 2344|       |template <typename Packet, typename ScalarExponent, bool ExponentIsSigned>
 2345|       |struct unary_pow_impl<Packet, ScalarExponent, false, true, ExponentIsSigned> {
 2346|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 2347|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& x, const ScalarExponent& exponent) {
 2348|       |    return unary_pow::int_pow(x, exponent);
 2349|       |  }
 2350|       |};
 2351|       |
 2352|       |template <typename Packet, typename ScalarExponent>
 2353|       |struct unary_pow_impl<Packet, ScalarExponent, true, true, true> {
 2354|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 2355|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& x, const ScalarExponent& exponent) {
 2356|       |    if (exponent < ScalarExponent(0)) {
 2357|       |      return unary_pow::handle_negative_exponent(x, exponent);
 2358|       |    } else {
 2359|       |      return unary_pow::int_pow(x, exponent);
 2360|       |    }
 2361|       |  }
 2362|       |};
 2363|       |
 2364|       |template <typename Packet, typename ScalarExponent>
 2365|       |struct unary_pow_impl<Packet, ScalarExponent, true, true, false> {
 2366|       |  typedef typename unpacket_traits<Packet>::type Scalar;
 2367|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet& x, const ScalarExponent& exponent) {
 2368|       |    return unary_pow::int_pow(x, exponent);
 2369|       |  }
 2370|       |};
 2371|       |
 2372|       |// This function computes exp2(x) = exp(ln(2) * x).
 2373|       |// To improve accuracy, the product ln(2)*x is computed using the twoprod
 2374|       |// algorithm, such that ln(2) * x = p_hi + p_lo holds exactly. Then exp2(x) is
 2375|       |// computed as exp2(x) = exp(p_hi) * exp(p_lo) ~= exp(p_hi) * (1 + p_lo). This
 2376|       |// correction step this reduces the maximum absolute error as follows:
 2377|       |//
 2378|       |// type   | max error (simple product) | max error (twoprod) |
 2379|       |// -----------------------------------------------------------
 2380|       |// float  |       35 ulps              |       4 ulps        |
 2381|       |// double |      363 ulps              |     110 ulps        |
 2382|       |//
 2383|       |template <typename Packet>
 2384|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_exp2(const Packet& _x) {
 2385|      0|  typedef typename unpacket_traits<Packet>::type Scalar;
 2386|      0|  constexpr int max_exponent = std::numeric_limits<Scalar>::max_exponent;
 2387|      0|  constexpr int digits = std::numeric_limits<Scalar>::digits;
 2388|      0|  constexpr Scalar max_cap = Scalar(max_exponent + 1);
 2389|      0|  constexpr Scalar min_cap = -Scalar(max_exponent + digits - 1);
 2390|      0|  Packet x = pmax(pmin(_x, pset1<Packet>(max_cap)), pset1<Packet>(min_cap));
 2391|      0|  Packet p_hi, p_lo;
 2392|      0|  twoprod(pset1<Packet>(Scalar(EIGEN_LN2)), x, p_hi, p_lo);
 2393|      0|  Packet exp2_hi = pexp(p_hi);
 2394|      0|  Packet exp2_lo = padd(pset1<Packet>(Scalar(1)), p_lo);
 2395|      0|  return pmul(exp2_hi, exp2_lo);
 2396|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12generic_exp2IDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12generic_exp2IDv2_dEET_RKS3_
  ------------------
 2397|       |
 2398|       |template <typename Packet>
 2399|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_rint(const Packet& a) {
 2400|      0|  using Scalar = typename unpacket_traits<Packet>::type;
 2401|      0|  using IntType = typename numext::get_integer_by_size<sizeof(Scalar)>::signed_type;
 2402|      0|  // Adds and subtracts signum(a) * 2^kMantissaBits to force rounding.
 2403|      0|  const IntType kLimit = IntType(1) << (NumTraits<Scalar>::digits() - 1);
 2404|      0|  const Packet cst_limit = pset1<Packet>(static_cast<Scalar>(kLimit));
 2405|      0|  Packet abs_a = pabs(a);
 2406|      0|  Packet sign_a = pandnot(a, abs_a);
 2407|      0|  Packet rint_a = padd(abs_a, cst_limit);
 2408|      0|  // Don't compile-away addition and subtraction.
 2409|      0|  EIGEN_OPTIMIZATION_BARRIER(rint_a);
 2410|      0|  rint_a = psub(rint_a, cst_limit);
 2411|      0|  rint_a = por(rint_a, sign_a);
 2412|      0|  // If greater than limit (or NaN), simply return a.
 2413|      0|  Packet mask = pcmp_lt(abs_a, cst_limit);
 2414|      0|  Packet result = pselect(mask, rint_a, a);
 2415|      0|  return result;
 2416|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12generic_rintIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12generic_rintIDv2_dEET_RKS3_
  ------------------
 2417|       |
 2418|       |template <typename Packet>
 2419|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_floor(const Packet& a) {
 2420|      0|  using Scalar = typename unpacket_traits<Packet>::type;
 2421|      0|  const Packet cst_1 = pset1<Packet>(Scalar(1));
 2422|      0|  Packet rint_a = generic_rint(a);
 2423|      0|  // if a < rint(a), then rint(a) == ceil(a)
 2424|      0|  Packet mask = pcmp_lt(a, rint_a);
 2425|      0|  Packet offset = pand(cst_1, mask);
 2426|      0|  Packet result = psub(rint_a, offset);
 2427|      0|  return result;
 2428|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13generic_floorIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal13generic_floorIDv2_dEET_RKS3_
  ------------------
 2429|       |
 2430|       |template <typename Packet>
 2431|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_ceil(const Packet& a) {
 2432|       |  using Scalar = typename unpacket_traits<Packet>::type;
 2433|       |  const Packet cst_1 = pset1<Packet>(Scalar(1));
 2434|       |  const Packet sign_mask = pset1<Packet>(static_cast<Scalar>(-0.0));
 2435|       |  Packet rint_a = generic_rint(a);
 2436|       |  // if rint(a) < a, then rint(a) == floor(a)
 2437|       |  Packet mask = pcmp_lt(rint_a, a);
 2438|       |  Packet offset = pand(cst_1, mask);
 2439|       |  Packet result = padd(rint_a, offset);
 2440|       |  // Signed zero must remain signed (e.g. ceil(-0.02) == -0).
 2441|       |  result = por(result, pand(sign_mask, a));
 2442|       |  return result;
 2443|       |}
 2444|       |
 2445|       |template <typename Packet>
 2446|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_trunc(const Packet& a) {
 2447|       |  Packet abs_a = pabs(a);
 2448|       |  Packet sign_a = pandnot(a, abs_a);
 2449|       |  Packet floor_abs_a = generic_floor(abs_a);
 2450|       |  Packet result = por(floor_abs_a, sign_a);
 2451|       |  return result;
 2452|       |}
 2453|       |
 2454|       |template <typename Packet>
 2455|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_round(const Packet& a) {
 2456|       |  using Scalar = typename unpacket_traits<Packet>::type;
 2457|       |  const Packet cst_half = pset1<Packet>(Scalar(0.5));
 2458|       |  const Packet cst_1 = pset1<Packet>(Scalar(1));
 2459|       |  Packet abs_a = pabs(a);
 2460|       |  Packet sign_a = pandnot(a, abs_a);
 2461|       |  Packet floor_abs_a = generic_floor(abs_a);
 2462|       |  Packet diff = psub(abs_a, floor_abs_a);
 2463|       |  Packet mask = pcmp_le(cst_half, diff);
 2464|       |  Packet offset = pand(cst_1, mask);
 2465|       |  Packet result = padd(floor_abs_a, offset);
 2466|       |  result = por(result, sign_a);
 2467|       |  return result;
 2468|       |}
 2469|       |
 2470|       |template <typename Packet>
 2471|       |struct nearest_integer_packetop_impl<Packet, /*IsScalar*/ false, /*IsInteger*/ false> {
 2472|       |  using Scalar = typename unpacket_traits<Packet>::type;
 2473|       |  static_assert(packet_traits<Scalar>::HasRound, "Generic nearest integer functions are disabled for this type.");
 2474|      0|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_floor(const Packet& x) { return generic_floor(x); }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal29nearest_integer_packetop_implIDv4_fLb0ELb0EE9run_floorERKS2_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal29nearest_integer_packetop_implIDv2_dLb0ELb0EE9run_floorERKS2_
  ------------------
 2475|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_ceil(const Packet& x) { return generic_ceil(x); }
 2476|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_rint(const Packet& x) { return generic_rint(x); }
 2477|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_round(const Packet& x) { return generic_round(x); }
 2478|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_trunc(const Packet& x) { return generic_trunc(x); }
 2479|       |};
 2480|       |
 2481|       |template <typename Packet>
 2482|       |struct nearest_integer_packetop_impl<Packet, /*IsScalar*/ false, /*IsInteger*/ true> {
 2483|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_floor(const Packet& x) { return x; }
 2484|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_ceil(const Packet& x) { return x; }
 2485|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_rint(const Packet& x) { return x; }
 2486|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_round(const Packet& x) { return x; }
 2487|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_trunc(const Packet& x) { return x; }
 2488|       |};
 2489|       |
 2490|       |}  // end namespace internal
 2491|       |}  // end namespace Eigen
 2492|       |
 2493|       |#endif  // EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctionsFwd.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2019 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_FWD_H
   11|       |#define EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_FWD_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |namespace internal {
   18|       |
   19|       |// Forward declarations of the generic math functions
   20|       |// implemented in GenericPacketMathFunctions.h
   21|       |// This is needed to workaround a circular dependency.
   22|       |
   23|       |/***************************************************************************
   24|       | * Some generic implementations to be used by implementers
   25|       | ***************************************************************************/
   26|       |
   27|       |/** Default implementation of pfrexp.
   28|       | * It is expected to be called by implementers of template<> pfrexp.
   29|       | */
   30|       |template <typename Packet>
   31|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pfrexp_generic(const Packet& a, Packet& exponent);
   32|       |
   33|       |// Extracts the biased exponent value from Packet p, and casts the results to
   34|       |// a floating-point Packet type. Used by pfrexp_generic. Override this if
   35|       |// there is no unpacket_traits<Packet>::integer_packet.
   36|       |template <typename Packet>
   37|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pfrexp_generic_get_biased_exponent(const Packet& p);
   38|       |
   39|       |/** Default implementation of pldexp.
   40|       | * It is expected to be called by implementers of template<> pldexp.
   41|       | */
   42|       |template <typename Packet>
   43|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pldexp_generic(const Packet& a, const Packet& exponent);
   44|       |
   45|       |// Explicitly multiplies
   46|       |//    a * (2^e)
   47|       |// clamping e to the range
   48|       |// [NumTraits<Scalar>::min_exponent()-2, NumTraits<Scalar>::max_exponent()]
   49|       |//
   50|       |// This is approx 7x faster than pldexp_impl, but will prematurely over/underflow
   51|       |// if 2^e doesn't fit into a normal floating-point Scalar.
   52|       |//
   53|       |// Assumes IEEE floating point format
   54|       |template <typename Packet>
   55|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pldexp_fast(const Packet& a, const Packet& exponent);
   56|       |
   57|       |/** \internal \returns log(x) for single precision float */
   58|       |template <typename Packet>
   59|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_float(const Packet _x);
   60|       |
   61|       |/** \internal \returns log2(x) for single precision float */
   62|       |template <typename Packet>
   63|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog2_float(const Packet _x);
   64|       |
   65|       |/** \internal \returns log(x) for single precision float */
   66|       |template <typename Packet>
   67|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_double(const Packet _x);
   68|       |
   69|       |/** \internal \returns log2(x) for single precision float */
   70|       |template <typename Packet>
   71|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog2_double(const Packet _x);
   72|       |
   73|       |/** \internal \returns log(1 + x) */
   74|       |template <typename Packet>
   75|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_log1p(const Packet& x);
   76|       |
   77|       |/** \internal \returns exp(x)-1 */
   78|       |template <typename Packet>
   79|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_expm1(const Packet& x);
   80|       |
   81|       |/** \internal \returns atan(x) */
   82|       |template <typename Packet>
   83|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_atan(const Packet& x);
   84|       |
   85|       |/** \internal \returns exp2(x) */
   86|       |template <typename Packet>
   87|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_exp2(const Packet& x);
   88|       |
   89|       |/** \internal \returns exp(x) for single precision float */
   90|       |template <typename Packet>
   91|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp_float(const Packet _x);
   92|       |
   93|       |/** \internal \returns exp(x) for double precision real numbers */
   94|       |template <typename Packet>
   95|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp_double(const Packet _x);
   96|       |
   97|       |/** \internal \returns sin(x) for single precision float */
   98|       |template <typename Packet>
   99|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psin_float(const Packet& x);
  100|       |
  101|       |/** \internal \returns cos(x) for single precision float */
  102|       |template <typename Packet>
  103|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcos_float(const Packet& x);
  104|       |
  105|       |/** \internal \returns sin(x) for double precision float */
  106|       |template <typename Packet>
  107|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psin_double(const Packet& x);
  108|       |
  109|       |/** \internal \returns cos(x) for double precision float */
  110|       |template <typename Packet>
  111|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcos_double(const Packet& x);
  112|       |
  113|       |/** \internal \returns asin(x) for single precision float */
  114|       |template <typename Packet>
  115|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pasin_float(const Packet& x);
  116|       |
  117|       |/** \internal \returns acos(x) for single precision float */
  118|       |template <typename Packet>
  119|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pacos_float(const Packet& x);
  120|       |
  121|       |/** \internal \returns tanh(x) for single precision float */
  122|       |template <typename Packet>
  123|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet ptanh_float(const Packet& x);
  124|       |
  125|       |/** \internal \returns tanh(x) for double precision float */
  126|       |template <typename Packet>
  127|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet ptanh_double(const Packet& x);
  128|       |
  129|       |/** \internal \returns atanh(x) for single precision float */
  130|       |template <typename Packet>
  131|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patanh_float(const Packet& x);
  132|       |
  133|       |/** \internal \returns atanh(x) for double precision float */
  134|       |template <typename Packet>
  135|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patanh_double(const Packet& x);
  136|       |
  137|       |/** \internal \returns sqrt(x) for complex types */
  138|       |template <typename Packet>
  139|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psqrt_complex(const Packet& a);
  140|       |
  141|       |/** \internal \returns x / y for complex types */
  142|       |template <typename Packet>
  143|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pdiv_complex(const Packet& x, const Packet& y);
  144|       |
  145|       |template <typename Packet, int N>
  146|       |struct ppolevl;
  147|       |
  148|       |/** \internal \returns log(x) for complex types */
  149|       |template <typename Packet>
  150|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_complex(const Packet& x);
  151|       |
  152|       |/** \internal \returns exp(x) for complex types */
  153|       |template <typename Packet>
  154|       |EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp_complex(const Packet& x);
  155|       |
  156|       |template <typename Packet>
  157|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_rint(const Packet& a);
  158|       |
  159|       |template <typename Packet>
  160|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_floor(const Packet& a);
  161|       |
  162|       |template <typename Packet>
  163|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_ceil(const Packet& a);
  164|       |
  165|       |template <typename Packet>
  166|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_trunc(const Packet& a);
  167|       |
  168|       |template <typename Packet>
  169|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_round(const Packet& a);
  170|       |
  171|       |// Macros for instantiating these generic functions for different backends.
  172|       |#define EIGEN_PACKET_FUNCTION(METHOD, SCALAR, PACKET)                                             \
  173|       |  template <>                                                                                     \
  174|      0|  EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_UNUSED PACKET p##METHOD<PACKET>(const PACKET& _x) { \
  175|      0|    return p##METHOD##_##SCALAR(_x);                                                              \
  176|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4psinIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4pcosIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5pasinIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5pacosIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5ptanhIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6patanhIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4plogIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5plog2IDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4pexpIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6patanhIDv2_dEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4plogIDv2_dEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4psinIDv2_dEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4pcosIDv2_dEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5plog2IDv2_dEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal4pexpIDv2_dEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5ptanhIDv2_dEET_RKS3_
  ------------------
  177|       |
  178|       |// Macros for instantiating these generic functions for different backends.
  179|       |#define EIGEN_GENERIC_PACKET_FUNCTION(METHOD, PACKET)                                             \
  180|       |  template <>                                                                                     \
  181|      0|  EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_UNUSED PACKET p##METHOD<PACKET>(const PACKET& _x) { \
  182|      0|    return generic_##METHOD(_x);                                                                  \
  183|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6pexpm1IDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5pexp2IDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal6plog1pIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5patanIDv4_fEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5patanIDv2_dEET_RKS3_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal5pexp2IDv2_dEET_RKS3_
  ------------------
  184|       |
  185|       |#define EIGEN_FLOAT_PACKET_FUNCTION(METHOD, PACKET) EIGEN_PACKET_FUNCTION(METHOD, float, PACKET)
  186|       |#define EIGEN_DOUBLE_PACKET_FUNCTION(METHOD, PACKET) EIGEN_PACKET_FUNCTION(METHOD, double, PACKET)
  187|       |
  188|       |#define EIGEN_INSTANTIATE_GENERIC_MATH_FUNCS_FLOAT(PACKET) \
  189|       |  EIGEN_FLOAT_PACKET_FUNCTION(sin, PACKET)                 \
  190|       |  EIGEN_FLOAT_PACKET_FUNCTION(cos, PACKET)                 \
  191|       |  EIGEN_FLOAT_PACKET_FUNCTION(asin, PACKET)                \
  192|       |  EIGEN_FLOAT_PACKET_FUNCTION(acos, PACKET)                \
  193|       |  EIGEN_FLOAT_PACKET_FUNCTION(tanh, PACKET)                \
  194|       |  EIGEN_FLOAT_PACKET_FUNCTION(atanh, PACKET)               \
  195|       |  EIGEN_FLOAT_PACKET_FUNCTION(log, PACKET)                 \
  196|       |  EIGEN_FLOAT_PACKET_FUNCTION(log2, PACKET)                \
  197|       |  EIGEN_FLOAT_PACKET_FUNCTION(exp, PACKET)                 \
  198|       |  EIGEN_GENERIC_PACKET_FUNCTION(expm1, PACKET)             \
  199|       |  EIGEN_GENERIC_PACKET_FUNCTION(exp2, PACKET)              \
  200|       |  EIGEN_GENERIC_PACKET_FUNCTION(log1p, PACKET)             \
  201|       |  EIGEN_GENERIC_PACKET_FUNCTION(atan, PACKET)
  202|       |
  203|       |#define EIGEN_INSTANTIATE_GENERIC_MATH_FUNCS_DOUBLE(PACKET) \
  204|       |  EIGEN_DOUBLE_PACKET_FUNCTION(atanh, PACKET)               \
  205|       |  EIGEN_DOUBLE_PACKET_FUNCTION(log, PACKET)                 \
  206|       |  EIGEN_DOUBLE_PACKET_FUNCTION(sin, PACKET)                 \
  207|       |  EIGEN_DOUBLE_PACKET_FUNCTION(cos, PACKET)                 \
  208|       |  EIGEN_DOUBLE_PACKET_FUNCTION(log2, PACKET)                \
  209|       |  EIGEN_DOUBLE_PACKET_FUNCTION(exp, PACKET)                 \
  210|       |  EIGEN_DOUBLE_PACKET_FUNCTION(tanh, PACKET)                \
  211|       |  EIGEN_GENERIC_PACKET_FUNCTION(atan, PACKET)               \
  212|       |  EIGEN_GENERIC_PACKET_FUNCTION(exp2, PACKET)
  213|       |
  214|       |}  // end namespace internal
  215|       |}  // end namespace Eigen
  216|       |
  217|       |#endif  // EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_FWD_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/arch/Default/Half.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// This Source Code Form is subject to the terms of the Mozilla
    5|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    6|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    7|       |//
    8|       |// The conversion routines are Copyright (c) Fabian Giesen, 2016.
    9|       |// The original license follows:
   10|       |//
   11|       |// Copyright (c) Fabian Giesen, 2016
   12|       |// All rights reserved.
   13|       |// Redistribution and use in source and binary forms, with or without
   14|       |// modification, are permitted.
   15|       |// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
   16|       |// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
   17|       |// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
   18|       |// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
   19|       |// HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
   20|       |// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
   21|       |// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
   22|       |// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
   23|       |// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
   24|       |// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
   25|       |// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
   26|       |
   27|       |// Standard 16-bit float type, mostly useful for GPUs. Defines a new
   28|       |// type Eigen::half (inheriting either from CUDA's or HIP's __half struct) with
   29|       |// operator overloads such that it behaves basically as an arithmetic
   30|       |// type. It will be quite slow on CPUs (so it is recommended to stay
   31|       |// in fp32 for CPUs, except for simple parameter conversions, I/O
   32|       |// to disk and the likes), but fast on GPUs.
   33|       |
   34|       |#ifndef EIGEN_HALF_H
   35|       |#define EIGEN_HALF_H
   36|       |
   37|       |// IWYU pragma: private
   38|       |#include "../../InternalHeaderCheck.h"
   39|       |
   40|       |#if defined(EIGEN_HAS_GPU_FP16) || defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
   41|       |// When compiling with GPU support, the "__half_raw" base class as well as
   42|       |// some other routines are defined in the GPU compiler header files
   43|       |// (cuda_fp16.h, hip_fp16.h), and they are not tagged constexpr
   44|       |// As a consequence, we get compile failures when compiling Eigen with
   45|       |// GPU support. Hence the need to disable EIGEN_CONSTEXPR when building
   46|       |// Eigen with GPU support
   47|       |#pragma push_macro("EIGEN_CONSTEXPR")
   48|       |#undef EIGEN_CONSTEXPR
   49|       |#define EIGEN_CONSTEXPR
   50|       |#endif
   51|       |
   52|       |#define F16_PACKET_FUNCTION(PACKET_F, PACKET_F16, METHOD)                                                  \
   53|       |  template <>                                                                                              \
   54|       |  EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_UNUSED PACKET_F16 METHOD<PACKET_F16>(const PACKET_F16& _x) { \
   55|       |    return float2half(METHOD<PACKET_F>(half2float(_x)));                                                   \
   56|       |  }
   57|       |
   58|       |namespace Eigen {
   59|       |
   60|       |struct half;
   61|       |
   62|       |namespace half_impl {
   63|       |
   64|       |// We want to use the __half_raw struct from the HIP header file only during the device compile phase.
   65|       |// This is required because of a quirk in the way TensorFlow GPU builds are done.
   66|       |// When compiling TensorFlow source code with GPU support, files that
   67|       |//  * contain GPU kernels (i.e. *.cu.cc files) are compiled via hipcc
   68|       |//  * do not contain GPU kernels ( i.e. *.cc files) are compiled via gcc (typically)
   69|       |//
   70|       |// Tensorflow uses the Eigen::half type as its FP16 type, and there are functions that
   71|       |//  * are defined in a file that gets compiled via hipcc AND
   72|       |//  * have Eigen::half as a pass-by-value argument AND
   73|       |//  * are called in a file that gets compiled via gcc
   74|       |//
   75|       |// In the scenario described above the caller and callee will see different versions
   76|       |// of the Eigen::half base class __half_raw, and they will be compiled by different compilers
   77|       |//
   78|       |// There appears to be an ABI mismatch between gcc and clang (which is called by hipcc) that results in
   79|       |// the callee getting corrupted values for the Eigen::half argument.
   80|       |//
   81|       |// Making the host side compile phase of hipcc use the same Eigen::half impl, as the gcc compile, resolves
   82|       |// this error, and hence the following convoluted #if condition
   83|       |#if !defined(EIGEN_HAS_GPU_FP16) || !defined(EIGEN_GPU_COMPILE_PHASE)
   84|       |// Make our own __half_raw definition that is similar to CUDA's.
   85|       |struct __half_raw {
   86|       |#if (defined(EIGEN_HAS_GPU_FP16) && !defined(EIGEN_GPU_COMPILE_PHASE))
   87|       |  // Eigen::half can be used as the datatype for shared memory declarations (in Eigen and TF)
   88|       |  // The element type for shared memory cannot have non-trivial constructors
   89|       |  // and hence the following special casing (which skips the zero-initilization).
   90|       |  // Note that this check gets done even in the host compilation phase, and
   91|       |  // hence the need for this
   92|       |  EIGEN_DEVICE_FUNC __half_raw() {}
   93|       |#else
   94|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __half_raw() : x(0) {}
   95|       |#endif
   96|       |#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
   97|       |  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __half_raw(numext::uint16_t raw) : x(numext::bit_cast<__fp16>(raw)) {}
   98|       |  __fp16 x;
   99|       |#else
  100|      0|  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __half_raw(numext::uint16_t raw) : x(raw) {}
  101|       |  numext::uint16_t x;
  102|       |#endif
  103|       |};
  104|       |
  105|       |#elif defined(EIGEN_HAS_HIP_FP16)
  106|       |// Nothing to do here
  107|       |// HIP fp16 header file has a definition for __half_raw
  108|       |#elif defined(EIGEN_HAS_CUDA_FP16)
  109|       |#if EIGEN_CUDA_SDK_VER < 90000
  110|       |// In CUDA < 9.0, __half is the equivalent of CUDA 9's __half_raw
  111|       |typedef __half __half_raw;
  112|       |#endif  // defined(EIGEN_HAS_CUDA_FP16)
  113|       |#elif defined(SYCL_DEVICE_ONLY)
  114|       |typedef cl::sycl::half __half_raw;
  115|       |#endif
  116|       |
  117|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __half_raw raw_uint16_to_half(numext::uint16_t x);
  118|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __half_raw float_to_half_rtne(float ff);
  119|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float half_to_float(__half_raw h);
  120|       |
  121|       |struct half_base : public __half_raw {
  122|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR half_base() {}
  123|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR half_base(const __half_raw& h) : __half_raw(h) {}
  124|       |
  125|       |#if defined(EIGEN_HAS_GPU_FP16)
  126|       |#if defined(EIGEN_HAS_HIP_FP16)
  127|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR half_base(const __half& h) { x = __half_as_ushort(h); }
  128|       |#elif defined(EIGEN_HAS_CUDA_FP16)
  129|       |#if EIGEN_CUDA_SDK_VER >= 90000
  130|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR half_base(const __half& h) : __half_raw(*(__half_raw*)&h) {}
  131|       |#endif
  132|       |#endif
  133|       |#endif
  134|       |};
  135|       |
  136|       |}  // namespace half_impl
  137|       |
  138|       |// Class definition.
  139|       |struct half : public half_impl::half_base {
  140|       |  // Writing this out as separate #if-else blocks to make the code easier to follow
  141|       |  // The same applies to most #if-else blocks in this file
  142|       |#if !defined(EIGEN_HAS_GPU_FP16) || !defined(EIGEN_GPU_COMPILE_PHASE)
  143|       |  // Use the same base class for the following two scenarios
  144|       |  // * when compiling without GPU support enabled
  145|       |  // * during host compile phase when compiling with GPU support enabled
  146|       |  typedef half_impl::__half_raw __half_raw;
  147|       |#elif defined(EIGEN_HAS_HIP_FP16)
  148|       |  // Nothing to do here
  149|       |  // HIP fp16 header file has a definition for __half_raw
  150|       |#elif defined(EIGEN_HAS_CUDA_FP16)
  151|       |// Note that EIGEN_CUDA_SDK_VER is set to 0 even when compiling with HIP, so
  152|       |// (EIGEN_CUDA_SDK_VER < 90000) is true even for HIP!  So keeping this within
  153|       |// #if defined(EIGEN_HAS_CUDA_FP16) is needed
  154|       |#if defined(EIGEN_CUDA_SDK_VER) && EIGEN_CUDA_SDK_VER < 90000
  155|       |  typedef half_impl::__half_raw __half_raw;
  156|       |#endif
  157|       |#endif
  158|       |
  159|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR half() {}
  160|       |
  161|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR half(const __half_raw& h) : half_impl::half_base(h) {}
  162|       |
  163|       |#if defined(EIGEN_HAS_GPU_FP16)
  164|       |#if defined(EIGEN_HAS_HIP_FP16)
  165|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR half(const __half& h) : half_impl::half_base(h) {}
  166|       |#elif defined(EIGEN_HAS_CUDA_FP16)
  167|       |#if defined(EIGEN_CUDA_SDK_VER) && EIGEN_CUDA_SDK_VER >= 90000
  168|       |  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR half(const __half& h) : half_impl::half_base(h) {}
  169|       |#endif
  170|       |#endif
  171|       |#endif
  172|       |
  173|       |  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR half(bool b)
  174|      0|      : half_impl::half_base(half_impl::raw_uint16_to_half(b ? 0x3c00 : 0)) {}
  175|       |  template <class T>
  176|       |  explicit EIGEN_DEVICE_FUNC half(T val)
  177|       |      : half_impl::half_base(half_impl::float_to_half_rtne(static_cast<float>(val))) {}
  178|      0|  explicit EIGEN_DEVICE_FUNC half(float f) : half_impl::half_base(half_impl::float_to_half_rtne(f)) {}
  179|       |
  180|       |  // Following the convention of numpy, converting between complex and
  181|       |  // float will lead to loss of imag value.
  182|       |  template <typename RealScalar>
  183|       |  explicit EIGEN_DEVICE_FUNC half(std::complex<RealScalar> c)
  184|       |      : half_impl::half_base(half_impl::float_to_half_rtne(static_cast<float>(c.real()))) {}
  185|       |
  186|      0|  EIGEN_DEVICE_FUNC operator float() const {  // NOLINT: Allow implicit conversion to float, because it is lossless.
  187|      0|    return half_impl::half_to_float(*this);
  188|      0|  }
  189|       |
  190|       |#if defined(EIGEN_HAS_GPU_FP16) && !defined(EIGEN_GPU_COMPILE_PHASE)
  191|       |  EIGEN_DEVICE_FUNC operator __half() const {
  192|       |    ::__half_raw hr;
  193|       |    hr.x = x;
  194|       |    return __half(hr);
  195|       |  }
  196|       |#endif
  197|       |};
  198|       |
  199|       |// TODO(majnemer): Get rid of this once we can rely on C++17 inline variables do
  200|       |// solve the ODR issue.
  201|       |namespace half_impl {
  202|       |template <typename = void>
  203|       |struct numeric_limits_half_impl {
  204|       |  static EIGEN_CONSTEXPR const bool is_specialized = true;
  205|       |  static EIGEN_CONSTEXPR const bool is_signed = true;
  206|       |  static EIGEN_CONSTEXPR const bool is_integer = false;
  207|       |  static EIGEN_CONSTEXPR const bool is_exact = false;
  208|       |  static EIGEN_CONSTEXPR const bool has_infinity = true;
  209|       |  static EIGEN_CONSTEXPR const bool has_quiet_NaN = true;
  210|       |  static EIGEN_CONSTEXPR const bool has_signaling_NaN = true;
  211|       |  EIGEN_DIAGNOSTICS(push)
  212|       |  EIGEN_DISABLE_DEPRECATED_WARNING
  213|       |  static EIGEN_CONSTEXPR const std::float_denorm_style has_denorm = std::denorm_present;
  214|       |  static EIGEN_CONSTEXPR const bool has_denorm_loss = false;
  215|       |  EIGEN_DIAGNOSTICS(pop)
  216|       |  static EIGEN_CONSTEXPR const std::float_round_style round_style = std::round_to_nearest;
  217|       |  static EIGEN_CONSTEXPR const bool is_iec559 = true;
  218|       |  // The C++ standard defines this as "true if the set of values representable
  219|       |  // by the type is finite." Half has finite precision.
  220|       |  static EIGEN_CONSTEXPR const bool is_bounded = true;
  221|       |  static EIGEN_CONSTEXPR const bool is_modulo = false;
  222|       |  static EIGEN_CONSTEXPR const int digits = 11;
  223|       |  static EIGEN_CONSTEXPR const int digits10 =
  224|       |      3;  // according to http://half.sourceforge.net/structstd_1_1numeric__limits_3_01half__float_1_1half_01_4.html
  225|       |  static EIGEN_CONSTEXPR const int max_digits10 =
  226|       |      5;  // according to http://half.sourceforge.net/structstd_1_1numeric__limits_3_01half__float_1_1half_01_4.html
  227|       |  static EIGEN_CONSTEXPR const int radix = std::numeric_limits<float>::radix;
  228|       |  static EIGEN_CONSTEXPR const int min_exponent = -13;
  229|       |  static EIGEN_CONSTEXPR const int min_exponent10 = -4;
  230|       |  static EIGEN_CONSTEXPR const int max_exponent = 16;
  231|       |  static EIGEN_CONSTEXPR const int max_exponent10 = 4;
  232|       |  static EIGEN_CONSTEXPR const bool traps = std::numeric_limits<float>::traps;
  233|       |  // IEEE754: "The implementer shall choose how tininess is detected, but shall
  234|       |  // detect tininess in the same way for all operations in radix two"
  235|       |  static EIGEN_CONSTEXPR const bool tinyness_before = std::numeric_limits<float>::tinyness_before;
  236|       |
  237|       |  static EIGEN_CONSTEXPR Eigen::half(min)() { return Eigen::half_impl::raw_uint16_to_half(0x0400); }
  238|       |  static EIGEN_CONSTEXPR Eigen::half lowest() { return Eigen::half_impl::raw_uint16_to_half(0xfbff); }
  239|       |  static EIGEN_CONSTEXPR Eigen::half(max)() { return Eigen::half_impl::raw_uint16_to_half(0x7bff); }
  240|       |  static EIGEN_CONSTEXPR Eigen::half epsilon() { return Eigen::half_impl::raw_uint16_to_half(0x1400); }
  241|       |  static EIGEN_CONSTEXPR Eigen::half round_error() { return Eigen::half_impl::raw_uint16_to_half(0x3800); }
  242|       |  static EIGEN_CONSTEXPR Eigen::half infinity() { return Eigen::half_impl::raw_uint16_to_half(0x7c00); }
  243|       |  static EIGEN_CONSTEXPR Eigen::half quiet_NaN() { return Eigen::half_impl::raw_uint16_to_half(0x7e00); }
  244|       |  static EIGEN_CONSTEXPR Eigen::half signaling_NaN() { return Eigen::half_impl::raw_uint16_to_half(0x7d00); }
  245|       |  static EIGEN_CONSTEXPR Eigen::half denorm_min() { return Eigen::half_impl::raw_uint16_to_half(0x0001); }
  246|       |};
  247|       |
  248|       |template <typename T>
  249|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::is_specialized;
  250|       |template <typename T>
  251|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::is_signed;
  252|       |template <typename T>
  253|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::is_integer;
  254|       |template <typename T>
  255|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::is_exact;
  256|       |template <typename T>
  257|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::has_infinity;
  258|       |template <typename T>
  259|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::has_quiet_NaN;
  260|       |template <typename T>
  261|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::has_signaling_NaN;
  262|       |EIGEN_DIAGNOSTICS(push)
  263|       |EIGEN_DISABLE_DEPRECATED_WARNING
  264|       |template <typename T>
  265|       |EIGEN_CONSTEXPR const std::float_denorm_style numeric_limits_half_impl<T>::has_denorm;
  266|       |template <typename T>
  267|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::has_denorm_loss;
  268|       |EIGEN_DIAGNOSTICS(pop)
  269|       |template <typename T>
  270|       |EIGEN_CONSTEXPR const std::float_round_style numeric_limits_half_impl<T>::round_style;
  271|       |template <typename T>
  272|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::is_iec559;
  273|       |template <typename T>
  274|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::is_bounded;
  275|       |template <typename T>
  276|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::is_modulo;
  277|       |template <typename T>
  278|       |EIGEN_CONSTEXPR const int numeric_limits_half_impl<T>::digits;
  279|       |template <typename T>
  280|       |EIGEN_CONSTEXPR const int numeric_limits_half_impl<T>::digits10;
  281|       |template <typename T>
  282|       |EIGEN_CONSTEXPR const int numeric_limits_half_impl<T>::max_digits10;
  283|       |template <typename T>
  284|       |EIGEN_CONSTEXPR const int numeric_limits_half_impl<T>::radix;
  285|       |template <typename T>
  286|       |EIGEN_CONSTEXPR const int numeric_limits_half_impl<T>::min_exponent;
  287|       |template <typename T>
  288|       |EIGEN_CONSTEXPR const int numeric_limits_half_impl<T>::min_exponent10;
  289|       |template <typename T>
  290|       |EIGEN_CONSTEXPR const int numeric_limits_half_impl<T>::max_exponent;
  291|       |template <typename T>
  292|       |EIGEN_CONSTEXPR const int numeric_limits_half_impl<T>::max_exponent10;
  293|       |template <typename T>
  294|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::traps;
  295|       |template <typename T>
  296|       |EIGEN_CONSTEXPR const bool numeric_limits_half_impl<T>::tinyness_before;
  297|       |}  // end namespace half_impl
  298|       |}  // end namespace Eigen
  299|       |
  300|       |namespace std {
  301|       |// If std::numeric_limits<T> is specialized, should also specialize
  302|       |// std::numeric_limits<const T>, std::numeric_limits<volatile T>, and
  303|       |// std::numeric_limits<const volatile T>
  304|       |// https://stackoverflow.com/a/16519653/
  305|       |template <>
  306|       |class numeric_limits<Eigen::half> : public Eigen::half_impl::numeric_limits_half_impl<> {};
  307|       |template <>
  308|       |class numeric_limits<const Eigen::half> : public numeric_limits<Eigen::half> {};
  309|       |template <>
  310|       |class numeric_limits<volatile Eigen::half> : public numeric_limits<Eigen::half> {};
  311|       |template <>
  312|       |class numeric_limits<const volatile Eigen::half> : public numeric_limits<Eigen::half> {};
  313|       |}  // end namespace std
  314|       |
  315|       |namespace Eigen {
  316|       |
  317|       |namespace half_impl {
  318|       |
  319|       |#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 530) || \
  320|       |    (defined(EIGEN_HAS_HIP_FP16) && defined(HIP_DEVICE_COMPILE))
  321|       |// Note: We deliberately do *not* define this to 1 even if we have Arm's native
  322|       |// fp16 type since GPU half types are rather different from native CPU half types.
  323|       |// TODO: Rename to something like EIGEN_HAS_NATIVE_GPU_FP16
  324|       |#define EIGEN_HAS_NATIVE_FP16
  325|       |#endif
  326|       |
  327|       |// Intrinsics for native fp16 support. Note that on current hardware,
  328|       |// these are no faster than fp32 arithmetic (you need to use the half2
  329|       |// versions to get the ALU speed increased), but you do save the
  330|       |// conversion steps back and forth.
  331|       |
  332|       |#if defined(EIGEN_HAS_NATIVE_FP16)
  333|       |EIGEN_STRONG_INLINE __device__ half operator+(const half& a, const half& b) {
  334|       |#if defined(EIGEN_CUDA_SDK_VER) && EIGEN_CUDA_SDK_VER >= 90000
  335|       |  return __hadd(::__half(a), ::__half(b));
  336|       |#else
  337|       |  return __hadd(a, b);
  338|       |#endif
  339|       |}
  340|       |EIGEN_STRONG_INLINE __device__ half operator*(const half& a, const half& b) { return __hmul(a, b); }
  341|       |EIGEN_STRONG_INLINE __device__ half operator-(const half& a, const half& b) { return __hsub(a, b); }
  342|       |EIGEN_STRONG_INLINE __device__ half operator/(const half& a, const half& b) {
  343|       |#if defined(EIGEN_CUDA_SDK_VER) && EIGEN_CUDA_SDK_VER >= 90000
  344|       |  return __hdiv(a, b);
  345|       |#else
  346|       |  float num = __half2float(a);
  347|       |  float denom = __half2float(b);
  348|       |  return __float2half(num / denom);
  349|       |#endif
  350|       |}
  351|       |EIGEN_STRONG_INLINE __device__ half operator-(const half& a) { return __hneg(a); }
  352|       |EIGEN_STRONG_INLINE __device__ half& operator+=(half& a, const half& b) {
  353|       |  a = a + b;
  354|       |  return a;
  355|       |}
  356|       |EIGEN_STRONG_INLINE __device__ half& operator*=(half& a, const half& b) {
  357|       |  a = a * b;
  358|       |  return a;
  359|       |}
  360|       |EIGEN_STRONG_INLINE __device__ half& operator-=(half& a, const half& b) {
  361|       |  a = a - b;
  362|       |  return a;
  363|       |}
  364|       |EIGEN_STRONG_INLINE __device__ half& operator/=(half& a, const half& b) {
  365|       |  a = a / b;
  366|       |  return a;
  367|       |}
  368|       |EIGEN_STRONG_INLINE __device__ bool operator==(const half& a, const half& b) { return __heq(a, b); }
  369|       |EIGEN_STRONG_INLINE __device__ bool operator!=(const half& a, const half& b) { return __hne(a, b); }
  370|       |EIGEN_STRONG_INLINE __device__ bool operator<(const half& a, const half& b) { return __hlt(a, b); }
  371|       |EIGEN_STRONG_INLINE __device__ bool operator<=(const half& a, const half& b) { return __hle(a, b); }
  372|       |EIGEN_STRONG_INLINE __device__ bool operator>(const half& a, const half& b) { return __hgt(a, b); }
  373|       |EIGEN_STRONG_INLINE __device__ bool operator>=(const half& a, const half& b) { return __hge(a, b); }
  374|       |#endif
  375|       |
  376|       |#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC) && !defined(EIGEN_GPU_COMPILE_PHASE)
  377|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator+(const half& a, const half& b) { return half(vaddh_f16(a.x, b.x)); }
  378|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator*(const half& a, const half& b) { return half(vmulh_f16(a.x, b.x)); }
  379|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half& a, const half& b) { return half(vsubh_f16(a.x, b.x)); }
  380|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator/(const half& a, const half& b) { return half(vdivh_f16(a.x, b.x)); }
  381|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half& a) { return half(vnegh_f16(a.x)); }
  382|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half& operator+=(half& a, const half& b) {
  383|       |  a = half(vaddh_f16(a.x, b.x));
  384|       |  return a;
  385|       |}
  386|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half& operator*=(half& a, const half& b) {
  387|       |  a = half(vmulh_f16(a.x, b.x));
  388|       |  return a;
  389|       |}
  390|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half& operator-=(half& a, const half& b) {
  391|       |  a = half(vsubh_f16(a.x, b.x));
  392|       |  return a;
  393|       |}
  394|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half& operator/=(half& a, const half& b) {
  395|       |  a = half(vdivh_f16(a.x, b.x));
  396|       |  return a;
  397|       |}
  398|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator==(const half& a, const half& b) { return vceqh_f16(a.x, b.x); }
  399|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator!=(const half& a, const half& b) { return !vceqh_f16(a.x, b.x); }
  400|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator<(const half& a, const half& b) { return vclth_f16(a.x, b.x); }
  401|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator<=(const half& a, const half& b) { return vcleh_f16(a.x, b.x); }
  402|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator>(const half& a, const half& b) { return vcgth_f16(a.x, b.x); }
  403|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator>=(const half& a, const half& b) { return vcgeh_f16(a.x, b.x); }
  404|       |// We need to distinguish clang as the CUDA compiler from clang as the host compiler,
  405|       |// invoked by NVCC (e.g. on MacOS). The former needs to see both host and device implementation
  406|       |// of the functions, while the latter can only deal with one of them.
  407|       |#elif !defined(EIGEN_HAS_NATIVE_FP16) || (EIGEN_COMP_CLANG && !EIGEN_COMP_NVCC)  // Emulate support for half floats
  408|       |
  409|       |#if EIGEN_COMP_CLANG && defined(EIGEN_GPUCC)
  410|       |// We need to provide emulated *host-side* FP16 operators for clang.
  411|       |#pragma push_macro("EIGEN_DEVICE_FUNC")
  412|       |#undef EIGEN_DEVICE_FUNC
  413|       |#if defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_HAS_NATIVE_FP16)
  414|       |#define EIGEN_DEVICE_FUNC __host__
  415|       |#else  // both host and device need emulated ops.
  416|       |#define EIGEN_DEVICE_FUNC __host__ __device__
  417|       |#endif
  418|       |#endif
  419|       |
  420|       |// Definitions for CPUs and older HIP+CUDA, mostly working through conversion
  421|       |// to/from fp32.
  422|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator+(const half& a, const half& b) { return half(float(a) + float(b)); }
  423|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator*(const half& a, const half& b) { return half(float(a) * float(b)); }
  424|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half& a, const half& b) { return half(float(a) - float(b)); }
  425|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator/(const half& a, const half& b) { return half(float(a) / float(b)); }
  426|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half& a) {
  427|      0|  half result;
  428|      0|  result.x = a.x ^ 0x8000;
  429|      0|  return result;
  430|      0|}
  431|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half& operator+=(half& a, const half& b) {
  432|      0|  a = half(float(a) + float(b));
  433|      0|  return a;
  434|      0|}
  435|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half& operator*=(half& a, const half& b) {
  436|      0|  a = half(float(a) * float(b));
  437|      0|  return a;
  438|      0|}
  439|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half& operator-=(half& a, const half& b) {
  440|      0|  a = half(float(a) - float(b));
  441|      0|  return a;
  442|      0|}
  443|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half& operator/=(half& a, const half& b) {
  444|      0|  a = half(float(a) / float(b));
  445|      0|  return a;
  446|      0|}
  447|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator==(const half& a, const half& b) {
  448|      0|  return numext::equal_strict(float(a), float(b));
  449|      0|}
  450|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator!=(const half& a, const half& b) {
  451|      0|  return numext::not_equal_strict(float(a), float(b));
  452|      0|}
  453|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator<(const half& a, const half& b) { return float(a) < float(b); }
  454|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator<=(const half& a, const half& b) { return float(a) <= float(b); }
  455|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator>(const half& a, const half& b) { return float(a) > float(b); }
  456|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator>=(const half& a, const half& b) { return float(a) >= float(b); }
  457|       |
  458|       |#if EIGEN_COMP_CLANG && defined(EIGEN_GPUCC)
  459|       |#pragma pop_macro("EIGEN_DEVICE_FUNC")
  460|       |#endif
  461|       |#endif  // Emulate support for half floats
  462|       |
  463|       |// Division by an index. Do it in full float precision to avoid accuracy
  464|       |// issues in converting the denominator to half.
  465|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator/(const half& a, Index b) {
  466|      0|  return half(static_cast<float>(a) / static_cast<float>(b));
  467|      0|}
  468|       |
  469|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator++(half& a) {
  470|      0|  a += half(1);
  471|      0|  return a;
  472|      0|}
  473|       |
  474|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator--(half& a) {
  475|      0|  a -= half(1);
  476|      0|  return a;
  477|      0|}
  478|       |
  479|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator++(half& a, int) {
  480|      0|  half original_value = a;
  481|      0|  ++a;
  482|      0|  return original_value;
  483|      0|}
  484|       |
  485|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator--(half& a, int) {
  486|      0|  half original_value = a;
  487|      0|  --a;
  488|      0|  return original_value;
  489|      0|}
  490|       |
  491|       |// Conversion routines, including fallbacks for the host or older CUDA.
  492|       |// Note that newer Intel CPUs (Haswell or newer) have vectorized versions of
  493|       |// these in hardware. If we need more performance on older/other CPUs, they are
  494|       |// also possible to vectorize directly.
  495|       |
  496|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __half_raw raw_uint16_to_half(numext::uint16_t x) {
  497|      0|  // We cannot simply do a "return __half_raw(x)" here, because __half_raw is union type
  498|      0|  // in the hip_fp16 header file, and that will trigger a compile error
  499|      0|  // On the other hand, having anything but a return statement also triggers a compile error
  500|      0|  // because this is constexpr function.
  501|      0|  // Fortunately, since we need to disable EIGEN_CONSTEXPR for GPU anyway, we can get out
  502|      0|  // of this catch22 by having separate bodies for GPU / non GPU
  503|      0|#if defined(EIGEN_HAS_GPU_FP16)
  504|      0|  __half_raw h;
  505|      0|  h.x = x;
  506|      0|  return h;
  507|      0|#else
  508|      0|  return __half_raw(x);
  509|      0|#endif
  510|      0|}
  511|       |
  512|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC numext::uint16_t raw_half_as_uint16(const __half_raw& h) {
  513|      0|  // HIP/CUDA/Default have a member 'x' of type uint16_t.
  514|      0|  // For ARM64 native half, the member 'x' is of type __fp16, so we need to bit-cast.
  515|      0|  // For SYCL, cl::sycl::half is _Float16, so cast directly.
  516|      0|#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
  517|      0|  return numext::bit_cast<numext::uint16_t>(h.x);
  518|      0|#elif defined(SYCL_DEVICE_ONLY)
  519|      0|  return numext::bit_cast<numext::uint16_t>(h);
  520|      0|#else
  521|      0|  return h.x;
  522|      0|#endif
  523|      0|}
  524|       |
  525|       |union float32_bits {
  526|       |  unsigned int u;
  527|       |  float f;
  528|       |};
  529|       |
  530|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __half_raw float_to_half_rtne(float ff) {
  531|      0|#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 300) || \
  532|      0|    (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIP_DEVICE_COMPILE))
  533|      0|  __half tmp_ff = __float2half(ff);
  534|      0|  return *(__half_raw*)&tmp_ff;
  535|      0|
  536|      0|#elif defined(EIGEN_HAS_FP16_C)
  537|      0|  __half_raw h;
  538|      0|#if EIGEN_COMP_MSVC
  539|      0|  // MSVC does not have scalar instructions.
  540|      0|  h.x = _mm_extract_epi16(_mm_cvtps_ph(_mm_set_ss(ff), 0), 0);
  541|      0|#else
  542|      0|  h.x = _cvtss_sh(ff, 0);
  543|      0|#endif
  544|      0|  return h;
  545|      0|
  546|      0|#elif defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
  547|      0|  __half_raw h;
  548|      0|  h.x = static_cast<__fp16>(ff);
  549|      0|  return h;
  550|      0|
  551|      0|#else
  552|      0|  float32_bits f;
  553|      0|  f.f = ff;
  554|      0|
  555|      0|  const float32_bits f32infty = {255 << 23};
  556|      0|  const float32_bits f16max = {(127 + 16) << 23};
  557|      0|  const float32_bits denorm_magic = {((127 - 15) + (23 - 10) + 1) << 23};
  558|      0|  unsigned int sign_mask = 0x80000000u;
  559|      0|  __half_raw o;
  560|      0|  o.x = static_cast<numext::uint16_t>(0x0u);
  561|      0|
  562|      0|  unsigned int sign = f.u & sign_mask;
  563|      0|  f.u ^= sign;
  564|      0|
  565|      0|  // NOTE all the integer compares in this function can be safely
  566|      0|  // compiled into signed compares since all operands are below
  567|      0|  // 0x80000000. Important if you want fast straight SSE2 code
  568|      0|  // (since there's no unsigned PCMPGTD).
  569|      0|
  570|      0|  if (f.u >= f16max.u) {                         // result is Inf or NaN (all exponent bits set)
  571|      0|    o.x = (f.u > f32infty.u) ? 0x7e00 : 0x7c00;  // NaN->qNaN and Inf->Inf
  572|      0|  } else {                                       // (De)normalized number or zero
  573|      0|    if (f.u < (113 << 23)) {                     // resulting FP16 is subnormal or zero
  574|      0|      // use a magic value to align our 10 mantissa bits at the bottom of
  575|      0|      // the float. as long as FP addition is round-to-nearest-even this
  576|      0|      // just works.
  577|      0|      f.f += denorm_magic.f;
  578|      0|
  579|      0|      // and one integer subtract of the bias later, we have our final float!
  580|      0|      o.x = static_cast<numext::uint16_t>(f.u - denorm_magic.u);
  581|      0|    } else {
  582|      0|      unsigned int mant_odd = (f.u >> 13) & 1;  // resulting mantissa is odd
  583|      0|
  584|      0|      // update exponent, rounding bias part 1
  585|      0|      // Equivalent to `f.u += ((unsigned int)(15 - 127) << 23) + 0xfff`, but
  586|      0|      // without arithmetic overflow.
  587|      0|      f.u += 0xc8000fffU;
  588|      0|      // rounding bias part 2
  589|      0|      f.u += mant_odd;
  590|      0|      // take the bits!
  591|      0|      o.x = static_cast<numext::uint16_t>(f.u >> 13);
  592|      0|    }
  593|      0|  }
  594|      0|
  595|      0|  o.x |= static_cast<numext::uint16_t>(sign >> 16);
  596|      0|  return o;
  597|      0|#endif
  598|      0|}
  599|       |
  600|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float half_to_float(__half_raw h) {
  601|      0|#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 300) || \
  602|      0|    (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIP_DEVICE_COMPILE))
  603|      0|  return __half2float(h);
  604|      0|#elif defined(EIGEN_HAS_FP16_C)
  605|      0|#if EIGEN_COMP_MSVC
  606|      0|  // MSVC does not have scalar instructions.
  607|      0|  return _mm_cvtss_f32(_mm_cvtph_ps(_mm_set1_epi16(h.x)));
  608|      0|#else
  609|      0|  return _cvtsh_ss(h.x);
  610|      0|#endif
  611|      0|#elif defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
  612|      0|  return static_cast<float>(h.x);
  613|      0|#else
  614|      0|  const float32_bits magic = {113 << 23};
  615|      0|  const unsigned int shifted_exp = 0x7c00 << 13;  // exponent mask after shift
  616|      0|  float32_bits o;
  617|      0|
  618|      0|  o.u = (h.x & 0x7fff) << 13;            // exponent/mantissa bits
  619|      0|  unsigned int exp = shifted_exp & o.u;  // just the exponent
  620|      0|  o.u += (127 - 15) << 23;               // exponent adjust
  621|      0|
  622|      0|  // handle exponent special cases
  623|      0|  if (exp == shifted_exp) {   // Inf/NaN?
  624|      0|    o.u += (128 - 16) << 23;  // extra exp adjust
  625|      0|  } else if (exp == 0) {      // Zero/Denormal?
  626|      0|    o.u += 1 << 23;           // extra exp adjust
  627|      0|    o.f -= magic.f;           // renormalize
  628|      0|  }
  629|      0|
  630|      0|  o.u |= (h.x & 0x8000) << 16;  // sign bit
  631|      0|  return o.f;
  632|      0|#endif
  633|      0|}
  634|       |
  635|       |// --- standard functions ---
  636|       |
  637|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isinf)(const half& a) {
  638|      0|#ifdef EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC
  639|      0|  return (numext::bit_cast<numext::uint16_t>(a.x) & 0x7fff) == 0x7c00;
  640|      0|#else
  641|      0|  return (a.x & 0x7fff) == 0x7c00;
  642|      0|#endif
  643|      0|}
  644|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isnan)(const half& a) {
  645|      0|#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 530) || \
  646|      0|    (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIP_DEVICE_COMPILE))
  647|      0|  return __hisnan(a);
  648|      0|#elif defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
  649|      0|  return (numext::bit_cast<numext::uint16_t>(a.x) & 0x7fff) > 0x7c00;
  650|      0|#else
  651|      0|  return (a.x & 0x7fff) > 0x7c00;
  652|      0|#endif
  653|      0|}
  654|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isfinite)(const half& a) {
  655|      0|  return !(isinf EIGEN_NOT_A_MACRO(a)) && !(isnan EIGEN_NOT_A_MACRO(a));
  656|      0|}
  657|       |
  658|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half abs(const half& a) {
  659|      0|#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
  660|      0|  return half(vabsh_f16(a.x));
  661|      0|#else
  662|      0|  half result;
  663|      0|  result.x = a.x & 0x7FFF;
  664|      0|  return result;
  665|      0|#endif
  666|      0|}
  667|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half exp(const half& a) {
  668|      0|#if (EIGEN_CUDA_SDK_VER >= 80000 && defined EIGEN_CUDA_ARCH && EIGEN_CUDA_ARCH >= 530) || \
  669|      0|    defined(EIGEN_HIP_DEVICE_COMPILE)
  670|      0|  return half(hexp(a));
  671|      0|#else
  672|      0|  return half(::expf(float(a)));
  673|      0|#endif
  674|      0|}
  675|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half exp2(const half& a) {
  676|      0|#if (EIGEN_CUDA_SDK_VER >= 80000 && defined EIGEN_CUDA_ARCH && EIGEN_CUDA_ARCH >= 530) || \
  677|      0|    defined(EIGEN_HIP_DEVICE_COMPILE)
  678|      0|  return half(hexp2(a));
  679|      0|#else
  680|      0|  return half(::exp2f(float(a)));
  681|      0|#endif
  682|      0|}
  683|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half expm1(const half& a) { return half(numext::expm1(float(a))); }
  684|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half log(const half& a) {
  685|      0|#if (defined(EIGEN_HAS_CUDA_FP16) && EIGEN_CUDA_SDK_VER >= 80000 && defined(EIGEN_CUDA_ARCH) && \
  686|      0|     EIGEN_CUDA_ARCH >= 530) ||                                                                 \
  687|      0|    (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIP_DEVICE_COMPILE))
  688|      0|  return half(hlog(a));
  689|      0|#else
  690|      0|  return half(::logf(float(a)));
  691|      0|#endif
  692|      0|}
  693|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half log1p(const half& a) { return half(numext::log1p(float(a))); }
  694|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half log10(const half& a) { return half(::log10f(float(a))); }
  695|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half log2(const half& a) {
  696|      0|  return half(static_cast<float>(EIGEN_LOG2E) * ::logf(float(a)));
  697|      0|}
  698|       |
  699|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half sqrt(const half& a) {
  700|      0|#if (EIGEN_CUDA_SDK_VER >= 80000 && defined EIGEN_CUDA_ARCH && EIGEN_CUDA_ARCH >= 530) || \
  701|      0|    defined(EIGEN_HIP_DEVICE_COMPILE)
  702|      0|  return half(hsqrt(a));
  703|      0|#else
  704|      0|  return half(::sqrtf(float(a)));
  705|      0|#endif
  706|      0|}
  707|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half pow(const half& a, const half& b) {
  708|      0|  return half(::powf(float(a), float(b)));
  709|      0|}
  710|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half atan2(const half& a, const half& b) {
  711|      0|  return half(::atan2f(float(a), float(b)));
  712|      0|}
  713|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half sin(const half& a) { return half(::sinf(float(a))); }
  714|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half cos(const half& a) { return half(::cosf(float(a))); }
  715|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half tan(const half& a) { return half(::tanf(float(a))); }
  716|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half tanh(const half& a) { return half(::tanhf(float(a))); }
  717|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half asin(const half& a) { return half(::asinf(float(a))); }
  718|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half acos(const half& a) { return half(::acosf(float(a))); }
  719|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half atan(const half& a) { return half(::atanf(float(a))); }
  720|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half atanh(const half& a) { return half(::atanhf(float(a))); }
  721|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half floor(const half& a) {
  722|      0|#if (EIGEN_CUDA_SDK_VER >= 80000 && defined EIGEN_CUDA_ARCH && EIGEN_CUDA_ARCH >= 300) || \
  723|      0|    defined(EIGEN_HIP_DEVICE_COMPILE)
  724|      0|  return half(hfloor(a));
  725|      0|#else
  726|      0|  return half(::floorf(float(a)));
  727|      0|#endif
  728|      0|}
  729|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half ceil(const half& a) {
  730|      0|#if (EIGEN_CUDA_SDK_VER >= 80000 && defined EIGEN_CUDA_ARCH && EIGEN_CUDA_ARCH >= 300) || \
  731|      0|    defined(EIGEN_HIP_DEVICE_COMPILE)
  732|      0|  return half(hceil(a));
  733|      0|#else
  734|      0|  return half(::ceilf(float(a)));
  735|      0|#endif
  736|      0|}
  737|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half rint(const half& a) { return half(::rintf(float(a))); }
  738|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half round(const half& a) { return half(::roundf(float(a))); }
  739|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half trunc(const half& a) { return half(::truncf(float(a))); }
  740|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half fmod(const half& a, const half& b) {
  741|      0|  return half(::fmodf(float(a), float(b)));
  742|      0|}
  743|       |
  744|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half(min)(const half& a, const half& b) {
  745|      0|#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 530) || \
  746|      0|    (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIP_DEVICE_COMPILE))
  747|      0|  return __hlt(b, a) ? b : a;
  748|      0|#else
  749|      0|  const float f1 = static_cast<float>(a);
  750|      0|  const float f2 = static_cast<float>(b);
  751|      0|  return f2 < f1 ? b : a;
  752|      0|#endif
  753|      0|}
  754|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half(max)(const half& a, const half& b) {
  755|      0|#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 530) || \
  756|      0|    (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIP_DEVICE_COMPILE))
  757|      0|  return __hlt(a, b) ? b : a;
  758|      0|#else
  759|      0|  const float f1 = static_cast<float>(a);
  760|      0|  const float f2 = static_cast<float>(b);
  761|      0|  return f1 < f2 ? b : a;
  762|      0|#endif
  763|      0|}
  764|       |
  765|       |#ifndef EIGEN_NO_IO
  766|      0|EIGEN_ALWAYS_INLINE std::ostream& operator<<(std::ostream& os, const half& v) {
  767|      0|  os << static_cast<float>(v);
  768|      0|  return os;
  769|      0|}
  770|       |#endif
  771|       |
  772|       |}  // end namespace half_impl
  773|       |
  774|       |// import Eigen::half_impl::half into Eigen namespace
  775|       |// using half_impl::half;
  776|       |
  777|       |namespace internal {
  778|       |
  779|       |template <>
  780|       |struct is_arithmetic<half> {
  781|       |  enum { value = true };
  782|       |};
  783|       |
  784|       |template <>
  785|       |struct random_impl<half> {
  786|       |  enum : int { MantissaBits = 10 };
  787|       |  using Impl = random_impl<float>;
  788|      0|  static EIGEN_DEVICE_FUNC inline half run(const half& x, const half& y) {
  789|      0|    float result = Impl::run(x, y, MantissaBits);
  790|      0|    return half(result);
  791|      0|  }
  792|      0|  static EIGEN_DEVICE_FUNC inline half run() {
  793|      0|    float result = Impl::run(MantissaBits);
  794|      0|    return half(result);
  795|      0|  }
  796|       |};
  797|       |
  798|       |}  // end namespace internal
  799|       |
  800|       |template <>
  801|       |struct NumTraits<Eigen::half> : GenericNumTraits<Eigen::half> {
  802|       |  enum { IsSigned = true, IsInteger = false, IsComplex = false, RequireInitialization = false };
  803|       |
  804|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half epsilon() {
  805|      0|    return half_impl::raw_uint16_to_half(0x0800);
  806|      0|  }
  807|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half dummy_precision() {
  808|      0|    return half_impl::raw_uint16_to_half(0x211f);  //  Eigen::half(1e-2f);
  809|      0|  }
  810|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half highest() {
  811|      0|    return half_impl::raw_uint16_to_half(0x7bff);
  812|      0|  }
  813|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half lowest() {
  814|      0|    return half_impl::raw_uint16_to_half(0xfbff);
  815|      0|  }
  816|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half infinity() {
  817|      0|    return half_impl::raw_uint16_to_half(0x7c00);
  818|      0|  }
  819|      0|  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half quiet_NaN() {
  820|      0|    return half_impl::raw_uint16_to_half(0x7e00);
  821|      0|  }
  822|       |};
  823|       |
  824|       |}  // end namespace Eigen
  825|       |
  826|       |#if defined(EIGEN_HAS_GPU_FP16) || defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
  827|       |#pragma pop_macro("EIGEN_CONSTEXPR")
  828|       |#endif
  829|       |
  830|       |namespace Eigen {
  831|       |namespace numext {
  832|       |
  833|       |#if defined(EIGEN_GPU_COMPILE_PHASE)
  834|       |
  835|       |template <>
  836|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isnan)(const Eigen::half& h) {
  837|       |  return (half_impl::isnan)(h);
  838|       |}
  839|       |
  840|       |template <>
  841|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isinf)(const Eigen::half& h) {
  842|       |  return (half_impl::isinf)(h);
  843|       |}
  844|       |
  845|       |template <>
  846|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isfinite)(const Eigen::half& h) {
  847|       |  return (half_impl::isfinite)(h);
  848|       |}
  849|       |
  850|       |#endif
  851|       |
  852|       |template <>
  853|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Eigen::half bit_cast<Eigen::half, uint16_t>(const uint16_t& src) {
  854|      0|  return Eigen::half(Eigen::half_impl::raw_uint16_to_half(src));
  855|      0|}
  856|       |
  857|       |template <>
  858|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC uint16_t bit_cast<uint16_t, Eigen::half>(const Eigen::half& src) {
  859|      0|  return Eigen::half_impl::raw_half_as_uint16(src);
  860|      0|}
  861|       |
  862|       |}  // namespace numext
  863|       |}  // namespace Eigen
  864|       |
  865|       |// Add the missing shfl* intrinsics.
  866|       |// The __shfl* functions are only valid on HIP or _CUDA_ARCH_ >= 300.
  867|       |//   CUDA defines them for (__CUDA_ARCH__ >= 300 || !defined(__CUDA_ARCH__))
  868|       |//
  869|       |// HIP and CUDA prior to SDK 9.0 define
  870|       |//    __shfl, __shfl_up, __shfl_down, __shfl_xor for int and float
  871|       |// CUDA since 9.0 deprecates those and instead defines
  872|       |//    __shfl_sync, __shfl_up_sync, __shfl_down_sync, __shfl_xor_sync,
  873|       |//    with native support for __half and __nv_bfloat16
  874|       |//
  875|       |// Note that the following are __device__ - only functions.
  876|       |#if (defined(EIGEN_CUDACC) && (!defined(EIGEN_CUDA_ARCH) || EIGEN_CUDA_ARCH >= 300)) || defined(EIGEN_HIPCC)
  877|       |
  878|       |#if defined(EIGEN_HAS_CUDA_FP16) && EIGEN_CUDA_SDK_VER >= 90000
  879|       |
  880|       |__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_sync(unsigned mask, Eigen::half var, int srcLane,
  881|       |                                                       int width = warpSize) {
  882|       |  const __half h = var;
  883|       |  return static_cast<Eigen::half>(__shfl_sync(mask, h, srcLane, width));
  884|       |}
  885|       |
  886|       |__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_up_sync(unsigned mask, Eigen::half var, unsigned int delta,
  887|       |                                                          int width = warpSize) {
  888|       |  const __half h = var;
  889|       |  return static_cast<Eigen::half>(__shfl_up_sync(mask, h, delta, width));
  890|       |}
  891|       |
  892|       |__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_down_sync(unsigned mask, Eigen::half var, unsigned int delta,
  893|       |                                                            int width = warpSize) {
  894|       |  const __half h = var;
  895|       |  return static_cast<Eigen::half>(__shfl_down_sync(mask, h, delta, width));
  896|       |}
  897|       |
  898|       |__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_xor_sync(unsigned mask, Eigen::half var, int laneMask,
  899|       |                                                           int width = warpSize) {
  900|       |  const __half h = var;
  901|       |  return static_cast<Eigen::half>(__shfl_xor_sync(mask, h, laneMask, width));
  902|       |}
  903|       |
  904|       |#else  // HIP or CUDA SDK < 9.0
  905|       |
  906|       |__device__ EIGEN_STRONG_INLINE Eigen::half __shfl(Eigen::half var, int srcLane, int width = warpSize) {
  907|       |  const int ivar = static_cast<int>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(var));
  908|       |  return Eigen::numext::bit_cast<Eigen::half>(static_cast<Eigen::numext::uint16_t>(__shfl(ivar, srcLane, width)));
  909|       |}
  910|       |
  911|       |__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_up(Eigen::half var, unsigned int delta, int width = warpSize) {
  912|       |  const int ivar = static_cast<int>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(var));
  913|       |  return Eigen::numext::bit_cast<Eigen::half>(static_cast<Eigen::numext::uint16_t>(__shfl_up(ivar, delta, width)));
  914|       |}
  915|       |
  916|       |__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_down(Eigen::half var, unsigned int delta, int width = warpSize) {
  917|       |  const int ivar = static_cast<int>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(var));
  918|       |  return Eigen::numext::bit_cast<Eigen::half>(static_cast<Eigen::numext::uint16_t>(__shfl_down(ivar, delta, width)));
  919|       |}
  920|       |
  921|       |__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_xor(Eigen::half var, int laneMask, int width = warpSize) {
  922|       |  const int ivar = static_cast<int>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(var));
  923|       |  return Eigen::numext::bit_cast<Eigen::half>(static_cast<Eigen::numext::uint16_t>(__shfl_xor(ivar, laneMask, width)));
  924|       |}
  925|       |
  926|       |#endif  // HIP vs CUDA
  927|       |#endif  // __shfl*
  928|       |
  929|       |// ldg() has an overload for __half_raw, but we also need one for Eigen::half.
  930|       |#if (defined(EIGEN_CUDACC) && (!defined(EIGEN_CUDA_ARCH) || EIGEN_CUDA_ARCH >= 350)) || defined(EIGEN_HIPCC)
  931|       |EIGEN_STRONG_INLINE __device__ Eigen::half __ldg(const Eigen::half* ptr) {
  932|       |  return Eigen::half_impl::raw_uint16_to_half(__ldg(reinterpret_cast<const Eigen::numext::uint16_t*>(ptr)));
  933|       |}
  934|       |#endif  // __ldg
  935|       |
  936|       |#if EIGEN_HAS_STD_HASH
  937|       |namespace std {
  938|       |template <>
  939|       |struct hash<Eigen::half> {
  940|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE std::size_t operator()(const Eigen::half& a) const {
  941|      0|    return static_cast<std::size_t>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(a));
  942|      0|  }
  943|       |};
  944|       |}  // end namespace std
  945|       |#endif
  946|       |
  947|       |namespace Eigen {
  948|       |namespace internal {
  949|       |
  950|       |template <>
  951|       |struct cast_impl<float, half> {
  952|      0|  EIGEN_DEVICE_FUNC static inline half run(const float& a) {
  953|      0|#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 300) || \
  954|      0|    (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIP_DEVICE_COMPILE))
  955|      0|    return __float2half(a);
  956|      0|#else
  957|      0|    return half(a);
  958|      0|#endif
  959|      0|  }
  960|       |};
  961|       |
  962|       |template <>
  963|       |struct cast_impl<int, half> {
  964|      0|  EIGEN_DEVICE_FUNC static inline half run(const int& a) {
  965|      0|#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 300) || \
  966|      0|    (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIP_DEVICE_COMPILE))
  967|      0|    return __float2half(static_cast<float>(a));
  968|      0|#else
  969|      0|    return half(static_cast<float>(a));
  970|      0|#endif
  971|      0|  }
  972|       |};
  973|       |
  974|       |template <>
  975|       |struct cast_impl<half, float> {
  976|      0|  EIGEN_DEVICE_FUNC static inline float run(const half& a) {
  977|      0|#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 300) || \
  978|      0|    (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIP_DEVICE_COMPILE))
  979|      0|    return __half2float(a);
  980|      0|#else
  981|      0|    return static_cast<float>(a);
  982|      0|#endif
  983|      0|  }
  984|       |};
  985|       |
  986|       |}  // namespace internal
  987|       |}  // namespace Eigen
  988|       |
  989|       |#endif  // EIGEN_HALF_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/arch/SSE/Complex.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2010 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_COMPLEX_SSE_H
   11|       |#define EIGEN_COMPLEX_SSE_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |//---------- float ----------
   21|       |struct Packet2cf {
   22|      0|  EIGEN_STRONG_INLINE Packet2cf() {}
   23|      0|  EIGEN_STRONG_INLINE explicit Packet2cf(const __m128& a) : v(a) {}
   24|       |  Packet4f v;
   25|       |};
   26|       |
   27|       |// Use the packet_traits defined in AVX/PacketMath.h instead if we're going
   28|       |// to leverage AVX instructions.
   29|       |#ifndef EIGEN_VECTORIZE_AVX
   30|       |template <>
   31|       |struct packet_traits<std::complex<float> > : default_packet_traits {
   32|       |  typedef Packet2cf type;
   33|       |  typedef Packet2cf half;
   34|       |  enum {
   35|       |    Vectorizable = 1,
   36|       |    AlignedOnScalar = 1,
   37|       |    size = 2,
   38|       |
   39|       |    HasAdd = 1,
   40|       |    HasSub = 1,
   41|       |    HasMul = 1,
   42|       |    HasDiv = 1,
   43|       |    HasNegate = 1,
   44|       |    HasSqrt = 1,
   45|       |    HasLog = 1,
   46|       |    HasExp = 1,
   47|       |    HasAbs = 0,
   48|       |    HasAbs2 = 0,
   49|       |    HasMin = 0,
   50|       |    HasMax = 0,
   51|       |    HasSetLinear = 0,
   52|       |    HasBlend = 1
   53|       |  };
   54|       |};
   55|       |#endif
   56|       |
   57|       |template <>
   58|       |struct unpacket_traits<Packet2cf> {
   59|       |  typedef std::complex<float> type;
   60|       |  typedef Packet2cf half;
   61|       |  typedef Packet4f as_real;
   62|       |  enum {
   63|       |    size = 2,
   64|       |    alignment = Aligned16,
   65|       |    vectorizable = true,
   66|       |    masked_load_available = false,
   67|       |    masked_store_available = false
   68|       |  };
   69|       |};
   70|       |
   71|       |template <>
   72|      0|EIGEN_STRONG_INLINE Packet2cf padd<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
   73|      0|  return Packet2cf(_mm_add_ps(a.v, b.v));
   74|      0|}
   75|       |template <>
   76|      0|EIGEN_STRONG_INLINE Packet2cf psub<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
   77|      0|  return Packet2cf(_mm_sub_ps(a.v, b.v));
   78|      0|}
   79|       |
   80|       |template <>
   81|      0|EIGEN_STRONG_INLINE Packet2cf pnegate(const Packet2cf& a) {
   82|      0|  const __m128 mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000, 0x80000000, 0x80000000, 0x80000000));
   83|      0|  return Packet2cf(_mm_xor_ps(a.v, mask));
   84|      0|}
   85|       |template <>
   86|      0|EIGEN_STRONG_INLINE Packet2cf pconj(const Packet2cf& a) {
   87|      0|  const __m128 mask = _mm_castsi128_ps(_mm_setr_epi32(0x00000000, 0x80000000, 0x00000000, 0x80000000));
   88|      0|  return Packet2cf(_mm_xor_ps(a.v, mask));
   89|      0|}
   90|       |
   91|       |template <>
   92|      0|EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) {
   93|      0|#ifdef EIGEN_VECTORIZE_SSE3
   94|      0|  __m128 tmp1 = _mm_mul_ps(_mm_movehdup_ps(a.v), vec4f_swizzle1(b.v, 1, 0, 3, 2));
   95|      0|  __m128 tmp2 = _mm_moveldup_ps(a.v);
   96|      0|#else
   97|      0|  __m128 tmp1 = _mm_mul_ps(vec4f_swizzle1(a.v, 1, 1, 3, 3), vec4f_swizzle1(b.v, 1, 0, 3, 2));
   98|      0|  __m128 tmp2 = vec4f_swizzle1(a.v, 0, 0, 2, 2);
   99|      0|#endif
  100|      0|#ifdef EIGEN_VECTORIZE_FMA
  101|      0|  __m128 result = _mm_fmaddsub_ps(tmp2, b.v, tmp1);
  102|      0|#else
  103|      0|#ifdef EIGEN_VECTORIZE_SSE3
  104|      0|  __m128 result = _mm_addsub_ps(_mm_mul_ps(tmp2, b.v), tmp1);
  105|      0|#else
  106|      0|  const __m128 mask = _mm_setr_ps(-0.0f, 0.0f, -0.0f, 0.0f);
  107|      0|  __m128 result = _mm_add_ps(_mm_mul_ps(tmp2, b.v), _mm_xor_ps(tmp1, mask));
  108|      0|#endif
  109|      0|#endif
  110|      0|  return Packet2cf(result);
  111|      0|}
  112|       |
  113|       |template <>
  114|      0|EIGEN_STRONG_INLINE Packet2cf ptrue<Packet2cf>(const Packet2cf& a) {
  115|      0|  return Packet2cf(ptrue(Packet4f(a.v)));
  116|      0|}
  117|       |template <>
  118|      0|EIGEN_STRONG_INLINE Packet2cf pand<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
  119|      0|  return Packet2cf(_mm_and_ps(a.v, b.v));
  120|      0|}
  121|       |template <>
  122|      0|EIGEN_STRONG_INLINE Packet2cf por<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
  123|      0|  return Packet2cf(_mm_or_ps(a.v, b.v));
  124|      0|}
  125|       |template <>
  126|      0|EIGEN_STRONG_INLINE Packet2cf pxor<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
  127|      0|  return Packet2cf(_mm_xor_ps(a.v, b.v));
  128|      0|}
  129|       |template <>
  130|      0|EIGEN_STRONG_INLINE Packet2cf pandnot<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
  131|      0|  return Packet2cf(_mm_andnot_ps(b.v, a.v));
  132|      0|}
  133|       |
  134|       |template <>
  135|      0|EIGEN_STRONG_INLINE Packet2cf pload<Packet2cf>(const std::complex<float>* from) {
  136|      0|  EIGEN_DEBUG_ALIGNED_LOAD return Packet2cf(_mm_load_ps(&numext::real_ref(*from)));
  137|      0|}
  138|       |template <>
  139|      0|EIGEN_STRONG_INLINE Packet2cf ploadu<Packet2cf>(const std::complex<float>* from) {
  140|      0|  EIGEN_DEBUG_UNALIGNED_LOAD return Packet2cf(_mm_loadu_ps(&numext::real_ref(*from)));
  141|      0|}
  142|       |
  143|       |template <>
  144|      0|EIGEN_STRONG_INLINE Packet2cf pset1<Packet2cf>(const std::complex<float>& from) {
  145|      0|  const float re = std::real(from);
  146|      0|  const float im = std::imag(from);
  147|      0|  return Packet2cf(_mm_set_ps(im, re, im, re));
  148|      0|}
  149|       |
  150|       |template <>
  151|      0|EIGEN_STRONG_INLINE Packet2cf ploaddup<Packet2cf>(const std::complex<float>* from) {
  152|      0|  return pset1<Packet2cf>(*from);
  153|      0|}
  154|       |
  155|       |template <>
  156|      0|EIGEN_STRONG_INLINE void pstore<std::complex<float> >(std::complex<float>* to, const Packet2cf& from) {
  157|      0|  EIGEN_DEBUG_ALIGNED_STORE _mm_store_ps(&numext::real_ref(*to), from.v);
  158|      0|}
  159|       |template <>
  160|      0|EIGEN_STRONG_INLINE void pstoreu<std::complex<float> >(std::complex<float>* to, const Packet2cf& from) {
  161|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_ps(&numext::real_ref(*to), from.v);
  162|      0|}
  163|       |
  164|       |template <>
  165|       |EIGEN_DEVICE_FUNC inline Packet2cf pgather<std::complex<float>, Packet2cf>(const std::complex<float>* from,
  166|      0|                                                                           Index stride) {
  167|      0|  return Packet2cf(_mm_set_ps(std::imag(from[1 * stride]), std::real(from[1 * stride]), std::imag(from[0 * stride]),
  168|      0|                              std::real(from[0 * stride])));
  169|      0|}
  170|       |
  171|       |template <>
  172|       |EIGEN_DEVICE_FUNC inline void pscatter<std::complex<float>, Packet2cf>(std::complex<float>* to, const Packet2cf& from,
  173|      0|                                                                       Index stride) {
  174|      0|  to[stride * 0] = std::complex<float>(_mm_cvtss_f32(_mm_shuffle_ps(from.v, from.v, 0)),
  175|      0|                                       _mm_cvtss_f32(_mm_shuffle_ps(from.v, from.v, 1)));
  176|      0|  to[stride * 1] = std::complex<float>(_mm_cvtss_f32(_mm_shuffle_ps(from.v, from.v, 2)),
  177|      0|                                       _mm_cvtss_f32(_mm_shuffle_ps(from.v, from.v, 3)));
  178|      0|}
  179|       |
  180|       |template <>
  181|      0|EIGEN_STRONG_INLINE void prefetch<std::complex<float> >(const std::complex<float>* addr) {
  182|      0|  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);
  183|      0|}
  184|       |
  185|       |template <>
  186|      0|EIGEN_STRONG_INLINE std::complex<float> pfirst<Packet2cf>(const Packet2cf& a) {
  187|      0|  alignas(alignof(__m64)) std::complex<float> res;
  188|      0|  _mm_storel_pi((__m64*)&res, a.v);
  189|      0|  return res;
  190|      0|}
  191|       |
  192|       |template <>
  193|      0|EIGEN_STRONG_INLINE Packet2cf preverse(const Packet2cf& a) {
  194|      0|  return Packet2cf(_mm_castpd_ps(preverse(Packet2d(_mm_castps_pd(a.v)))));
  195|      0|}
  196|       |
  197|       |template <>
  198|      0|EIGEN_STRONG_INLINE std::complex<float> predux<Packet2cf>(const Packet2cf& a) {
  199|      0|  return pfirst(Packet2cf(_mm_add_ps(a.v, _mm_movehl_ps(a.v, a.v))));
  200|      0|}
  201|       |
  202|       |template <>
  203|      0|EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet2cf>(const Packet2cf& a) {
  204|      0|  return pfirst(pmul(a, Packet2cf(_mm_movehl_ps(a.v, a.v))));
  205|      0|}
  206|       |
  207|      0|EIGEN_STRONG_INLINE Packet2cf pcplxflip /* <Packet2cf> */ (const Packet2cf& x) {
  208|      0|  return Packet2cf(vec4f_swizzle1(x.v, 1, 0, 3, 2));
  209|      0|}
  210|       |
  211|       |EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf, Packet4f)
  212|       |
  213|       |template <>
  214|      0|EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
  215|      0|  return pdiv_complex(a, b);
  216|      0|}
  217|       |
  218|       |//---------- double ----------
  219|       |struct Packet1cd {
  220|      0|  EIGEN_STRONG_INLINE Packet1cd() {}
  221|      0|  EIGEN_STRONG_INLINE explicit Packet1cd(const __m128d& a) : v(a) {}
  222|       |  Packet2d v;
  223|       |};
  224|       |
  225|       |// Use the packet_traits defined in AVX/PacketMath.h instead if we're going
  226|       |// to leverage AVX instructions.
  227|       |#ifndef EIGEN_VECTORIZE_AVX
  228|       |template <>
  229|       |struct packet_traits<std::complex<double> > : default_packet_traits {
  230|       |  typedef Packet1cd type;
  231|       |  typedef Packet1cd half;
  232|       |  enum {
  233|       |    Vectorizable = 1,
  234|       |    AlignedOnScalar = 0,
  235|       |    size = 1,
  236|       |
  237|       |    HasAdd = 1,
  238|       |    HasSub = 1,
  239|       |    HasMul = 1,
  240|       |    HasDiv = 1,
  241|       |    HasNegate = 1,
  242|       |    HasSqrt = 1,
  243|       |    HasLog = 1,
  244|       |    HasAbs = 0,
  245|       |    HasAbs2 = 0,
  246|       |    HasMin = 0,
  247|       |    HasMax = 0,
  248|       |    HasSetLinear = 0
  249|       |  };
  250|       |};
  251|       |#endif
  252|       |
  253|       |template <>
  254|       |struct unpacket_traits<Packet1cd> {
  255|       |  typedef std::complex<double> type;
  256|       |  typedef Packet1cd half;
  257|       |  typedef Packet2d as_real;
  258|       |  enum {
  259|       |    size = 1,
  260|       |    alignment = Aligned16,
  261|       |    vectorizable = true,
  262|       |    masked_load_available = false,
  263|       |    masked_store_available = false
  264|       |  };
  265|       |};
  266|       |
  267|       |template <>
  268|      0|EIGEN_STRONG_INLINE Packet1cd padd<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
  269|      0|  return Packet1cd(_mm_add_pd(a.v, b.v));
  270|      0|}
  271|       |template <>
  272|      0|EIGEN_STRONG_INLINE Packet1cd psub<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
  273|      0|  return Packet1cd(_mm_sub_pd(a.v, b.v));
  274|      0|}
  275|       |template <>
  276|      0|EIGEN_STRONG_INLINE Packet1cd pnegate(const Packet1cd& a) {
  277|      0|  return Packet1cd(pnegate(Packet2d(a.v)));
  278|      0|}
  279|       |template <>
  280|      0|EIGEN_STRONG_INLINE Packet1cd pconj(const Packet1cd& a) {
  281|      0|  const __m128d mask = _mm_castsi128_pd(_mm_set_epi32(0x80000000, 0x0, 0x0, 0x0));
  282|      0|  return Packet1cd(_mm_xor_pd(a.v, mask));
  283|      0|}
  284|       |
  285|       |template <>
  286|      0|EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) {
  287|      0|  __m128d tmp1 = _mm_mul_pd(_mm_unpackhi_pd(a.v, a.v), vec2d_swizzle1(b.v, 1, 0));
  288|      0|#ifdef EIGEN_VECTORIZE_SSE3
  289|      0|  __m128d tmp2 = _mm_movedup_pd(a.v);
  290|      0|#else
  291|      0|  __m128d tmp2 = _mm_unpacklo_pd(a.v, a.v);
  292|      0|#endif
  293|      0|#ifdef EIGEN_VECTORIZE_FMA
  294|      0|  __m128d result = _mm_fmaddsub_pd(tmp2, b.v, tmp1);
  295|      0|#else
  296|      0|#ifdef EIGEN_VECTORIZE_SSE3
  297|      0|  __m128d result = _mm_addsub_pd(_mm_mul_pd(tmp2, b.v), tmp1);
  298|      0|#else
  299|      0|  const __m128d mask = _mm_setr_pd(-0.0, 0.0);
  300|      0|  __m128d result = _mm_add_pd(_mm_mul_pd(tmp2, b.v), _mm_xor_pd(tmp1, mask));
  301|      0|#endif
  302|      0|#endif
  303|      0|  return Packet1cd(result);
  304|      0|}
  305|       |
  306|       |template <>
  307|      0|EIGEN_STRONG_INLINE Packet1cd ptrue<Packet1cd>(const Packet1cd& a) {
  308|      0|  return Packet1cd(ptrue(Packet2d(a.v)));
  309|      0|}
  310|       |template <>
  311|      0|EIGEN_STRONG_INLINE Packet1cd pand<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
  312|      0|  return Packet1cd(_mm_and_pd(a.v, b.v));
  313|      0|}
  314|       |template <>
  315|      0|EIGEN_STRONG_INLINE Packet1cd por<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
  316|      0|  return Packet1cd(_mm_or_pd(a.v, b.v));
  317|      0|}
  318|       |template <>
  319|      0|EIGEN_STRONG_INLINE Packet1cd pxor<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
  320|      0|  return Packet1cd(_mm_xor_pd(a.v, b.v));
  321|      0|}
  322|       |template <>
  323|      0|EIGEN_STRONG_INLINE Packet1cd pandnot<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
  324|      0|  return Packet1cd(_mm_andnot_pd(b.v, a.v));
  325|      0|}
  326|       |
  327|       |// FIXME force unaligned load, this is a temporary fix
  328|       |template <>
  329|      0|EIGEN_STRONG_INLINE Packet1cd pload<Packet1cd>(const std::complex<double>* from) {
  330|      0|  EIGEN_DEBUG_ALIGNED_LOAD return Packet1cd(_mm_load_pd((const double*)from));
  331|      0|}
  332|       |template <>
  333|      0|EIGEN_STRONG_INLINE Packet1cd ploadu<Packet1cd>(const std::complex<double>* from) {
  334|      0|  EIGEN_DEBUG_UNALIGNED_LOAD return Packet1cd(_mm_loadu_pd((const double*)from));
  335|      0|}
  336|       |template <>
  337|       |EIGEN_STRONG_INLINE Packet1cd
  338|      0|pset1<Packet1cd>(const std::complex<double>& from) { /* here we really have to use unaligned loads :( */
  339|      0|  return ploadu<Packet1cd>(&from);
  340|      0|}
  341|       |
  342|       |template <>
  343|      0|EIGEN_STRONG_INLINE Packet1cd ploaddup<Packet1cd>(const std::complex<double>* from) {
  344|      0|  return pset1<Packet1cd>(*from);
  345|      0|}
  346|       |
  347|       |// FIXME force unaligned store, this is a temporary fix
  348|       |template <>
  349|      0|EIGEN_STRONG_INLINE void pstore<std::complex<double> >(std::complex<double>* to, const Packet1cd& from) {
  350|      0|  EIGEN_DEBUG_ALIGNED_STORE _mm_store_pd((double*)to, from.v);
  351|      0|}
  352|       |template <>
  353|      0|EIGEN_STRONG_INLINE void pstoreu<std::complex<double> >(std::complex<double>* to, const Packet1cd& from) {
  354|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_pd((double*)to, from.v);
  355|      0|}
  356|       |
  357|       |template <>
  358|      0|EIGEN_STRONG_INLINE void prefetch<std::complex<double> >(const std::complex<double>* addr) {
  359|      0|  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);
  360|      0|}
  361|       |
  362|       |template <>
  363|      0|EIGEN_STRONG_INLINE std::complex<double> pfirst<Packet1cd>(const Packet1cd& a) {
  364|      0|  EIGEN_ALIGN16 double res[2];
  365|      0|  _mm_store_pd(res, a.v);
  366|      0|  return std::complex<double>(res[0], res[1]);
  367|      0|}
  368|       |
  369|       |template <>
  370|      0|EIGEN_STRONG_INLINE Packet1cd preverse(const Packet1cd& a) {
  371|      0|  return a;
  372|      0|}
  373|       |
  374|       |template <>
  375|      0|EIGEN_STRONG_INLINE std::complex<double> predux<Packet1cd>(const Packet1cd& a) {
  376|      0|  return pfirst(a);
  377|      0|}
  378|       |
  379|       |template <>
  380|      0|EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a) {
  381|      0|  return pfirst(a);
  382|      0|}
  383|       |
  384|       |EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd, Packet2d)
  385|       |
  386|       |template <>
  387|      0|EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
  388|      0|  return pdiv_complex(a, b);
  389|      0|}
  390|       |
  391|      0|EIGEN_STRONG_INLINE Packet1cd pcplxflip /* <Packet1cd> */ (const Packet1cd& x) {
  392|      0|  return Packet1cd(preverse(Packet2d(x.v)));
  393|      0|}
  394|       |
  395|      0|EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet2cf, 2>& kernel) {
  396|      0|  __m128d w1 = _mm_castps_pd(kernel.packet[0].v);
  397|      0|  __m128d w2 = _mm_castps_pd(kernel.packet[1].v);
  398|      0|
  399|      0|  __m128 tmp = _mm_castpd_ps(_mm_unpackhi_pd(w1, w2));
  400|      0|  kernel.packet[0].v = _mm_castpd_ps(_mm_unpacklo_pd(w1, w2));
  401|      0|  kernel.packet[1].v = tmp;
  402|      0|}
  403|       |
  404|       |template <>
  405|      0|EIGEN_STRONG_INLINE Packet2cf pcmp_eq(const Packet2cf& a, const Packet2cf& b) {
  406|      0|  __m128 eq = _mm_cmpeq_ps(a.v, b.v);
  407|      0|  return Packet2cf(pand<Packet4f>(eq, vec4f_swizzle1(eq, 1, 0, 3, 2)));
  408|      0|}
  409|       |
  410|       |template <>
  411|      0|EIGEN_STRONG_INLINE Packet1cd pcmp_eq(const Packet1cd& a, const Packet1cd& b) {
  412|      0|  __m128d eq = _mm_cmpeq_pd(a.v, b.v);
  413|      0|  return Packet1cd(pand<Packet2d>(eq, vec2d_swizzle1(eq, 1, 0)));
  414|      0|}
  415|       |
  416|       |template <>
  417|       |EIGEN_STRONG_INLINE Packet2cf pblend(const Selector<2>& ifPacket, const Packet2cf& thenPacket,
  418|      0|                                     const Packet2cf& elsePacket) {
  419|      0|  __m128d result = pblend<Packet2d>(ifPacket, _mm_castps_pd(thenPacket.v), _mm_castps_pd(elsePacket.v));
  420|      0|  return Packet2cf(_mm_castpd_ps(result));
  421|      0|}
  422|       |
  423|       |template <>
  424|      0|EIGEN_STRONG_INLINE Packet1cd psqrt<Packet1cd>(const Packet1cd& a) {
  425|      0|  return psqrt_complex<Packet1cd>(a);
  426|      0|}
  427|       |
  428|       |template <>
  429|      0|EIGEN_STRONG_INLINE Packet2cf psqrt<Packet2cf>(const Packet2cf& a) {
  430|      0|  return psqrt_complex<Packet2cf>(a);
  431|      0|}
  432|       |
  433|       |template <>
  434|      0|EIGEN_STRONG_INLINE Packet1cd plog<Packet1cd>(const Packet1cd& a) {
  435|      0|  return plog_complex<Packet1cd>(a);
  436|      0|}
  437|       |
  438|       |template <>
  439|      0|EIGEN_STRONG_INLINE Packet2cf plog<Packet2cf>(const Packet2cf& a) {
  440|      0|  return plog_complex<Packet2cf>(a);
  441|      0|}
  442|       |
  443|       |template <>
  444|      0|EIGEN_STRONG_INLINE Packet2cf pexp<Packet2cf>(const Packet2cf& a) {
  445|      0|  return pexp_complex<Packet2cf>(a);
  446|      0|}
  447|       |
  448|       |#ifdef EIGEN_VECTORIZE_FMA
  449|       |// std::complex<float>
  450|       |template <>
  451|       |EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& a, const Packet2cf& b, const Packet2cf& c) {
  452|       |  __m128 a_odd = _mm_movehdup_ps(a.v);
  453|       |  __m128 a_even = _mm_moveldup_ps(a.v);
  454|       |  __m128 b_swap = _mm_permute_ps(b.v, _MM_SHUFFLE(2, 3, 0, 1));
  455|       |  __m128 result = _mm_fmaddsub_ps(a_even, b.v, _mm_fmaddsub_ps(a_odd, b_swap, c.v));
  456|       |  return Packet2cf(result);
  457|       |}
  458|       |template <>
  459|       |EIGEN_STRONG_INLINE Packet2cf pmsub(const Packet2cf& a, const Packet2cf& b, const Packet2cf& c) {
  460|       |  __m128 a_odd = _mm_movehdup_ps(a.v);
  461|       |  __m128 a_even = _mm_moveldup_ps(a.v);
  462|       |  __m128 b_swap = _mm_permute_ps(b.v, _MM_SHUFFLE(2, 3, 0, 1));
  463|       |  __m128 result = _mm_fmaddsub_ps(a_even, b.v, _mm_fmsubadd_ps(a_odd, b_swap, c.v));
  464|       |  return Packet2cf(result);
  465|       |}
  466|       |template <>
  467|       |EIGEN_STRONG_INLINE Packet2cf pnmadd(const Packet2cf& a, const Packet2cf& b, const Packet2cf& c) {
  468|       |  __m128 a_odd = _mm_movehdup_ps(a.v);
  469|       |  __m128 a_even = _mm_moveldup_ps(a.v);
  470|       |  __m128 b_swap = _mm_permute_ps(b.v, _MM_SHUFFLE(2, 3, 0, 1));
  471|       |  __m128 result = _mm_fmaddsub_ps(a_odd, b_swap, _mm_fmaddsub_ps(a_even, b.v, c.v));
  472|       |  return Packet2cf(result);
  473|       |}
  474|       |template <>
  475|       |EIGEN_STRONG_INLINE Packet2cf pnmsub(const Packet2cf& a, const Packet2cf& b, const Packet2cf& c) {
  476|       |  __m128 a_odd = _mm_movehdup_ps(a.v);
  477|       |  __m128 a_even = _mm_moveldup_ps(a.v);
  478|       |  __m128 b_swap = _mm_permute_ps(b.v, _MM_SHUFFLE(2, 3, 0, 1));
  479|       |  __m128 result = _mm_fmaddsub_ps(a_odd, b_swap, _mm_fmsubadd_ps(a_even, b.v, c.v));
  480|       |  return Packet2cf(result);
  481|       |}
  482|       |// std::complex<double>
  483|       |template <>
  484|       |EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& a, const Packet1cd& b, const Packet1cd& c) {
  485|       |  __m128d a_odd = _mm_permute_pd(a.v, 0x3);
  486|       |  __m128d a_even = _mm_movedup_pd(a.v);
  487|       |  __m128d b_swap = _mm_permute_pd(b.v, 0x1);
  488|       |  __m128d result = _mm_fmaddsub_pd(a_even, b.v, _mm_fmaddsub_pd(a_odd, b_swap, c.v));
  489|       |  return Packet1cd(result);
  490|       |}
  491|       |template <>
  492|       |EIGEN_STRONG_INLINE Packet1cd pmsub(const Packet1cd& a, const Packet1cd& b, const Packet1cd& c) {
  493|       |  __m128d a_odd = _mm_permute_pd(a.v, 0x3);
  494|       |  __m128d a_even = _mm_movedup_pd(a.v);
  495|       |  __m128d b_swap = _mm_permute_pd(b.v, 0x1);
  496|       |  __m128d result = _mm_fmaddsub_pd(a_even, b.v, _mm_fmsubadd_pd(a_odd, b_swap, c.v));
  497|       |  return Packet1cd(result);
  498|       |}
  499|       |template <>
  500|       |EIGEN_STRONG_INLINE Packet1cd pnmadd(const Packet1cd& a, const Packet1cd& b, const Packet1cd& c) {
  501|       |  __m128d a_odd = _mm_permute_pd(a.v, 0x3);
  502|       |  __m128d a_even = _mm_movedup_pd(a.v);
  503|       |  __m128d b_swap = _mm_permute_pd(b.v, 0x1);
  504|       |  __m128d result = _mm_fmaddsub_pd(a_odd, b_swap, _mm_fmaddsub_pd(a_even, b.v, c.v));
  505|       |  return Packet1cd(result);
  506|       |}
  507|       |template <>
  508|       |EIGEN_STRONG_INLINE Packet1cd pnmsub(const Packet1cd& a, const Packet1cd& b, const Packet1cd& c) {
  509|       |  __m128d a_odd = _mm_permute_pd(a.v, 0x3);
  510|       |  __m128d a_even = _mm_movedup_pd(a.v);
  511|       |  __m128d b_swap = _mm_permute_pd(b.v, 0x1);
  512|       |  __m128d result = _mm_fmaddsub_pd(a_odd, b_swap, _mm_fmsubadd_pd(a_even, b.v, c.v));
  513|       |  return Packet1cd(result);
  514|       |}
  515|       |#endif
  516|       |}  // end namespace internal
  517|       |}  // end namespace Eigen
  518|       |
  519|       |#endif  // EIGEN_COMPLEX_SSE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/arch/SSE/MathFunctions.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2007 Julien Pommier
    5|       |// Copyright (C) 2009 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |/* The sin and cos and functions of this file come from
   12|       | * Julien Pommier's sse math library: http://gruntthepeon.free.fr/ssemath/
   13|       | */
   14|       |
   15|       |#ifndef EIGEN_MATH_FUNCTIONS_SSE_H
   16|       |#define EIGEN_MATH_FUNCTIONS_SSE_H
   17|       |
   18|       |// IWYU pragma: private
   19|       |#include "../../InternalHeaderCheck.h"
   20|       |
   21|       |namespace Eigen {
   22|       |
   23|       |namespace internal {
   24|       |
   25|       |EIGEN_INSTANTIATE_GENERIC_MATH_FUNCS_FLOAT(Packet4f)
   26|       |EIGEN_INSTANTIATE_GENERIC_MATH_FUNCS_DOUBLE(Packet2d)
   27|       |
   28|       |// Notice that for newer processors, it is counterproductive to use Newton
   29|       |// iteration for square root. In particular, Skylake and Zen2 processors
   30|       |// have approximately doubled throughput of the _mm_sqrt_ps instruction
   31|       |// compared to their predecessors.
   32|       |template <>
   33|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet4f psqrt<Packet4f>(const Packet4f& x) {
   34|      0|  return _mm_sqrt_ps(x);
   35|      0|}
   36|       |template <>
   37|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet2d psqrt<Packet2d>(const Packet2d& x) {
   38|      0|  return _mm_sqrt_pd(x);
   39|      0|}
   40|       |template <>
   41|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet16b psqrt<Packet16b>(const Packet16b& x) {
   42|      0|  return x;
   43|      0|}
   44|       |
   45|       |#if EIGEN_FAST_MATH
   46|       |// Even on Skylake, using Newton iteration is a win for reciprocal square root.
   47|       |template <>
   48|      0|EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet4f prsqrt<Packet4f>(const Packet4f& x) {
   49|      0|  return generic_rsqrt_newton_step<Packet4f, /*Steps=*/1>::run(x, _mm_rsqrt_ps(x));
   50|      0|}
   51|       |
   52|       |#ifdef EIGEN_VECTORIZE_FMA
   53|       |// Trying to speed up reciprocal using Newton-Raphson is counterproductive
   54|       |// unless FMA is available. Without FMA pdiv(pset1<Packet>(Scalar(1),a)) is
   55|       |// 30% faster.
   56|       |template <>
   57|       |EIGEN_STRONG_INLINE Packet4f preciprocal<Packet4f>(const Packet4f& x) {
   58|       |  return generic_reciprocal_newton_step<Packet4f, /*Steps=*/1>::run(x, _mm_rcp_ps(x));
   59|       |}
   60|       |#endif
   61|       |
   62|       |#endif
   63|       |
   64|       |}  // end namespace internal
   65|       |
   66|       |namespace numext {
   67|       |
   68|       |template <>
   69|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float sqrt(const float& x) {
   70|      0|  return internal::pfirst(internal::Packet4f(_mm_sqrt_ss(_mm_set_ss(x))));
   71|      0|}
   72|       |
   73|       |template <>
   74|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double sqrt(const double& x) {
   75|      0|#if EIGEN_COMP_GNUC_STRICT
   76|      0|  // This works around a GCC bug generating poor code for _mm_sqrt_pd
   77|      0|  // See https://gitlab.com/libeigen/eigen/commit/8dca9f97e38970
   78|      0|  return internal::pfirst(internal::Packet2d(__builtin_ia32_sqrtsd(_mm_set_sd(x))));
   79|      0|#else
   80|      0|  return internal::pfirst(internal::Packet2d(_mm_sqrt_pd(_mm_set_sd(x))));
   81|      0|#endif
   82|      0|}
   83|       |
   84|       |}  // namespace numext
   85|       |
   86|       |}  // end namespace Eigen
   87|       |
   88|       |#endif  // EIGEN_MATH_FUNCTIONS_SSE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/arch/SSE/PacketMath.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2009 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_PACKET_MATH_SSE_H
   11|       |#define EIGEN_PACKET_MATH_SSE_H
   12|       |
   13|       |#include <cstdint>
   14|       |// IWYU pragma: private
   15|       |#include "../../InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |
   21|       |#ifndef EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD
   22|       |#define EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD 8
   23|       |#endif
   24|       |
   25|       |#if !defined(EIGEN_VECTORIZE_AVX) && !defined(EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS)
   26|       |// 32 bits =>  8 registers
   27|       |// 64 bits => 16 registers
   28|       |#define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS (2 * sizeof(void*))
   29|       |#endif
   30|       |
   31|       |#ifdef EIGEN_VECTORIZE_FMA
   32|       |#ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
   33|       |#define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
   34|       |#endif
   35|       |#endif
   36|       |
   37|       |#if ((defined EIGEN_VECTORIZE_AVX) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_MINGW || EIGEN_COMP_LCC) && \
   38|       |     (__GXX_ABI_VERSION < 1004)) ||                                                                     \
   39|       |    EIGEN_OS_QNX
   40|       |// With GCC's default ABI version, a __m128 or __m256 are the same types and therefore we cannot
   41|       |// have overloads for both types without linking error.
   42|       |// One solution is to increase ABI version using -fabi-version=4 (or greater).
   43|       |// Otherwise, we workaround this inconvenience by wrapping 128bit types into the following helper
   44|       |// structure:
   45|       |typedef eigen_packet_wrapper<__m128> Packet4f;
   46|       |typedef eigen_packet_wrapper<__m128d> Packet2d;
   47|       |#else
   48|       |typedef __m128 Packet4f;
   49|       |typedef __m128d Packet2d;
   50|       |#endif
   51|       |
   52|       |typedef eigen_packet_wrapper<__m128i, 0> Packet4i;
   53|       |typedef eigen_packet_wrapper<__m128i, 1> Packet16b;
   54|       |typedef eigen_packet_wrapper<__m128i, 4> Packet4ui;
   55|       |typedef eigen_packet_wrapper<__m128i, 5> Packet2l;
   56|       |
   57|       |template <>
   58|       |struct is_arithmetic<__m128> {
   59|       |  enum { value = true };
   60|       |};
   61|       |template <>
   62|       |struct is_arithmetic<__m128i> {
   63|       |  enum { value = true };
   64|       |};
   65|       |template <>
   66|       |struct is_arithmetic<__m128d> {
   67|       |  enum { value = true };
   68|       |};
   69|       |template <>
   70|       |struct is_arithmetic<Packet4i> {
   71|       |  enum { value = true };
   72|       |};
   73|       |template <>
   74|       |struct is_arithmetic<Packet2l> {
   75|       |  enum { value = true };
   76|       |};
   77|       |// Note that `Packet4ui` uses the underlying type `__m128i`, which is
   78|       |// interpreted as a vector of _signed_ `int32`s, which breaks some arithmetic
   79|       |// operations used in `GenericPacketMath.h`.
   80|       |template <>
   81|       |struct is_arithmetic<Packet4ui> {
   82|       |  enum { value = false };
   83|       |};
   84|       |template <>
   85|       |struct is_arithmetic<Packet16b> {
   86|       |  enum { value = true };
   87|       |};
   88|       |
   89|       |template <int p, int q, int r, int s>
   90|       |struct shuffle_mask {
   91|       |  enum { mask = (s) << 6 | (r) << 4 | (q) << 2 | (p) };
   92|       |};
   93|       |
   94|       |// TODO: change the implementation of all swizzle* ops from macro to template,
   95|       |#define vec4f_swizzle1(v, p, q, r, s) \
   96|       |  Packet4f(_mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(v), (shuffle_mask<p, q, r, s>::mask))))
   97|       |
   98|       |#define vec4i_swizzle1(v, p, q, r, s) Packet4i(_mm_shuffle_epi32(v, (shuffle_mask<p, q, r, s>::mask)))
   99|       |
  100|       |#define vec4ui_swizzle1(v, p, q, r, s) Packet4ui(vec4i_swizzle1(v, p, q, r, s))
  101|       |
  102|       |#define vec2d_swizzle1(v, p, q) \
  103|       |  Packet2d(_mm_castsi128_pd(    \
  104|       |      _mm_shuffle_epi32(_mm_castpd_si128(v), (shuffle_mask<2 * p, 2 * p + 1, 2 * q, 2 * q + 1>::mask))))
  105|       |
  106|       |#define vec4f_swizzle2(a, b, p, q, r, s) Packet4f(_mm_shuffle_ps((a), (b), (shuffle_mask<p, q, r, s>::mask)))
  107|       |
  108|       |#define vec4i_swizzle2(a, b, p, q, r, s) \
  109|       |  Packet4i(                              \
  110|       |      _mm_castps_si128((_mm_shuffle_ps(_mm_castsi128_ps(a), _mm_castsi128_ps(b), (shuffle_mask<p, q, r, s>::mask)))))
  111|       |
  112|       |#define vec4ui_swizzle2(a, b, p, q, r, s) Packet4i(vec4i_swizzle2(a, b, p, q, r, s))
  113|       |
  114|      0|EIGEN_STRONG_INLINE Packet4f vec4f_movelh(const Packet4f& a, const Packet4f& b) {
  115|      0|  return Packet4f(_mm_movelh_ps(a, b));
  116|      0|}
  117|      0|EIGEN_STRONG_INLINE Packet4f vec4f_movehl(const Packet4f& a, const Packet4f& b) {
  118|      0|  return Packet4f(_mm_movehl_ps(a, b));
  119|      0|}
  120|      0|EIGEN_STRONG_INLINE Packet4f vec4f_unpacklo(const Packet4f& a, const Packet4f& b) {
  121|      0|  return Packet4f(_mm_unpacklo_ps(a, b));
  122|      0|}
  123|      0|EIGEN_STRONG_INLINE Packet4f vec4f_unpackhi(const Packet4f& a, const Packet4f& b) {
  124|      0|  return Packet4f(_mm_unpackhi_ps(a, b));
  125|      0|}
  126|       |#define vec4f_duplane(a, p) vec4f_swizzle2(a, a, p, p, p, p)
  127|       |
  128|       |#define vec2d_swizzle2(a, b, mask) Packet2d(_mm_shuffle_pd(a, b, mask))
  129|       |
  130|      0|EIGEN_STRONG_INLINE Packet2d vec2d_unpacklo(const Packet2d& a, const Packet2d& b) {
  131|      0|  return Packet2d(_mm_unpacklo_pd(a, b));
  132|      0|}
  133|      0|EIGEN_STRONG_INLINE Packet2d vec2d_unpackhi(const Packet2d& a, const Packet2d& b) {
  134|      0|  return Packet2d(_mm_unpackhi_pd(a, b));
  135|      0|}
  136|       |#define vec2d_duplane(a, p) vec2d_swizzle2(a, a, (p << 1) | p)
  137|       |
  138|       |#define EIGEN_DECLARE_CONST_Packet4f(NAME, X) const Packet4f p4f_##NAME = pset1<Packet4f>(X)
  139|       |
  140|       |#define EIGEN_DECLARE_CONST_Packet2d(NAME, X) const Packet2d p2d_##NAME = pset1<Packet2d>(X)
  141|       |
  142|       |#define EIGEN_DECLARE_CONST_Packet4f_FROM_INT(NAME, X) const Packet4f p4f_##NAME = pset1frombits<Packet4f>(X)
  143|       |
  144|       |#define EIGEN_DECLARE_CONST_Packet4i(NAME, X) const Packet4i p4i_##NAME = pset1<Packet4i>(X)
  145|       |
  146|       |#define EIGEN_DECLARE_CONST_Packet4ui(NAME, X) const Packet4ui p4ui_##NAME = pset1<Packet4ui>(X)
  147|       |
  148|       |// Work around lack of extract/cvt for epi64 when compiling for 32-bit.
  149|       |#if EIGEN_ARCH_x86_64
  150|      0|EIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_0(const __m128i& a) { return _mm_cvtsi128_si64(a); }
  151|       |#ifdef EIGEN_VECTORIZE_SSE4_1
  152|       |EIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_1(const __m128i& a) { return _mm_extract_epi64(a, 1); }
  153|       |#else
  154|      0|EIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_1(const __m128i& a) {
  155|      0|  return _mm_cvtsi128_si64(_mm_castpd_si128(_mm_shuffle_pd(_mm_castsi128_pd(a), _mm_castsi128_pd(a), 0x1)));
  156|      0|}
  157|       |#endif
  158|       |#else
  159|       |// epi64 instructions are not available.  The following seems to generate the same instructions
  160|       |// with -O2 in GCC/Clang.
  161|       |EIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_0(const __m128i& a) {
  162|       |  return numext::bit_cast<int64_t>(_mm_cvtsd_f64(_mm_castsi128_pd(a)));
  163|       |}
  164|       |EIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_1(const __m128i& a) {
  165|       |  return numext::bit_cast<int64_t>(_mm_cvtsd_f64(_mm_shuffle_pd(_mm_castsi128_pd(a), _mm_castsi128_pd(a), 0x1)));
  166|       |}
  167|       |#endif
  168|       |
  169|       |// Use the packet_traits defined in AVX/PacketMath.h instead if we're going
  170|       |// to leverage AVX instructions.
  171|       |#ifndef EIGEN_VECTORIZE_AVX
  172|       |template <>
  173|       |struct packet_traits<float> : default_packet_traits {
  174|       |  typedef Packet4f type;
  175|       |  typedef Packet4f half;
  176|       |  enum {
  177|       |    Vectorizable = 1,
  178|       |    AlignedOnScalar = 1,
  179|       |    size = 4,
  180|       |
  181|       |    HasCmp = 1,
  182|       |    HasDiv = 1,
  183|       |    HasReciprocal = EIGEN_FAST_MATH,
  184|       |    HasSin = EIGEN_FAST_MATH,
  185|       |    HasCos = EIGEN_FAST_MATH,
  186|       |    HasACos = 1,
  187|       |    HasASin = 1,
  188|       |    HasATan = 1,
  189|       |    HasATanh = 1,
  190|       |    HasLog = 1,
  191|       |    HasLog1p = 1,
  192|       |    HasExpm1 = 1,
  193|       |    HasNdtri = 1,
  194|       |    HasExp = 1,
  195|       |    HasBessel = 1,
  196|       |    HasSqrt = 1,
  197|       |    HasRsqrt = 1,
  198|       |    HasTanh = EIGEN_FAST_MATH,
  199|       |    HasErf = EIGEN_FAST_MATH,
  200|       |    HasErfc = EIGEN_FAST_MATH,
  201|       |    HasBlend = 1,
  202|       |    HasSign = 0  // The manually vectorized version is slightly slower for SSE.
  203|       |  };
  204|       |};
  205|       |template <>
  206|       |struct packet_traits<double> : default_packet_traits {
  207|       |  typedef Packet2d type;
  208|       |  typedef Packet2d half;
  209|       |  enum {
  210|       |    Vectorizable = 1,
  211|       |    AlignedOnScalar = 1,
  212|       |    size = 2,
  213|       |
  214|       |    HasCmp = 1,
  215|       |    HasDiv = 1,
  216|       |    HasSin = EIGEN_FAST_MATH,
  217|       |    HasCos = EIGEN_FAST_MATH,
  218|       |    HasTanh = EIGEN_FAST_MATH,
  219|       |    HasLog = 1,
  220|       |    HasErf = EIGEN_FAST_MATH,
  221|       |    HasErfc = EIGEN_FAST_MATH,
  222|       |    HasExp = 1,
  223|       |    HasSqrt = 1,
  224|       |    HasRsqrt = 1,
  225|       |    HasATan = 1,
  226|       |    HasATanh = 1,
  227|       |    HasBlend = 1
  228|       |  };
  229|       |};
  230|       |template <>
  231|       |struct packet_traits<int> : default_packet_traits {
  232|       |  typedef Packet4i type;
  233|       |  typedef Packet4i half;
  234|       |  enum {
  235|       |    Vectorizable = 1,
  236|       |    AlignedOnScalar = 1,
  237|       |    size = 4,
  238|       |
  239|       |    HasCmp = 1,
  240|       |    HasDiv = 1,
  241|       |    HasShift = 1,
  242|       |    HasBlend = 1
  243|       |  };
  244|       |};
  245|       |template <>
  246|       |struct packet_traits<uint32_t> : default_packet_traits {
  247|       |  typedef Packet4ui type;
  248|       |  typedef Packet4ui half;
  249|       |  enum {
  250|       |    Vectorizable = 1,
  251|       |    AlignedOnScalar = 1,
  252|       |    size = 4,
  253|       |
  254|       |    HasDiv = 0,
  255|       |    HasNegate = 0,
  256|       |    HasCmp = 1,
  257|       |    HasShift = 1,
  258|       |    HasBlend = 1
  259|       |  };
  260|       |};
  261|       |template <>
  262|       |struct packet_traits<int64_t> : default_packet_traits {
  263|       |  typedef Packet2l type;
  264|       |  typedef Packet2l half;
  265|       |  enum {
  266|       |    Vectorizable = 1,
  267|       |    AlignedOnScalar = 1,
  268|       |    size = 2,
  269|       |
  270|       |    HasDiv = 0,
  271|       |    HasCmp = 1,
  272|       |    HasShift = 1,
  273|       |    HasBlend = 1
  274|       |  };
  275|       |};
  276|       |#endif
  277|       |template <>
  278|       |struct packet_traits<bool> : default_packet_traits {
  279|       |  typedef Packet16b type;
  280|       |  typedef Packet16b half;
  281|       |  enum {
  282|       |    Vectorizable = 1,
  283|       |    AlignedOnScalar = 1,
  284|       |    size = 16,
  285|       |
  286|       |    HasCmp = 1,  // note -- only pcmp_eq is defined
  287|       |    HasShift = 0,
  288|       |    HasAbs = 0,
  289|       |    HasAbs2 = 0,
  290|       |    HasMin = 0,
  291|       |    HasMax = 0,
  292|       |    HasConj = 0,
  293|       |    HasSqrt = 1,
  294|       |    HasNegate = 0,
  295|       |    HasSign = 0  // Don't try to vectorize psign<bool> = identity.
  296|       |  };
  297|       |};
  298|       |
  299|       |template <>
  300|       |struct unpacket_traits<Packet4f> {
  301|       |  typedef float type;
  302|       |  typedef Packet4f half;
  303|       |  typedef Packet4i integer_packet;
  304|       |  enum {
  305|       |    size = 4,
  306|       |    alignment = Aligned16,
  307|       |    vectorizable = true,
  308|       |    masked_load_available = false,
  309|       |    masked_store_available = false
  310|       |  };
  311|       |};
  312|       |template <>
  313|       |struct unpacket_traits<Packet2d> {
  314|       |  typedef double type;
  315|       |  typedef Packet2d half;
  316|       |  typedef Packet2l integer_packet;
  317|       |  enum {
  318|       |    size = 2,
  319|       |    alignment = Aligned16,
  320|       |    vectorizable = true,
  321|       |    masked_load_available = false,
  322|       |    masked_store_available = false
  323|       |  };
  324|       |};
  325|       |template <>
  326|       |struct unpacket_traits<Packet2l> {
  327|       |  typedef int64_t type;
  328|       |  typedef Packet2l half;
  329|       |  enum {
  330|       |    size = 2,
  331|       |    alignment = Aligned16,
  332|       |    vectorizable = true,
  333|       |    masked_load_available = false,
  334|       |    masked_store_available = false
  335|       |  };
  336|       |};
  337|       |template <>
  338|       |struct unpacket_traits<Packet4i> {
  339|       |  typedef int type;
  340|       |  typedef Packet4i half;
  341|       |  enum {
  342|       |    size = 4,
  343|       |    alignment = Aligned16,
  344|       |    vectorizable = true,
  345|       |    masked_load_available = false,
  346|       |    masked_store_available = false
  347|       |  };
  348|       |};
  349|       |template <>
  350|       |struct unpacket_traits<Packet4ui> {
  351|       |  typedef uint32_t type;
  352|       |  typedef Packet4ui half;
  353|       |  enum {
  354|       |    size = 4,
  355|       |    alignment = Aligned16,
  356|       |    vectorizable = true,
  357|       |    masked_load_available = false,
  358|       |    masked_store_available = false
  359|       |  };
  360|       |};
  361|       |template <>
  362|       |struct unpacket_traits<Packet16b> {
  363|       |  typedef bool type;
  364|       |  typedef Packet16b half;
  365|       |  enum {
  366|       |    size = 16,
  367|       |    alignment = Aligned16,
  368|       |    vectorizable = true,
  369|       |    masked_load_available = false,
  370|       |    masked_store_available = false
  371|       |  };
  372|       |};
  373|       |
  374|       |#ifndef EIGEN_VECTORIZE_AVX
  375|       |template <>
  376|       |struct scalar_div_cost<float, true> {
  377|       |  enum { value = 7 };
  378|       |};
  379|       |template <>
  380|       |struct scalar_div_cost<double, true> {
  381|       |  enum { value = 8 };
  382|       |};
  383|       |#endif
  384|       |
  385|       |template <>
  386|      0|EIGEN_STRONG_INLINE Packet4f pset1<Packet4f>(const float& from) {
  387|      0|  return _mm_set_ps1(from);
  388|      0|}
  389|       |template <>
  390|      0|EIGEN_STRONG_INLINE Packet2d pset1<Packet2d>(const double& from) {
  391|      0|  return _mm_set1_pd(from);
  392|      0|}
  393|       |template <>
  394|      0|EIGEN_STRONG_INLINE Packet2l pset1<Packet2l>(const int64_t& from) {
  395|      0|  return _mm_set1_epi64x(from);
  396|      0|}
  397|       |template <>
  398|      0|EIGEN_STRONG_INLINE Packet4i pset1<Packet4i>(const int& from) {
  399|      0|  return _mm_set1_epi32(from);
  400|      0|}
  401|       |template <>
  402|      0|EIGEN_STRONG_INLINE Packet4ui pset1<Packet4ui>(const uint32_t& from) {
  403|      0|  return _mm_set1_epi32(numext::bit_cast<int32_t>(from));
  404|      0|}
  405|       |template <>
  406|      0|EIGEN_STRONG_INLINE Packet16b pset1<Packet16b>(const bool& from) {
  407|      0|  return _mm_set1_epi8(static_cast<char>(from));
  408|      0|}
  409|       |
  410|       |template <>
  411|      0|EIGEN_STRONG_INLINE Packet4f pset1frombits<Packet4f>(unsigned int from) {
  412|      0|  return _mm_castsi128_ps(pset1<Packet4i>(from));
  413|      0|}
  414|       |template <>
  415|      0|EIGEN_STRONG_INLINE Packet2d pset1frombits<Packet2d>(uint64_t from) {
  416|      0|  return _mm_castsi128_pd(_mm_set1_epi64x(from));
  417|      0|}
  418|       |
  419|       |template <>
  420|      0|EIGEN_STRONG_INLINE Packet4f peven_mask(const Packet4f& /*a*/) {
  421|      0|  return _mm_castsi128_ps(_mm_set_epi32(0, -1, 0, -1));
  422|      0|}
  423|       |template <>
  424|      0|EIGEN_STRONG_INLINE Packet2l peven_mask(const Packet2l& /*a*/) {
  425|      0|  return _mm_set_epi32(0, 0, -1, -1);
  426|      0|}
  427|       |template <>
  428|      0|EIGEN_STRONG_INLINE Packet4i peven_mask(const Packet4i& /*a*/) {
  429|      0|  return _mm_set_epi32(0, -1, 0, -1);
  430|      0|}
  431|       |template <>
  432|      0|EIGEN_STRONG_INLINE Packet4ui peven_mask(const Packet4ui& /*a*/) {
  433|      0|  return _mm_set_epi32(0, -1, 0, -1);
  434|      0|}
  435|       |template <>
  436|      0|EIGEN_STRONG_INLINE Packet2d peven_mask(const Packet2d& /*a*/) {
  437|      0|  return _mm_castsi128_pd(_mm_set_epi32(0, 0, -1, -1));
  438|      0|}
  439|       |
  440|       |template <>
  441|      0|EIGEN_STRONG_INLINE Packet4f pzero(const Packet4f& /*a*/) {
  442|      0|  return _mm_setzero_ps();
  443|      0|}
  444|       |template <>
  445|      0|EIGEN_STRONG_INLINE Packet2d pzero(const Packet2d& /*a*/) {
  446|      0|  return _mm_setzero_pd();
  447|      0|}
  448|       |template <>
  449|      0|EIGEN_STRONG_INLINE Packet2l pzero(const Packet2l& /*a*/) {
  450|      0|  return _mm_setzero_si128();
  451|      0|}
  452|       |template <>
  453|      0|EIGEN_STRONG_INLINE Packet4i pzero(const Packet4i& /*a*/) {
  454|      0|  return _mm_setzero_si128();
  455|      0|}
  456|       |template <>
  457|      0|EIGEN_STRONG_INLINE Packet4ui pzero(const Packet4ui& /*a*/) {
  458|      0|  return _mm_setzero_si128();
  459|      0|}
  460|       |
  461|       |// GCC generates a shufps instruction for _mm_set1_ps/_mm_load1_ps instead of the more efficient pshufd instruction.
  462|       |// However, using inrinsics for pset1 makes gcc to generate crappy code in some cases (see bug 203)
  463|       |// Using inline assembly is also not an option because then gcc fails to reorder properly the instructions.
  464|       |// Therefore, we introduced the pload1 functions to be used in product kernels for which bug 203 does not apply.
  465|       |// Also note that with AVX, we want it to generate a vbroadcastss.
  466|       |#if EIGEN_COMP_GNUC_STRICT && (!defined __AVX__)
  467|       |template <>
  468|       |EIGEN_STRONG_INLINE Packet4f pload1<Packet4f>(const float* from) {
  469|       |  return vec4f_swizzle1(_mm_load_ss(from), 0, 0, 0, 0);
  470|       |}
  471|       |#endif
  472|       |
  473|       |template <>
  474|      0|EIGEN_STRONG_INLINE Packet4f plset<Packet4f>(const float& a) {
  475|      0|  return _mm_add_ps(pset1<Packet4f>(a), _mm_set_ps(3, 2, 1, 0));
  476|      0|}
  477|       |template <>
  478|      0|EIGEN_STRONG_INLINE Packet2d plset<Packet2d>(const double& a) {
  479|      0|  return _mm_add_pd(pset1<Packet2d>(a), _mm_set_pd(1, 0));
  480|      0|}
  481|       |template <>
  482|      0|EIGEN_STRONG_INLINE Packet2l plset<Packet2l>(const int64_t& a) {
  483|      0|  return _mm_add_epi32(pset1<Packet2l>(a), _mm_set_epi64x(1, 0));
  484|      0|}
  485|       |template <>
  486|      0|EIGEN_STRONG_INLINE Packet4i plset<Packet4i>(const int& a) {
  487|      0|  return _mm_add_epi32(pset1<Packet4i>(a), _mm_set_epi32(3, 2, 1, 0));
  488|      0|}
  489|       |template <>
  490|      0|EIGEN_STRONG_INLINE Packet4ui plset<Packet4ui>(const uint32_t& a) {
  491|      0|  return _mm_add_epi32(pset1<Packet4ui>(a), _mm_set_epi32(3, 2, 1, 0));
  492|      0|}
  493|       |
  494|       |template <>
  495|      0|EIGEN_STRONG_INLINE Packet4f padd<Packet4f>(const Packet4f& a, const Packet4f& b) {
  496|      0|  return _mm_add_ps(a, b);
  497|      0|}
  498|       |template <>
  499|      0|EIGEN_STRONG_INLINE Packet2d padd<Packet2d>(const Packet2d& a, const Packet2d& b) {
  500|      0|  return _mm_add_pd(a, b);
  501|      0|}
  502|       |template <>
  503|      0|EIGEN_STRONG_INLINE Packet2l padd<Packet2l>(const Packet2l& a, const Packet2l& b) {
  504|      0|  return _mm_add_epi64(a, b);
  505|      0|}
  506|       |template <>
  507|      0|EIGEN_STRONG_INLINE Packet4i padd<Packet4i>(const Packet4i& a, const Packet4i& b) {
  508|      0|  return _mm_add_epi32(a, b);
  509|      0|}
  510|       |template <>
  511|      0|EIGEN_STRONG_INLINE Packet4ui padd<Packet4ui>(const Packet4ui& a, const Packet4ui& b) {
  512|      0|  return _mm_add_epi32(a, b);
  513|      0|}
  514|       |
  515|       |template <>
  516|      0|EIGEN_STRONG_INLINE Packet16b padd<Packet16b>(const Packet16b& a, const Packet16b& b) {
  517|      0|  return _mm_or_si128(a, b);
  518|      0|}
  519|       |
  520|       |template <typename Packet>
  521|       |EIGEN_STRONG_INLINE Packet padds(const Packet& a, const Packet& b);
  522|       |template <>
  523|      0|EIGEN_STRONG_INLINE Packet4f padds<Packet4f>(const Packet4f& a, const Packet4f& b) {
  524|      0|  return _mm_add_ss(a, b);
  525|      0|}
  526|       |template <>
  527|      0|EIGEN_STRONG_INLINE Packet2d padds<Packet2d>(const Packet2d& a, const Packet2d& b) {
  528|      0|  return _mm_add_sd(a, b);
  529|      0|}
  530|       |
  531|       |template <>
  532|      0|EIGEN_STRONG_INLINE Packet4f psub<Packet4f>(const Packet4f& a, const Packet4f& b) {
  533|      0|  return _mm_sub_ps(a, b);
  534|      0|}
  535|       |template <>
  536|      0|EIGEN_STRONG_INLINE Packet2d psub<Packet2d>(const Packet2d& a, const Packet2d& b) {
  537|      0|  return _mm_sub_pd(a, b);
  538|      0|}
  539|       |template <>
  540|      0|EIGEN_STRONG_INLINE Packet2l psub<Packet2l>(const Packet2l& a, const Packet2l& b) {
  541|      0|  return _mm_sub_epi64(a, b);
  542|      0|}
  543|       |template <>
  544|      0|EIGEN_STRONG_INLINE Packet4i psub<Packet4i>(const Packet4i& a, const Packet4i& b) {
  545|      0|  return _mm_sub_epi32(a, b);
  546|      0|}
  547|       |template <>
  548|      0|EIGEN_STRONG_INLINE Packet4ui psub<Packet4ui>(const Packet4ui& a, const Packet4ui& b) {
  549|      0|  return _mm_sub_epi32(a, b);
  550|      0|}
  551|       |template <>
  552|      0|EIGEN_STRONG_INLINE Packet16b psub<Packet16b>(const Packet16b& a, const Packet16b& b) {
  553|      0|  return _mm_xor_si128(a, b);
  554|      0|}
  555|       |
  556|       |template <>
  557|       |EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b);
  558|       |template <>
  559|      0|EIGEN_STRONG_INLINE Packet4f paddsub<Packet4f>(const Packet4f& a, const Packet4f& b) {
  560|      0|#ifdef EIGEN_VECTORIZE_SSE3
  561|      0|  return _mm_addsub_ps(a, b);
  562|      0|#else
  563|      0|  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000, 0x0, 0x80000000, 0x0));
  564|      0|  return padd(a, pxor(mask, b));
  565|      0|#endif
  566|      0|}
  567|       |
  568|       |template <>
  569|       |EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d&, const Packet2d&);
  570|       |template <>
  571|      0|EIGEN_STRONG_INLINE Packet2d paddsub<Packet2d>(const Packet2d& a, const Packet2d& b) {
  572|      0|#ifdef EIGEN_VECTORIZE_SSE3
  573|      0|  return _mm_addsub_pd(a, b);
  574|      0|#else
  575|      0|  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0x0, 0x80000000, 0x0, 0x0));
  576|      0|  return padd(a, pxor(mask, b));
  577|      0|#endif
  578|      0|}
  579|       |
  580|       |template <>
  581|      0|EIGEN_STRONG_INLINE Packet4f pnegate(const Packet4f& a) {
  582|      0|  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000, 0x80000000, 0x80000000, 0x80000000));
  583|      0|  return _mm_xor_ps(a, mask);
  584|      0|}
  585|       |template <>
  586|      0|EIGEN_STRONG_INLINE Packet2d pnegate(const Packet2d& a) {
  587|      0|  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0x0, 0x80000000, 0x0, 0x80000000));
  588|      0|  return _mm_xor_pd(a, mask);
  589|      0|}
  590|       |template <>
  591|      0|EIGEN_STRONG_INLINE Packet2l pnegate(const Packet2l& a) {
  592|      0|  return psub(pzero(a), a);
  593|      0|}
  594|       |
  595|       |template <>
  596|      0|EIGEN_STRONG_INLINE Packet4i pnegate(const Packet4i& a) {
  597|      0|  return psub(pzero(a), a);
  598|      0|}
  599|       |
  600|       |template <>
  601|      0|EIGEN_STRONG_INLINE Packet4f pconj(const Packet4f& a) {
  602|      0|  return a;
  603|      0|}
  604|       |template <>
  605|      0|EIGEN_STRONG_INLINE Packet2d pconj(const Packet2d& a) {
  606|      0|  return a;
  607|      0|}
  608|       |template <>
  609|      0|EIGEN_STRONG_INLINE Packet2l pconj(const Packet2l& a) {
  610|      0|  return a;
  611|      0|}
  612|       |template <>
  613|      0|EIGEN_STRONG_INLINE Packet4i pconj(const Packet4i& a) {
  614|      0|  return a;
  615|      0|}
  616|       |
  617|       |template <>
  618|      0|EIGEN_STRONG_INLINE Packet4f pmul<Packet4f>(const Packet4f& a, const Packet4f& b) {
  619|      0|  return _mm_mul_ps(a, b);
  620|      0|}
  621|       |template <>
  622|      0|EIGEN_STRONG_INLINE Packet2d pmul<Packet2d>(const Packet2d& a, const Packet2d& b) {
  623|      0|  return _mm_mul_pd(a, b);
  624|      0|}
  625|       |template <>
  626|      0|EIGEN_STRONG_INLINE Packet2l pmul<Packet2l>(const Packet2l& a, const Packet2l& b) {
  627|      0|  // 64-bit mul requires avx512, so do this with 32-bit multiplication
  628|      0|  __m128i upper32_a = _mm_srli_epi64(a, 32);
  629|      0|  __m128i upper32_b = _mm_srli_epi64(b, 32);
  630|      0|
  631|      0|  // upper * lower
  632|      0|  __m128i mul1 = _mm_mul_epu32(upper32_a, b);
  633|      0|  __m128i mul2 = _mm_mul_epu32(upper32_b, a);
  634|      0|  // Gives us both upper*upper and lower*lower
  635|      0|  __m128i mul3 = _mm_mul_epu32(a, b);
  636|      0|
  637|      0|  __m128i high = _mm_slli_epi64(_mm_add_epi64(mul1, mul2), 32);
  638|      0|  return _mm_add_epi64(high, mul3);
  639|      0|}
  640|       |template <>
  641|      0|EIGEN_STRONG_INLINE Packet4i pmul<Packet4i>(const Packet4i& a, const Packet4i& b) {
  642|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
  643|      0|  return _mm_mullo_epi32(a, b);
  644|      0|#else
  645|      0|  // this version is slightly faster than 4 scalar products
  646|      0|  return vec4i_swizzle1(
  647|      0|      vec4i_swizzle2(_mm_mul_epu32(a, b), _mm_mul_epu32(vec4i_swizzle1(a, 1, 0, 3, 2), vec4i_swizzle1(b, 1, 0, 3, 2)),
  648|      0|                     0, 2, 0, 2),
  649|      0|      0, 2, 1, 3);
  650|      0|#endif
  651|      0|}
  652|       |template <>
  653|      0|EIGEN_STRONG_INLINE Packet4ui pmul<Packet4ui>(const Packet4ui& a, const Packet4ui& b) {
  654|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
  655|      0|  return _mm_mullo_epi32(a, b);
  656|      0|#else
  657|      0|  // this version is slightly faster than 4 scalar products
  658|      0|  return vec4ui_swizzle1(
  659|      0|      vec4ui_swizzle2(_mm_mul_epu32(a, b),
  660|      0|                      _mm_mul_epu32(vec4ui_swizzle1(a, 1, 0, 3, 2), vec4ui_swizzle1(b, 1, 0, 3, 2)), 0, 2, 0, 2),
  661|      0|      0, 2, 1, 3);
  662|      0|#endif
  663|      0|}
  664|       |
  665|       |template <>
  666|      0|EIGEN_STRONG_INLINE Packet16b pmul<Packet16b>(const Packet16b& a, const Packet16b& b) {
  667|      0|  return _mm_and_si128(a, b);
  668|      0|}
  669|       |
  670|       |template <>
  671|      0|EIGEN_STRONG_INLINE Packet4f pdiv<Packet4f>(const Packet4f& a, const Packet4f& b) {
  672|      0|  return _mm_div_ps(a, b);
  673|      0|}
  674|       |template <>
  675|      0|EIGEN_STRONG_INLINE Packet2d pdiv<Packet2d>(const Packet2d& a, const Packet2d& b) {
  676|      0|  return _mm_div_pd(a, b);
  677|      0|}
  678|       |
  679|       |template <>
  680|      0|EIGEN_STRONG_INLINE Packet4i pdiv<Packet4i>(const Packet4i& a, const Packet4i& b) {
  681|      0|#ifdef EIGEN_VECTORIZE_AVX
  682|      0|  return _mm256_cvttpd_epi32(_mm256_div_pd(_mm256_cvtepi32_pd(a), _mm256_cvtepi32_pd(b)));
  683|      0|#else
  684|      0|  __m128i q_lo = _mm_cvttpd_epi32(_mm_div_pd(_mm_cvtepi32_pd(a), _mm_cvtepi32_pd(b)));
  685|      0|  __m128i q_hi = _mm_cvttpd_epi32(
  686|      0|      _mm_div_pd(_mm_cvtepi32_pd(vec4i_swizzle1(a, 2, 3, 0, 1)), _mm_cvtepi32_pd(vec4i_swizzle1(b, 2, 3, 0, 1))));
  687|      0|  return vec4i_swizzle1(_mm_unpacklo_epi32(q_lo, q_hi), 0, 2, 1, 3);
  688|      0|#endif
  689|      0|}
  690|       |
  691|       |#ifdef EIGEN_VECTORIZE_FMA
  692|       |template <>
  693|       |EIGEN_STRONG_INLINE Packet4f pmadd(const Packet4f& a, const Packet4f& b, const Packet4f& c) {
  694|       |  return _mm_fmadd_ps(a, b, c);
  695|       |}
  696|       |template <>
  697|       |EIGEN_STRONG_INLINE Packet2d pmadd(const Packet2d& a, const Packet2d& b, const Packet2d& c) {
  698|       |  return _mm_fmadd_pd(a, b, c);
  699|       |}
  700|       |template <>
  701|       |EIGEN_STRONG_INLINE Packet4f pmsub(const Packet4f& a, const Packet4f& b, const Packet4f& c) {
  702|       |  return _mm_fmsub_ps(a, b, c);
  703|       |}
  704|       |template <>
  705|       |EIGEN_STRONG_INLINE Packet2d pmsub(const Packet2d& a, const Packet2d& b, const Packet2d& c) {
  706|       |  return _mm_fmsub_pd(a, b, c);
  707|       |}
  708|       |template <>
  709|       |EIGEN_STRONG_INLINE Packet4f pnmadd(const Packet4f& a, const Packet4f& b, const Packet4f& c) {
  710|       |  return _mm_fnmadd_ps(a, b, c);
  711|       |}
  712|       |template <>
  713|       |EIGEN_STRONG_INLINE Packet2d pnmadd(const Packet2d& a, const Packet2d& b, const Packet2d& c) {
  714|       |  return _mm_fnmadd_pd(a, b, c);
  715|       |}
  716|       |template <>
  717|       |EIGEN_STRONG_INLINE Packet4f pnmsub(const Packet4f& a, const Packet4f& b, const Packet4f& c) {
  718|       |  return _mm_fnmsub_ps(a, b, c);
  719|       |}
  720|       |template <>
  721|       |EIGEN_STRONG_INLINE Packet2d pnmsub(const Packet2d& a, const Packet2d& b, const Packet2d& c) {
  722|       |  return _mm_fnmsub_pd(a, b, c);
  723|       |}
  724|       |
  725|       |template <typename Packet>
  726|       |EIGEN_STRONG_INLINE Packet pmadds(const Packet& a, const Packet& b, const Packet& c);
  727|       |template <>
  728|       |EIGEN_STRONG_INLINE Packet4f pmadds<Packet4f>(const Packet4f& a, const Packet4f& b, const Packet4f& c) {
  729|       |  return _mm_fmadd_ss(a, b, c);
  730|       |}
  731|       |template <>
  732|       |EIGEN_STRONG_INLINE Packet2d pmadds<Packet2d>(const Packet2d& a, const Packet2d& b, const Packet2d& c) {
  733|       |  return _mm_fmadd_sd(a, b, c);
  734|       |}
  735|       |#endif
  736|       |
  737|       |#ifdef EIGEN_VECTORIZE_SSE4_1
  738|       |template <>
  739|       |EIGEN_STRONG_INLINE Packet4f pselect(const Packet4f& mask, const Packet4f& a, const Packet4f& b) {
  740|       |  return _mm_blendv_ps(b, a, mask);
  741|       |}
  742|       |
  743|       |template <>
  744|       |EIGEN_STRONG_INLINE Packet2l pselect(const Packet2l& mask, const Packet2l& a, const Packet2l& b) {
  745|       |  return _mm_castpd_si128(_mm_blendv_pd(_mm_castsi128_pd(b), _mm_castsi128_pd(a), _mm_castsi128_pd(mask)));
  746|       |}
  747|       |
  748|       |template <>
  749|       |EIGEN_STRONG_INLINE Packet4i pselect(const Packet4i& mask, const Packet4i& a, const Packet4i& b) {
  750|       |  return _mm_castps_si128(_mm_blendv_ps(_mm_castsi128_ps(b), _mm_castsi128_ps(a), _mm_castsi128_ps(mask)));
  751|       |}
  752|       |
  753|       |template <>
  754|       |EIGEN_STRONG_INLINE Packet4ui pselect(const Packet4ui& mask, const Packet4ui& a, const Packet4ui& b) {
  755|       |  return _mm_castps_si128(_mm_blendv_ps(_mm_castsi128_ps(b), _mm_castsi128_ps(a), _mm_castsi128_ps(mask)));
  756|       |}
  757|       |
  758|       |template <>
  759|       |EIGEN_STRONG_INLINE Packet2d pselect(const Packet2d& mask, const Packet2d& a, const Packet2d& b) {
  760|       |  return _mm_blendv_pd(b, a, mask);
  761|       |}
  762|       |#endif
  763|       |
  764|       |template <>
  765|      0|EIGEN_STRONG_INLINE Packet2l ptrue<Packet2l>(const Packet2l& a) {
  766|      0|  return _mm_cmpeq_epi32(a, a);
  767|      0|}
  768|       |template <>
  769|      0|EIGEN_STRONG_INLINE Packet4i ptrue<Packet4i>(const Packet4i& a) {
  770|      0|  return _mm_cmpeq_epi32(a, a);
  771|      0|}
  772|       |template <>
  773|      0|EIGEN_STRONG_INLINE Packet16b ptrue<Packet16b>(const Packet16b& /*a*/) {
  774|      0|  return pset1<Packet16b>(true);
  775|      0|}
  776|       |template <>
  777|      0|EIGEN_STRONG_INLINE Packet4f ptrue<Packet4f>(const Packet4f& a) {
  778|      0|  Packet4i b = _mm_castps_si128(a);
  779|      0|  return _mm_castsi128_ps(_mm_cmpeq_epi32(b, b));
  780|      0|}
  781|       |template <>
  782|      0|EIGEN_STRONG_INLINE Packet2d ptrue<Packet2d>(const Packet2d& a) {
  783|      0|  Packet4i b = _mm_castpd_si128(a);
  784|      0|  return _mm_castsi128_pd(_mm_cmpeq_epi32(b, b));
  785|      0|}
  786|       |
  787|       |template <>
  788|      0|EIGEN_STRONG_INLINE Packet4f pand<Packet4f>(const Packet4f& a, const Packet4f& b) {
  789|      0|  return _mm_and_ps(a, b);
  790|      0|}
  791|       |template <>
  792|      0|EIGEN_STRONG_INLINE Packet2d pand<Packet2d>(const Packet2d& a, const Packet2d& b) {
  793|      0|  return _mm_and_pd(a, b);
  794|      0|}
  795|       |template <>
  796|      0|EIGEN_STRONG_INLINE Packet2l pand<Packet2l>(const Packet2l& a, const Packet2l& b) {
  797|      0|  return _mm_and_si128(a, b);
  798|      0|}
  799|       |template <>
  800|      0|EIGEN_STRONG_INLINE Packet4i pand<Packet4i>(const Packet4i& a, const Packet4i& b) {
  801|      0|  return _mm_and_si128(a, b);
  802|      0|}
  803|       |template <>
  804|      0|EIGEN_STRONG_INLINE Packet4ui pand<Packet4ui>(const Packet4ui& a, const Packet4ui& b) {
  805|      0|  return _mm_and_si128(a, b);
  806|      0|}
  807|       |template <>
  808|      0|EIGEN_STRONG_INLINE Packet16b pand<Packet16b>(const Packet16b& a, const Packet16b& b) {
  809|      0|  return _mm_and_si128(a, b);
  810|      0|}
  811|       |
  812|       |template <>
  813|      0|EIGEN_STRONG_INLINE Packet4f por<Packet4f>(const Packet4f& a, const Packet4f& b) {
  814|      0|  return _mm_or_ps(a, b);
  815|      0|}
  816|       |template <>
  817|      0|EIGEN_STRONG_INLINE Packet2d por<Packet2d>(const Packet2d& a, const Packet2d& b) {
  818|      0|  return _mm_or_pd(a, b);
  819|      0|}
  820|       |template <>
  821|      0|EIGEN_STRONG_INLINE Packet2l por<Packet2l>(const Packet2l& a, const Packet2l& b) {
  822|      0|  return _mm_or_si128(a, b);
  823|      0|}
  824|       |template <>
  825|      0|EIGEN_STRONG_INLINE Packet4i por<Packet4i>(const Packet4i& a, const Packet4i& b) {
  826|      0|  return _mm_or_si128(a, b);
  827|      0|}
  828|       |template <>
  829|      0|EIGEN_STRONG_INLINE Packet4ui por<Packet4ui>(const Packet4ui& a, const Packet4ui& b) {
  830|      0|  return _mm_or_si128(a, b);
  831|      0|}
  832|       |template <>
  833|      0|EIGEN_STRONG_INLINE Packet16b por<Packet16b>(const Packet16b& a, const Packet16b& b) {
  834|      0|  return _mm_or_si128(a, b);
  835|      0|}
  836|       |
  837|       |template <>
  838|      0|EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b) {
  839|      0|  return _mm_xor_ps(a, b);
  840|      0|}
  841|       |template <>
  842|      0|EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& a, const Packet2d& b) {
  843|      0|  return _mm_xor_pd(a, b);
  844|      0|}
  845|       |template <>
  846|      0|EIGEN_STRONG_INLINE Packet2l pxor<Packet2l>(const Packet2l& a, const Packet2l& b) {
  847|      0|  return _mm_xor_si128(a, b);
  848|      0|}
  849|       |template <>
  850|      0|EIGEN_STRONG_INLINE Packet4i pxor<Packet4i>(const Packet4i& a, const Packet4i& b) {
  851|      0|  return _mm_xor_si128(a, b);
  852|      0|}
  853|       |template <>
  854|      0|EIGEN_STRONG_INLINE Packet4ui pxor<Packet4ui>(const Packet4ui& a, const Packet4ui& b) {
  855|      0|  return _mm_xor_si128(a, b);
  856|      0|}
  857|       |template <>
  858|      0|EIGEN_STRONG_INLINE Packet16b pxor<Packet16b>(const Packet16b& a, const Packet16b& b) {
  859|      0|  return _mm_xor_si128(a, b);
  860|      0|}
  861|       |
  862|       |template <>
  863|      0|EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b) {
  864|      0|  return _mm_andnot_ps(b, a);
  865|      0|}
  866|       |template <>
  867|      0|EIGEN_STRONG_INLINE Packet2d pandnot<Packet2d>(const Packet2d& a, const Packet2d& b) {
  868|      0|  return _mm_andnot_pd(b, a);
  869|      0|}
  870|       |template <>
  871|      0|EIGEN_STRONG_INLINE Packet2l pandnot<Packet2l>(const Packet2l& a, const Packet2l& b) {
  872|      0|  return _mm_andnot_si128(b, a);
  873|      0|}
  874|       |template <>
  875|      0|EIGEN_STRONG_INLINE Packet4i pandnot<Packet4i>(const Packet4i& a, const Packet4i& b) {
  876|      0|  return _mm_andnot_si128(b, a);
  877|      0|}
  878|       |template <>
  879|      0|EIGEN_STRONG_INLINE Packet4ui pandnot<Packet4ui>(const Packet4ui& a, const Packet4ui& b) {
  880|      0|  return _mm_andnot_si128(b, a);
  881|      0|}
  882|       |
  883|       |template <>
  884|      0|EIGEN_STRONG_INLINE Packet4f pcmp_le(const Packet4f& a, const Packet4f& b) {
  885|      0|  return _mm_cmple_ps(a, b);
  886|      0|}
  887|       |template <>
  888|      0|EIGEN_STRONG_INLINE Packet4f pcmp_lt(const Packet4f& a, const Packet4f& b) {
  889|      0|  return _mm_cmplt_ps(a, b);
  890|      0|}
  891|       |template <>
  892|      0|EIGEN_STRONG_INLINE Packet4f pcmp_lt_or_nan(const Packet4f& a, const Packet4f& b) {
  893|      0|  return _mm_cmpnge_ps(a, b);
  894|      0|}
  895|       |template <>
  896|      0|EIGEN_STRONG_INLINE Packet4f pcmp_eq(const Packet4f& a, const Packet4f& b) {
  897|      0|  return _mm_cmpeq_ps(a, b);
  898|      0|}
  899|       |
  900|       |template <>
  901|      0|EIGEN_STRONG_INLINE Packet2d pcmp_le(const Packet2d& a, const Packet2d& b) {
  902|      0|  return _mm_cmple_pd(a, b);
  903|      0|}
  904|       |template <>
  905|      0|EIGEN_STRONG_INLINE Packet2d pcmp_lt(const Packet2d& a, const Packet2d& b) {
  906|      0|  return _mm_cmplt_pd(a, b);
  907|      0|}
  908|       |template <>
  909|      0|EIGEN_STRONG_INLINE Packet2d pcmp_lt_or_nan(const Packet2d& a, const Packet2d& b) {
  910|      0|  return _mm_cmpnge_pd(a, b);
  911|      0|}
  912|       |template <>
  913|      0|EIGEN_STRONG_INLINE Packet2d pcmp_eq(const Packet2d& a, const Packet2d& b) {
  914|      0|  return _mm_cmpeq_pd(a, b);
  915|      0|}
  916|       |template <>
  917|      0|EIGEN_STRONG_INLINE Packet4i pcmp_lt(const Packet4i& a, const Packet4i& b) {
  918|      0|  return _mm_cmplt_epi32(a, b);
  919|      0|}
  920|       |template <>
  921|      0|EIGEN_STRONG_INLINE Packet4i pcmp_eq(const Packet4i& a, const Packet4i& b) {
  922|      0|  return _mm_cmpeq_epi32(a, b);
  923|      0|}
  924|       |template <>
  925|      0|EIGEN_STRONG_INLINE Packet4i pcmp_le(const Packet4i& a, const Packet4i& b) {
  926|      0|  return por(pcmp_lt(a, b), pcmp_eq(a, b));
  927|      0|}
  928|       |template <>
  929|      0|EIGEN_STRONG_INLINE Packet2l pcmp_lt(const Packet2l& a, const Packet2l& b) {
  930|      0|#ifdef EIGEN_VECTORIZE_SSE4_2
  931|      0|  return _mm_cmpgt_epi64(b, a);
  932|      0|#else
  933|      0|  Packet4i eq = pcmp_eq<Packet4i>(Packet4i(a), Packet4i(b));
  934|      0|  Packet2l hi_eq = Packet2l(_mm_shuffle_epi32(eq, (shuffle_mask<1, 1, 3, 3>::mask)));
  935|      0|  Packet4i lt = pcmp_lt<Packet4i>(Packet4i(a), Packet4i(b));
  936|      0|  Packet2l hi_lt = Packet2l(_mm_shuffle_epi32(lt, (shuffle_mask<1, 1, 3, 3>::mask)));
  937|      0|  Packet2l lo_lt = Packet2l(_mm_shuffle_epi32(lt, (shuffle_mask<0, 0, 2, 2>::mask)));
  938|      0|  // return hi(a) < hi(b) || (hi(a) == hi(b) && lo(a) < lo(b))
  939|      0|  return por(hi_lt, pand(hi_eq, lo_lt));
  940|      0|#endif
  941|      0|}
  942|       |template <>
  943|      0|EIGEN_STRONG_INLINE Packet2l pcmp_eq(const Packet2l& a, const Packet2l& b) {
  944|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
  945|      0|  return _mm_cmpeq_epi64(a, b);
  946|      0|#else
  947|      0|  Packet4i tmp = pcmp_eq<Packet4i>(Packet4i(a), Packet4i(b));
  948|      0|  return Packet2l(pand<Packet4i>(tmp, _mm_shuffle_epi32(tmp, (shuffle_mask<1, 0, 3, 2>::mask))));
  949|      0|#endif
  950|      0|}
  951|       |template <>
  952|      0|EIGEN_STRONG_INLINE Packet2l pcmp_le(const Packet2l& a, const Packet2l& b) {
  953|      0|  return por(pcmp_lt(a, b), pcmp_eq(a, b));
  954|      0|}
  955|       |template <>
  956|      0|EIGEN_STRONG_INLINE Packet16b pcmp_eq(const Packet16b& a, const Packet16b& b) {
  957|      0|  // Mask out invalid bool bits to avoid UB.
  958|      0|  const Packet16b kBoolMask = pset1<Packet16b>(true);
  959|      0|  return _mm_and_si128(_mm_cmpeq_epi8(a, b), kBoolMask);
  960|      0|}
  961|       |template <>
  962|      0|EIGEN_STRONG_INLINE Packet4ui pcmp_eq(const Packet4ui& a, const Packet4ui& b) {
  963|      0|  return _mm_cmpeq_epi32(a, b);
  964|      0|}
  965|       |
  966|       |template <>
  967|      0|EIGEN_STRONG_INLINE Packet4f pmin<Packet4f>(const Packet4f& a, const Packet4f& b) {
  968|      0|#if EIGEN_GNUC_STRICT_LESS_THAN(6, 3, 0)
  969|      0|// There appears to be a bug in GCC, by which the optimizer may
  970|      0|// flip the argument order in calls to _mm_min_ps, so we have to
  971|      0|// resort to inline ASM here. This is supposed to be fixed in gcc6.3,
  972|      0|// see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
  973|      0|#ifdef EIGEN_VECTORIZE_AVX
  974|      0|  Packet4f res;
  975|      0|  asm("vminps %[a], %[b], %[res]" : [res] "=x"(res) : [a] "x"(a), [b] "x"(b));
  976|      0|#else
  977|      0|  Packet4f res = b;
  978|      0|  asm("minps %[a], %[res]" : [res] "+x"(res) : [a] "x"(a));
  979|      0|#endif
  980|      0|  return res;
  981|      0|#else
  982|      0|  // Arguments are reversed to match NaN propagation behavior of std::min.
  983|      0|  return _mm_min_ps(b, a);
  984|      0|#endif
  985|      0|}
  986|       |template <>
  987|      0|EIGEN_STRONG_INLINE Packet2d pmin<Packet2d>(const Packet2d& a, const Packet2d& b) {
  988|      0|#if EIGEN_GNUC_STRICT_LESS_THAN(6, 3, 0)
  989|      0|// There appears to be a bug in GCC, by which the optimizer may
  990|      0|// flip the argument order in calls to _mm_min_pd, so we have to
  991|      0|// resort to inline ASM here. This is supposed to be fixed in gcc6.3,
  992|      0|// see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
  993|      0|#ifdef EIGEN_VECTORIZE_AVX
  994|      0|  Packet2d res;
  995|      0|  asm("vminpd %[a], %[b], %[res]" : [res] "=x"(res) : [a] "x"(a), [b] "x"(b));
  996|      0|#else
  997|      0|  Packet2d res = b;
  998|      0|  asm("minpd %[a], %[res]" : [res] "+x"(res) : [a] "x"(a));
  999|      0|#endif
 1000|      0|  return res;
 1001|      0|#else
 1002|      0|  // Arguments are reversed to match NaN propagation behavior of std::min.
 1003|      0|  return _mm_min_pd(b, a);
 1004|      0|#endif
 1005|      0|}
 1006|       |template <>
 1007|      0|EIGEN_STRONG_INLINE Packet2l pmin<Packet2l>(const Packet2l& a, const Packet2l& b) {
 1008|      0|  Packet2l a_lt_mask = pcmp_lt(a, b);
 1009|      0|  return por(pandnot(b, a_lt_mask), pand(a, a_lt_mask));
 1010|      0|}
 1011|       |template <>
 1012|      0|EIGEN_STRONG_INLINE Packet4i pmin<Packet4i>(const Packet4i& a, const Packet4i& b) {
 1013|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 1014|      0|  return _mm_min_epi32(a, b);
 1015|      0|#else
 1016|      0|  // after some bench, this version *is* faster than a scalar implementation
 1017|      0|  Packet4i mask = _mm_cmplt_epi32(a, b);
 1018|      0|  return _mm_or_si128(_mm_and_si128(mask, a), _mm_andnot_si128(mask, b));
 1019|      0|#endif
 1020|      0|}
 1021|       |template <>
 1022|      0|EIGEN_STRONG_INLINE Packet4ui pmin<Packet4ui>(const Packet4ui& a, const Packet4ui& b) {
 1023|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 1024|      0|  return _mm_min_epu32(a, b);
 1025|      0|#else
 1026|      0|  return padd((Packet4ui)pmin((Packet4i)psub(a, pset1<Packet4ui>(0x80000000UL)),
 1027|      0|                              (Packet4i)psub(b, pset1<Packet4ui>(0x80000000UL))),
 1028|      0|              pset1<Packet4ui>(0x80000000UL));
 1029|      0|#endif
 1030|      0|}
 1031|       |
 1032|       |template <>
 1033|      0|EIGEN_STRONG_INLINE Packet4f pmax<Packet4f>(const Packet4f& a, const Packet4f& b) {
 1034|      0|#if EIGEN_GNUC_STRICT_LESS_THAN(6, 3, 0)
 1035|      0|// There appears to be a bug in GCC, by which the optimizer may
 1036|      0|// flip the argument order in calls to _mm_max_ps, so we have to
 1037|      0|// resort to inline ASM here. This is supposed to be fixed in gcc6.3,
 1038|      0|// see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
 1039|      0|#ifdef EIGEN_VECTORIZE_AVX
 1040|      0|  Packet4f res;
 1041|      0|  asm("vmaxps %[a], %[b], %[res]" : [res] "=x"(res) : [a] "x"(a), [b] "x"(b));
 1042|      0|#else
 1043|      0|  Packet4f res = b;
 1044|      0|  asm("maxps %[a], %[res]" : [res] "+x"(res) : [a] "x"(a));
 1045|      0|#endif
 1046|      0|  return res;
 1047|      0|#else
 1048|      0|  // Arguments are reversed to match NaN propagation behavior of std::max.
 1049|      0|  return _mm_max_ps(b, a);
 1050|      0|#endif
 1051|      0|}
 1052|       |template <>
 1053|      0|EIGEN_STRONG_INLINE Packet2d pmax<Packet2d>(const Packet2d& a, const Packet2d& b) {
 1054|      0|#if EIGEN_GNUC_STRICT_LESS_THAN(6, 3, 0)
 1055|      0|// There appears to be a bug in GCC, by which the optimizer may
 1056|      0|// flip the argument order in calls to _mm_max_pd, so we have to
 1057|      0|// resort to inline ASM here. This is supposed to be fixed in gcc6.3,
 1058|      0|// see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
 1059|      0|#ifdef EIGEN_VECTORIZE_AVX
 1060|      0|  Packet2d res;
 1061|      0|  asm("vmaxpd %[a], %[b], %[res]" : [res] "=x"(res) : [a] "x"(a), [b] "x"(b));
 1062|      0|#else
 1063|      0|  Packet2d res = b;
 1064|      0|  asm("maxpd %[a], %[res]" : [res] "+x"(res) : [a] "x"(a));
 1065|      0|#endif
 1066|      0|  return res;
 1067|      0|#else
 1068|      0|  // Arguments are reversed to match NaN propagation behavior of std::max.
 1069|      0|  return _mm_max_pd(b, a);
 1070|      0|#endif
 1071|      0|}
 1072|       |template <>
 1073|      0|EIGEN_STRONG_INLINE Packet2l pmax<Packet2l>(const Packet2l& a, const Packet2l& b) {
 1074|      0|  Packet2l a_lt_mask = pcmp_lt(a, b);
 1075|      0|  return por(pandnot(a, a_lt_mask), pand(b, a_lt_mask));
 1076|      0|}
 1077|       |template <>
 1078|      0|EIGEN_STRONG_INLINE Packet4i pmax<Packet4i>(const Packet4i& a, const Packet4i& b) {
 1079|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 1080|      0|  return _mm_max_epi32(a, b);
 1081|      0|#else
 1082|      0|  // after some bench, this version *is* faster than a scalar implementation
 1083|      0|  Packet4i mask = _mm_cmpgt_epi32(a, b);
 1084|      0|  return _mm_or_si128(_mm_and_si128(mask, a), _mm_andnot_si128(mask, b));
 1085|      0|#endif
 1086|      0|}
 1087|       |template <>
 1088|      0|EIGEN_STRONG_INLINE Packet4ui pmax<Packet4ui>(const Packet4ui& a, const Packet4ui& b) {
 1089|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 1090|      0|  return _mm_max_epu32(a, b);
 1091|      0|#else
 1092|      0|  return padd((Packet4ui)pmax((Packet4i)psub(a, pset1<Packet4ui>(0x80000000UL)),
 1093|      0|                              (Packet4i)psub(b, pset1<Packet4ui>(0x80000000UL))),
 1094|      0|              pset1<Packet4ui>(0x80000000UL));
 1095|      0|#endif
 1096|      0|}
 1097|       |
 1098|       |template <>
 1099|      0|EIGEN_STRONG_INLINE Packet4ui pcmp_lt(const Packet4ui& a, const Packet4ui& b) {
 1100|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 1101|      0|  return pxor(pcmp_eq(a, pmax(a, b)), ptrue(a));
 1102|      0|#else
 1103|      0|  return (Packet4ui)pcmp_lt((Packet4i)psub(a, pset1<Packet4ui>(0x80000000UL)),
 1104|      0|                            (Packet4i)psub(b, pset1<Packet4ui>(0x80000000UL)));
 1105|      0|#endif
 1106|      0|}
 1107|       |template <>
 1108|      0|EIGEN_STRONG_INLINE Packet4ui pcmp_le(const Packet4ui& a, const Packet4ui& b) {
 1109|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 1110|      0|  return pcmp_eq(a, pmin(a, b));
 1111|      0|#else
 1112|      0|  return (Packet4ui)pcmp_le((Packet4i)psub(a, pset1<Packet4ui>(0x80000000UL)),
 1113|      0|                            (Packet4i)psub(b, pset1<Packet4ui>(0x80000000UL)));
 1114|      0|#endif
 1115|      0|}
 1116|       |
 1117|       |template <typename Packet, typename Op>
 1118|      0|EIGEN_STRONG_INLINE Packet pminmax_propagate_numbers(const Packet& a, const Packet& b, Op op) {
 1119|      0|  // In this implementation, we take advantage of the fact that pmin/pmax for SSE
 1120|      0|  // always return a if either a or b is NaN.
 1121|      0|  Packet not_nan_mask_a = pcmp_eq(a, a);
 1122|      0|  Packet m = op(a, b);
 1123|      0|  return pselect<Packet>(not_nan_mask_a, m, b);
 1124|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25pminmax_propagate_numbersIDv4_fPFS2_RKS2_S4_EEET_RKS7_S9_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal25pminmax_propagate_numbersIDv2_dPFS2_RKS2_S4_EEET_RKS7_S9_T0_
  ------------------
 1125|       |
 1126|       |template <typename Packet, typename Op>
 1127|      0|EIGEN_STRONG_INLINE Packet pminmax_propagate_nan(const Packet& a, const Packet& b, Op op) {
 1128|      0|  // In this implementation, we take advantage of the fact that pmin/pmax for SSE
 1129|      0|  // always return a if either a or b is NaN.
 1130|      0|  Packet not_nan_mask_a = pcmp_eq(a, a);
 1131|      0|  Packet m = op(b, a);
 1132|      0|  return pselect<Packet>(not_nan_mask_a, m, a);
 1133|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21pminmax_propagate_nanIDv4_fPFS2_RKS2_S4_EEET_RKS7_S9_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21pminmax_propagate_nanIDv2_dPFS2_RKS2_S4_EEET_RKS7_S9_T0_
  ------------------
 1134|       |
 1135|       |// Add specializations for min/max with prescribed NaN propagation.
 1136|       |template <>
 1137|      0|EIGEN_STRONG_INLINE Packet4f pmin<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) {
 1138|      0|  return pminmax_propagate_numbers(a, b, pmin<Packet4f>);
 1139|      0|}
 1140|       |template <>
 1141|      0|EIGEN_STRONG_INLINE Packet2d pmin<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) {
 1142|      0|  return pminmax_propagate_numbers(a, b, pmin<Packet2d>);
 1143|      0|}
 1144|       |template <>
 1145|      0|EIGEN_STRONG_INLINE Packet4f pmax<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) {
 1146|      0|  return pminmax_propagate_numbers(a, b, pmax<Packet4f>);
 1147|      0|}
 1148|       |template <>
 1149|      0|EIGEN_STRONG_INLINE Packet2d pmax<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) {
 1150|      0|  return pminmax_propagate_numbers(a, b, pmax<Packet2d>);
 1151|      0|}
 1152|       |template <>
 1153|      0|EIGEN_STRONG_INLINE Packet4f pmin<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) {
 1154|      0|  return pminmax_propagate_nan(a, b, pmin<Packet4f>);
 1155|      0|}
 1156|       |template <>
 1157|      0|EIGEN_STRONG_INLINE Packet2d pmin<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) {
 1158|      0|  return pminmax_propagate_nan(a, b, pmin<Packet2d>);
 1159|      0|}
 1160|       |template <>
 1161|      0|EIGEN_STRONG_INLINE Packet4f pmax<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) {
 1162|      0|  return pminmax_propagate_nan(a, b, pmax<Packet4f>);
 1163|      0|}
 1164|       |template <>
 1165|      0|EIGEN_STRONG_INLINE Packet2d pmax<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) {
 1166|      0|  return pminmax_propagate_nan(a, b, pmax<Packet2d>);
 1167|      0|}
 1168|       |
 1169|       |template <>
 1170|      0|EIGEN_STRONG_INLINE Packet4f psignbit(const Packet4f& a) {
 1171|      0|  return _mm_castsi128_ps(_mm_srai_epi32(_mm_castps_si128(a), 31));
 1172|      0|}
 1173|       |template <>
 1174|      0|EIGEN_STRONG_INLINE Packet2d psignbit(const Packet2d& a) {
 1175|      0|  Packet4f tmp = psignbit<Packet4f>(_mm_castpd_ps(a));
 1176|      0|#ifdef EIGEN_VECTORIZE_AVX
 1177|      0|  return _mm_castps_pd(_mm_permute_ps(tmp, (shuffle_mask<1, 1, 3, 3>::mask)));
 1178|      0|#else
 1179|      0|  return _mm_castps_pd(_mm_shuffle_ps(tmp, tmp, (shuffle_mask<1, 1, 3, 3>::mask)));
 1180|      0|#endif  // EIGEN_VECTORIZE_AVX
 1181|      0|}
 1182|       |template <>
 1183|      0|EIGEN_STRONG_INLINE Packet4i psignbit(const Packet4i& a) {
 1184|      0|  return _mm_srai_epi32(a, 31);
 1185|      0|}
 1186|       |template <>
 1187|      0|EIGEN_STRONG_INLINE Packet4ui psignbit(const Packet4ui& a) {
 1188|      0|  return pzero(a);
 1189|      0|}
 1190|       |template <>
 1191|      0|EIGEN_STRONG_INLINE Packet2l psignbit(const Packet2l& a) {
 1192|      0|  Packet4i tmp = psignbit<Packet4i>(Packet4i(a));
 1193|      0|  return Packet2l(_mm_shuffle_epi32(tmp, (shuffle_mask<1, 1, 3, 3>::mask)));
 1194|      0|}
 1195|       |
 1196|       |template <int N>
 1197|       |EIGEN_STRONG_INLINE Packet2l parithmetic_shift_right(const Packet2l& a) {
 1198|       |  Packet2l signbit = psignbit(a);
 1199|       |  return por(_mm_slli_epi64(signbit, 64 - N), _mm_srli_epi64(a, N));
 1200|       |}
 1201|       |template <int N>
 1202|       |EIGEN_STRONG_INLINE Packet2l plogical_shift_right(const Packet2l& a) {
 1203|       |  return _mm_srli_epi64(a, N);
 1204|       |}
 1205|       |template <int N>
 1206|      0|EIGEN_STRONG_INLINE Packet2l plogical_shift_left(const Packet2l& a) {
 1207|      0|  return _mm_slli_epi64(a, N);
 1208|      0|}
 1209|       |template <int N>
 1210|      0|EIGEN_STRONG_INLINE Packet4i parithmetic_shift_right(const Packet4i& a) {
 1211|      0|  return _mm_srai_epi32(a, N);
 1212|      0|}
 1213|       |template <int N>
 1214|      0|EIGEN_STRONG_INLINE Packet4i plogical_shift_right(const Packet4i& a) {
 1215|      0|  return _mm_srli_epi32(a, N);
 1216|      0|}
 1217|       |template <int N>
 1218|      0|EIGEN_STRONG_INLINE Packet4i plogical_shift_left(const Packet4i& a) {
 1219|      0|  return _mm_slli_epi32(a, N);
 1220|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19plogical_shift_leftILi23EEENS0_20eigen_packet_wrapperIDv2_xLi0EEERKS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19plogical_shift_leftILi30EEENS0_20eigen_packet_wrapperIDv2_xLi0EEERKS4_
  ------------------
 1221|       |template <int N>
 1222|       |EIGEN_STRONG_INLINE Packet4ui parithmetic_shift_right(const Packet4ui& a) {
 1223|       |  return _mm_srli_epi32(a, N);
 1224|       |}
 1225|       |template <int N>
 1226|       |EIGEN_STRONG_INLINE Packet4ui plogical_shift_right(const Packet4ui& a) {
 1227|       |  return _mm_srli_epi32(a, N);
 1228|       |}
 1229|       |template <int N>
 1230|       |EIGEN_STRONG_INLINE Packet4ui plogical_shift_left(const Packet4ui& a) {
 1231|       |  return _mm_slli_epi32(a, N);
 1232|       |}
 1233|       |
 1234|       |template <>
 1235|      0|EIGEN_STRONG_INLINE Packet4f pabs(const Packet4f& a) {
 1236|      0|  const __m128i mask = _mm_setr_epi32(0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF);
 1237|      0|  return _mm_castsi128_ps(_mm_and_si128(mask, _mm_castps_si128(a)));
 1238|      0|}
 1239|       |template <>
 1240|      0|EIGEN_STRONG_INLINE Packet2d pabs(const Packet2d& a) {
 1241|      0|  const __m128i mask = _mm_setr_epi32(0xFFFFFFFF, 0x7FFFFFFF, 0xFFFFFFFF, 0x7FFFFFFF);
 1242|      0|  return _mm_castsi128_pd(_mm_and_si128(mask, _mm_castpd_si128(a)));
 1243|      0|}
 1244|       |template <>
 1245|      0|EIGEN_STRONG_INLINE Packet2l pabs(const Packet2l& a) {
 1246|      0|  Packet2l signbit = psignbit(a);
 1247|      0|  return _mm_sub_epi64(_mm_xor_si128(a, signbit), signbit);
 1248|      0|}
 1249|       |template <>
 1250|      0|EIGEN_STRONG_INLINE Packet4i pabs(const Packet4i& a) {
 1251|      0|#ifdef EIGEN_VECTORIZE_SSSE3
 1252|      0|  return _mm_abs_epi32(a);
 1253|      0|#else
 1254|      0|  Packet4i signbit = psignbit(a);
 1255|      0|  return _mm_sub_epi32(_mm_xor_si128(a, signbit), signbit);
 1256|      0|#endif
 1257|      0|}
 1258|       |template <>
 1259|      0|EIGEN_STRONG_INLINE Packet4ui pabs(const Packet4ui& a) {
 1260|      0|  return a;
 1261|      0|}
 1262|       |
 1263|       |#ifdef EIGEN_VECTORIZE_SSE4_1
 1264|       |template <>
 1265|       |EIGEN_STRONG_INLINE Packet4f pround<Packet4f>(const Packet4f& a) {
 1266|       |  // Unfortunately _mm_round_ps doesn't have a rounding mode to implement numext::round.
 1267|       |  const Packet4f mask = pset1frombits<Packet4f>(0x80000000u);
 1268|       |  const Packet4f prev0dot5 = pset1frombits<Packet4f>(0x3EFFFFFFu);
 1269|       |  return _mm_round_ps(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
 1270|       |}
 1271|       |
 1272|       |template <>
 1273|       |EIGEN_STRONG_INLINE Packet2d pround<Packet2d>(const Packet2d& a) {
 1274|       |  const Packet2d mask = _mm_castsi128_pd(_mm_set_epi64x(0x8000000000000000ull, 0x8000000000000000ull));
 1275|       |  const Packet2d prev0dot5 = _mm_castsi128_pd(_mm_set_epi64x(0x3FDFFFFFFFFFFFFFull, 0x3FDFFFFFFFFFFFFFull));
 1276|       |  return _mm_round_pd(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
 1277|       |}
 1278|       |
 1279|       |template <>
 1280|       |EIGEN_STRONG_INLINE Packet4f print<Packet4f>(const Packet4f& a) {
 1281|       |  return _mm_round_ps(a, _MM_FROUND_CUR_DIRECTION);
 1282|       |}
 1283|       |template <>
 1284|       |EIGEN_STRONG_INLINE Packet2d print<Packet2d>(const Packet2d& a) {
 1285|       |  return _mm_round_pd(a, _MM_FROUND_CUR_DIRECTION);
 1286|       |}
 1287|       |
 1288|       |template <>
 1289|       |EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>(const Packet4f& a) {
 1290|       |  return _mm_ceil_ps(a);
 1291|       |}
 1292|       |template <>
 1293|       |EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const Packet2d& a) {
 1294|       |  return _mm_ceil_pd(a);
 1295|       |}
 1296|       |
 1297|       |template <>
 1298|       |EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a) {
 1299|       |  return _mm_floor_ps(a);
 1300|       |}
 1301|       |template <>
 1302|       |EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a) {
 1303|       |  return _mm_floor_pd(a);
 1304|       |}
 1305|       |
 1306|       |template <>
 1307|       |EIGEN_STRONG_INLINE Packet4f ptrunc<Packet4f>(const Packet4f& a) {
 1308|       |  return _mm_round_ps(a, _MM_FROUND_TRUNC);
 1309|       |}
 1310|       |template <>
 1311|       |EIGEN_STRONG_INLINE Packet2d ptrunc<Packet2d>(const Packet2d& a) {
 1312|       |  return _mm_round_pd(a, _MM_FROUND_TRUNC);
 1313|       |}
 1314|       |#endif
 1315|       |
 1316|       |template <>
 1317|      0|EIGEN_STRONG_INLINE Packet4f pload<Packet4f>(const float* from) {
 1318|      0|  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_ps(from);
 1319|      0|}
 1320|       |template <>
 1321|      0|EIGEN_STRONG_INLINE Packet2d pload<Packet2d>(const double* from) {
 1322|      0|  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_pd(from);
 1323|      0|}
 1324|       |template <>
 1325|      0|EIGEN_STRONG_INLINE Packet2l pload<Packet2l>(const int64_t* from) {
 1326|      0|  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast<const __m128i*>(from));
 1327|      0|}
 1328|       |template <>
 1329|      0|EIGEN_STRONG_INLINE Packet4i pload<Packet4i>(const int* from) {
 1330|      0|  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast<const __m128i*>(from));
 1331|      0|}
 1332|       |template <>
 1333|      0|EIGEN_STRONG_INLINE Packet4ui pload<Packet4ui>(const uint32_t* from) {
 1334|      0|  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast<const __m128i*>(from));
 1335|      0|}
 1336|       |template <>
 1337|      0|EIGEN_STRONG_INLINE Packet16b pload<Packet16b>(const bool* from) {
 1338|      0|  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast<const __m128i*>(from));
 1339|      0|}
 1340|       |
 1341|       |#if EIGEN_COMP_MSVC
 1342|       |template <>
 1343|       |EIGEN_STRONG_INLINE Packet4f ploadu<Packet4f>(const float* from) {
 1344|       |  EIGEN_DEBUG_UNALIGNED_LOAD
 1345|       |  return _mm_loadu_ps(from);
 1346|       |}
 1347|       |#else
 1348|       |// NOTE: with the code below, MSVC's compiler crashes!
 1349|       |
 1350|       |template <>
 1351|      0|EIGEN_STRONG_INLINE Packet4f ploadu<Packet4f>(const float* from) {
 1352|      0|  EIGEN_DEBUG_UNALIGNED_LOAD
 1353|      0|  return _mm_loadu_ps(from);
 1354|      0|}
 1355|       |#endif
 1356|       |
 1357|       |template <>
 1358|      0|EIGEN_STRONG_INLINE Packet2d ploadu<Packet2d>(const double* from) {
 1359|      0|  EIGEN_DEBUG_UNALIGNED_LOAD
 1360|      0|  return _mm_loadu_pd(from);
 1361|      0|}
 1362|       |template <>
 1363|      0|EIGEN_STRONG_INLINE Packet2l ploadu<Packet2l>(const int64_t* from) {
 1364|      0|  EIGEN_DEBUG_UNALIGNED_LOAD
 1365|      0|  return _mm_loadu_si128(reinterpret_cast<const __m128i*>(from));
 1366|      0|}
 1367|       |template <>
 1368|      0|EIGEN_STRONG_INLINE Packet4i ploadu<Packet4i>(const int* from) {
 1369|      0|  EIGEN_DEBUG_UNALIGNED_LOAD
 1370|      0|  return _mm_loadu_si128(reinterpret_cast<const __m128i*>(from));
 1371|      0|}
 1372|       |template <>
 1373|      0|EIGEN_STRONG_INLINE Packet4ui ploadu<Packet4ui>(const uint32_t* from) {
 1374|      0|  EIGEN_DEBUG_UNALIGNED_LOAD
 1375|      0|  return _mm_loadu_si128(reinterpret_cast<const __m128i*>(from));
 1376|      0|}
 1377|       |template <>
 1378|      0|EIGEN_STRONG_INLINE Packet16b ploadu<Packet16b>(const bool* from) {
 1379|      0|  EIGEN_DEBUG_UNALIGNED_LOAD
 1380|      0|  return _mm_loadu_si128(reinterpret_cast<const __m128i*>(from));
 1381|      0|}
 1382|       |
 1383|       |// Load lower part of packet zero extending.
 1384|       |template <typename Packet>
 1385|       |EIGEN_STRONG_INLINE Packet ploadl(const typename unpacket_traits<Packet>::type* from);
 1386|       |template <>
 1387|      0|EIGEN_STRONG_INLINE Packet4f ploadl<Packet4f>(const float* from) {
 1388|      0|  EIGEN_DEBUG_UNALIGNED_LOAD return _mm_castpd_ps(_mm_load_sd(reinterpret_cast<const double*>(from)));
 1389|      0|}
 1390|       |template <>
 1391|      0|EIGEN_STRONG_INLINE Packet2d ploadl<Packet2d>(const double* from) {
 1392|      0|  EIGEN_DEBUG_UNALIGNED_LOAD return _mm_load_sd(from);
 1393|      0|}
 1394|       |
 1395|       |// Load scalar
 1396|       |template <typename Packet>
 1397|       |EIGEN_STRONG_INLINE Packet ploads(const typename unpacket_traits<Packet>::type* from);
 1398|       |template <>
 1399|      0|EIGEN_STRONG_INLINE Packet4f ploads<Packet4f>(const float* from) {
 1400|      0|  EIGEN_DEBUG_UNALIGNED_LOAD return _mm_load_ss(from);
 1401|      0|}
 1402|       |template <>
 1403|      0|EIGEN_STRONG_INLINE Packet2d ploads<Packet2d>(const double* from) {
 1404|      0|  EIGEN_DEBUG_UNALIGNED_LOAD return _mm_load_sd(from);
 1405|      0|}
 1406|       |
 1407|       |template <>
 1408|      0|EIGEN_STRONG_INLINE Packet4f ploaddup<Packet4f>(const float* from) {
 1409|      0|  return vec4f_swizzle1(_mm_castpd_ps(_mm_load_sd(reinterpret_cast<const double*>(from))), 0, 0, 1, 1);
 1410|      0|}
 1411|       |template <>
 1412|      0|EIGEN_STRONG_INLINE Packet2d ploaddup<Packet2d>(const double* from) {
 1413|      0|  return pset1<Packet2d>(from[0]);
 1414|      0|}
 1415|       |template <>
 1416|      0|EIGEN_STRONG_INLINE Packet2l ploaddup<Packet2l>(const int64_t* from) {
 1417|      0|  return pset1<Packet2l>(from[0]);
 1418|      0|}
 1419|       |template <>
 1420|      0|EIGEN_STRONG_INLINE Packet4i ploaddup<Packet4i>(const int* from) {
 1421|      0|  Packet4i tmp;
 1422|      0|  tmp = _mm_loadl_epi64(reinterpret_cast<const __m128i*>(from));
 1423|      0|  return vec4i_swizzle1(tmp, 0, 0, 1, 1);
 1424|      0|}
 1425|       |template <>
 1426|      0|EIGEN_STRONG_INLINE Packet4ui ploaddup<Packet4ui>(const uint32_t* from) {
 1427|      0|  Packet4ui tmp;
 1428|      0|  tmp = _mm_loadl_epi64(reinterpret_cast<const __m128i*>(from));
 1429|      0|  return vec4ui_swizzle1(tmp, 0, 0, 1, 1);
 1430|      0|}
 1431|       |
 1432|       |// Loads 8 bools from memory and returns the packet
 1433|       |// {b0, b0, b1, b1, b2, b2, b3, b3, b4, b4, b5, b5, b6, b6, b7, b7}
 1434|       |template <>
 1435|      0|EIGEN_STRONG_INLINE Packet16b ploaddup<Packet16b>(const bool* from) {
 1436|      0|  __m128i tmp = _mm_castpd_si128(pload1<Packet2d>(reinterpret_cast<const double*>(from)));
 1437|      0|  return _mm_unpacklo_epi8(tmp, tmp);
 1438|      0|}
 1439|       |
 1440|       |// Loads 4 bools from memory and returns the packet
 1441|       |// {b0, b0  b0, b0, b1, b1, b1, b1, b2, b2, b2, b2, b3, b3, b3, b3}
 1442|       |template <>
 1443|      0|EIGEN_STRONG_INLINE Packet16b ploadquad<Packet16b>(const bool* from) {
 1444|      0|  __m128i tmp = _mm_castps_si128(pload1<Packet4f>(reinterpret_cast<const float*>(from)));
 1445|      0|  tmp = _mm_unpacklo_epi8(tmp, tmp);
 1446|      0|  return _mm_unpacklo_epi16(tmp, tmp);
 1447|      0|}
 1448|       |
 1449|       |template <>
 1450|      0|EIGEN_STRONG_INLINE void pstore<float>(float* to, const Packet4f& from) {
 1451|      0|  EIGEN_DEBUG_ALIGNED_STORE _mm_store_ps(to, from);
 1452|      0|}
 1453|       |template <>
 1454|      0|EIGEN_STRONG_INLINE void pstore<double>(double* to, const Packet2d& from) {
 1455|      0|  EIGEN_DEBUG_ALIGNED_STORE _mm_store_pd(to, from);
 1456|      0|}
 1457|       |template <>
 1458|      0|EIGEN_STRONG_INLINE void pstore<int64_t>(int64_t* to, const Packet2l& from) {
 1459|      0|  EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast<__m128i*>(to), from);
 1460|      0|}
 1461|       |template <>
 1462|      0|EIGEN_STRONG_INLINE void pstore<int>(int* to, const Packet4i& from) {
 1463|      0|  EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast<__m128i*>(to), from);
 1464|      0|}
 1465|       |template <>
 1466|      0|EIGEN_STRONG_INLINE void pstore<uint32_t>(uint32_t* to, const Packet4ui& from) {
 1467|      0|  EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast<__m128i*>(to), from);
 1468|      0|}
 1469|       |template <>
 1470|      0|EIGEN_STRONG_INLINE void pstore<bool>(bool* to, const Packet16b& from) {
 1471|      0|  EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast<__m128i*>(to), from);
 1472|      0|}
 1473|       |
 1474|       |template <>
 1475|      0|EIGEN_STRONG_INLINE void pstoreu<double>(double* to, const Packet2d& from) {
 1476|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_pd(to, from);
 1477|      0|}
 1478|       |template <>
 1479|      0|EIGEN_STRONG_INLINE void pstoreu<float>(float* to, const Packet4f& from) {
 1480|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_ps(to, from);
 1481|      0|}
 1482|       |template <>
 1483|      0|EIGEN_STRONG_INLINE void pstoreu<int64_t>(int64_t* to, const Packet2l& from) {
 1484|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from);
 1485|      0|}
 1486|       |template <>
 1487|      0|EIGEN_STRONG_INLINE void pstoreu<int>(int* to, const Packet4i& from) {
 1488|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from);
 1489|      0|}
 1490|       |template <>
 1491|      0|EIGEN_STRONG_INLINE void pstoreu<uint32_t>(uint32_t* to, const Packet4ui& from) {
 1492|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from);
 1493|      0|}
 1494|       |template <>
 1495|      0|EIGEN_STRONG_INLINE void pstoreu<bool>(bool* to, const Packet16b& from) {
 1496|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from);
 1497|      0|}
 1498|       |
 1499|       |template <typename Scalar, typename Packet>
 1500|       |EIGEN_STRONG_INLINE void pstorel(Scalar* to, const Packet& from);
 1501|       |template <>
 1502|      0|EIGEN_STRONG_INLINE void pstorel(float* to, const Packet4f& from) {
 1503|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storel_pi(reinterpret_cast<__m64*>(to), from);
 1504|      0|}
 1505|       |template <>
 1506|      0|EIGEN_STRONG_INLINE void pstorel(double* to, const Packet2d& from) {
 1507|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_storel_pd(to, from);
 1508|      0|}
 1509|       |
 1510|       |template <typename Scalar, typename Packet>
 1511|       |EIGEN_STRONG_INLINE void pstores(Scalar* to, const Packet& from);
 1512|       |template <>
 1513|      0|EIGEN_STRONG_INLINE void pstores(float* to, const Packet4f& from) {
 1514|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_store_ss(to, from);
 1515|      0|}
 1516|       |template <>
 1517|      0|EIGEN_STRONG_INLINE void pstores(double* to, const Packet2d& from) {
 1518|      0|  EIGEN_DEBUG_UNALIGNED_STORE _mm_store_sd(to, from);
 1519|      0|}
 1520|       |
 1521|       |template <>
 1522|      0|EIGEN_STRONG_INLINE Packet4f preverse(const Packet4f& a) {
 1523|      0|  return _mm_shuffle_ps(a, a, 0x1B);
 1524|      0|}
 1525|       |template <>
 1526|      0|EIGEN_STRONG_INLINE Packet2d preverse(const Packet2d& a) {
 1527|      0|  return _mm_shuffle_pd(a, a, 0x1);
 1528|      0|}
 1529|       |template <>
 1530|      0|EIGEN_STRONG_INLINE Packet2l preverse(const Packet2l& a) {
 1531|      0|  return _mm_castpd_si128(preverse(_mm_castsi128_pd(a)));
 1532|      0|}
 1533|       |template <>
 1534|      0|EIGEN_STRONG_INLINE Packet4i preverse(const Packet4i& a) {
 1535|      0|  return _mm_shuffle_epi32(a, 0x1B);
 1536|      0|}
 1537|       |template <>
 1538|      0|EIGEN_STRONG_INLINE Packet4ui preverse(const Packet4ui& a) {
 1539|      0|  return _mm_shuffle_epi32(a, 0x1B);
 1540|      0|}
 1541|       |template <>
 1542|      0|EIGEN_STRONG_INLINE Packet16b preverse(const Packet16b& a) {
 1543|      0|#ifdef EIGEN_VECTORIZE_SSSE3
 1544|      0|  __m128i mask = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);
 1545|      0|  return _mm_shuffle_epi8(a, mask);
 1546|      0|#else
 1547|      0|  Packet16b tmp = _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 1, 2, 3));
 1548|      0|  tmp = _mm_shufflehi_epi16(_mm_shufflelo_epi16(tmp, _MM_SHUFFLE(2, 3, 0, 1)), _MM_SHUFFLE(2, 3, 0, 1));
 1549|      0|  return _mm_or_si128(_mm_slli_epi16(tmp, 8), _mm_srli_epi16(tmp, 8));
 1550|      0|#endif
 1551|      0|}
 1552|       |
 1553|       |#if EIGEN_COMP_MSVC_STRICT && EIGEN_OS_WIN64
 1554|       |// The temporary variable fixes an internal compilation error in vs <= 2008 and a wrong-result bug in vs 2010
 1555|       |// Direct of the struct members fixed bug #62.
 1556|       |template <>
 1557|       |EIGEN_STRONG_INLINE float pfirst<Packet4f>(const Packet4f& a) {
 1558|       |  return a.m128_f32[0];
 1559|       |}
 1560|       |template <>
 1561|       |EIGEN_STRONG_INLINE double pfirst<Packet2d>(const Packet2d& a) {
 1562|       |  return a.m128d_f64[0];
 1563|       |}
 1564|       |template <>
 1565|       |EIGEN_STRONG_INLINE int64_t pfirst<Packet2l>(const Packet2l& a) {
 1566|       |  int64_t x = _mm_extract_epi64_0(a);
 1567|       |  return x;
 1568|       |}
 1569|       |template <>
 1570|       |EIGEN_STRONG_INLINE int pfirst<Packet4i>(const Packet4i& a) {
 1571|       |  int x = _mm_cvtsi128_si32(a);
 1572|       |  return x;
 1573|       |}
 1574|       |template <>
 1575|       |EIGEN_STRONG_INLINE uint32_t pfirst<Packet4ui>(const Packet4ui& a) {
 1576|       |  uint32_t x = numext::bit_cast<uint32_t>(_mm_cvtsi128_si32(a));
 1577|       |  return x;
 1578|       |}
 1579|       |#elif EIGEN_COMP_MSVC_STRICT
 1580|       |// The temporary variable fixes an internal compilation error in vs <= 2008 and a wrong-result bug in vs 2010
 1581|       |template <>
 1582|       |EIGEN_STRONG_INLINE float pfirst<Packet4f>(const Packet4f& a) {
 1583|       |  float x = _mm_cvtss_f32(a);
 1584|       |  return x;
 1585|       |}
 1586|       |template <>
 1587|       |EIGEN_STRONG_INLINE double pfirst<Packet2d>(const Packet2d& a) {
 1588|       |  double x = _mm_cvtsd_f64(a);
 1589|       |  return x;
 1590|       |}
 1591|       |template <>
 1592|       |EIGEN_STRONG_INLINE int64_t pfirst<Packet2l>(const Packet2l& a) {
 1593|       |  int64_t x = _mm_extract_epi64_0(a);
 1594|       |  return x;
 1595|       |}
 1596|       |template <>
 1597|       |EIGEN_STRONG_INLINE int pfirst<Packet4i>(const Packet4i& a) {
 1598|       |  int x = _mm_cvtsi128_si32(a);
 1599|       |  return x;
 1600|       |}
 1601|       |template <>
 1602|       |EIGEN_STRONG_INLINE uint32_t pfirst<Packet4ui>(const Packet4ui& a) {
 1603|       |  uint32_t x = numext::bit_cast<uint32_t>(_mm_cvtsi128_si32(a));
 1604|       |  return x;
 1605|       |}
 1606|       |#else
 1607|       |template <>
 1608|      0|EIGEN_STRONG_INLINE float pfirst<Packet4f>(const Packet4f& a) {
 1609|      0|  return _mm_cvtss_f32(a);
 1610|      0|}
 1611|       |template <>
 1612|      0|EIGEN_STRONG_INLINE double pfirst<Packet2d>(const Packet2d& a) {
 1613|      0|  return _mm_cvtsd_f64(a);
 1614|      0|}
 1615|       |template <>
 1616|      0|EIGEN_STRONG_INLINE int64_t pfirst<Packet2l>(const Packet2l& a) {
 1617|      0|  return _mm_extract_epi64_0(a);
 1618|      0|}
 1619|       |template <>
 1620|      0|EIGEN_STRONG_INLINE int pfirst<Packet4i>(const Packet4i& a) {
 1621|      0|  return _mm_cvtsi128_si32(a);
 1622|      0|}
 1623|       |template <>
 1624|      0|EIGEN_STRONG_INLINE uint32_t pfirst<Packet4ui>(const Packet4ui& a) {
 1625|      0|  return numext::bit_cast<uint32_t>(_mm_cvtsi128_si32(a));
 1626|      0|}
 1627|       |#endif
 1628|       |template <>
 1629|      0|EIGEN_STRONG_INLINE bool pfirst<Packet16b>(const Packet16b& a) {
 1630|      0|  int x = _mm_cvtsi128_si32(a);
 1631|      0|  return static_cast<bool>(x & 1);
 1632|      0|}
 1633|       |
 1634|       |template <>
 1635|      0|EIGEN_STRONG_INLINE Packet4f pgather<float, Packet4f>(const float* from, Index stride) {
 1636|      0|  return _mm_set_ps(from[3 * stride], from[2 * stride], from[1 * stride], from[0 * stride]);
 1637|      0|}
 1638|       |template <>
 1639|      0|EIGEN_STRONG_INLINE Packet2d pgather<double, Packet2d>(const double* from, Index stride) {
 1640|      0|  return _mm_set_pd(from[1 * stride], from[0 * stride]);
 1641|      0|}
 1642|       |template <>
 1643|      0|EIGEN_STRONG_INLINE Packet2l pgather<int64_t, Packet2l>(const int64_t* from, Index stride) {
 1644|      0|  return _mm_set_epi64x(from[1 * stride], from[0 * stride]);
 1645|      0|}
 1646|       |template <>
 1647|      0|EIGEN_STRONG_INLINE Packet4i pgather<int, Packet4i>(const int* from, Index stride) {
 1648|      0|  return _mm_set_epi32(from[3 * stride], from[2 * stride], from[1 * stride], from[0 * stride]);
 1649|      0|}
 1650|       |template <>
 1651|      0|EIGEN_STRONG_INLINE Packet4ui pgather<uint32_t, Packet4ui>(const uint32_t* from, Index stride) {
 1652|      0|  return _mm_set_epi32(numext::bit_cast<int32_t>(from[3 * stride]), numext::bit_cast<int32_t>(from[2 * stride]),
 1653|      0|                       numext::bit_cast<int32_t>(from[1 * stride]), numext::bit_cast<int32_t>(from[0 * stride]));
 1654|      0|}
 1655|       |
 1656|       |template <>
 1657|      0|EIGEN_STRONG_INLINE Packet16b pgather<bool, Packet16b>(const bool* from, Index stride) {
 1658|      0|  return _mm_set_epi8(from[15 * stride], from[14 * stride], from[13 * stride], from[12 * stride], from[11 * stride],
 1659|      0|                      from[10 * stride], from[9 * stride], from[8 * stride], from[7 * stride], from[6 * stride],
 1660|      0|                      from[5 * stride], from[4 * stride], from[3 * stride], from[2 * stride], from[1 * stride],
 1661|      0|                      from[0 * stride]);
 1662|      0|}
 1663|       |
 1664|       |template <>
 1665|      0|EIGEN_STRONG_INLINE void pscatter<float, Packet4f>(float* to, const Packet4f& from, Index stride) {
 1666|      0|  to[stride * 0] = pfirst(from);
 1667|      0|  to[stride * 1] = pfirst(_mm_shuffle_ps(from, from, 1));
 1668|      0|  to[stride * 2] = pfirst(_mm_shuffle_ps(from, from, 2));
 1669|      0|  to[stride * 3] = pfirst(_mm_shuffle_ps(from, from, 3));
 1670|      0|}
 1671|       |template <>
 1672|      0|EIGEN_STRONG_INLINE void pscatter<double, Packet2d>(double* to, const Packet2d& from, Index stride) {
 1673|      0|  to[stride * 0] = pfirst(from);
 1674|      0|  to[stride * 1] = pfirst(preverse(from));
 1675|      0|}
 1676|       |template <>
 1677|      0|EIGEN_STRONG_INLINE void pscatter<int64_t, Packet2l>(int64_t* to, const Packet2l& from, Index stride) {
 1678|      0|  to[stride * 0] = pfirst(from);
 1679|      0|  to[stride * 1] = pfirst(preverse(from));
 1680|      0|}
 1681|       |template <>
 1682|      0|EIGEN_STRONG_INLINE void pscatter<int, Packet4i>(int* to, const Packet4i& from, Index stride) {
 1683|      0|  to[stride * 0] = _mm_cvtsi128_si32(from);
 1684|      0|  to[stride * 1] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 1));
 1685|      0|  to[stride * 2] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 2));
 1686|      0|  to[stride * 3] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 3));
 1687|      0|}
 1688|       |template <>
 1689|      0|EIGEN_STRONG_INLINE void pscatter<uint32_t, Packet4ui>(uint32_t* to, const Packet4ui& from, Index stride) {
 1690|      0|  to[stride * 0] = numext::bit_cast<uint32_t>(_mm_cvtsi128_si32(from));
 1691|      0|  to[stride * 1] = numext::bit_cast<uint32_t>(_mm_cvtsi128_si32(_mm_shuffle_epi32(from, 1)));
 1692|      0|  to[stride * 2] = numext::bit_cast<uint32_t>(_mm_cvtsi128_si32(_mm_shuffle_epi32(from, 2)));
 1693|      0|  to[stride * 3] = numext::bit_cast<uint32_t>(_mm_cvtsi128_si32(_mm_shuffle_epi32(from, 3)));
 1694|      0|}
 1695|       |template <>
 1696|      0|EIGEN_STRONG_INLINE void pscatter<bool, Packet16b>(bool* to, const Packet16b& from, Index stride) {
 1697|      0|  to[4 * stride * 0] = _mm_cvtsi128_si32(from);
 1698|      0|  to[4 * stride * 1] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 1));
 1699|      0|  to[4 * stride * 2] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 2));
 1700|      0|  to[4 * stride * 3] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 3));
 1701|      0|}
 1702|       |
 1703|       |// some compilers might be tempted to perform multiple moves instead of using a vector path.
 1704|       |template <>
 1705|      0|EIGEN_STRONG_INLINE void pstore1<Packet4f>(float* to, const float& a) {
 1706|      0|  Packet4f pa = _mm_set_ss(a);
 1707|      0|  pstore(to, Packet4f(vec4f_swizzle1(pa, 0, 0, 0, 0)));
 1708|      0|}
 1709|       |// some compilers might be tempted to perform multiple moves instead of using a vector path.
 1710|       |template <>
 1711|      0|EIGEN_STRONG_INLINE void pstore1<Packet2d>(double* to, const double& a) {
 1712|      0|  Packet2d pa = _mm_set_sd(a);
 1713|      0|  pstore(to, Packet2d(vec2d_swizzle1(pa, 0, 0)));
 1714|      0|}
 1715|       |
 1716|       |#if EIGEN_COMP_PGI && EIGEN_COMP_PGI < 1900
 1717|       |typedef const void* SsePrefetchPtrType;
 1718|       |#else
 1719|       |typedef const char* SsePrefetchPtrType;
 1720|       |#endif
 1721|       |
 1722|       |#ifndef EIGEN_VECTORIZE_AVX
 1723|       |template <>
 1724|      0|EIGEN_STRONG_INLINE void prefetch<float>(const float* addr) {
 1725|      0|  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);
 1726|      0|}
 1727|       |template <>
 1728|      0|EIGEN_STRONG_INLINE void prefetch<double>(const double* addr) {
 1729|      0|  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);
 1730|      0|}
 1731|       |template <>
 1732|      0|EIGEN_STRONG_INLINE void prefetch<int>(const int* addr) {
 1733|      0|  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);
 1734|      0|}
 1735|       |template <>
 1736|      0|EIGEN_STRONG_INLINE void prefetch<int64_t>(const int64_t* addr) {
 1737|      0|  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);
 1738|      0|}
 1739|       |template <>
 1740|      0|EIGEN_STRONG_INLINE void prefetch<uint32_t>(const uint32_t* addr) {
 1741|      0|  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);
 1742|      0|}
 1743|       |#endif
 1744|       |
 1745|       |template <>
 1746|      0|EIGEN_STRONG_INLINE Packet4f pfrexp<Packet4f>(const Packet4f& a, Packet4f& exponent) {
 1747|      0|  return pfrexp_generic(a, exponent);
 1748|      0|}
 1749|       |
 1750|       |// Extract exponent without existence of Packet2l.
 1751|       |template <>
 1752|      0|EIGEN_STRONG_INLINE Packet2d pfrexp_generic_get_biased_exponent(const Packet2d& a) {
 1753|      0|  const Packet2d cst_exp_mask = pset1frombits<Packet2d>(static_cast<uint64_t>(0x7ff0000000000000ull));
 1754|      0|  __m128i a_expo = _mm_srli_epi64(_mm_castpd_si128(pand(a, cst_exp_mask)), 52);
 1755|      0|  return _mm_cvtepi32_pd(vec4i_swizzle1(a_expo, 0, 2, 1, 3));
 1756|      0|}
 1757|       |
 1758|       |template <>
 1759|      0|EIGEN_STRONG_INLINE Packet2d pfrexp<Packet2d>(const Packet2d& a, Packet2d& exponent) {
 1760|      0|  return pfrexp_generic(a, exponent);
 1761|      0|}
 1762|       |
 1763|       |template <>
 1764|      0|EIGEN_STRONG_INLINE Packet4f pldexp<Packet4f>(const Packet4f& a, const Packet4f& exponent) {
 1765|      0|  return pldexp_generic(a, exponent);
 1766|      0|}
 1767|       |
 1768|       |// We specialize pldexp here, since the generic implementation uses Packet2l, which is not well
 1769|       |// supported by SSE, and has more range than is needed for exponents.
 1770|       |template <>
 1771|      0|EIGEN_STRONG_INLINE Packet2d pldexp<Packet2d>(const Packet2d& a, const Packet2d& exponent) {
 1772|      0|  // Clamp exponent to [-2099, 2099]
 1773|      0|  const Packet2d max_exponent = pset1<Packet2d>(2099.0);
 1774|      0|  const Packet2d e = pmin(pmax(exponent, pnegate(max_exponent)), max_exponent);
 1775|      0|
 1776|      0|  // Convert e to integer and swizzle to low-order bits.
 1777|      0|  const Packet4i ei = vec4i_swizzle1(_mm_cvtpd_epi32(e), 0, 3, 1, 3);
 1778|      0|
 1779|      0|  // Split 2^e into four factors and multiply:
 1780|      0|  const Packet4i bias = _mm_set_epi32(0, 1023, 0, 1023);
 1781|      0|  Packet4i b = parithmetic_shift_right<2>(ei);                       // floor(e/4)
 1782|      0|  Packet2d c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));  // 2^b
 1783|      0|  Packet2d out = pmul(pmul(pmul(a, c), c), c);                       // a * 2^(3b)
 1784|      0|  b = psub(psub(psub(ei, b), b), b);                                 // e - 3b
 1785|      0|  c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));           // 2^(e - 3b)
 1786|      0|  out = pmul(out, c);                                                // a * 2^e
 1787|      0|  return out;
 1788|      0|}
 1789|       |
 1790|       |// We specialize pldexp here, since the generic implementation uses Packet2l, which is not well
 1791|       |// supported by SSE, and has more range than is needed for exponents.
 1792|       |template <>
 1793|      0|EIGEN_STRONG_INLINE Packet2d pldexp_fast<Packet2d>(const Packet2d& a, const Packet2d& exponent) {
 1794|      0|  // Clamp exponent to [-1023, 1024]
 1795|      0|  const Packet2d min_exponent = pset1<Packet2d>(-1023.0);
 1796|      0|  const Packet2d max_exponent = pset1<Packet2d>(1024.0);
 1797|      0|  const Packet2d e = pmin(pmax(exponent, min_exponent), max_exponent);
 1798|      0|
 1799|      0|  // Convert e to integer and swizzle to low-order bits.
 1800|      0|  const Packet4i ei = vec4i_swizzle1(_mm_cvtpd_epi32(e), 0, 3, 1, 3);
 1801|      0|
 1802|      0|  // Compute 2^e multiply:
 1803|      0|  const Packet4i bias = _mm_set_epi32(0, 1023, 0, 1023);
 1804|      0|  const Packet2d c = _mm_castsi128_pd(_mm_slli_epi64(padd(ei, bias), 52));  // 2^e
 1805|      0|  return pmul(a, c);
 1806|      0|}
 1807|       |
 1808|       |// with AVX, the default implementations based on pload1 are faster
 1809|       |#ifndef __AVX__
 1810|       |template <>
 1811|      0|EIGEN_STRONG_INLINE void pbroadcast4<Packet4f>(const float* a, Packet4f& a0, Packet4f& a1, Packet4f& a2, Packet4f& a3) {
 1812|      0|  a3 = pload<Packet4f>(a);
 1813|      0|  a0 = vec4f_swizzle1(a3, 0, 0, 0, 0);
 1814|      0|  a1 = vec4f_swizzle1(a3, 1, 1, 1, 1);
 1815|      0|  a2 = vec4f_swizzle1(a3, 2, 2, 2, 2);
 1816|      0|  a3 = vec4f_swizzle1(a3, 3, 3, 3, 3);
 1817|      0|}
 1818|       |template <>
 1819|       |EIGEN_STRONG_INLINE void pbroadcast4<Packet2d>(const double* a, Packet2d& a0, Packet2d& a1, Packet2d& a2,
 1820|      0|                                               Packet2d& a3) {
 1821|      0|#ifdef EIGEN_VECTORIZE_SSE3
 1822|      0|  a0 = _mm_loaddup_pd(a + 0);
 1823|      0|  a1 = _mm_loaddup_pd(a + 1);
 1824|      0|  a2 = _mm_loaddup_pd(a + 2);
 1825|      0|  a3 = _mm_loaddup_pd(a + 3);
 1826|      0|#else
 1827|      0|  a1 = pload<Packet2d>(a);
 1828|      0|  a0 = vec2d_swizzle1(a1, 0, 0);
 1829|      0|  a1 = vec2d_swizzle1(a1, 1, 1);
 1830|      0|  a3 = pload<Packet2d>(a + 2);
 1831|      0|  a2 = vec2d_swizzle1(a3, 0, 0);
 1832|      0|  a3 = vec2d_swizzle1(a3, 1, 1);
 1833|      0|#endif
 1834|      0|}
 1835|       |#endif
 1836|       |
 1837|      0|EIGEN_STRONG_INLINE void punpackp(Packet4f* vecs) {
 1838|      0|  vecs[1] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0x55));
 1839|      0|  vecs[2] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0xAA));
 1840|      0|  vecs[3] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0xFF));
 1841|      0|  vecs[0] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0x00));
 1842|      0|}
 1843|       |
 1844|       |template <>
 1845|      0|EIGEN_STRONG_INLINE float predux<Packet4f>(const Packet4f& a) {
 1846|      0|  // Disable SSE3 _mm_hadd_pd that is extremely slow on all existing Intel's architectures
 1847|      0|  // (from Nehalem to Haswell)
 1848|      0|  // #ifdef EIGEN_VECTORIZE_SSE3
 1849|      0|  //   Packet4f tmp = _mm_add_ps(a, vec4f_swizzle1(a,2,3,2,3));
 1850|      0|  //   return pfirst<Packet4f>(_mm_hadd_ps(tmp, tmp));
 1851|      0|  // #else
 1852|      0|  Packet4f tmp = _mm_add_ps(a, _mm_movehl_ps(a, a));
 1853|      0|  return pfirst<Packet4f>(_mm_add_ss(tmp, _mm_shuffle_ps(tmp, tmp, 1)));
 1854|      0|  // #endif
 1855|      0|}
 1856|       |
 1857|       |template <>
 1858|      0|EIGEN_STRONG_INLINE double predux<Packet2d>(const Packet2d& a) {
 1859|      0|  // Disable SSE3 _mm_hadd_pd that is extremely slow on all existing Intel's architectures
 1860|      0|  // (from Nehalem to Haswell)
 1861|      0|  // #ifdef EIGEN_VECTORIZE_SSE3
 1862|      0|  //   return pfirst<Packet2d>(_mm_hadd_pd(a, a));
 1863|      0|  // #else
 1864|      0|  return pfirst<Packet2d>(_mm_add_sd(a, _mm_unpackhi_pd(a, a)));
 1865|      0|  // #endif
 1866|      0|}
 1867|       |
 1868|       |template <>
 1869|      0|EIGEN_STRONG_INLINE int64_t predux<Packet2l>(const Packet2l& a) {
 1870|      0|  return pfirst<Packet2l>(_mm_add_epi64(a, _mm_unpackhi_epi64(a, a)));
 1871|      0|}
 1872|       |
 1873|       |#ifdef EIGEN_VECTORIZE_SSSE3
 1874|       |template <>
 1875|       |EIGEN_STRONG_INLINE int predux<Packet4i>(const Packet4i& a) {
 1876|       |  Packet4i tmp0 = _mm_hadd_epi32(a, a);
 1877|       |  return pfirst<Packet4i>(_mm_hadd_epi32(tmp0, tmp0));
 1878|       |}
 1879|       |template <>
 1880|       |EIGEN_STRONG_INLINE uint32_t predux<Packet4ui>(const Packet4ui& a) {
 1881|       |  Packet4ui tmp0 = _mm_hadd_epi32(a, a);
 1882|       |  return pfirst<Packet4ui>(_mm_hadd_epi32(tmp0, tmp0));
 1883|       |}
 1884|       |#else
 1885|       |template <>
 1886|      0|EIGEN_STRONG_INLINE int predux<Packet4i>(const Packet4i& a) {
 1887|      0|  Packet4i tmp = _mm_add_epi32(a, _mm_unpackhi_epi64(a, a));
 1888|      0|  return pfirst(tmp) + pfirst<Packet4i>(_mm_shuffle_epi32(tmp, 1));
 1889|      0|}
 1890|       |template <>
 1891|      0|EIGEN_STRONG_INLINE uint32_t predux<Packet4ui>(const Packet4ui& a) {
 1892|      0|  Packet4ui tmp = _mm_add_epi32(a, _mm_unpackhi_epi64(a, a));
 1893|      0|  return pfirst(tmp) + pfirst<Packet4ui>(_mm_shuffle_epi32(tmp, 1));
 1894|      0|}
 1895|       |#endif
 1896|       |
 1897|       |template <>
 1898|      0|EIGEN_STRONG_INLINE bool predux<Packet16b>(const Packet16b& a) {
 1899|      0|  Packet4i tmp = _mm_or_si128(a, _mm_unpackhi_epi64(a, a));
 1900|      0|  return (pfirst(tmp) != 0) || (pfirst<Packet4i>(_mm_shuffle_epi32(tmp, 1)) != 0);
 1901|      0|}
 1902|       |
 1903|       |// Other reduction functions:
 1904|       |
 1905|       |// mul
 1906|       |template <>
 1907|      0|EIGEN_STRONG_INLINE float predux_mul<Packet4f>(const Packet4f& a) {
 1908|      0|  Packet4f tmp = _mm_mul_ps(a, _mm_movehl_ps(a, a));
 1909|      0|  return pfirst<Packet4f>(_mm_mul_ss(tmp, _mm_shuffle_ps(tmp, tmp, 1)));
 1910|      0|}
 1911|       |template <>
 1912|      0|EIGEN_STRONG_INLINE double predux_mul<Packet2d>(const Packet2d& a) {
 1913|      0|  return pfirst<Packet2d>(_mm_mul_sd(a, _mm_unpackhi_pd(a, a)));
 1914|      0|}
 1915|       |template <>
 1916|      0|EIGEN_STRONG_INLINE int64_t predux_mul<Packet2l>(const Packet2l& a) {
 1917|      0|  EIGEN_ALIGN16 int64_t aux[2];
 1918|      0|  pstore(aux, a);
 1919|      0|  return aux[0] * aux[1];
 1920|      0|}
 1921|       |template <>
 1922|      0|EIGEN_STRONG_INLINE int predux_mul<Packet4i>(const Packet4i& a) {
 1923|      0|  // after some experiments, it is seems this is the fastest way to implement it
 1924|      0|  // for GCC (e.g., reusing pmul is very slow!)
 1925|      0|  // TODO try to call _mm_mul_epu32 directly
 1926|      0|  EIGEN_ALIGN16 int aux[4];
 1927|      0|  pstore(aux, a);
 1928|      0|  return (aux[0] * aux[1]) * (aux[2] * aux[3]);
 1929|      0|}
 1930|       |template <>
 1931|      0|EIGEN_STRONG_INLINE uint32_t predux_mul<Packet4ui>(const Packet4ui& a) {
 1932|      0|  // after some experiments, it is seems this is the fastest way to implement it
 1933|      0|  // for GCC (eg., reusing pmul is very slow !)
 1934|      0|  // TODO try to call _mm_mul_epu32 directly
 1935|      0|  EIGEN_ALIGN16 uint32_t aux[4];
 1936|      0|  pstore(aux, a);
 1937|      0|  return (aux[0] * aux[1]) * (aux[2] * aux[3]);
 1938|      0|}
 1939|       |
 1940|       |template <>
 1941|      0|EIGEN_STRONG_INLINE bool predux_mul<Packet16b>(const Packet16b& a) {
 1942|      0|  Packet4i tmp = _mm_and_si128(a, _mm_unpackhi_epi64(a, a));
 1943|      0|  return ((pfirst<Packet4i>(tmp) == 0x01010101) && (pfirst<Packet4i>(_mm_shuffle_epi32(tmp, 1)) == 0x01010101));
 1944|      0|}
 1945|       |
 1946|       |// min
 1947|       |template <>
 1948|      0|EIGEN_STRONG_INLINE float predux_min<Packet4f>(const Packet4f& a) {
 1949|      0|  Packet4f tmp = _mm_min_ps(a, _mm_movehl_ps(a, a));
 1950|      0|  return pfirst<Packet4f>(_mm_min_ss(tmp, _mm_shuffle_ps(tmp, tmp, 1)));
 1951|      0|}
 1952|       |template <>
 1953|      0|EIGEN_STRONG_INLINE double predux_min<Packet2d>(const Packet2d& a) {
 1954|      0|  return pfirst<Packet2d>(_mm_min_sd(a, _mm_unpackhi_pd(a, a)));
 1955|      0|}
 1956|       |template <>
 1957|      0|EIGEN_STRONG_INLINE int predux_min<Packet4i>(const Packet4i& a) {
 1958|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 1959|      0|  Packet4i tmp = _mm_min_epi32(a, _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 0, 3, 2)));
 1960|      0|  return pfirst<Packet4i>(_mm_min_epi32(tmp, _mm_shuffle_epi32(tmp, 1)));
 1961|      0|#else
 1962|      0|  // after some experiments, it is seems this is the fastest way to implement it
 1963|      0|  // for GCC (eg., it does not like using std::min after the pstore !!)
 1964|      0|  EIGEN_ALIGN16 int aux[4];
 1965|      0|  pstore(aux, a);
 1966|      0|  int aux0 = aux[0] < aux[1] ? aux[0] : aux[1];
 1967|      0|  int aux2 = aux[2] < aux[3] ? aux[2] : aux[3];
 1968|      0|  return aux0 < aux2 ? aux0 : aux2;
 1969|      0|#endif  // EIGEN_VECTORIZE_SSE4_1
 1970|      0|}
 1971|       |template <>
 1972|      0|EIGEN_STRONG_INLINE uint32_t predux_min<Packet4ui>(const Packet4ui& a) {
 1973|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 1974|      0|  Packet4ui tmp = _mm_min_epu32(a, _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 0, 3, 2)));
 1975|      0|  return pfirst<Packet4ui>(_mm_min_epu32(tmp, _mm_shuffle_epi32(tmp, 1)));
 1976|      0|#else
 1977|      0|  // after some experiments, it is seems this is the fastest way to implement it
 1978|      0|  // for GCC (eg., it does not like using std::min after the pstore !!)
 1979|      0|  EIGEN_ALIGN16 uint32_t aux[4];
 1980|      0|  pstore(aux, a);
 1981|      0|  uint32_t aux0 = aux[0] < aux[1] ? aux[0] : aux[1];
 1982|      0|  uint32_t aux2 = aux[2] < aux[3] ? aux[2] : aux[3];
 1983|      0|  return aux0 < aux2 ? aux0 : aux2;
 1984|      0|#endif  // EIGEN_VECTORIZE_SSE4_1
 1985|      0|}
 1986|       |
 1987|       |// max
 1988|       |template <>
 1989|      0|EIGEN_STRONG_INLINE float predux_max<Packet4f>(const Packet4f& a) {
 1990|      0|  Packet4f tmp = _mm_max_ps(a, _mm_movehl_ps(a, a));
 1991|      0|  return pfirst<Packet4f>(_mm_max_ss(tmp, _mm_shuffle_ps(tmp, tmp, 1)));
 1992|      0|}
 1993|       |template <>
 1994|      0|EIGEN_STRONG_INLINE double predux_max<Packet2d>(const Packet2d& a) {
 1995|      0|  return pfirst<Packet2d>(_mm_max_sd(a, _mm_unpackhi_pd(a, a)));
 1996|      0|}
 1997|       |template <>
 1998|      0|EIGEN_STRONG_INLINE int predux_max<Packet4i>(const Packet4i& a) {
 1999|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 2000|      0|  Packet4i tmp = _mm_max_epi32(a, _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 0, 3, 2)));
 2001|      0|  return pfirst<Packet4i>(_mm_max_epi32(tmp, _mm_shuffle_epi32(tmp, 1)));
 2002|      0|#else
 2003|      0|  // after some experiments, it is seems this is the fastest way to implement it
 2004|      0|  // for GCC (eg., it does not like using std::min after the pstore !!)
 2005|      0|  EIGEN_ALIGN16 int aux[4];
 2006|      0|  pstore(aux, a);
 2007|      0|  int aux0 = aux[0] > aux[1] ? aux[0] : aux[1];
 2008|      0|  int aux2 = aux[2] > aux[3] ? aux[2] : aux[3];
 2009|      0|  return aux0 > aux2 ? aux0 : aux2;
 2010|      0|#endif  // EIGEN_VECTORIZE_SSE4_1
 2011|      0|}
 2012|       |template <>
 2013|      0|EIGEN_STRONG_INLINE uint32_t predux_max<Packet4ui>(const Packet4ui& a) {
 2014|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
 2015|      0|  Packet4ui tmp = _mm_max_epu32(a, _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 0, 3, 2)));
 2016|      0|  return pfirst<Packet4ui>(_mm_max_epu32(tmp, _mm_shuffle_epi32(tmp, 1)));
 2017|      0|#else
 2018|      0|  // after some experiments, it is seems this is the fastest way to implement it
 2019|      0|  // for GCC (eg., it does not like using std::min after the pstore !!)
 2020|      0|  EIGEN_ALIGN16 uint32_t aux[4];
 2021|      0|  pstore(aux, a);
 2022|      0|  uint32_t aux0 = aux[0] > aux[1] ? aux[0] : aux[1];
 2023|      0|  uint32_t aux2 = aux[2] > aux[3] ? aux[2] : aux[3];
 2024|      0|  return aux0 > aux2 ? aux0 : aux2;
 2025|      0|#endif  // EIGEN_VECTORIZE_SSE4_1
 2026|      0|}
 2027|       |
 2028|       |// not needed yet
 2029|       |// template<> EIGEN_STRONG_INLINE bool predux_all(const Packet4f& x)
 2030|       |// {
 2031|       |//   return _mm_movemask_ps(x) == 0xF;
 2032|       |// }
 2033|       |
 2034|       |template <>
 2035|      0|EIGEN_STRONG_INLINE bool predux_any(const Packet2d& x) {
 2036|      0|  return _mm_movemask_pd(x) != 0x0;
 2037|      0|}
 2038|       |
 2039|       |template <>
 2040|      0|EIGEN_STRONG_INLINE bool predux_any(const Packet4f& x) {
 2041|      0|  return _mm_movemask_ps(x) != 0x0;
 2042|      0|}
 2043|       |
 2044|       |template <>
 2045|      0|EIGEN_STRONG_INLINE bool predux_any(const Packet2l& x) {
 2046|      0|  return _mm_movemask_pd(_mm_castsi128_pd(x)) != 0x0;
 2047|      0|}
 2048|       |
 2049|       |template <>
 2050|      0|EIGEN_STRONG_INLINE bool predux_any(const Packet4i& x) {
 2051|      0|  return _mm_movemask_ps(_mm_castsi128_ps(x)) != 0x0;
 2052|      0|}
 2053|       |template <>
 2054|      0|EIGEN_STRONG_INLINE bool predux_any(const Packet4ui& x) {
 2055|      0|  return _mm_movemask_ps(_mm_castsi128_ps(x)) != 0x0;
 2056|      0|}
 2057|       |
 2058|      0|EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4f, 4>& kernel) {
 2059|      0|  _MM_TRANSPOSE4_PS(kernel.packet[0], kernel.packet[1], kernel.packet[2], kernel.packet[3]);
 2060|      0|}
 2061|       |
 2062|      0|EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2d, 2>& kernel) {
 2063|      0|  __m128d tmp = _mm_unpackhi_pd(kernel.packet[0], kernel.packet[1]);
 2064|      0|  kernel.packet[0] = _mm_unpacklo_pd(kernel.packet[0], kernel.packet[1]);
 2065|      0|  kernel.packet[1] = tmp;
 2066|      0|}
 2067|       |
 2068|      0|EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2l, 2>& kernel) {
 2069|      0|  __m128i tmp = _mm_unpackhi_epi64(kernel.packet[0], kernel.packet[1]);
 2070|      0|  kernel.packet[0] = _mm_unpacklo_epi64(kernel.packet[0], kernel.packet[1]);
 2071|      0|  kernel.packet[1] = tmp;
 2072|      0|}
 2073|       |
 2074|      0|EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4i, 4>& kernel) {
 2075|      0|  __m128i T0 = _mm_unpacklo_epi32(kernel.packet[0], kernel.packet[1]);
 2076|      0|  __m128i T1 = _mm_unpacklo_epi32(kernel.packet[2], kernel.packet[3]);
 2077|      0|  __m128i T2 = _mm_unpackhi_epi32(kernel.packet[0], kernel.packet[1]);
 2078|      0|  __m128i T3 = _mm_unpackhi_epi32(kernel.packet[2], kernel.packet[3]);
 2079|      0|
 2080|      0|  kernel.packet[0] = _mm_unpacklo_epi64(T0, T1);
 2081|      0|  kernel.packet[1] = _mm_unpackhi_epi64(T0, T1);
 2082|      0|  kernel.packet[2] = _mm_unpacklo_epi64(T2, T3);
 2083|      0|  kernel.packet[3] = _mm_unpackhi_epi64(T2, T3);
 2084|      0|}
 2085|      0|EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4ui, 4>& kernel) {
 2086|      0|  ptranspose((PacketBlock<Packet4i, 4>&)kernel);
 2087|      0|}
 2088|       |
 2089|      0|EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16b, 4>& kernel) {
 2090|      0|  __m128i T0 = _mm_unpacklo_epi8(kernel.packet[0], kernel.packet[1]);
 2091|      0|  __m128i T1 = _mm_unpackhi_epi8(kernel.packet[0], kernel.packet[1]);
 2092|      0|  __m128i T2 = _mm_unpacklo_epi8(kernel.packet[2], kernel.packet[3]);
 2093|      0|  __m128i T3 = _mm_unpackhi_epi8(kernel.packet[2], kernel.packet[3]);
 2094|      0|  kernel.packet[0] = _mm_unpacklo_epi16(T0, T2);
 2095|      0|  kernel.packet[1] = _mm_unpackhi_epi16(T0, T2);
 2096|      0|  kernel.packet[2] = _mm_unpacklo_epi16(T1, T3);
 2097|      0|  kernel.packet[3] = _mm_unpackhi_epi16(T1, T3);
 2098|      0|}
 2099|       |
 2100|      0|EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16b, 16>& kernel) {
 2101|      0|  // If we number the elements in the input thus:
 2102|      0|  // kernel.packet[ 0] = {00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 0a, 0b, 0c, 0d, 0e, 0f}
 2103|      0|  // kernel.packet[ 1] = {10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 1a, 1b, 1c, 1d, 1e, 1f}
 2104|      0|  // ...
 2105|      0|  // kernel.packet[15] = {f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, fa, fb, fc, fd, fe, ff},
 2106|      0|  //
 2107|      0|  // the desired output is:
 2108|      0|  // kernel.packet[ 0] = {00, 10, 20, 30, 40, 50, 60, 70, 80, 90, a0, b0, c0, d0, e0, f0}
 2109|      0|  // kernel.packet[ 1] = {01, 11, 21, 31, 41, 51, 61, 71, 81, 91, a1, b1, c1, d1, e1, f1}
 2110|      0|  // ...
 2111|      0|  // kernel.packet[15] = {0f, 1f, 2f, 3f, 4f, 5f, 6f, 7f, 8f, 9f, af, bf, cf, df, ef, ff},
 2112|      0|  __m128i t0 =
 2113|      0|      _mm_unpacklo_epi8(kernel.packet[0], kernel.packet[1]);  // 00 10 01 11 02 12 03 13 04 14 05 15 06 16 07 17
 2114|      0|  __m128i t1 =
 2115|      0|      _mm_unpackhi_epi8(kernel.packet[0], kernel.packet[1]);  // 08 18 09 19 0a 1a 0b 1b 0c 1c 0d 1d 0e 1e 0f 1f
 2116|      0|  __m128i t2 =
 2117|      0|      _mm_unpacklo_epi8(kernel.packet[2], kernel.packet[3]);  // 20 30 21 31 22 32 ...                     27 37
 2118|      0|  __m128i t3 =
 2119|      0|      _mm_unpackhi_epi8(kernel.packet[2], kernel.packet[3]);  // 28 38 29 39 2a 3a ...                     2f 3f
 2120|      0|  __m128i t4 =
 2121|      0|      _mm_unpacklo_epi8(kernel.packet[4], kernel.packet[5]);  // 40 50 41 51 42 52                         47 57
 2122|      0|  __m128i t5 = _mm_unpackhi_epi8(kernel.packet[4], kernel.packet[5]);  // 48 58 49 59 4a 5a
 2123|      0|  __m128i t6 = _mm_unpacklo_epi8(kernel.packet[6], kernel.packet[7]);
 2124|      0|  __m128i t7 = _mm_unpackhi_epi8(kernel.packet[6], kernel.packet[7]);
 2125|      0|  __m128i t8 = _mm_unpacklo_epi8(kernel.packet[8], kernel.packet[9]);
 2126|      0|  __m128i t9 = _mm_unpackhi_epi8(kernel.packet[8], kernel.packet[9]);
 2127|      0|  __m128i ta = _mm_unpacklo_epi8(kernel.packet[10], kernel.packet[11]);
 2128|      0|  __m128i tb = _mm_unpackhi_epi8(kernel.packet[10], kernel.packet[11]);
 2129|      0|  __m128i tc = _mm_unpacklo_epi8(kernel.packet[12], kernel.packet[13]);
 2130|      0|  __m128i td = _mm_unpackhi_epi8(kernel.packet[12], kernel.packet[13]);
 2131|      0|  __m128i te = _mm_unpacklo_epi8(kernel.packet[14], kernel.packet[15]);
 2132|      0|  __m128i tf = _mm_unpackhi_epi8(kernel.packet[14], kernel.packet[15]);
 2133|      0|
 2134|      0|  __m128i s0 = _mm_unpacklo_epi16(t0, t2);  // 00 10 20 30 01 11 21 31 02 12 22 32 03 13 23 33
 2135|      0|  __m128i s1 = _mm_unpackhi_epi16(t0, t2);  // 04 14 24 34
 2136|      0|  __m128i s2 = _mm_unpacklo_epi16(t1, t3);  // 08 18 28 38 ...
 2137|      0|  __m128i s3 = _mm_unpackhi_epi16(t1, t3);  // 0c 1c 2c 3c ...
 2138|      0|  __m128i s4 = _mm_unpacklo_epi16(t4, t6);  // 40 50 60 70 41 51 61 71 42 52 62 72 43 53 63 73
 2139|      0|  __m128i s5 = _mm_unpackhi_epi16(t4, t6);  // 44 54 64 74 ...
 2140|      0|  __m128i s6 = _mm_unpacklo_epi16(t5, t7);
 2141|      0|  __m128i s7 = _mm_unpackhi_epi16(t5, t7);
 2142|      0|  __m128i s8 = _mm_unpacklo_epi16(t8, ta);
 2143|      0|  __m128i s9 = _mm_unpackhi_epi16(t8, ta);
 2144|      0|  __m128i sa = _mm_unpacklo_epi16(t9, tb);
 2145|      0|  __m128i sb = _mm_unpackhi_epi16(t9, tb);
 2146|      0|  __m128i sc = _mm_unpacklo_epi16(tc, te);
 2147|      0|  __m128i sd = _mm_unpackhi_epi16(tc, te);
 2148|      0|  __m128i se = _mm_unpacklo_epi16(td, tf);
 2149|      0|  __m128i sf = _mm_unpackhi_epi16(td, tf);
 2150|      0|
 2151|      0|  __m128i u0 = _mm_unpacklo_epi32(s0, s4);  // 00 10 20 30 40 50 60 70 01 11 21 31 41 51 61 71
 2152|      0|  __m128i u1 = _mm_unpackhi_epi32(s0, s4);  // 02 12 22 32 42 52 62 72 03 13 23 33 43 53 63 73
 2153|      0|  __m128i u2 = _mm_unpacklo_epi32(s1, s5);
 2154|      0|  __m128i u3 = _mm_unpackhi_epi32(s1, s5);
 2155|      0|  __m128i u4 = _mm_unpacklo_epi32(s2, s6);
 2156|      0|  __m128i u5 = _mm_unpackhi_epi32(s2, s6);
 2157|      0|  __m128i u6 = _mm_unpacklo_epi32(s3, s7);
 2158|      0|  __m128i u7 = _mm_unpackhi_epi32(s3, s7);
 2159|      0|  __m128i u8 = _mm_unpacklo_epi32(s8, sc);
 2160|      0|  __m128i u9 = _mm_unpackhi_epi32(s8, sc);
 2161|      0|  __m128i ua = _mm_unpacklo_epi32(s9, sd);
 2162|      0|  __m128i ub = _mm_unpackhi_epi32(s9, sd);
 2163|      0|  __m128i uc = _mm_unpacklo_epi32(sa, se);
 2164|      0|  __m128i ud = _mm_unpackhi_epi32(sa, se);
 2165|      0|  __m128i ue = _mm_unpacklo_epi32(sb, sf);
 2166|      0|  __m128i uf = _mm_unpackhi_epi32(sb, sf);
 2167|      0|
 2168|      0|  kernel.packet[0] = _mm_unpacklo_epi64(u0, u8);
 2169|      0|  kernel.packet[1] = _mm_unpackhi_epi64(u0, u8);
 2170|      0|  kernel.packet[2] = _mm_unpacklo_epi64(u1, u9);
 2171|      0|  kernel.packet[3] = _mm_unpackhi_epi64(u1, u9);
 2172|      0|  kernel.packet[4] = _mm_unpacklo_epi64(u2, ua);
 2173|      0|  kernel.packet[5] = _mm_unpackhi_epi64(u2, ua);
 2174|      0|  kernel.packet[6] = _mm_unpacklo_epi64(u3, ub);
 2175|      0|  kernel.packet[7] = _mm_unpackhi_epi64(u3, ub);
 2176|      0|  kernel.packet[8] = _mm_unpacklo_epi64(u4, uc);
 2177|      0|  kernel.packet[9] = _mm_unpackhi_epi64(u4, uc);
 2178|      0|  kernel.packet[10] = _mm_unpacklo_epi64(u5, ud);
 2179|      0|  kernel.packet[11] = _mm_unpackhi_epi64(u5, ud);
 2180|      0|  kernel.packet[12] = _mm_unpacklo_epi64(u6, ue);
 2181|      0|  kernel.packet[13] = _mm_unpackhi_epi64(u6, ue);
 2182|      0|  kernel.packet[14] = _mm_unpacklo_epi64(u7, uf);
 2183|      0|  kernel.packet[15] = _mm_unpackhi_epi64(u7, uf);
 2184|      0|}
 2185|       |
 2186|      0|EIGEN_STRONG_INLINE __m128i sse_blend_mask(const Selector<2>& ifPacket) {
 2187|      0|  return _mm_set_epi64x(0 - ifPacket.select[1], 0 - ifPacket.select[0]);
 2188|      0|}
 2189|       |
 2190|      0|EIGEN_STRONG_INLINE __m128i sse_blend_mask(const Selector<4>& ifPacket) {
 2191|      0|  return _mm_set_epi32(0 - ifPacket.select[3], 0 - ifPacket.select[2], 0 - ifPacket.select[1], 0 - ifPacket.select[0]);
 2192|      0|}
 2193|       |
 2194|       |template <>
 2195|       |EIGEN_STRONG_INLINE Packet2l pblend(const Selector<2>& ifPacket, const Packet2l& thenPacket,
 2196|      0|                                    const Packet2l& elsePacket) {
 2197|      0|  const __m128i true_mask = sse_blend_mask(ifPacket);
 2198|      0|  return pselect<Packet2l>(true_mask, thenPacket, elsePacket);
 2199|      0|}
 2200|       |template <>
 2201|       |EIGEN_STRONG_INLINE Packet4i pblend(const Selector<4>& ifPacket, const Packet4i& thenPacket,
 2202|      0|                                    const Packet4i& elsePacket) {
 2203|      0|  const __m128i true_mask = sse_blend_mask(ifPacket);
 2204|      0|  return pselect<Packet4i>(true_mask, thenPacket, elsePacket);
 2205|      0|}
 2206|       |template <>
 2207|       |EIGEN_STRONG_INLINE Packet4ui pblend(const Selector<4>& ifPacket, const Packet4ui& thenPacket,
 2208|      0|                                     const Packet4ui& elsePacket) {
 2209|      0|  return (Packet4ui)pblend(ifPacket, (Packet4i)thenPacket, (Packet4i)elsePacket);
 2210|      0|}
 2211|       |template <>
 2212|       |EIGEN_STRONG_INLINE Packet4f pblend(const Selector<4>& ifPacket, const Packet4f& thenPacket,
 2213|      0|                                    const Packet4f& elsePacket) {
 2214|      0|  const __m128i true_mask = sse_blend_mask(ifPacket);
 2215|      0|  return pselect<Packet4f>(_mm_castsi128_ps(true_mask), thenPacket, elsePacket);
 2216|      0|}
 2217|       |template <>
 2218|       |EIGEN_STRONG_INLINE Packet2d pblend(const Selector<2>& ifPacket, const Packet2d& thenPacket,
 2219|      0|                                    const Packet2d& elsePacket) {
 2220|      0|  const __m128i true_mask = sse_blend_mask(ifPacket);
 2221|      0|  return pselect<Packet2d>(_mm_castsi128_pd(true_mask), thenPacket, elsePacket);
 2222|      0|}
 2223|       |
 2224|       |// Scalar path for pmadd with FMA to ensure consistency with vectorized path.
 2225|       |#ifdef EIGEN_VECTORIZE_FMA
 2226|       |template <>
 2227|       |EIGEN_STRONG_INLINE float pmadd(const float& a, const float& b, const float& c) {
 2228|       |  return ::fmaf(a, b, c);
 2229|       |}
 2230|       |template <>
 2231|       |EIGEN_STRONG_INLINE double pmadd(const double& a, const double& b, const double& c) {
 2232|       |  return ::fma(a, b, c);
 2233|       |}
 2234|       |template <>
 2235|       |EIGEN_STRONG_INLINE float pmsub(const float& a, const float& b, const float& c) {
 2236|       |  return ::fmaf(a, b, -c);
 2237|       |}
 2238|       |template <>
 2239|       |EIGEN_STRONG_INLINE double pmsub(const double& a, const double& b, const double& c) {
 2240|       |  return ::fma(a, b, -c);
 2241|       |}
 2242|       |template <>
 2243|       |EIGEN_STRONG_INLINE float pnmadd(const float& a, const float& b, const float& c) {
 2244|       |  return ::fmaf(-a, b, c);
 2245|       |}
 2246|       |template <>
 2247|       |EIGEN_STRONG_INLINE double pnmadd(const double& a, const double& b, const double& c) {
 2248|       |  return ::fma(-a, b, c);
 2249|       |}
 2250|       |template <>
 2251|       |EIGEN_STRONG_INLINE float pnmsub(const float& a, const float& b, const float& c) {
 2252|       |  return ::fmaf(-a, b, -c);
 2253|       |}
 2254|       |template <>
 2255|       |EIGEN_STRONG_INLINE double pnmsub(const double& a, const double& b, const double& c) {
 2256|       |  return ::fma(-a, b, -c);
 2257|       |}
 2258|       |#endif
 2259|       |
 2260|       |#ifdef EIGEN_VECTORIZE_SSE4_1
 2261|       |// Helpers for half->float and float->half conversions.
 2262|       |// Currently only used by the AVX code.
 2263|       |EIGEN_STRONG_INLINE __m128i half2floatsse(__m128i h) {
 2264|       |  __m128i input = _mm_cvtepu16_epi32(h);
 2265|       |
 2266|       |  // Direct vectorization of half_to_float, C parts in the comments.
 2267|       |  __m128i shifted_exp = _mm_set1_epi32(0x7c00 << 13);
 2268|       |  // o.u = (h.x & 0x7fff) << 13; // exponent/mantissa bits
 2269|       |  __m128i ou = _mm_slli_epi32(_mm_and_si128(input, _mm_set1_epi32(0x7fff)), 13);
 2270|       |  // exp = shifted_exp & o.u;   // just the exponent
 2271|       |  __m128i exp = _mm_and_si128(ou, shifted_exp);
 2272|       |  // o.u += (127 - 15) << 23;
 2273|       |  ou = _mm_add_epi32(ou, _mm_set1_epi32((127 - 15) << 23));
 2274|       |
 2275|       |  // Inf/NaN?
 2276|       |  __m128i naninf_mask = _mm_cmpeq_epi32(exp, shifted_exp);
 2277|       |  // Inf/NaN adjust
 2278|       |  __m128i naninf_adj = _mm_and_si128(_mm_set1_epi32((128 - 16) << 23), naninf_mask);
 2279|       |  // extra exp adjust for  Inf/NaN
 2280|       |  ou = _mm_add_epi32(ou, naninf_adj);
 2281|       |
 2282|       |  // Zero/Denormal?
 2283|       |  __m128i zeroden_mask = _mm_cmpeq_epi32(exp, _mm_setzero_si128());
 2284|       |  __m128i zeroden_adj = _mm_and_si128(zeroden_mask, _mm_set1_epi32(1 << 23));
 2285|       |  // o.u += 1 << 23;
 2286|       |  ou = _mm_add_epi32(ou, zeroden_adj);
 2287|       |  // magic.u = 113 << 23
 2288|       |  __m128i magic = _mm_and_si128(zeroden_mask, _mm_set1_epi32(113 << 23));
 2289|       |  // o.f -= magic.f
 2290|       |  ou = _mm_castps_si128(_mm_sub_ps(_mm_castsi128_ps(ou), _mm_castsi128_ps(magic)));
 2291|       |
 2292|       |  __m128i sign = _mm_slli_epi32(_mm_and_si128(input, _mm_set1_epi32(0x8000)), 16);
 2293|       |  // o.u |= (h.x & 0x8000) << 16;    // sign bit
 2294|       |  ou = _mm_or_si128(ou, sign);
 2295|       |  // return o.f;
 2296|       |  // We are actually returning uint version, to make
 2297|       |  // _mm256_insertf128_si256 work.
 2298|       |  return ou;
 2299|       |}
 2300|       |
 2301|       |EIGEN_STRONG_INLINE __m128i float2half(__m128 f) {
 2302|       |  // unsigned int sign_mask = 0x80000000u;
 2303|       |  __m128i sign = _mm_set1_epi32(0x80000000u);
 2304|       |  // unsigned int sign = f.u & sign_mask;
 2305|       |  sign = _mm_and_si128(sign, _mm_castps_si128(f));
 2306|       |  // f.u ^= sign;
 2307|       |  f = _mm_xor_ps(f, _mm_castsi128_ps(sign));
 2308|       |
 2309|       |  __m128i fu = _mm_castps_si128(f);
 2310|       |
 2311|       |  __m128i f16max = _mm_set1_epi32((127 + 16) << 23);
 2312|       |  __m128i f32infty = _mm_set1_epi32(255 << 23);
 2313|       |  // if (f.u >= f16max.u) // result is Inf or NaN (all exponent bits set)
 2314|       |  // there is no _mm_cmpge_epi32, so use lt and swap operands
 2315|       |  __m128i infnan_mask = _mm_cmplt_epi32(f16max, _mm_castps_si128(f));
 2316|       |  __m128i inf_mask = _mm_cmpgt_epi32(_mm_castps_si128(f), f32infty);
 2317|       |  __m128i nan_mask = _mm_andnot_si128(inf_mask, infnan_mask);
 2318|       |  __m128i inf_value = _mm_and_si128(inf_mask, _mm_set1_epi32(0x7e00));
 2319|       |  __m128i nan_value = _mm_and_si128(nan_mask, _mm_set1_epi32(0x7c00));
 2320|       |  // o.x = (f.u > f32infty.u) ? 0x7e00 : 0x7c00; // NaN->qNaN and Inf->Inf
 2321|       |  __m128i naninf_value = _mm_or_si128(inf_value, nan_value);
 2322|       |
 2323|       |  __m128i denorm_magic = _mm_set1_epi32(((127 - 15) + (23 - 10) + 1) << 23);
 2324|       |  __m128i subnorm_mask = _mm_cmplt_epi32(_mm_castps_si128(f), _mm_set1_epi32(113 << 23));
 2325|       |  //  f.f += denorm_magic.f;
 2326|       |  f = _mm_add_ps(f, _mm_castsi128_ps(denorm_magic));
 2327|       |  // f.u - denorm_magic.u
 2328|       |  __m128i o = _mm_sub_epi32(_mm_castps_si128(f), denorm_magic);
 2329|       |  o = _mm_and_si128(o, subnorm_mask);
 2330|       |  // Correct result for inf/nan/zero/subnormal, 0 otherwise
 2331|       |  o = _mm_or_si128(o, naninf_value);
 2332|       |
 2333|       |  __m128i mask = _mm_or_si128(infnan_mask, subnorm_mask);
 2334|       |  o = _mm_and_si128(o, mask);
 2335|       |
 2336|       |  // mant_odd = (f.u >> 13) & 1;
 2337|       |  __m128i mand_odd = _mm_and_si128(_mm_srli_epi32(fu, 13), _mm_set1_epi32(0x1));
 2338|       |  // f.u += 0xc8000fffU;
 2339|       |  fu = _mm_add_epi32(fu, _mm_set1_epi32(0xc8000fffU));
 2340|       |  // f.u += mant_odd;
 2341|       |  fu = _mm_add_epi32(fu, mand_odd);
 2342|       |  fu = _mm_andnot_si128(mask, fu);
 2343|       |  // f.u >> 13
 2344|       |  fu = _mm_srli_epi32(fu, 13);
 2345|       |  o = _mm_or_si128(fu, o);
 2346|       |
 2347|       |  // o.x |= static_cast<numext::uint16_t>(sign >> 16);
 2348|       |  o = _mm_or_si128(o, _mm_srli_epi32(sign, 16));
 2349|       |
 2350|       |  // 16 bit values
 2351|       |  return _mm_and_si128(o, _mm_set1_epi32(0xffff));
 2352|       |}
 2353|       |#endif
 2354|       |
 2355|       |// Packet math for Eigen::half
 2356|       |// Disable the following code since it's broken on too many platforms / compilers.
 2357|       |// #elif defined(EIGEN_VECTORIZE_SSE) && (!EIGEN_ARCH_x86_64) && (!EIGEN_COMP_MSVC)
 2358|       |#if 0
 2359|       |
 2360|       |typedef struct {
 2361|       |  __m64 x;
 2362|       |} Packet4h;
 2363|       |
 2364|       |
 2365|       |template<> struct is_arithmetic<Packet4h> { enum { value = true }; };
 2366|       |
 2367|       |template <>
 2368|       |struct packet_traits<Eigen::half> : default_packet_traits {
 2369|       |  typedef Packet4h type;
 2370|       |  // There is no half-size packet for Packet4h.
 2371|       |  typedef Packet4h half;
 2372|       |  enum {
 2373|       |    Vectorizable = 1,
 2374|       |    AlignedOnScalar = 1,
 2375|       |    size = 4,
 2376|       |    HasAdd    = 1,
 2377|       |    HasSub    = 1,
 2378|       |    HasMul    = 1,
 2379|       |    HasDiv    = 1,
 2380|       |    HasNegate = 0,
 2381|       |    HasAbs    = 0,
 2382|       |    HasAbs2   = 0,
 2383|       |    HasMin    = 0,
 2384|       |    HasMax    = 0,
 2385|       |    HasConj   = 0,
 2386|       |    HasSetLinear = 0,
 2387|       |  };
 2388|       |};
 2389|       |
 2390|       |
 2391|       |template<> struct unpacket_traits<Packet4h> { typedef Eigen::half type; enum {size=4, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet4h half; };
 2392|       |
 2393|       |template<> EIGEN_STRONG_INLINE Packet4h pset1<Packet4h>(const Eigen::half& from) {
 2394|       |  Packet4h result;
 2395|       |  result.x = _mm_set1_pi16(from.x);
 2396|       |  return result;
 2397|       |}
 2398|       |
 2399|       |template<> EIGEN_STRONG_INLINE Eigen::half pfirst<Packet4h>(const Packet4h& from) {
 2400|       |  return half_impl::raw_uint16_to_half(static_cast<unsigned short>(_mm_cvtsi64_si32(from.x)));
 2401|       |}
 2402|       |
 2403|       |template<> EIGEN_STRONG_INLINE Packet4h pconj(const Packet4h& a) { return a; }
 2404|       |
 2405|       |template<> EIGEN_STRONG_INLINE Packet4h padd<Packet4h>(const Packet4h& a, const Packet4h& b) {
 2406|       |  __int64_t a64 = _mm_cvtm64_si64(a.x);
 2407|       |  __int64_t b64 = _mm_cvtm64_si64(b.x);
 2408|       |
 2409|       |  Eigen::half h[4];
 2410|       |
 2411|       |  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
 2412|       |  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
 2413|       |  h[0] = ha + hb;
 2414|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
 2415|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
 2416|       |  h[1] = ha + hb;
 2417|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
 2418|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
 2419|       |  h[2] = ha + hb;
 2420|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
 2421|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
 2422|       |  h[3] = ha + hb;
 2423|       |  Packet4h result;
 2424|       |  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
 2425|       |  return result;
 2426|       |}
 2427|       |
 2428|       |template<> EIGEN_STRONG_INLINE Packet4h psub<Packet4h>(const Packet4h& a, const Packet4h& b) {
 2429|       |  __int64_t a64 = _mm_cvtm64_si64(a.x);
 2430|       |  __int64_t b64 = _mm_cvtm64_si64(b.x);
 2431|       |
 2432|       |  Eigen::half h[4];
 2433|       |
 2434|       |  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
 2435|       |  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
 2436|       |  h[0] = ha - hb;
 2437|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
 2438|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
 2439|       |  h[1] = ha - hb;
 2440|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
 2441|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
 2442|       |  h[2] = ha - hb;
 2443|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
 2444|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
 2445|       |  h[3] = ha - hb;
 2446|       |  Packet4h result;
 2447|       |  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
 2448|       |  return result;
 2449|       |}
 2450|       |
 2451|       |template<> EIGEN_STRONG_INLINE Packet4h pmul<Packet4h>(const Packet4h& a, const Packet4h& b) {
 2452|       |  __int64_t a64 = _mm_cvtm64_si64(a.x);
 2453|       |  __int64_t b64 = _mm_cvtm64_si64(b.x);
 2454|       |
 2455|       |  Eigen::half h[4];
 2456|       |
 2457|       |  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
 2458|       |  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
 2459|       |  h[0] = ha * hb;
 2460|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
 2461|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
 2462|       |  h[1] = ha * hb;
 2463|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
 2464|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
 2465|       |  h[2] = ha * hb;
 2466|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
 2467|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
 2468|       |  h[3] = ha * hb;
 2469|       |  Packet4h result;
 2470|       |  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
 2471|       |  return result;
 2472|       |}
 2473|       |
 2474|       |template<> EIGEN_STRONG_INLINE Packet4h pdiv<Packet4h>(const Packet4h& a, const Packet4h& b) {
 2475|       |  __int64_t a64 = _mm_cvtm64_si64(a.x);
 2476|       |  __int64_t b64 = _mm_cvtm64_si64(b.x);
 2477|       |
 2478|       |  Eigen::half h[4];
 2479|       |
 2480|       |  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
 2481|       |  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
 2482|       |  h[0] = ha / hb;
 2483|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
 2484|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
 2485|       |  h[1] = ha / hb;
 2486|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
 2487|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
 2488|       |  h[2] = ha / hb;
 2489|       |  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
 2490|       |  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
 2491|       |  h[3] = ha / hb;
 2492|       |  Packet4h result;
 2493|       |  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
 2494|       |  return result;
 2495|       |}
 2496|       |
 2497|       |template<> EIGEN_STRONG_INLINE Packet4h pload<Packet4h>(const Eigen::half* from) {
 2498|       |  Packet4h result;
 2499|       |  result.x = _mm_cvtsi64_m64(*reinterpret_cast<const __int64_t*>(from));
 2500|       |  return result;
 2501|       |}
 2502|       |
 2503|       |template<> EIGEN_STRONG_INLINE Packet4h ploadu<Packet4h>(const Eigen::half* from) {
 2504|       |  Packet4h result;
 2505|       |  result.x = _mm_cvtsi64_m64(*reinterpret_cast<const __int64_t*>(from));
 2506|       |  return result;
 2507|       |}
 2508|       |
 2509|       |template<> EIGEN_STRONG_INLINE void pstore<Eigen::half>(Eigen::half* to, const Packet4h& from) {
 2510|       |  __int64_t r = _mm_cvtm64_si64(from.x);
 2511|       |  *(reinterpret_cast<__int64_t*>(to)) = r;
 2512|       |}
 2513|       |
 2514|       |template<> EIGEN_STRONG_INLINE void pstoreu<Eigen::half>(Eigen::half* to, const Packet4h& from) {
 2515|       |  __int64_t r = _mm_cvtm64_si64(from.x);
 2516|       |  *(reinterpret_cast<__int64_t*>(to)) = r;
 2517|       |}
 2518|       |
 2519|       |template<> EIGEN_STRONG_INLINE Packet4h
 2520|       |ploadquad<Packet4h>(const Eigen::half* from) {
 2521|       |  return pset1<Packet4h>(*from);
 2522|       |}
 2523|       |
 2524|       |template<> EIGEN_STRONG_INLINE Packet4h pgather<Eigen::half, Packet4h>(const Eigen::half* from, Index stride)
 2525|       |{
 2526|       |  Packet4h result;
 2527|       |  result.x = _mm_set_pi16(from[3*stride].x, from[2*stride].x, from[1*stride].x, from[0*stride].x);
 2528|       |  return result;
 2529|       |}
 2530|       |
 2531|       |template<> EIGEN_STRONG_INLINE void pscatter<Eigen::half, Packet4h>(Eigen::half* to, const Packet4h& from, Index stride)
 2532|       |{
 2533|       |  __int64_t a = _mm_cvtm64_si64(from.x);
 2534|       |  to[stride*0].x = static_cast<unsigned short>(a);
 2535|       |  to[stride*1].x = static_cast<unsigned short>(a >> 16);
 2536|       |  to[stride*2].x = static_cast<unsigned short>(a >> 32);
 2537|       |  to[stride*3].x = static_cast<unsigned short>(a >> 48);
 2538|       |}
 2539|       |
 2540|       |EIGEN_STRONG_INLINE void
 2541|       |ptranspose(PacketBlock<Packet4h,4>& kernel) {
 2542|       |  __m64 T0 = _mm_unpacklo_pi16(kernel.packet[0].x, kernel.packet[1].x);
 2543|       |  __m64 T1 = _mm_unpacklo_pi16(kernel.packet[2].x, kernel.packet[3].x);
 2544|       |  __m64 T2 = _mm_unpackhi_pi16(kernel.packet[0].x, kernel.packet[1].x);
 2545|       |  __m64 T3 = _mm_unpackhi_pi16(kernel.packet[2].x, kernel.packet[3].x);
 2546|       |
 2547|       |  kernel.packet[0].x = _mm_unpacklo_pi32(T0, T1);
 2548|       |  kernel.packet[1].x = _mm_unpackhi_pi32(T0, T1);
 2549|       |  kernel.packet[2].x = _mm_unpacklo_pi32(T2, T3);
 2550|       |  kernel.packet[3].x = _mm_unpackhi_pi32(T2, T3);
 2551|       |}
 2552|       |
 2553|       |#endif
 2554|       |
 2555|       |}  // end namespace internal
 2556|       |
 2557|       |}  // end namespace Eigen
 2558|       |
 2559|       |#if EIGEN_COMP_PGI && EIGEN_COMP_PGI < 1900
 2560|       |// PGI++ does not define the following intrinsics in C++ mode.
 2561|       |static inline __m128 _mm_castpd_ps(__m128d x) { return reinterpret_cast<__m128&>(x); }
 2562|       |static inline __m128i _mm_castpd_si128(__m128d x) { return reinterpret_cast<__m128i&>(x); }
 2563|       |static inline __m128d _mm_castps_pd(__m128 x) { return reinterpret_cast<__m128d&>(x); }
 2564|       |static inline __m128i _mm_castps_si128(__m128 x) { return reinterpret_cast<__m128i&>(x); }
 2565|       |static inline __m128 _mm_castsi128_ps(__m128i x) { return reinterpret_cast<__m128&>(x); }
 2566|       |static inline __m128d _mm_castsi128_pd(__m128i x) { return reinterpret_cast<__m128d&>(x); }
 2567|       |#endif
 2568|       |
 2569|       |#endif  // EIGEN_PACKET_MATH_SSE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2015 Benoit Steiner <benoit.steiner.goog@gmail.com>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_TYPE_CASTING_SSE_H
   11|       |#define EIGEN_TYPE_CASTING_SSE_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |#ifndef EIGEN_VECTORIZE_AVX
   21|       |template <>
   22|       |struct type_casting_traits<float, bool> : vectorized_type_casting_traits<float, bool> {};
   23|       |template <>
   24|       |struct type_casting_traits<bool, float> : vectorized_type_casting_traits<bool, float> {};
   25|       |
   26|       |template <>
   27|       |struct type_casting_traits<float, int> : vectorized_type_casting_traits<float, int> {};
   28|       |template <>
   29|       |struct type_casting_traits<int, float> : vectorized_type_casting_traits<int, float> {};
   30|       |
   31|       |template <>
   32|       |struct type_casting_traits<float, double> : vectorized_type_casting_traits<float, double> {};
   33|       |template <>
   34|       |struct type_casting_traits<double, float> : vectorized_type_casting_traits<double, float> {};
   35|       |
   36|       |template <>
   37|       |struct type_casting_traits<double, int> : vectorized_type_casting_traits<double, int> {};
   38|       |template <>
   39|       |struct type_casting_traits<int, double> : vectorized_type_casting_traits<int, double> {};
   40|       |
   41|       |#ifndef EIGEN_VECTORIZE_AVX2
   42|       |template <>
   43|       |struct type_casting_traits<double, int64_t> : vectorized_type_casting_traits<double, int64_t> {};
   44|       |template <>
   45|       |struct type_casting_traits<int64_t, double> : vectorized_type_casting_traits<int64_t, double> {};
   46|       |#endif
   47|       |#endif
   48|       |
   49|       |template <>
   50|       |EIGEN_STRONG_INLINE Packet16b pcast<Packet4f, Packet16b>(const Packet4f& a, const Packet4f& b, const Packet4f& c,
   51|      0|                                                         const Packet4f& d) {
   52|      0|  __m128 zero = pzero(a);
   53|      0|  __m128 nonzero_a = _mm_cmpneq_ps(a, zero);
   54|      0|  __m128 nonzero_b = _mm_cmpneq_ps(b, zero);
   55|      0|  __m128 nonzero_c = _mm_cmpneq_ps(c, zero);
   56|      0|  __m128 nonzero_d = _mm_cmpneq_ps(d, zero);
   57|      0|  __m128i ab_bytes = _mm_packs_epi32(_mm_castps_si128(nonzero_a), _mm_castps_si128(nonzero_b));
   58|      0|  __m128i cd_bytes = _mm_packs_epi32(_mm_castps_si128(nonzero_c), _mm_castps_si128(nonzero_d));
   59|      0|  __m128i merged = _mm_packs_epi16(ab_bytes, cd_bytes);
   60|      0|  return _mm_and_si128(merged, _mm_set1_epi8(1));
   61|      0|}
   62|       |
   63|       |template <>
   64|      0|EIGEN_STRONG_INLINE Packet4f pcast<Packet16b, Packet4f>(const Packet16b& a) {
   65|      0|  const __m128 cst_one = _mm_set_ps1(1.0f);
   66|      0|#ifdef EIGEN_VECTORIZE_SSE4_1
   67|      0|  __m128i a_extended = _mm_cvtepi8_epi32(a);
   68|      0|  __m128i abcd = _mm_cmpeq_epi32(a_extended, _mm_setzero_si128());
   69|      0|#else
   70|      0|  __m128i abcd_efhg_ijkl_mnop = _mm_cmpeq_epi8(a, _mm_setzero_si128());
   71|      0|  __m128i aabb_ccdd_eeff_gghh = _mm_unpacklo_epi8(abcd_efhg_ijkl_mnop, abcd_efhg_ijkl_mnop);
   72|      0|  __m128i abcd = _mm_unpacklo_epi8(aabb_ccdd_eeff_gghh, aabb_ccdd_eeff_gghh);
   73|      0|#endif
   74|      0|  __m128 result = _mm_andnot_ps(_mm_castsi128_ps(abcd), cst_one);
   75|      0|  return result;
   76|      0|}
   77|       |
   78|       |template <>
   79|      0|EIGEN_STRONG_INLINE Packet4i pcast<Packet4f, Packet4i>(const Packet4f& a) {
   80|      0|  return _mm_cvttps_epi32(a);
   81|      0|}
   82|       |
   83|       |template <>
   84|      0|EIGEN_STRONG_INLINE Packet4i pcast<Packet2d, Packet4i>(const Packet2d& a, const Packet2d& b) {
   85|      0|  return _mm_castps_si128(_mm_shuffle_ps(_mm_castsi128_ps(_mm_cvttpd_epi32(a)), _mm_castsi128_ps(_mm_cvttpd_epi32(b)),
   86|      0|                                         (1 << 2) | (1 << 6)));
   87|      0|}
   88|       |
   89|       |template <>
   90|      0|EIGEN_STRONG_INLINE Packet2l pcast<Packet2d, Packet2l>(const Packet2d& a) {
   91|      0|#if EIGEN_ARCH_x86_64
   92|      0|  return _mm_set_epi64x(_mm_cvttsd_si64(preverse(a)), _mm_cvttsd_si64(a));
   93|      0|#else
   94|      0|  return _mm_set_epi64x(static_cast<int64_t>(pfirst(preverse(a))), static_cast<int64_t>(pfirst(a)));
   95|      0|#endif
   96|      0|}
   97|       |
   98|       |template <>
   99|      0|EIGEN_STRONG_INLINE Packet2d pcast<Packet2l, Packet2d>(const Packet2l& a) {
  100|      0|  EIGEN_ALIGN16 int64_t aux[2];
  101|      0|  pstore(aux, a);
  102|      0|  return _mm_set_pd(static_cast<double>(aux[1]), static_cast<double>(aux[0]));
  103|      0|}
  104|       |
  105|       |template <>
  106|      0|EIGEN_STRONG_INLINE Packet4f pcast<Packet4i, Packet4f>(const Packet4i& a) {
  107|      0|  return _mm_cvtepi32_ps(a);
  108|      0|}
  109|       |
  110|       |template <>
  111|      0|EIGEN_STRONG_INLINE Packet4f pcast<Packet2d, Packet4f>(const Packet2d& a, const Packet2d& b) {
  112|      0|  return _mm_shuffle_ps(_mm_cvtpd_ps(a), _mm_cvtpd_ps(b), (1 << 2) | (1 << 6));
  113|      0|}
  114|       |
  115|       |template <>
  116|      0|EIGEN_STRONG_INLINE Packet2d pcast<Packet4i, Packet2d>(const Packet4i& a) {
  117|      0|  // Simply discard the second half of the input
  118|      0|  return _mm_cvtepi32_pd(a);
  119|      0|}
  120|       |
  121|       |template <>
  122|      0|EIGEN_STRONG_INLINE Packet2d pcast<Packet4f, Packet2d>(const Packet4f& a) {
  123|      0|  // Simply discard the second half of the input
  124|      0|  return _mm_cvtps_pd(a);
  125|      0|}
  126|       |
  127|       |template <>
  128|      0|EIGEN_STRONG_INLINE Packet2d preinterpret<Packet2d, Packet4f>(const Packet4f& a) {
  129|      0|  return _mm_castps_pd(a);
  130|      0|}
  131|       |
  132|       |template <>
  133|      0|EIGEN_STRONG_INLINE Packet4f preinterpret<Packet4f, Packet2d>(const Packet2d& a) {
  134|      0|  return _mm_castpd_ps(a);
  135|      0|}
  136|       |
  137|       |template <>
  138|      0|EIGEN_STRONG_INLINE Packet4i preinterpret<Packet4i, Packet4f>(const Packet4f& a) {
  139|      0|  return _mm_castps_si128(a);
  140|      0|}
  141|       |
  142|       |template <>
  143|      0|EIGEN_STRONG_INLINE Packet4f preinterpret<Packet4f, Packet4i>(const Packet4i& a) {
  144|      0|  return _mm_castsi128_ps(a);
  145|      0|}
  146|       |
  147|       |template <>
  148|      0|EIGEN_STRONG_INLINE Packet2d preinterpret<Packet2d, Packet4i>(const Packet4i& a) {
  149|      0|  return _mm_castsi128_pd(a);
  150|      0|}
  151|       |
  152|       |template <>
  153|      0|EIGEN_STRONG_INLINE Packet2d preinterpret<Packet2d, Packet2l>(const Packet2l& a) {
  154|      0|  return _mm_castsi128_pd(a);
  155|      0|}
  156|       |template <>
  157|      0|EIGEN_STRONG_INLINE Packet2l preinterpret<Packet2l, Packet2d>(const Packet2d& a) {
  158|      0|  return _mm_castpd_si128(a);
  159|      0|}
  160|       |
  161|       |template <>
  162|      0|EIGEN_STRONG_INLINE Packet4i preinterpret<Packet4i, Packet2d>(const Packet2d& a) {
  163|      0|  return _mm_castpd_si128(a);
  164|      0|}
  165|       |
  166|       |template <>
  167|      0|EIGEN_STRONG_INLINE Packet4ui preinterpret<Packet4ui, Packet4i>(const Packet4i& a) {
  168|      0|  return Packet4ui(a);
  169|      0|}
  170|       |
  171|       |template <>
  172|      0|EIGEN_STRONG_INLINE Packet4i preinterpret<Packet4i, Packet4ui>(const Packet4ui& a) {
  173|      0|  return Packet4i(a);
  174|      0|}
  175|       |
  176|       |// Disable the following code since it's broken on too many platforms / compilers.
  177|       |// #elif defined(EIGEN_VECTORIZE_SSE) && (!EIGEN_ARCH_x86_64) && (!EIGEN_COMP_MSVC)
  178|       |#if 0
  179|       |
  180|       |template <>
  181|       |struct type_casting_traits<Eigen::half, float> {
  182|       |  enum {
  183|       |    VectorizedCast = 1,
  184|       |    SrcCoeffRatio = 1,
  185|       |    TgtCoeffRatio = 1
  186|       |  };
  187|       |};
  188|       |
  189|       |template<> EIGEN_STRONG_INLINE Packet4f pcast<Packet4h, Packet4f>(const Packet4h& a) {
  190|       |  __int64_t a64 = _mm_cvtm64_si64(a.x);
  191|       |  Eigen::half h = raw_uint16_to_half(static_cast<unsigned short>(a64));
  192|       |  float f1 = static_cast<float>(h);
  193|       |  h = raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
  194|       |  float f2 = static_cast<float>(h);
  195|       |  h = raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
  196|       |  float f3 = static_cast<float>(h);
  197|       |  h = raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
  198|       |  float f4 = static_cast<float>(h);
  199|       |  return _mm_set_ps(f4, f3, f2, f1);
  200|       |}
  201|       |
  202|       |template <>
  203|       |struct type_casting_traits<float, Eigen::half> {
  204|       |  enum {
  205|       |    VectorizedCast = 1,
  206|       |    SrcCoeffRatio = 1,
  207|       |    TgtCoeffRatio = 1
  208|       |  };
  209|       |};
  210|       |
  211|       |template<> EIGEN_STRONG_INLINE Packet4h pcast<Packet4f, Packet4h>(const Packet4f& a) {
  212|       |  EIGEN_ALIGN16 float aux[4];
  213|       |  pstore(aux, a);
  214|       |  Eigen::half h0(aux[0]);
  215|       |  Eigen::half h1(aux[1]);
  216|       |  Eigen::half h2(aux[2]);
  217|       |  Eigen::half h3(aux[3]);
  218|       |
  219|       |  Packet4h result;
  220|       |  result.x = _mm_set_pi16(h3.x, h2.x, h1.x, h0.x);
  221|       |  return result;
  222|       |}
  223|       |
  224|       |#endif
  225|       |
  226|       |}  // end namespace internal
  227|       |
  228|       |}  // end namespace Eigen
  229|       |
  230|       |#endif  // EIGEN_TYPE_CASTING_SSE_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/functors/AssignmentFunctors.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_ASSIGNMENT_FUNCTORS_H
   11|       |#define EIGEN_ASSIGNMENT_FUNCTORS_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |/** \internal
   21|       | * \brief Template functor for scalar/packet assignment
   22|       | *
   23|       | */
   24|       |template <typename DstScalar, typename SrcScalar>
   25|       |struct assign_op {
   26|  7.55k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(DstScalar& a, const SrcScalar& b) const { a = b; }
   27|       |
   28|       |  template <int Alignment, typename Packet>
   29|       |  EIGEN_STRONG_INLINE void assignPacket(DstScalar* a, const Packet& b) const {
   30|       |    internal::pstoret<DstScalar, Packet, Alignment>(a, b);
   31|       |  }
   32|       |};
   33|       |
   34|       |// Empty overload for void type (used by PermutationMatrix)
   35|       |template <typename DstScalar>
   36|       |struct assign_op<DstScalar, void> {};
   37|       |
   38|       |template <typename DstScalar, typename SrcScalar>
   39|       |struct functor_traits<assign_op<DstScalar, SrcScalar> > {
   40|       |  enum {
   41|       |    Cost = NumTraits<DstScalar>::ReadCost,
   42|       |    PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::Vectorizable &&
   43|       |                   packet_traits<SrcScalar>::Vectorizable
   44|       |  };
   45|       |};
   46|       |
   47|       |/** \internal
   48|       | * \brief Template functor for scalar/packet assignment with addition
   49|       | *
   50|       | */
   51|       |template <typename DstScalar, typename SrcScalar>
   52|       |struct add_assign_op {
   53|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(DstScalar& a, const SrcScalar& b) const { a += b; }
   54|       |
   55|       |  template <int Alignment, typename Packet>
   56|       |  EIGEN_STRONG_INLINE void assignPacket(DstScalar* a, const Packet& b) const {
   57|       |    internal::pstoret<DstScalar, Packet, Alignment>(a, internal::padd(internal::ploadt<Packet, Alignment>(a), b));
   58|       |  }
   59|       |};
   60|       |template <typename DstScalar, typename SrcScalar>
   61|       |struct functor_traits<add_assign_op<DstScalar, SrcScalar> > {
   62|       |  enum {
   63|       |    Cost = NumTraits<DstScalar>::ReadCost + NumTraits<DstScalar>::AddCost,
   64|       |    PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::HasAdd
   65|       |  };
   66|       |};
   67|       |
   68|       |/** \internal
   69|       | * \brief Template functor for scalar/packet assignment with subtraction
   70|       | *
   71|       | */
   72|       |template <typename DstScalar, typename SrcScalar>
   73|       |struct sub_assign_op {
   74|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(DstScalar& a, const SrcScalar& b) const { a -= b; }
   75|       |
   76|       |  template <int Alignment, typename Packet>
   77|       |  EIGEN_STRONG_INLINE void assignPacket(DstScalar* a, const Packet& b) const {
   78|       |    internal::pstoret<DstScalar, Packet, Alignment>(a, internal::psub(internal::ploadt<Packet, Alignment>(a), b));
   79|       |  }
   80|       |};
   81|       |template <typename DstScalar, typename SrcScalar>
   82|       |struct functor_traits<sub_assign_op<DstScalar, SrcScalar> > {
   83|       |  enum {
   84|       |    Cost = NumTraits<DstScalar>::ReadCost + NumTraits<DstScalar>::AddCost,
   85|       |    PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::HasSub
   86|       |  };
   87|       |};
   88|       |
   89|       |/** \internal
   90|       | * \brief Template functor for scalar/packet assignment with multiplication
   91|       | *
   92|       | */
   93|       |template <typename DstScalar, typename SrcScalar = DstScalar>
   94|       |struct mul_assign_op {
   95|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(DstScalar& a, const SrcScalar& b) const { a *= b; }
   96|       |
   97|       |  template <int Alignment, typename Packet>
   98|       |  EIGEN_STRONG_INLINE void assignPacket(DstScalar* a, const Packet& b) const {
   99|       |    internal::pstoret<DstScalar, Packet, Alignment>(a, internal::pmul(internal::ploadt<Packet, Alignment>(a), b));
  100|       |  }
  101|       |};
  102|       |template <typename DstScalar, typename SrcScalar>
  103|       |struct functor_traits<mul_assign_op<DstScalar, SrcScalar> > {
  104|       |  enum {
  105|       |    Cost = NumTraits<DstScalar>::ReadCost + NumTraits<DstScalar>::MulCost,
  106|       |    PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::HasMul
  107|       |  };
  108|       |};
  109|       |
  110|       |/** \internal
  111|       | * \brief Template functor for scalar/packet assignment with diviving
  112|       | *
  113|       | */
  114|       |template <typename DstScalar, typename SrcScalar = DstScalar>
  115|       |struct div_assign_op {
  116|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(DstScalar& a, const SrcScalar& b) const { a /= b; }
  117|       |
  118|       |  template <int Alignment, typename Packet>
  119|       |  EIGEN_STRONG_INLINE void assignPacket(DstScalar* a, const Packet& b) const {
  120|       |    internal::pstoret<DstScalar, Packet, Alignment>(a, internal::pdiv(internal::ploadt<Packet, Alignment>(a), b));
  121|       |  }
  122|       |};
  123|       |template <typename DstScalar, typename SrcScalar>
  124|       |struct functor_traits<div_assign_op<DstScalar, SrcScalar> > {
  125|       |  enum {
  126|       |    Cost = NumTraits<DstScalar>::ReadCost + NumTraits<DstScalar>::MulCost,
  127|       |    PacketAccess = is_same<DstScalar, SrcScalar>::value && packet_traits<DstScalar>::HasDiv
  128|       |  };
  129|       |};
  130|       |
  131|       |/** \internal
  132|       | * \brief Template functor for scalar/packet assignment with swapping
  133|       | *
  134|       | * It works as follow. For a non-vectorized evaluation loop, we have:
  135|       | *   for(i) func(A.coeffRef(i), B.coeff(i));
  136|       | * where B is a SwapWrapper expression. The trick is to make SwapWrapper::coeff behaves like a non-const coeffRef.
  137|       | * Actually, SwapWrapper might not even be needed since even if B is a plain expression, since it has to be writable
  138|       | * B.coeff already returns a const reference to the underlying scalar value.
  139|       | *
  140|       | * The case of a vectorized loop is more tricky:
  141|       | *   for(i,j) func.assignPacket<A_Align>(&A.coeffRef(i,j), B.packet<B_Align>(i,j));
  142|       | * Here, B must be a SwapWrapper whose packet function actually returns a proxy object holding a Scalar*,
  143|       | * the actual alignment and Packet type.
  144|       | *
  145|       | */
  146|       |template <typename Scalar>
  147|       |struct swap_assign_op {
  148|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(Scalar& a, const Scalar& b) const {
  149|       |#ifdef EIGEN_GPUCC
  150|       |    // FIXME is there some kind of cuda::swap?
  151|       |    Scalar t = b;
  152|       |    const_cast<Scalar&>(b) = a;
  153|       |    a = t;
  154|       |#else
  155|       |    using std::swap;
  156|       |    swap(a, const_cast<Scalar&>(b));
  157|       |#endif
  158|       |  }
  159|       |};
  160|       |template <typename Scalar>
  161|       |struct functor_traits<swap_assign_op<Scalar> > {
  162|       |  enum {
  163|       |    Cost = 3 * NumTraits<Scalar>::ReadCost,
  164|       |    PacketAccess =
  165|       |#if defined(EIGEN_VECTORIZE_AVX) && (EIGEN_CLANG_STRICT_LESS_THAN(8, 0, 0) || EIGEN_COMP_CLANGAPPLE)
  166|       |        // This is a partial workaround for a bug in clang generating bad code
  167|       |        // when mixing 256/512 bits loads and 128 bits moves.
  168|       |        // See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1684
  169|       |        //     https://bugs.llvm.org/show_bug.cgi?id=40815
  170|       |    0
  171|       |#else
  172|       |        packet_traits<Scalar>::Vectorizable
  173|       |#endif
  174|       |  };
  175|       |};
  176|       |
  177|       |}  // namespace internal
  178|       |
  179|       |}  // namespace Eigen
  180|       |
  181|       |#endif  // EIGEN_ASSIGNMENT_FUNCTORS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/functors/BinaryFunctors.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_BINARY_FUNCTORS_H
   11|       |#define EIGEN_BINARY_FUNCTORS_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |//---------- associative binary functors ----------
   21|       |
   22|       |template <typename Arg1, typename Arg2>
   23|       |struct binary_op_base {
   24|       |  typedef Arg1 first_argument_type;
   25|       |  typedef Arg2 second_argument_type;
   26|       |};
   27|       |
   28|       |/** \internal
   29|       | * \brief Template functor to compute the sum of two scalars
   30|       | *
   31|       | * \sa class CwiseBinaryOp, MatrixBase::operator+, class VectorwiseOp, DenseBase::sum()
   32|       | */
   33|       |template <typename LhsScalar, typename RhsScalar>
   34|       |struct scalar_sum_op : binary_op_base<LhsScalar, RhsScalar> {
   35|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_sum_op>::ReturnType result_type;
   36|       |#ifdef EIGEN_SCALAR_BINARY_OP_PLUGIN
   37|       |  scalar_sum_op(){EIGEN_SCALAR_BINARY_OP_PLUGIN}
   38|       |#endif
   39|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type
   40|     68|  operator()(const LhsScalar& a, const RhsScalar& b) const {
   41|     68|    return a + b;
   42|     68|  }
   43|       |  template <typename Packet>
   44|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
   45|       |    return internal::padd(a, b);
   46|       |  }
   47|       |  template <typename Packet>
   48|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type predux(const Packet& a) const {
   49|       |    return internal::predux(a);
   50|       |  }
   51|       |};
   52|       |template <typename LhsScalar, typename RhsScalar>
   53|       |struct functor_traits<scalar_sum_op<LhsScalar, RhsScalar>> {
   54|       |  enum {
   55|       |    Cost = (int(NumTraits<LhsScalar>::AddCost) + int(NumTraits<RhsScalar>::AddCost)) / 2,  // rough estimate!
   56|       |    PacketAccess =
   57|       |        is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasAdd && packet_traits<RhsScalar>::HasAdd
   58|       |    // TODO vectorize mixed sum
   59|       |  };
   60|       |};
   61|       |
   62|       |template <>
   63|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool scalar_sum_op<bool, bool>::operator()(const bool& a, const bool& b) const {
   64|      0|  return a || b;
   65|      0|}
   66|       |
   67|       |/** \internal
   68|       | * \brief Template functor to compute the product of two scalars
   69|       | *
   70|       | * \sa class CwiseBinaryOp, Cwise::operator*(), class VectorwiseOp, MatrixBase::redux()
   71|       | */
   72|       |template <typename LhsScalar, typename RhsScalar>
   73|       |struct scalar_product_op : binary_op_base<LhsScalar, RhsScalar> {
   74|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_product_op>::ReturnType result_type;
   75|       |#ifdef EIGEN_SCALAR_BINARY_OP_PLUGIN
   76|       |  scalar_product_op(){EIGEN_SCALAR_BINARY_OP_PLUGIN}
   77|       |#endif
   78|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type
   79|      0|  operator()(const LhsScalar& a, const RhsScalar& b) const {
   80|      0|    return a * b;
   81|      0|  }
   82|       |  template <typename Packet>
   83|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
   84|       |    return internal::pmul(a, b);
   85|       |  }
   86|       |  template <typename Packet>
   87|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type predux(const Packet& a) const {
   88|       |    return internal::predux_mul(a);
   89|       |  }
   90|       |};
   91|       |template <typename LhsScalar, typename RhsScalar>
   92|       |struct functor_traits<scalar_product_op<LhsScalar, RhsScalar>> {
   93|       |  enum {
   94|       |    Cost = (int(NumTraits<LhsScalar>::MulCost) + int(NumTraits<RhsScalar>::MulCost)) / 2,  // rough estimate!
   95|       |    PacketAccess =
   96|       |        is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMul && packet_traits<RhsScalar>::HasMul
   97|       |    // TODO vectorize mixed product
   98|       |  };
   99|       |};
  100|       |
  101|       |template <>
  102|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool scalar_product_op<bool, bool>::operator()(const bool& a,
  103|      0|                                                                                     const bool& b) const {
  104|      0|  return a && b;
  105|      0|}
  106|       |
  107|       |/** \internal
  108|       | * \brief Template functor to compute the conjugate product of two scalars
  109|       | *
  110|       | * This is a short cut for conj(x) * y which is needed for optimization purpose; in Eigen2 support mode, this becomes x
  111|       | * * conj(y)
  112|       | */
  113|       |template <typename LhsScalar, typename RhsScalar>
  114|       |struct scalar_conj_product_op : binary_op_base<LhsScalar, RhsScalar> {
  115|       |  enum { Conj = NumTraits<LhsScalar>::IsComplex };
  116|       |
  117|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_conj_product_op>::ReturnType result_type;
  118|       |
  119|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  120|       |    return conj_helper<LhsScalar, RhsScalar, Conj, false>().pmul(a, b);
  121|       |  }
  122|       |
  123|       |  template <typename Packet>
  124|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  125|       |    return conj_helper<Packet, Packet, Conj, false>().pmul(a, b);
  126|       |  }
  127|       |};
  128|       |template <typename LhsScalar, typename RhsScalar>
  129|       |struct functor_traits<scalar_conj_product_op<LhsScalar, RhsScalar>> {
  130|       |  enum {
  131|       |    Cost = NumTraits<LhsScalar>::MulCost,
  132|       |    PacketAccess = internal::is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMul
  133|       |  };
  134|       |};
  135|       |
  136|       |/** \internal
  137|       | * \brief Template functor to compute the min of two scalars
  138|       | *
  139|       | * \sa class CwiseBinaryOp, MatrixBase::cwiseMin, class VectorwiseOp, MatrixBase::minCoeff()
  140|       | */
  141|       |template <typename LhsScalar, typename RhsScalar, int NaNPropagation>
  142|       |struct scalar_min_op : binary_op_base<LhsScalar, RhsScalar> {
  143|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_min_op>::ReturnType result_type;
  144|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  145|       |    return internal::pmin<NaNPropagation>(a, b);
  146|       |  }
  147|       |  template <typename Packet>
  148|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  149|       |    return internal::pmin<NaNPropagation>(a, b);
  150|       |  }
  151|       |  template <typename Packet>
  152|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type predux(const Packet& a) const {
  153|       |    return internal::predux_min<NaNPropagation>(a);
  154|       |  }
  155|       |};
  156|       |
  157|       |template <typename LhsScalar, typename RhsScalar, int NaNPropagation>
  158|       |struct functor_traits<scalar_min_op<LhsScalar, RhsScalar, NaNPropagation>> {
  159|       |  enum {
  160|       |    Cost = (NumTraits<LhsScalar>::AddCost + NumTraits<RhsScalar>::AddCost) / 2,
  161|       |    PacketAccess = internal::is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMin
  162|       |  };
  163|       |};
  164|       |
  165|       |/** \internal
  166|       | * \brief Template functor to compute the max of two scalars
  167|       | *
  168|       | * \sa class CwiseBinaryOp, MatrixBase::cwiseMax, class VectorwiseOp, MatrixBase::maxCoeff()
  169|       | */
  170|       |template <typename LhsScalar, typename RhsScalar, int NaNPropagation>
  171|       |struct scalar_max_op : binary_op_base<LhsScalar, RhsScalar> {
  172|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_max_op>::ReturnType result_type;
  173|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  174|       |    return internal::pmax<NaNPropagation>(a, b);
  175|       |  }
  176|       |  template <typename Packet>
  177|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  178|       |    return internal::pmax<NaNPropagation>(a, b);
  179|       |  }
  180|       |  template <typename Packet>
  181|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type predux(const Packet& a) const {
  182|       |    return internal::predux_max<NaNPropagation>(a);
  183|       |  }
  184|       |};
  185|       |
  186|       |template <typename LhsScalar, typename RhsScalar, int NaNPropagation>
  187|       |struct functor_traits<scalar_max_op<LhsScalar, RhsScalar, NaNPropagation>> {
  188|       |  enum {
  189|       |    Cost = (NumTraits<LhsScalar>::AddCost + NumTraits<RhsScalar>::AddCost) / 2,
  190|       |    PacketAccess = internal::is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMax
  191|       |  };
  192|       |};
  193|       |
  194|       |/** \internal
  195|       | * \brief Template functors for comparison of two scalars
  196|       | * \todo Implement packet-comparisons
  197|       | */
  198|       |template <typename LhsScalar, typename RhsScalar, ComparisonName cmp, bool UseTypedComparators = false>
  199|       |struct scalar_cmp_op;
  200|       |
  201|       |template <typename LhsScalar, typename RhsScalar, ComparisonName cmp, bool UseTypedComparators>
  202|       |struct functor_traits<scalar_cmp_op<LhsScalar, RhsScalar, cmp, UseTypedComparators>> {
  203|       |  enum {
  204|       |    Cost = (NumTraits<LhsScalar>::AddCost + NumTraits<RhsScalar>::AddCost) / 2,
  205|       |    PacketAccess = (UseTypedComparators || is_same<LhsScalar, bool>::value) && is_same<LhsScalar, RhsScalar>::value &&
  206|       |                   packet_traits<LhsScalar>::HasCmp
  207|       |  };
  208|       |};
  209|       |
  210|       |template <typename LhsScalar, typename RhsScalar, bool UseTypedComparators>
  211|       |struct typed_cmp_helper {
  212|       |  static constexpr bool SameType = is_same<LhsScalar, RhsScalar>::value;
  213|       |  static constexpr bool IsNumeric = is_arithmetic<typename NumTraits<LhsScalar>::Real>::value;
  214|       |  static constexpr bool UseTyped = UseTypedComparators && SameType && IsNumeric;
  215|       |  using type = typename conditional<UseTyped, LhsScalar, bool>::type;
  216|       |};
  217|       |
  218|       |template <typename LhsScalar, typename RhsScalar, bool UseTypedComparators>
  219|       |using cmp_return_t = typename typed_cmp_helper<LhsScalar, RhsScalar, UseTypedComparators>::type;
  220|       |
  221|       |template <typename LhsScalar, typename RhsScalar, bool UseTypedComparators>
  222|       |struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_EQ, UseTypedComparators> : binary_op_base<LhsScalar, RhsScalar> {
  223|       |  using result_type = cmp_return_t<LhsScalar, RhsScalar, UseTypedComparators>;
  224|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  225|       |    return a == b ? result_type(1) : result_type(0);
  226|       |  }
  227|       |  template <typename Packet>
  228|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  229|       |    const Packet cst_one = pset1<Packet>(result_type(1));
  230|       |    return pand(pcmp_eq(a, b), cst_one);
  231|       |  }
  232|       |};
  233|       |
  234|       |template <typename LhsScalar, typename RhsScalar, bool UseTypedComparators>
  235|       |struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_LT, UseTypedComparators> : binary_op_base<LhsScalar, RhsScalar> {
  236|       |  using result_type = cmp_return_t<LhsScalar, RhsScalar, UseTypedComparators>;
  237|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  238|       |    return a < b ? result_type(1) : result_type(0);
  239|       |  }
  240|       |  template <typename Packet>
  241|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  242|       |    const Packet cst_one = pset1<Packet>(result_type(1));
  243|       |    return pand(pcmp_lt(a, b), cst_one);
  244|       |  }
  245|       |};
  246|       |
  247|       |template <typename LhsScalar, typename RhsScalar, bool UseTypedComparators>
  248|       |struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_LE, UseTypedComparators> : binary_op_base<LhsScalar, RhsScalar> {
  249|       |  using result_type = cmp_return_t<LhsScalar, RhsScalar, UseTypedComparators>;
  250|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  251|       |    return a <= b ? result_type(1) : result_type(0);
  252|       |  }
  253|       |  template <typename Packet>
  254|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  255|       |    const Packet cst_one = pset1<Packet>(result_type(1));
  256|       |    return pand(cst_one, pcmp_le(a, b));
  257|       |  }
  258|       |};
  259|       |
  260|       |template <typename LhsScalar, typename RhsScalar, bool UseTypedComparators>
  261|       |struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_GT, UseTypedComparators> : binary_op_base<LhsScalar, RhsScalar> {
  262|       |  using result_type = cmp_return_t<LhsScalar, RhsScalar, UseTypedComparators>;
  263|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  264|       |    return a > b ? result_type(1) : result_type(0);
  265|       |  }
  266|       |  template <typename Packet>
  267|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  268|       |    const Packet cst_one = pset1<Packet>(result_type(1));
  269|       |    return pand(cst_one, pcmp_lt(b, a));
  270|       |  }
  271|       |};
  272|       |
  273|       |template <typename LhsScalar, typename RhsScalar, bool UseTypedComparators>
  274|       |struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_GE, UseTypedComparators> : binary_op_base<LhsScalar, RhsScalar> {
  275|       |  using result_type = cmp_return_t<LhsScalar, RhsScalar, UseTypedComparators>;
  276|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  277|       |    return a >= b ? result_type(1) : result_type(0);
  278|       |  }
  279|       |  template <typename Packet>
  280|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  281|       |    const Packet cst_one = pset1<Packet>(result_type(1));
  282|       |    return pand(cst_one, pcmp_le(b, a));
  283|       |  }
  284|       |};
  285|       |
  286|       |template <typename LhsScalar, typename RhsScalar, bool UseTypedComparators>
  287|       |struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_UNORD, UseTypedComparators> : binary_op_base<LhsScalar, RhsScalar> {
  288|       |  using result_type = cmp_return_t<LhsScalar, RhsScalar, UseTypedComparators>;
  289|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  290|       |    return !(a <= b || b <= a) ? result_type(1) : result_type(0);
  291|       |  }
  292|       |  template <typename Packet>
  293|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  294|       |    const Packet cst_one = pset1<Packet>(result_type(1));
  295|       |    return pandnot(cst_one, por(pcmp_le(a, b), pcmp_le(b, a)));
  296|       |  }
  297|       |};
  298|       |
  299|       |template <typename LhsScalar, typename RhsScalar, bool UseTypedComparators>
  300|       |struct scalar_cmp_op<LhsScalar, RhsScalar, cmp_NEQ, UseTypedComparators> : binary_op_base<LhsScalar, RhsScalar> {
  301|       |  using result_type = cmp_return_t<LhsScalar, RhsScalar, UseTypedComparators>;
  302|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const LhsScalar& a, const RhsScalar& b) const {
  303|       |    return a != b ? result_type(1) : result_type(0);
  304|       |  }
  305|       |  template <typename Packet>
  306|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  307|       |    const Packet cst_one = pset1<Packet>(result_type(1));
  308|       |    return pandnot(cst_one, pcmp_eq(a, b));
  309|       |  }
  310|       |};
  311|       |
  312|       |/** \internal
  313|       | * \brief Template functor to compute the hypot of two \b positive \b and \b real scalars
  314|       | *
  315|       | * \sa MatrixBase::stableNorm(), class Redux
  316|       | */
  317|       |template <typename Scalar>
  318|       |struct scalar_hypot_op<Scalar, Scalar> : binary_op_base<Scalar, Scalar> {
  319|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& x, const Scalar& y) const {
  320|       |    // This functor is used by hypotNorm only for which it is faster to first apply abs
  321|       |    // on all coefficients prior to reduction through hypot.
  322|       |    // This way we avoid calling abs on positive and real entries, and this also permits
  323|       |    // to seamlessly handle complexes. Otherwise we would have to handle both real and complexes
  324|       |    // through the same functor...
  325|       |    return internal::positive_real_hypot(x, y);
  326|       |  }
  327|       |};
  328|       |template <typename Scalar>
  329|       |struct functor_traits<scalar_hypot_op<Scalar, Scalar>> {
  330|       |  enum {
  331|       |    Cost = 3 * NumTraits<Scalar>::AddCost + 2 * NumTraits<Scalar>::MulCost + 2 * scalar_div_cost<Scalar, false>::value,
  332|       |    PacketAccess = false
  333|       |  };
  334|       |};
  335|       |
  336|       |/** \internal
  337|       | * \brief Template functor to compute the pow of two scalars
  338|       | * See the specification of pow in https://en.cppreference.com/w/cpp/numeric/math/pow
  339|       | */
  340|       |template <typename Scalar, typename Exponent>
  341|       |struct scalar_pow_op : binary_op_base<Scalar, Exponent> {
  342|       |  typedef typename ScalarBinaryOpTraits<Scalar, Exponent, scalar_pow_op>::ReturnType result_type;
  343|       |#ifdef EIGEN_SCALAR_BINARY_OP_PLUGIN
  344|       |  scalar_pow_op() {
  345|       |    typedef Scalar LhsScalar;
  346|       |    typedef Exponent RhsScalar;
  347|       |    EIGEN_SCALAR_BINARY_OP_PLUGIN
  348|       |  }
  349|       |#endif
  350|       |
  351|       |  EIGEN_DEVICE_FUNC inline result_type operator()(const Scalar& a, const Exponent& b) const {
  352|       |    return numext::pow(a, b);
  353|       |  }
  354|       |
  355|       |  template <typename Packet>
  356|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const {
  357|       |    return generic_pow(a, b);
  358|       |  }
  359|       |};
  360|       |
  361|       |template <typename Scalar, typename Exponent>
  362|       |struct functor_traits<scalar_pow_op<Scalar, Exponent>> {
  363|       |  enum {
  364|       |    Cost = 5 * NumTraits<Scalar>::MulCost,
  365|       |    PacketAccess = (!NumTraits<Scalar>::IsComplex && !NumTraits<Scalar>::IsInteger && packet_traits<Scalar>::HasExp &&
  366|       |                    packet_traits<Scalar>::HasLog && packet_traits<Scalar>::HasRound && packet_traits<Scalar>::HasCmp &&
  367|       |                    // Temporarily disable packet access for half/bfloat16 until
  368|       |                    // accuracy is improved.
  369|       |                    !is_same<Scalar, half>::value && !is_same<Scalar, bfloat16>::value)
  370|       |  };
  371|       |};
  372|       |
  373|       |//---------- non associative binary functors ----------
  374|       |
  375|       |/** \internal
  376|       | * \brief Template functor to compute the difference of two scalars
  377|       | *
  378|       | * \sa class CwiseBinaryOp, MatrixBase::operator-
  379|       | */
  380|       |template <typename LhsScalar, typename RhsScalar>
  381|       |struct scalar_difference_op : binary_op_base<LhsScalar, RhsScalar> {
  382|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_difference_op>::ReturnType result_type;
  383|       |#ifdef EIGEN_SCALAR_BINARY_OP_PLUGIN
  384|       |  scalar_difference_op(){EIGEN_SCALAR_BINARY_OP_PLUGIN}
  385|       |#endif
  386|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type
  387|       |  operator()(const LhsScalar& a, const RhsScalar& b) const {
  388|       |    return a - b;
  389|       |  }
  390|       |  template <typename Packet>
  391|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const {
  392|       |    return internal::psub(a, b);
  393|       |  }
  394|       |};
  395|       |template <typename LhsScalar, typename RhsScalar>
  396|       |struct functor_traits<scalar_difference_op<LhsScalar, RhsScalar>> {
  397|       |  enum {
  398|       |    Cost = (int(NumTraits<LhsScalar>::AddCost) + int(NumTraits<RhsScalar>::AddCost)) / 2,
  399|       |    PacketAccess =
  400|       |        is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasSub && packet_traits<RhsScalar>::HasSub
  401|       |  };
  402|       |};
  403|       |
  404|       |template <typename Packet, bool IsInteger = NumTraits<typename unpacket_traits<Packet>::type>::IsInteger>
  405|       |struct maybe_raise_div_by_zero {
  406|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Packet x) { EIGEN_UNUSED_VARIABLE(x); }
  407|       |};
  408|       |
  409|       |#ifndef EIGEN_GPU_COMPILE_PHASE
  410|       |template <typename Packet>
  411|       |struct maybe_raise_div_by_zero<Packet, true> {
  412|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Packet x) {
  413|       |    if (EIGEN_PREDICT_FALSE(predux_any(pcmp_eq(x, pzero(x))))) {
  414|       |      // Use volatile variables to force a division by zero, which will
  415|       |      // result in the default platform behaviour (usually SIGFPE).
  416|       |      volatile typename unpacket_traits<Packet>::type zero = 0;
  417|       |      volatile typename unpacket_traits<Packet>::type val = 1;
  418|       |      val = val / zero;
  419|       |    }
  420|       |  }
  421|       |};
  422|       |#endif
  423|       |
  424|       |/** \internal
  425|       | * \brief Template functor to compute the quotient of two scalars
  426|       | *
  427|       | * \sa class CwiseBinaryOp, Cwise::operator/()
  428|       | */
  429|       |template <typename LhsScalar, typename RhsScalar>
  430|       |struct scalar_quotient_op : binary_op_base<LhsScalar, RhsScalar> {
  431|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_quotient_op>::ReturnType result_type;
  432|       |#ifdef EIGEN_SCALAR_BINARY_OP_PLUGIN
  433|       |  scalar_quotient_op(){EIGEN_SCALAR_BINARY_OP_PLUGIN}
  434|       |#endif
  435|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type
  436|       |  operator()(const LhsScalar& a, const RhsScalar& b) const {
  437|       |    return a / b;
  438|       |  }
  439|       |  template <typename Packet>
  440|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const {
  441|       |    maybe_raise_div_by_zero<Packet>::run(b);
  442|       |    return internal::pdiv(a, b);
  443|       |  }
  444|       |};
  445|       |template <typename LhsScalar, typename RhsScalar>
  446|       |struct functor_traits<scalar_quotient_op<LhsScalar, RhsScalar>> {
  447|       |  typedef typename scalar_quotient_op<LhsScalar, RhsScalar>::result_type result_type;
  448|       |  enum {
  449|       |    PacketAccess =
  450|       |        is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasDiv && packet_traits<RhsScalar>::HasDiv,
  451|       |    Cost = scalar_div_cost<result_type, PacketAccess>::value
  452|       |  };
  453|       |};
  454|       |
  455|       |/** \internal
  456|       | * \brief Template functor to compute the and of two scalars as if they were booleans
  457|       | *
  458|       | * \sa class CwiseBinaryOp, ArrayBase::operator&&
  459|       | */
  460|       |template <typename Scalar>
  461|       |struct scalar_boolean_and_op {
  462|       |  using result_type = Scalar;
  463|       |  // `false` any value `a` that satisfies `a == Scalar(0)`
  464|       |  // `true` is the complement of `false`
  465|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a, const Scalar& b) const {
  466|       |    return (a != Scalar(0)) && (b != Scalar(0)) ? Scalar(1) : Scalar(0);
  467|       |  }
  468|       |  template <typename Packet>
  469|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  470|       |    const Packet cst_one = pset1<Packet>(Scalar(1));
  471|       |    // and(a,b) == !or(!a,!b)
  472|       |    Packet not_a = pcmp_eq(a, pzero(a));
  473|       |    Packet not_b = pcmp_eq(b, pzero(b));
  474|       |    Packet a_nand_b = por(not_a, not_b);
  475|       |    return pandnot(cst_one, a_nand_b);
  476|       |  }
  477|       |};
  478|       |template <typename Scalar>
  479|       |struct functor_traits<scalar_boolean_and_op<Scalar>> {
  480|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasCmp };
  481|       |};
  482|       |
  483|       |/** \internal
  484|       | * \brief Template functor to compute the or of two scalars as if they were booleans
  485|       | *
  486|       | * \sa class CwiseBinaryOp, ArrayBase::operator||
  487|       | */
  488|       |template <typename Scalar>
  489|       |struct scalar_boolean_or_op {
  490|       |  using result_type = Scalar;
  491|       |  // `false` any value `a` that satisfies `a == Scalar(0)`
  492|       |  // `true` is the complement of `false`
  493|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a, const Scalar& b) const {
  494|       |    return (a != Scalar(0)) || (b != Scalar(0)) ? Scalar(1) : Scalar(0);
  495|       |  }
  496|       |  template <typename Packet>
  497|       |  EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  498|       |    const Packet cst_one = pset1<Packet>(Scalar(1));
  499|       |    // if or(a,b) == 0, then a == 0 and b == 0
  500|       |    // or(a,b) == !nor(a,b)
  501|       |    Packet a_nor_b = pcmp_eq(por(a, b), pzero(a));
  502|       |    return pandnot(cst_one, a_nor_b);
  503|       |  }
  504|       |};
  505|       |template <typename Scalar>
  506|       |struct functor_traits<scalar_boolean_or_op<Scalar>> {
  507|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasCmp };
  508|       |};
  509|       |
  510|       |/** \internal
  511|       | * \brief Template functor to compute the xor of two scalars as if they were booleans
  512|       | *
  513|       | * \sa class CwiseBinaryOp, ArrayBase::operator^
  514|       | */
  515|       |template <typename Scalar>
  516|       |struct scalar_boolean_xor_op {
  517|       |  using result_type = Scalar;
  518|       |  // `false` any value `a` that satisfies `a == Scalar(0)`
  519|       |  // `true` is the complement of `false`
  520|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a, const Scalar& b) const {
  521|       |    return (a != Scalar(0)) != (b != Scalar(0)) ? Scalar(1) : Scalar(0);
  522|       |  }
  523|       |  template <typename Packet>
  524|       |  EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  525|       |    const Packet cst_one = pset1<Packet>(Scalar(1));
  526|       |    // xor(a,b) == xor(!a,!b)
  527|       |    Packet not_a = pcmp_eq(a, pzero(a));
  528|       |    Packet not_b = pcmp_eq(b, pzero(b));
  529|       |    Packet a_xor_b = pxor(not_a, not_b);
  530|       |    return pand(cst_one, a_xor_b);
  531|       |  }
  532|       |};
  533|       |template <typename Scalar>
  534|       |struct functor_traits<scalar_boolean_xor_op<Scalar>> {
  535|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasCmp };
  536|       |};
  537|       |
  538|       |template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
  539|       |struct bitwise_binary_impl {
  540|       |  static constexpr size_t Size = sizeof(Scalar);
  541|       |  using uint_t = typename numext::get_integer_by_size<Size>::unsigned_type;
  542|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_and(const Scalar& a, const Scalar& b) {
  543|       |    uint_t a_as_uint = numext::bit_cast<uint_t, Scalar>(a);
  544|       |    uint_t b_as_uint = numext::bit_cast<uint_t, Scalar>(b);
  545|       |    uint_t result = a_as_uint & b_as_uint;
  546|       |    return numext::bit_cast<Scalar, uint_t>(result);
  547|       |  }
  548|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_or(const Scalar& a, const Scalar& b) {
  549|       |    uint_t a_as_uint = numext::bit_cast<uint_t, Scalar>(a);
  550|       |    uint_t b_as_uint = numext::bit_cast<uint_t, Scalar>(b);
  551|       |    uint_t result = a_as_uint | b_as_uint;
  552|       |    return numext::bit_cast<Scalar, uint_t>(result);
  553|       |  }
  554|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_xor(const Scalar& a, const Scalar& b) {
  555|       |    uint_t a_as_uint = numext::bit_cast<uint_t, Scalar>(a);
  556|       |    uint_t b_as_uint = numext::bit_cast<uint_t, Scalar>(b);
  557|       |    uint_t result = a_as_uint ^ b_as_uint;
  558|       |    return numext::bit_cast<Scalar, uint_t>(result);
  559|       |  }
  560|       |};
  561|       |
  562|       |template <typename Scalar>
  563|       |struct bitwise_binary_impl<Scalar, true> {
  564|       |  using Real = typename NumTraits<Scalar>::Real;
  565|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_and(const Scalar& a, const Scalar& b) {
  566|       |    Real real_result = bitwise_binary_impl<Real>::run_and(numext::real(a), numext::real(b));
  567|       |    Real imag_result = bitwise_binary_impl<Real>::run_and(numext::imag(a), numext::imag(b));
  568|       |    return Scalar(real_result, imag_result);
  569|       |  }
  570|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_or(const Scalar& a, const Scalar& b) {
  571|       |    Real real_result = bitwise_binary_impl<Real>::run_or(numext::real(a), numext::real(b));
  572|       |    Real imag_result = bitwise_binary_impl<Real>::run_or(numext::imag(a), numext::imag(b));
  573|       |    return Scalar(real_result, imag_result);
  574|       |  }
  575|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_xor(const Scalar& a, const Scalar& b) {
  576|       |    Real real_result = bitwise_binary_impl<Real>::run_xor(numext::real(a), numext::real(b));
  577|       |    Real imag_result = bitwise_binary_impl<Real>::run_xor(numext::imag(a), numext::imag(b));
  578|       |    return Scalar(real_result, imag_result);
  579|       |  }
  580|       |};
  581|       |
  582|       |/** \internal
  583|       | * \brief Template functor to compute the bitwise and of two scalars
  584|       | *
  585|       | * \sa class CwiseBinaryOp, ArrayBase::operator&
  586|       | */
  587|       |template <typename Scalar>
  588|       |struct scalar_bitwise_and_op {
  589|       |  EIGEN_STATIC_ASSERT(!NumTraits<Scalar>::RequireInitialization,
  590|       |                      BITWISE OPERATIONS MAY ONLY BE PERFORMED ON PLAIN DATA TYPES)
  591|       |  EIGEN_STATIC_ASSERT((!internal::is_same<Scalar, bool>::value), DONT USE BITWISE OPS ON BOOLEAN TYPES)
  592|       |  using result_type = Scalar;
  593|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a, const Scalar& b) const {
  594|       |    return bitwise_binary_impl<Scalar>::run_and(a, b);
  595|       |  }
  596|       |  template <typename Packet>
  597|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  598|       |    return pand(a, b);
  599|       |  }
  600|       |};
  601|       |template <typename Scalar>
  602|       |struct functor_traits<scalar_bitwise_and_op<Scalar>> {
  603|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = true };
  604|       |};
  605|       |
  606|       |/** \internal
  607|       | * \brief Template functor to compute the bitwise or of two scalars
  608|       | *
  609|       | * \sa class CwiseBinaryOp, ArrayBase::operator|
  610|       | */
  611|       |template <typename Scalar>
  612|       |struct scalar_bitwise_or_op {
  613|       |  EIGEN_STATIC_ASSERT(!NumTraits<Scalar>::RequireInitialization,
  614|       |                      BITWISE OPERATIONS MAY ONLY BE PERFORMED ON PLAIN DATA TYPES)
  615|       |  EIGEN_STATIC_ASSERT((!internal::is_same<Scalar, bool>::value), DONT USE BITWISE OPS ON BOOLEAN TYPES)
  616|       |  using result_type = Scalar;
  617|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a, const Scalar& b) const {
  618|       |    return bitwise_binary_impl<Scalar>::run_or(a, b);
  619|       |  }
  620|       |  template <typename Packet>
  621|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  622|       |    return por(a, b);
  623|       |  }
  624|       |};
  625|       |template <typename Scalar>
  626|       |struct functor_traits<scalar_bitwise_or_op<Scalar>> {
  627|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = true };
  628|       |};
  629|       |
  630|       |/** \internal
  631|       | * \brief Template functor to compute the bitwise xor of two scalars
  632|       | *
  633|       | * \sa class CwiseBinaryOp, ArrayBase::operator^
  634|       | */
  635|       |template <typename Scalar>
  636|       |struct scalar_bitwise_xor_op {
  637|       |  EIGEN_STATIC_ASSERT(!NumTraits<Scalar>::RequireInitialization,
  638|       |                      BITWISE OPERATIONS MAY ONLY BE PERFORMED ON PLAIN DATA TYPES)
  639|       |  EIGEN_STATIC_ASSERT((!internal::is_same<Scalar, bool>::value), DONT USE BITWISE OPS ON BOOLEAN TYPES)
  640|       |  using result_type = Scalar;
  641|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a, const Scalar& b) const {
  642|       |    return bitwise_binary_impl<Scalar>::run_xor(a, b);
  643|       |  }
  644|       |  template <typename Packet>
  645|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const {
  646|       |    return pxor(a, b);
  647|       |  }
  648|       |};
  649|       |template <typename Scalar>
  650|       |struct functor_traits<scalar_bitwise_xor_op<Scalar>> {
  651|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = true };
  652|       |};
  653|       |
  654|       |/** \internal
  655|       | * \brief Template functor to compute the absolute difference of two scalars
  656|       | *
  657|       | * \sa class CwiseBinaryOp, MatrixBase::absolute_difference
  658|       | */
  659|       |template <typename LhsScalar, typename RhsScalar>
  660|       |struct scalar_absolute_difference_op : binary_op_base<LhsScalar, RhsScalar> {
  661|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar, scalar_absolute_difference_op>::ReturnType result_type;
  662|       |#ifdef EIGEN_SCALAR_BINARY_OP_PLUGIN
  663|       |  scalar_absolute_difference_op(){EIGEN_SCALAR_BINARY_OP_PLUGIN}
  664|       |#endif
  665|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type
  666|       |  operator()(const LhsScalar& a, const RhsScalar& b) const {
  667|       |    return numext::absdiff(a, b);
  668|       |  }
  669|       |  template <typename Packet>
  670|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const {
  671|       |    return internal::pabsdiff(a, b);
  672|       |  }
  673|       |};
  674|       |template <typename LhsScalar, typename RhsScalar>
  675|       |struct functor_traits<scalar_absolute_difference_op<LhsScalar, RhsScalar>> {
  676|       |  enum {
  677|       |    Cost = (NumTraits<LhsScalar>::AddCost + NumTraits<RhsScalar>::AddCost) / 2,
  678|       |    PacketAccess = is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasAbsDiff
  679|       |  };
  680|       |};
  681|       |
  682|       |template <typename LhsScalar, typename RhsScalar>
  683|       |struct scalar_atan2_op {
  684|       |  using Scalar = LhsScalar;
  685|       |
  686|       |  static constexpr bool Enable =
  687|       |      is_same<LhsScalar, RhsScalar>::value && !NumTraits<Scalar>::IsInteger && !NumTraits<Scalar>::IsComplex;
  688|       |  EIGEN_STATIC_ASSERT(Enable, "LhsScalar and RhsScalar must be the same non-integer, non-complex type")
  689|       |
  690|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& y, const Scalar& x) const {
  691|       |    return numext::atan2(y, x);
  692|       |  }
  693|       |  template <typename Packet>
  694|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& y, const Packet& x) const {
  695|       |    return internal::patan2(y, x);
  696|       |  }
  697|       |};
  698|       |
  699|       |template <typename LhsScalar, typename RhsScalar>
  700|       |struct functor_traits<scalar_atan2_op<LhsScalar, RhsScalar>> {
  701|       |  using Scalar = LhsScalar;
  702|       |  enum {
  703|       |    PacketAccess = is_same<LhsScalar, RhsScalar>::value && packet_traits<Scalar>::HasATan &&
  704|       |                   packet_traits<Scalar>::HasDiv && !NumTraits<Scalar>::IsInteger && !NumTraits<Scalar>::IsComplex,
  705|       |    Cost = int(scalar_div_cost<Scalar, PacketAccess>::value) + int(functor_traits<scalar_atan_op<Scalar>>::Cost)
  706|       |  };
  707|       |};
  708|       |
  709|       |//---------- binary functors bound to a constant, thus appearing as a unary functor ----------
  710|       |
  711|       |// The following two classes permits to turn any binary functor into a unary one with one argument bound to a constant
  712|       |// value. They are analogues to std::binder1st/binder2nd but with the following differences:
  713|       |//  - they are compatible with packetOp
  714|       |//  - they are portable across C++ versions (the std::binder* are deprecated in C++11)
  715|       |template <typename BinaryOp>
  716|       |struct bind1st_op : BinaryOp {
  717|       |  typedef typename BinaryOp::first_argument_type first_argument_type;
  718|       |  typedef typename BinaryOp::second_argument_type second_argument_type;
  719|       |  typedef typename BinaryOp::result_type result_type;
  720|       |
  721|       |  EIGEN_DEVICE_FUNC explicit bind1st_op(const first_argument_type& val) : m_value(val) {}
  722|       |
  723|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator()(const second_argument_type& b) const {
  724|       |    return BinaryOp::operator()(m_value, b);
  725|       |  }
  726|       |
  727|       |  template <typename Packet>
  728|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& b) const {
  729|       |    return BinaryOp::packetOp(internal::pset1<Packet>(m_value), b);
  730|       |  }
  731|       |
  732|       |  first_argument_type m_value;
  733|       |};
  734|       |template <typename BinaryOp>
  735|       |struct functor_traits<bind1st_op<BinaryOp>> : functor_traits<BinaryOp> {};
  736|       |
  737|       |template <typename BinaryOp>
  738|       |struct bind2nd_op : BinaryOp {
  739|       |  typedef typename BinaryOp::first_argument_type first_argument_type;
  740|       |  typedef typename BinaryOp::second_argument_type second_argument_type;
  741|       |  typedef typename BinaryOp::result_type result_type;
  742|       |
  743|       |  EIGEN_DEVICE_FUNC explicit bind2nd_op(const second_argument_type& val) : m_value(val) {}
  744|       |
  745|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator()(const first_argument_type& a) const {
  746|       |    return BinaryOp::operator()(a, m_value);
  747|       |  }
  748|       |
  749|       |  template <typename Packet>
  750|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
  751|       |    return BinaryOp::packetOp(a, internal::pset1<Packet>(m_value));
  752|       |  }
  753|       |
  754|       |  second_argument_type m_value;
  755|       |};
  756|       |template <typename BinaryOp>
  757|       |struct functor_traits<bind2nd_op<BinaryOp>> : functor_traits<BinaryOp> {};
  758|       |
  759|       |}  // end namespace internal
  760|       |
  761|       |}  // end namespace Eigen
  762|       |
  763|       |#endif  // EIGEN_BINARY_FUNCTORS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/functors/NullaryFunctors.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2016 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_NULLARY_FUNCTORS_H
   11|       |#define EIGEN_NULLARY_FUNCTORS_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |template <typename Scalar>
   21|       |struct scalar_constant_op {
   22|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE scalar_constant_op(const Scalar& other) : m_other(other) {}
   23|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()() const { return m_other; }
   24|       |  template <typename PacketType>
   25|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const PacketType packetOp() const {
   26|       |    return internal::pset1<PacketType>(m_other);
   27|       |  }
   28|       |  const Scalar m_other;
   29|       |};
   30|       |template <typename Scalar>
   31|       |struct functor_traits<scalar_constant_op<Scalar> > {
   32|       |  enum {
   33|       |    Cost = 0 /* as the constant value should be loaded in register only once for the whole expression */,
   34|       |    PacketAccess = packet_traits<Scalar>::Vectorizable,
   35|       |    IsRepeatable = true
   36|       |  };
   37|       |};
   38|       |
   39|       |template <typename Scalar>
   40|       |struct scalar_zero_op {
   41|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE scalar_zero_op() = default;
   42|  7.55k|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()() const { return Scalar(0); }
   43|       |  template <typename PacketType>
   44|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const PacketType packetOp() const {
   45|       |    return internal::pzero<PacketType>(PacketType());
   46|       |  }
   47|       |};
   48|       |template <typename Scalar>
   49|       |struct functor_traits<scalar_zero_op<Scalar>> : functor_traits<scalar_constant_op<Scalar>> {};
   50|       |
   51|       |template <typename Scalar>
   52|       |struct scalar_identity_op {
   53|       |  template <typename IndexType>
   54|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(IndexType row, IndexType col) const {
   55|       |    return row == col ? Scalar(1) : Scalar(0);
   56|       |  }
   57|       |};
   58|       |template <typename Scalar>
   59|       |struct functor_traits<scalar_identity_op<Scalar> > {
   60|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = false, IsRepeatable = true };
   61|       |};
   62|       |
   63|       |template <typename Scalar, bool IsInteger>
   64|       |struct linspaced_op_impl;
   65|       |
   66|       |template <typename Scalar>
   67|       |struct linspaced_op_impl<Scalar, /*IsInteger*/ false> {
   68|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
   69|       |
   70|       |  EIGEN_DEVICE_FUNC linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps)
   71|       |      : m_low(low),
   72|       |        m_high(high),
   73|       |        m_size1(num_steps == 1 ? 1 : num_steps - 1),
   74|       |        m_step(num_steps == 1 ? Scalar() : Scalar((high - low) / RealScalar(num_steps - 1))),
   75|       |        m_flip(numext::abs(high) < numext::abs(low)) {}
   76|       |
   77|       |  template <typename IndexType>
   78|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(IndexType i) const {
   79|       |    if (m_flip)
   80|       |      return (i == 0) ? m_low : Scalar(m_high - RealScalar(m_size1 - i) * m_step);
   81|       |    else
   82|       |      return (i == m_size1) ? m_high : Scalar(m_low + RealScalar(i) * m_step);
   83|       |  }
   84|       |
   85|       |  template <typename Packet, typename IndexType>
   86|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(IndexType i) const {
   87|       |    // Principle:
   88|       |    // [low, ..., low] + ( [step, ..., step] * ( [i, ..., i] + [0, ..., size] ) )
   89|       |    if (m_flip) {
   90|       |      Packet pi = plset<Packet>(Scalar(i - m_size1));
   91|       |      Packet res = padd(pset1<Packet>(m_high), pmul(pset1<Packet>(m_step), pi));
   92|       |      if (EIGEN_PREDICT_TRUE(i != 0)) return res;
   93|       |      Packet mask = pcmp_lt(pset1<Packet>(0), plset<Packet>(0));
   94|       |      return pselect<Packet>(mask, res, pset1<Packet>(m_low));
   95|       |    } else {
   96|       |      Packet pi = plset<Packet>(Scalar(i));
   97|       |      Packet res = padd(pset1<Packet>(m_low), pmul(pset1<Packet>(m_step), pi));
   98|       |      if (EIGEN_PREDICT_TRUE(i != m_size1 - unpacket_traits<Packet>::size + 1)) return res;
   99|       |      Packet mask = pcmp_lt(plset<Packet>(0), pset1<Packet>(unpacket_traits<Packet>::size - 1));
  100|       |      return pselect<Packet>(mask, res, pset1<Packet>(m_high));
  101|       |    }
  102|       |  }
  103|       |
  104|       |  const Scalar m_low;
  105|       |  const Scalar m_high;
  106|       |  const Index m_size1;
  107|       |  const Scalar m_step;
  108|       |  const bool m_flip;
  109|       |};
  110|       |
  111|       |template <typename Scalar>
  112|       |struct linspaced_op_impl<Scalar, /*IsInteger*/ true> {
  113|       |  EIGEN_DEVICE_FUNC linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps)
  114|       |      : m_low(low),
  115|       |        m_multiplier((high - low) / convert_index<Scalar>(num_steps <= 1 ? 1 : num_steps - 1)),
  116|       |        m_divisor(convert_index<Scalar>((high >= low ? num_steps : -num_steps) + (high - low)) /
  117|       |                  ((numext::abs(high - low) + 1) == 0 ? 1 : (numext::abs(high - low) + 1))),
  118|       |        m_use_divisor(num_steps > 1 && (numext::abs(high - low) + 1) < num_steps) {}
  119|       |
  120|       |  template <typename IndexType>
  121|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(IndexType i) const {
  122|       |    if (m_use_divisor)
  123|       |      return m_low + convert_index<Scalar>(i) / m_divisor;
  124|       |    else
  125|       |      return m_low + convert_index<Scalar>(i) * m_multiplier;
  126|       |  }
  127|       |
  128|       |  const Scalar m_low;
  129|       |  const Scalar m_multiplier;
  130|       |  const Scalar m_divisor;
  131|       |  const bool m_use_divisor;
  132|       |};
  133|       |
  134|       |// ----- Linspace functor ----------------------------------------------------------------
  135|       |
  136|       |// Forward declaration (we default to random access which does not really give
  137|       |// us a speed gain when using packet access but it allows to use the functor in
  138|       |// nested expressions).
  139|       |template <typename Scalar>
  140|       |struct linspaced_op;
  141|       |template <typename Scalar>
  142|       |struct functor_traits<linspaced_op<Scalar> > {
  143|       |  enum {
  144|       |    Cost = 1,
  145|       |    PacketAccess = (!NumTraits<Scalar>::IsInteger) && packet_traits<Scalar>::HasSetLinear,
  146|       |    /*&& ((!NumTraits<Scalar>::IsInteger) || packet_traits<Scalar>::HasDiv),*/  // <- vectorization for integer is
  147|       |                                                                                // currently disabled
  148|       |    IsRepeatable = true
  149|       |  };
  150|       |};
  151|       |template <typename Scalar>
  152|       |struct linspaced_op {
  153|       |  EIGEN_DEVICE_FUNC linspaced_op(const Scalar& low, const Scalar& high, Index num_steps)
  154|       |      : impl((num_steps == 1 ? high : low), high, num_steps) {}
  155|       |
  156|       |  template <typename IndexType>
  157|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(IndexType i) const {
  158|       |    return impl(i);
  159|       |  }
  160|       |
  161|       |  template <typename Packet, typename IndexType>
  162|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(IndexType i) const {
  163|       |    return impl.template packetOp<Packet>(i);
  164|       |  }
  165|       |
  166|       |  // This proxy object handles the actual required temporaries and the different
  167|       |  // implementations (integer vs. floating point).
  168|       |  const linspaced_op_impl<Scalar, NumTraits<Scalar>::IsInteger> impl;
  169|       |};
  170|       |
  171|       |template <typename Scalar>
  172|       |struct equalspaced_op {
  173|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  174|       |
  175|       |  EIGEN_DEVICE_FUNC equalspaced_op(const Scalar& start, const Scalar& step) : m_start(start), m_step(step) {}
  176|       |  template <typename IndexType>
  177|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(IndexType i) const {
  178|       |    return m_start + m_step * static_cast<Scalar>(i);
  179|       |  }
  180|       |  template <typename Packet, typename IndexType>
  181|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(IndexType i) const {
  182|       |    const Packet cst_start = pset1<Packet>(m_start);
  183|       |    const Packet cst_step = pset1<Packet>(m_step);
  184|       |    const Packet cst_lin0 = plset<Packet>(Scalar(0));
  185|       |    const Packet cst_offset = pmadd(cst_lin0, cst_step, cst_start);
  186|       |
  187|       |    Packet i_packet = pset1<Packet>(static_cast<Scalar>(i));
  188|       |    return pmadd(i_packet, cst_step, cst_offset);
  189|       |  }
  190|       |  const Scalar m_start;
  191|       |  const Scalar m_step;
  192|       |};
  193|       |
  194|       |template <typename Scalar>
  195|       |struct functor_traits<equalspaced_op<Scalar> > {
  196|       |  enum {
  197|       |    Cost = NumTraits<Scalar>::AddCost + NumTraits<Scalar>::MulCost,
  198|       |    PacketAccess =
  199|       |        packet_traits<Scalar>::HasSetLinear && packet_traits<Scalar>::HasMul && packet_traits<Scalar>::HasAdd,
  200|       |    IsRepeatable = true
  201|       |  };
  202|       |};
  203|       |
  204|       |// Linear access is automatically determined from the operator() prototypes available for the given functor.
  205|       |// If it exposes an operator()(i,j), then we assume the i and j coefficients are required independently
  206|       |// and linear access is not possible. In all other cases, linear access is enabled.
  207|       |// Users should not have to deal with this structure.
  208|       |template <typename Functor>
  209|       |struct functor_has_linear_access {
  210|       |  enum { ret = !has_binary_operator<Functor>::value };
  211|       |};
  212|       |
  213|       |// For unreliable compilers, let's specialize the has_*ary_operator
  214|       |// helpers so that at least built-in nullary functors work fine.
  215|       |#if !(EIGEN_COMP_MSVC || EIGEN_COMP_GNUC || (EIGEN_COMP_ICC >= 1600))
  216|       |template <typename Scalar, typename IndexType>
  217|       |struct has_nullary_operator<scalar_constant_op<Scalar>, IndexType> {
  218|       |  enum { value = 1 };
  219|       |};
  220|       |template <typename Scalar, typename IndexType>
  221|       |struct has_unary_operator<scalar_constant_op<Scalar>, IndexType> {
  222|       |  enum { value = 0 };
  223|       |};
  224|       |template <typename Scalar, typename IndexType>
  225|       |struct has_binary_operator<scalar_constant_op<Scalar>, IndexType> {
  226|       |  enum { value = 0 };
  227|       |};
  228|       |
  229|       |template <typename Scalar, typename IndexType>
  230|       |struct has_nullary_operator<scalar_identity_op<Scalar>, IndexType> {
  231|       |  enum { value = 0 };
  232|       |};
  233|       |template <typename Scalar, typename IndexType>
  234|       |struct has_unary_operator<scalar_identity_op<Scalar>, IndexType> {
  235|       |  enum { value = 0 };
  236|       |};
  237|       |template <typename Scalar, typename IndexType>
  238|       |struct has_binary_operator<scalar_identity_op<Scalar>, IndexType> {
  239|       |  enum { value = 1 };
  240|       |};
  241|       |
  242|       |template <typename Scalar, typename IndexType>
  243|       |struct has_nullary_operator<linspaced_op<Scalar>, IndexType> {
  244|       |  enum { value = 0 };
  245|       |};
  246|       |template <typename Scalar, typename IndexType>
  247|       |struct has_unary_operator<linspaced_op<Scalar>, IndexType> {
  248|       |  enum { value = 1 };
  249|       |};
  250|       |template <typename Scalar, typename IndexType>
  251|       |struct has_binary_operator<linspaced_op<Scalar>, IndexType> {
  252|       |  enum { value = 0 };
  253|       |};
  254|       |
  255|       |template <typename Scalar, typename IndexType>
  256|       |struct has_nullary_operator<scalar_random_op<Scalar>, IndexType> {
  257|       |  enum { value = 1 };
  258|       |};
  259|       |template <typename Scalar, typename IndexType>
  260|       |struct has_unary_operator<scalar_random_op<Scalar>, IndexType> {
  261|       |  enum { value = 0 };
  262|       |};
  263|       |template <typename Scalar, typename IndexType>
  264|       |struct has_binary_operator<scalar_random_op<Scalar>, IndexType> {
  265|       |  enum { value = 0 };
  266|       |};
  267|       |#endif
  268|       |
  269|       |}  // end namespace internal
  270|       |
  271|       |}  // end namespace Eigen
  272|       |
  273|       |#endif  // EIGEN_NULLARY_FUNCTORS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/functors/UnaryFunctors.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2016 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_UNARY_FUNCTORS_H
   11|       |#define EIGEN_UNARY_FUNCTORS_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |/** \internal
   21|       | * \brief Template functor to compute the opposite of a scalar
   22|       | *
   23|       | * \sa class CwiseUnaryOp, MatrixBase::operator-
   24|       | */
   25|       |template <typename Scalar>
   26|       |struct scalar_opposite_op {
   27|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const { return numext::negate(a); }
   28|       |  template <typename Packet>
   29|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
   30|       |    return internal::pnegate(a);
   31|       |  }
   32|       |};
   33|       |template <typename Scalar>
   34|       |struct functor_traits<scalar_opposite_op<Scalar>> {
   35|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasNegate };
   36|       |};
   37|       |
   38|       |/** \internal
   39|       | * \brief Template functor to compute the absolute value of a scalar
   40|       | *
   41|       | * \sa class CwiseUnaryOp, Cwise::abs
   42|       | */
   43|       |template <typename Scalar>
   44|       |struct scalar_abs_op {
   45|       |  typedef typename NumTraits<Scalar>::Real result_type;
   46|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator()(const Scalar& a) const { return numext::abs(a); }
   47|       |  template <typename Packet>
   48|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
   49|       |    return internal::pabs(a);
   50|       |  }
   51|       |};
   52|       |template <typename Scalar>
   53|       |struct functor_traits<scalar_abs_op<Scalar>> {
   54|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasAbs };
   55|       |};
   56|       |
   57|       |/** \internal
   58|       | * \brief Template functor to compute the score of a scalar, to chose a pivot
   59|       | *
   60|       | * \sa class CwiseUnaryOp
   61|       | */
   62|       |template <typename Scalar>
   63|       |struct scalar_score_coeff_op : scalar_abs_op<Scalar> {
   64|       |  typedef void Score_is_abs;
   65|       |};
   66|       |template <typename Scalar>
   67|       |struct functor_traits<scalar_score_coeff_op<Scalar>> : functor_traits<scalar_abs_op<Scalar>> {};
   68|       |
   69|       |/* Avoid recomputing abs when we know the score and they are the same. Not a true Eigen functor.  */
   70|       |template <typename Scalar, typename = void>
   71|       |struct abs_knowing_score {
   72|       |  typedef typename NumTraits<Scalar>::Real result_type;
   73|       |  template <typename Score>
   74|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator()(const Scalar& a, const Score&) const {
   75|       |    return numext::abs(a);
   76|       |  }
   77|       |};
   78|       |template <typename Scalar>
   79|       |struct abs_knowing_score<Scalar, typename scalar_score_coeff_op<Scalar>::Score_is_abs> {
   80|       |  typedef typename NumTraits<Scalar>::Real result_type;
   81|       |  template <typename Scal>
   82|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator()(const Scal&, const result_type& a) const {
   83|       |    return a;
   84|       |  }
   85|       |};
   86|       |
   87|       |/** \internal
   88|       | * \brief Template functor to compute the squared absolute value of a scalar
   89|       | *
   90|       | * \sa class CwiseUnaryOp, Cwise::abs2
   91|       | */
   92|       |template <typename Scalar>
   93|       |struct scalar_abs2_op {
   94|       |  typedef typename NumTraits<Scalar>::Real result_type;
   95|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator()(const Scalar& a) const { return numext::abs2(a); }
   96|       |  template <typename Packet>
   97|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
   98|       |    return internal::pmul(a, a);
   99|       |  }
  100|       |};
  101|       |template <typename Scalar>
  102|       |struct functor_traits<scalar_abs2_op<Scalar>> {
  103|       |  enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasAbs2 };
  104|       |};
  105|       |
  106|       |template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
  107|       |struct squared_norm_functor {
  108|       |  typedef Scalar result_type;
  109|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const {
  110|       |    return Scalar(numext::real(a) * numext::real(a), numext::imag(a) * numext::imag(a));
  111|       |  }
  112|       |  template <typename Packet>
  113|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
  114|       |    return Packet(pmul(a.v, a.v));
  115|       |  }
  116|       |};
  117|       |template <typename Scalar>
  118|       |struct squared_norm_functor<Scalar, false> : scalar_abs2_op<Scalar> {};
  119|       |
  120|       |template <typename Scalar>
  121|       |struct functor_traits<squared_norm_functor<Scalar>> {
  122|       |  using Real = typename NumTraits<Scalar>::Real;
  123|       |  enum { Cost = NumTraits<Real>::MulCost, PacketAccess = packet_traits<Real>::HasMul };
  124|       |};
  125|       |
  126|       |/** \internal
  127|       | * \brief Template functor to compute the conjugate of a complex value
  128|       | *
  129|       | * \sa class CwiseUnaryOp, MatrixBase::conjugate()
  130|       | */
  131|       |template <typename Scalar>
  132|       |struct scalar_conjugate_op {
  133|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const { return numext::conj(a); }
  134|       |  template <typename Packet>
  135|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
  136|       |    return internal::pconj(a);
  137|       |  }
  138|       |};
  139|       |template <typename Scalar>
  140|       |struct functor_traits<scalar_conjugate_op<Scalar>> {
  141|       |  enum {
  142|       |    Cost = 0,
  143|       |    // Yes the cost is zero even for complexes because in most cases for which
  144|       |    // the cost is used, conjugation turns to be a no-op. Some examples:
  145|       |    //   cost(a*conj(b)) == cost(a*b)
  146|       |    //   cost(a+conj(b)) == cost(a+b)
  147|       |    //   <etc.
  148|       |    // If we don't set it to zero, then:
  149|       |    //   A.conjugate().lazyProduct(B.conjugate())
  150|       |    // will bake its operands. We definitely don't want that!
  151|       |    PacketAccess = packet_traits<Scalar>::HasConj
  152|       |  };
  153|       |};
  154|       |
  155|       |/** \internal
  156|       | * \brief Template functor to compute the phase angle of a complex
  157|       | *
  158|       | * \sa class CwiseUnaryOp, Cwise::arg
  159|       | */
  160|       |template <typename Scalar>
  161|       |struct scalar_arg_op {
  162|       |  typedef typename NumTraits<Scalar>::Real result_type;
  163|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator()(const Scalar& a) const { return numext::arg(a); }
  164|       |  template <typename Packet>
  165|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
  166|       |    return internal::parg(a);
  167|       |  }
  168|       |};
  169|       |template <typename Scalar>
  170|       |struct functor_traits<scalar_arg_op<Scalar>> {
  171|       |  enum {
  172|       |    Cost = NumTraits<Scalar>::IsComplex ? 5 * NumTraits<Scalar>::MulCost : NumTraits<Scalar>::AddCost,
  173|       |    PacketAccess = packet_traits<Scalar>::HasArg
  174|       |  };
  175|       |};
  176|       |
  177|       |/** \internal
  178|       | * \brief Template functor to compute the complex argument, returned as a complex type
  179|       | *
  180|       | * \sa class CwiseUnaryOp, Cwise::carg
  181|       | */
  182|       |template <typename Scalar>
  183|       |struct scalar_carg_op {
  184|       |  using result_type = Scalar;
  185|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const {
  186|       |    return Scalar(numext::arg(a));
  187|       |  }
  188|       |  template <typename Packet>
  189|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
  190|       |    return pcarg(a);
  191|       |  }
  192|       |};
  193|       |template <typename Scalar>
  194|       |struct functor_traits<scalar_carg_op<Scalar>> {
  195|       |  using RealScalar = typename NumTraits<Scalar>::Real;
  196|       |  enum { Cost = functor_traits<scalar_atan2_op<RealScalar>>::Cost, PacketAccess = packet_traits<RealScalar>::HasATan };
  197|       |};
  198|       |
  199|       |/** \internal
  200|       | * \brief Template functor to cast a scalar to another type
  201|       | *
  202|       | * \sa class CwiseUnaryOp, MatrixBase::cast()
  203|       | */
  204|       |template <typename Scalar, typename NewType>
  205|       |struct scalar_cast_op {
  206|       |  typedef NewType result_type;
  207|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const NewType operator()(const Scalar& a) const {
  208|       |    return cast<Scalar, NewType>(a);
  209|       |  }
  210|       |};
  211|       |
  212|       |template <typename Scalar, typename NewType>
  213|       |struct functor_traits<scalar_cast_op<Scalar, NewType>> {
  214|       |  enum { Cost = is_same<Scalar, NewType>::value ? 0 : NumTraits<NewType>::AddCost, PacketAccess = false };
  215|       |};
  216|       |
  217|       |/** \internal
  218|       | * `core_cast_op` serves to distinguish the vectorized implementation from that of the legacy `scalar_cast_op` for
  219|       | * backwards compatibility. The manner in which packet ops are handled is defined by the specialized unary_evaluator:
  220|       | * `unary_evaluator<CwiseUnaryOp<core_cast_op<SrcType, DstType>, ArgType>, IndexBased>` in CoreEvaluators.h
  221|       | * Otherwise, the non-vectorized behavior is identical to that of `scalar_cast_op`
  222|       | */
  223|       |template <typename SrcType, typename DstType>
  224|       |struct core_cast_op : scalar_cast_op<SrcType, DstType> {};
  225|       |
  226|       |template <typename SrcType, typename DstType>
  227|       |struct functor_traits<core_cast_op<SrcType, DstType>> {
  228|       |  using CastingTraits = type_casting_traits<SrcType, DstType>;
  229|       |  enum {
  230|       |    Cost = is_same<SrcType, DstType>::value ? 0 : NumTraits<DstType>::AddCost,
  231|       |    PacketAccess = CastingTraits::VectorizedCast && (CastingTraits::SrcCoeffRatio <= 8)
  232|       |  };
  233|       |};
  234|       |
  235|       |/** \internal
  236|       | * \brief Template functor to arithmetically shift a scalar right by a number of bits
  237|       | *
  238|       | * \sa class CwiseUnaryOp, MatrixBase::shift_right()
  239|       | */
  240|       |template <typename Scalar, int N>
  241|       |struct scalar_shift_right_op {
  242|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const {
  243|       |    return numext::arithmetic_shift_right(a);
  244|       |  }
  245|       |  template <typename Packet>
  246|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
  247|       |    return internal::parithmetic_shift_right<N>(a);
  248|       |  }
  249|       |};
  250|       |template <typename Scalar, int N>
  251|       |struct functor_traits<scalar_shift_right_op<Scalar, N>> {
  252|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasShift };
  253|       |};
  254|       |
  255|       |/** \internal
  256|       | * \brief Template functor to logically shift a scalar left by a number of bits
  257|       | *
  258|       | * \sa class CwiseUnaryOp, MatrixBase::shift_left()
  259|       | */
  260|       |template <typename Scalar, int N>
  261|       |struct scalar_shift_left_op {
  262|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const {
  263|       |    return numext::logical_shift_left(a);
  264|       |  }
  265|       |  template <typename Packet>
  266|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const {
  267|       |    return internal::plogical_shift_left<N>(a);
  268|       |  }
  269|       |};
  270|       |template <typename Scalar, int N>
  271|       |struct functor_traits<scalar_shift_left_op<Scalar, N>> {
  272|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasShift };
  273|       |};
  274|       |
  275|       |/** \internal
  276|       | * \brief Template functor to extract the real part of a complex
  277|       | *
  278|       | * \sa class CwiseUnaryOp, MatrixBase::real()
  279|       | */
  280|       |template <typename Scalar>
  281|       |struct scalar_real_op {
  282|       |  typedef typename NumTraits<Scalar>::Real result_type;
  283|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const Scalar& a) const { return numext::real(a); }
  284|       |};
  285|       |template <typename Scalar>
  286|       |struct functor_traits<scalar_real_op<Scalar>> {
  287|       |  enum { Cost = 0, PacketAccess = false };
  288|       |};
  289|       |
  290|       |/** \internal
  291|       | * \brief Template functor to extract the imaginary part of a complex
  292|       | *
  293|       | * \sa class CwiseUnaryOp, MatrixBase::imag()
  294|       | */
  295|       |template <typename Scalar>
  296|       |struct scalar_imag_op {
  297|       |  typedef typename NumTraits<Scalar>::Real result_type;
  298|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const Scalar& a) const { return numext::imag(a); }
  299|       |};
  300|       |template <typename Scalar>
  301|       |struct functor_traits<scalar_imag_op<Scalar>> {
  302|       |  enum { Cost = 0, PacketAccess = false };
  303|       |};
  304|       |
  305|       |/** \internal
  306|       | * \brief Template functor to extract the real part of a complex as a reference
  307|       | *
  308|       | * \sa class CwiseUnaryOp, MatrixBase::real()
  309|       | */
  310|       |template <typename Scalar>
  311|       |struct scalar_real_ref_op {
  312|       |  typedef typename NumTraits<Scalar>::Real result_type;
  313|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type& operator()(const Scalar& a) const {
  314|       |    return numext::real_ref(a);
  315|       |  }
  316|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type& operator()(Scalar& a) const { return numext::real_ref(a); }
  317|       |};
  318|       |template <typename Scalar>
  319|       |struct functor_traits<scalar_real_ref_op<Scalar>> {
  320|       |  enum { Cost = 0, PacketAccess = false };
  321|       |};
  322|       |
  323|       |/** \internal
  324|       | * \brief Template functor to extract the imaginary part of a complex as a reference
  325|       | *
  326|       | * \sa class CwiseUnaryOp, MatrixBase::imag()
  327|       | */
  328|       |template <typename Scalar>
  329|       |struct scalar_imag_ref_op {
  330|       |  typedef typename NumTraits<Scalar>::Real result_type;
  331|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type& operator()(Scalar& a) const { return numext::imag_ref(a); }
  332|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type& operator()(const Scalar& a) const {
  333|       |    return numext::imag_ref(a);
  334|       |  }
  335|       |};
  336|       |template <typename Scalar>
  337|       |struct functor_traits<scalar_imag_ref_op<Scalar>> {
  338|       |  enum { Cost = 0, PacketAccess = false };
  339|       |};
  340|       |
  341|       |/** \internal
  342|       | *
  343|       | * \brief Template functor to compute the exponential of a scalar
  344|       | *
  345|       | * \sa class CwiseUnaryOp, Cwise::exp()
  346|       | */
  347|       |template <typename Scalar>
  348|       |struct scalar_exp_op {
  349|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return internal::pexp(a); }
  350|       |  template <typename Packet>
  351|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  352|       |    return internal::pexp(a);
  353|       |  }
  354|       |};
  355|       |template <typename Scalar>
  356|       |struct functor_traits<scalar_exp_op<Scalar>> {
  357|       |  enum {
  358|       |    PacketAccess = packet_traits<Scalar>::HasExp,
  359|       |  // The following numbers are based on the AVX implementation.
  360|       |#ifdef EIGEN_VECTORIZE_FMA
  361|       |    // Haswell can issue 2 add/mul/madd per cycle.
  362|       |    Cost = (sizeof(Scalar) == 4
  363|       |                // float: 8 pmadd, 4 pmul, 2 padd/psub, 6 other
  364|       |                ? (8 * NumTraits<Scalar>::AddCost + 6 * NumTraits<Scalar>::MulCost)
  365|       |                // double: 7 pmadd, 5 pmul, 3 padd/psub, 1 div,  13 other
  366|       |                : (14 * NumTraits<Scalar>::AddCost + 6 * NumTraits<Scalar>::MulCost +
  367|       |                   scalar_div_cost<Scalar, packet_traits<Scalar>::HasDiv>::value))
  368|       |#else
  369|       |    Cost = (sizeof(Scalar) == 4
  370|       |                // float: 7 pmadd, 6 pmul, 4 padd/psub, 10 other
  371|       |                ? (21 * NumTraits<Scalar>::AddCost + 13 * NumTraits<Scalar>::MulCost)
  372|       |                // double: 7 pmadd, 5 pmul, 3 padd/psub, 1 div,  13 other
  373|       |                : (23 * NumTraits<Scalar>::AddCost + 12 * NumTraits<Scalar>::MulCost +
  374|       |                   scalar_div_cost<Scalar, packet_traits<Scalar>::HasDiv>::value))
  375|       |#endif
  376|       |  };
  377|       |};
  378|       |
  379|       |template <typename Scalar>
  380|       |struct scalar_exp2_op {
  381|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return internal::pexp2(a); }
  382|       |  template <typename Packet>
  383|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  384|       |    return internal::pexp2(a);
  385|       |  }
  386|       |};
  387|       |template <typename Scalar>
  388|       |struct functor_traits<scalar_exp2_op<Scalar>> {
  389|       |  enum {
  390|       |    PacketAccess = packet_traits<Scalar>::HasExp,
  391|       |    Cost = functor_traits<scalar_exp_op<Scalar>>::Cost  // TODO measure cost of exp2
  392|       |  };
  393|       |};
  394|       |
  395|       |/** \internal
  396|       | *
  397|       | * \brief Template functor to compute the exponential of a scalar - 1.
  398|       | *
  399|       | * \sa class CwiseUnaryOp, ArrayBase::expm1()
  400|       | */
  401|       |template <typename Scalar>
  402|       |struct scalar_expm1_op {
  403|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::expm1(a); }
  404|       |  template <typename Packet>
  405|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  406|       |    return internal::pexpm1(a);
  407|       |  }
  408|       |};
  409|       |template <typename Scalar>
  410|       |struct functor_traits<scalar_expm1_op<Scalar>> {
  411|       |  enum {
  412|       |    PacketAccess = packet_traits<Scalar>::HasExpm1,
  413|       |    Cost = functor_traits<scalar_exp_op<Scalar>>::Cost  // TODO measure cost of expm1
  414|       |  };
  415|       |};
  416|       |
  417|       |/** \internal
  418|       | *
  419|       | * \brief Template functor to compute the logarithm of a scalar
  420|       | *
  421|       | * \sa class CwiseUnaryOp, ArrayBase::log()
  422|       | */
  423|       |template <typename Scalar>
  424|       |struct scalar_log_op {
  425|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::log(a); }
  426|       |  template <typename Packet>
  427|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  428|       |    return internal::plog(a);
  429|       |  }
  430|       |};
  431|       |template <typename Scalar>
  432|       |struct functor_traits<scalar_log_op<Scalar>> {
  433|       |  enum {
  434|       |    PacketAccess = packet_traits<Scalar>::HasLog,
  435|       |    Cost = (PacketAccess
  436|       |  // The following numbers are based on the AVX implementation.
  437|       |#ifdef EIGEN_VECTORIZE_FMA
  438|       |                // 8 pmadd, 6 pmul, 8 padd/psub, 16 other, can issue 2 add/mul/madd per cycle.
  439|       |                ? (20 * NumTraits<Scalar>::AddCost + 7 * NumTraits<Scalar>::MulCost)
  440|       |#else
  441|       |                // 8 pmadd, 6 pmul, 8 padd/psub, 20 other
  442|       |                ? (36 * NumTraits<Scalar>::AddCost + 14 * NumTraits<Scalar>::MulCost)
  443|       |#endif
  444|       |                // Measured cost of std::log.
  445|       |                : sizeof(Scalar) == 4 ? 40 : 85)
  446|       |  };
  447|       |};
  448|       |
  449|       |/** \internal
  450|       | *
  451|       | * \brief Template functor to compute the logarithm of 1 plus a scalar value
  452|       | *
  453|       | * \sa class CwiseUnaryOp, ArrayBase::log1p()
  454|       | */
  455|       |template <typename Scalar>
  456|       |struct scalar_log1p_op {
  457|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::log1p(a); }
  458|       |  template <typename Packet>
  459|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  460|       |    return internal::plog1p(a);
  461|       |  }
  462|       |};
  463|       |template <typename Scalar>
  464|       |struct functor_traits<scalar_log1p_op<Scalar>> {
  465|       |  enum {
  466|       |    PacketAccess = packet_traits<Scalar>::HasLog1p,
  467|       |    Cost = functor_traits<scalar_log_op<Scalar>>::Cost  // TODO measure cost of log1p
  468|       |  };
  469|       |};
  470|       |
  471|       |/** \internal
  472|       | *
  473|       | * \brief Template functor to compute the base-10 logarithm of a scalar
  474|       | *
  475|       | * \sa class CwiseUnaryOp, Cwise::log10()
  476|       | */
  477|       |template <typename Scalar>
  478|       |struct scalar_log10_op {
  479|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { EIGEN_USING_STD(log10) return log10(a); }
  480|       |  template <typename Packet>
  481|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  482|       |    return internal::plog10(a);
  483|       |  }
  484|       |};
  485|       |template <typename Scalar>
  486|       |struct functor_traits<scalar_log10_op<Scalar>> {
  487|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasLog10 };
  488|       |};
  489|       |
  490|       |/** \internal
  491|       | *
  492|       | * \brief Template functor to compute the base-2 logarithm of a scalar
  493|       | *
  494|       | * \sa class CwiseUnaryOp, Cwise::log2()
  495|       | */
  496|       |template <typename Scalar>
  497|       |struct scalar_log2_op {
  498|       |  using RealScalar = typename NumTraits<Scalar>::Real;
  499|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const {
  500|       |    return Scalar(RealScalar(EIGEN_LOG2E)) * numext::log(a);
  501|       |  }
  502|       |  template <typename Packet>
  503|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  504|       |    return internal::plog2(a);
  505|       |  }
  506|       |};
  507|       |template <typename Scalar>
  508|       |struct functor_traits<scalar_log2_op<Scalar>> {
  509|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasLog };
  510|       |};
  511|       |
  512|       |/** \internal
  513|       | * \brief Template functor to compute the square root of a scalar
  514|       | * \sa class CwiseUnaryOp, Cwise::sqrt()
  515|       | */
  516|       |template <typename Scalar>
  517|       |struct scalar_sqrt_op {
  518|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::sqrt(a); }
  519|       |  template <typename Packet>
  520|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  521|       |    return internal::psqrt(a);
  522|       |  }
  523|       |};
  524|       |template <typename Scalar>
  525|       |struct functor_traits<scalar_sqrt_op<Scalar>> {
  526|       |  enum {
  527|       |#if EIGEN_FAST_MATH
  528|       |    // The following numbers are based on the AVX implementation.
  529|       |    Cost = (sizeof(Scalar) == 8 ? 28
  530|       |                                // 4 pmul, 1 pmadd, 3 other
  531|       |                                : (3 * NumTraits<Scalar>::AddCost + 5 * NumTraits<Scalar>::MulCost)),
  532|       |#else
  533|       |    // The following numbers are based on min VSQRT throughput on Haswell.
  534|       |    Cost = (sizeof(Scalar) == 8 ? 28 : 14),
  535|       |#endif
  536|       |    PacketAccess = packet_traits<Scalar>::HasSqrt
  537|       |  };
  538|       |};
  539|       |
  540|       |// Boolean specialization to eliminate -Wimplicit-conversion-floating-point-to-bool warnings.
  541|       |template <>
  542|       |struct scalar_sqrt_op<bool> {
  543|      0|  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline bool operator()(const bool& a) const { return a; }
  544|       |  template <typename Packet>
  545|       |  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  546|       |    return a;
  547|       |  }
  548|       |};
  549|       |template <>
  550|       |struct functor_traits<scalar_sqrt_op<bool>> {
  551|       |  enum { Cost = 1, PacketAccess = packet_traits<bool>::Vectorizable };
  552|       |};
  553|       |
  554|       |/** \internal
  555|       | * \brief Template functor to compute the cube root of a scalar
  556|       | * \sa class CwiseUnaryOp, Cwise::sqrt()
  557|       | */
  558|       |template <typename Scalar>
  559|       |struct scalar_cbrt_op {
  560|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::cbrt(a); }
  561|       |};
  562|       |
  563|       |template <typename Scalar>
  564|       |struct functor_traits<scalar_cbrt_op<Scalar>> {
  565|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = false };
  566|       |};
  567|       |
  568|       |/** \internal
  569|       | * \brief Template functor to compute the reciprocal square root of a scalar
  570|       | * \sa class CwiseUnaryOp, Cwise::rsqrt()
  571|       | */
  572|       |template <typename Scalar>
  573|       |struct scalar_rsqrt_op {
  574|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::rsqrt(a); }
  575|       |  template <typename Packet>
  576|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  577|       |    return internal::prsqrt(a);
  578|       |  }
  579|       |};
  580|       |
  581|       |template <typename Scalar>
  582|       |struct functor_traits<scalar_rsqrt_op<Scalar>> {
  583|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasRsqrt };
  584|       |};
  585|       |
  586|       |/** \internal
  587|       | * \brief Template functor to compute the cosine of a scalar
  588|       | * \sa class CwiseUnaryOp, ArrayBase::cos()
  589|       | */
  590|       |template <typename Scalar>
  591|       |struct scalar_cos_op {
  592|       |  EIGEN_DEVICE_FUNC inline Scalar operator()(const Scalar& a) const { return numext::cos(a); }
  593|       |  template <typename Packet>
  594|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  595|       |    return internal::pcos(a);
  596|       |  }
  597|       |};
  598|       |template <typename Scalar>
  599|       |struct functor_traits<scalar_cos_op<Scalar>> {
  600|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasCos };
  601|       |};
  602|       |
  603|       |/** \internal
  604|       | * \brief Template functor to compute the sine of a scalar
  605|       | * \sa class CwiseUnaryOp, ArrayBase::sin()
  606|       | */
  607|       |template <typename Scalar>
  608|       |struct scalar_sin_op {
  609|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::sin(a); }
  610|       |  template <typename Packet>
  611|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  612|       |    return internal::psin(a);
  613|       |  }
  614|       |};
  615|       |template <typename Scalar>
  616|       |struct functor_traits<scalar_sin_op<Scalar>> {
  617|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasSin };
  618|       |};
  619|       |
  620|       |/** \internal
  621|       | * \brief Template functor to compute the tan of a scalar
  622|       | * \sa class CwiseUnaryOp, ArrayBase::tan()
  623|       | */
  624|       |template <typename Scalar>
  625|       |struct scalar_tan_op {
  626|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::tan(a); }
  627|       |  template <typename Packet>
  628|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  629|       |    return internal::ptan(a);
  630|       |  }
  631|       |};
  632|       |template <typename Scalar>
  633|       |struct functor_traits<scalar_tan_op<Scalar>> {
  634|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasTan };
  635|       |};
  636|       |
  637|       |/** \internal
  638|       | * \brief Template functor to compute the arc cosine of a scalar
  639|       | * \sa class CwiseUnaryOp, ArrayBase::acos()
  640|       | */
  641|       |template <typename Scalar>
  642|       |struct scalar_acos_op {
  643|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::acos(a); }
  644|       |  template <typename Packet>
  645|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  646|       |    return internal::pacos(a);
  647|       |  }
  648|       |};
  649|       |template <typename Scalar>
  650|       |struct functor_traits<scalar_acos_op<Scalar>> {
  651|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasACos };
  652|       |};
  653|       |
  654|       |/** \internal
  655|       | * \brief Template functor to compute the arc sine of a scalar
  656|       | * \sa class CwiseUnaryOp, ArrayBase::asin()
  657|       | */
  658|       |template <typename Scalar>
  659|       |struct scalar_asin_op {
  660|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::asin(a); }
  661|       |  template <typename Packet>
  662|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  663|       |    return internal::pasin(a);
  664|       |  }
  665|       |};
  666|       |template <typename Scalar>
  667|       |struct functor_traits<scalar_asin_op<Scalar>> {
  668|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasASin };
  669|       |};
  670|       |
  671|       |/** \internal
  672|       | * \brief Template functor to compute the atan of a scalar
  673|       | * \sa class CwiseUnaryOp, ArrayBase::atan()
  674|       | */
  675|       |template <typename Scalar>
  676|       |struct scalar_atan_op {
  677|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::atan(a); }
  678|       |  template <typename Packet>
  679|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  680|       |    return internal::patan(a);
  681|       |  }
  682|       |};
  683|       |template <typename Scalar>
  684|       |struct functor_traits<scalar_atan_op<Scalar>> {
  685|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasATan };
  686|       |};
  687|       |
  688|       |/** \internal
  689|       | * \brief Template functor to compute the tanh of a scalar
  690|       | * \sa class CwiseUnaryOp, ArrayBase::tanh()
  691|       | */
  692|       |template <typename Scalar>
  693|       |struct scalar_tanh_op {
  694|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::tanh(a); }
  695|       |  template <typename Packet>
  696|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& x) const {
  697|       |    return ptanh(x);
  698|       |  }
  699|       |};
  700|       |
  701|       |template <typename Scalar>
  702|       |struct functor_traits<scalar_tanh_op<Scalar>> {
  703|       |  enum {
  704|       |    PacketAccess = packet_traits<Scalar>::HasTanh,
  705|       |    Cost = ((EIGEN_FAST_MATH && is_same<Scalar, float>::value)
  706|       |// The following numbers are based on the AVX implementation,
  707|       |#ifdef EIGEN_VECTORIZE_FMA
  708|       |                // Haswell can issue 2 add/mul/madd per cycle.
  709|       |                // 9 pmadd, 2 pmul, 1 div, 2 other
  710|       |                ? (2 * NumTraits<Scalar>::AddCost + 6 * NumTraits<Scalar>::MulCost +
  711|       |                   scalar_div_cost<Scalar, packet_traits<Scalar>::HasDiv>::value)
  712|       |#else
  713|       |                ? (11 * NumTraits<Scalar>::AddCost + 11 * NumTraits<Scalar>::MulCost +
  714|       |                   scalar_div_cost<Scalar, packet_traits<Scalar>::HasDiv>::value)
  715|       |#endif
  716|       |                // This number assumes a naive implementation of tanh
  717|       |                : (6 * NumTraits<Scalar>::AddCost + 3 * NumTraits<Scalar>::MulCost +
  718|       |                   2 * scalar_div_cost<Scalar, packet_traits<Scalar>::HasDiv>::value +
  719|       |                   functor_traits<scalar_exp_op<Scalar>>::Cost))
  720|       |  };
  721|       |};
  722|       |
  723|       |/** \internal
  724|       | * \brief Template functor to compute the atanh of a scalar
  725|       | * \sa class CwiseUnaryOp, ArrayBase::atanh()
  726|       | */
  727|       |template <typename Scalar>
  728|       |struct scalar_atanh_op {
  729|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::atanh(a); }
  730|       |  template <typename Packet>
  731|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& x) const {
  732|       |    return patanh(x);
  733|       |  }
  734|       |};
  735|       |
  736|       |template <typename Scalar>
  737|       |struct functor_traits<scalar_atanh_op<Scalar>> {
  738|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasATanh };
  739|       |};
  740|       |
  741|       |/** \internal
  742|       | * \brief Template functor to compute the sinh of a scalar
  743|       | * \sa class CwiseUnaryOp, ArrayBase::sinh()
  744|       | */
  745|       |template <typename Scalar>
  746|       |struct scalar_sinh_op {
  747|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::sinh(a); }
  748|       |  template <typename Packet>
  749|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  750|       |    return internal::psinh(a);
  751|       |  }
  752|       |};
  753|       |template <typename Scalar>
  754|       |struct functor_traits<scalar_sinh_op<Scalar>> {
  755|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasSinh };
  756|       |};
  757|       |
  758|       |/** \internal
  759|       | * \brief Template functor to compute the asinh of a scalar
  760|       | * \sa class CwiseUnaryOp, ArrayBase::asinh()
  761|       | */
  762|       |template <typename Scalar>
  763|       |struct scalar_asinh_op {
  764|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::asinh(a); }
  765|       |};
  766|       |
  767|       |template <typename Scalar>
  768|       |struct functor_traits<scalar_asinh_op<Scalar>> {
  769|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = false };
  770|       |};
  771|       |
  772|       |/** \internal
  773|       | * \brief Template functor to compute the cosh of a scalar
  774|       | * \sa class CwiseUnaryOp, ArrayBase::cosh()
  775|       | */
  776|       |template <typename Scalar>
  777|       |struct scalar_cosh_op {
  778|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::cosh(a); }
  779|       |  template <typename Packet>
  780|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  781|       |    return internal::pcosh(a);
  782|       |  }
  783|       |};
  784|       |template <typename Scalar>
  785|       |struct functor_traits<scalar_cosh_op<Scalar>> {
  786|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasCosh };
  787|       |};
  788|       |
  789|       |/** \internal
  790|       | * \brief Template functor to compute the acosh of a scalar
  791|       | * \sa class CwiseUnaryOp, ArrayBase::acosh()
  792|       | */
  793|       |template <typename Scalar>
  794|       |struct scalar_acosh_op {
  795|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::acosh(a); }
  796|       |};
  797|       |
  798|       |template <typename Scalar>
  799|       |struct functor_traits<scalar_acosh_op<Scalar>> {
  800|       |  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = false };
  801|       |};
  802|       |
  803|       |/** \internal
  804|       | * \brief Template functor to compute the inverse of a scalar
  805|       | * \sa class CwiseUnaryOp, Cwise::inverse()
  806|       | */
  807|       |template <typename Scalar>
  808|       |struct scalar_inverse_op {
  809|       |  EIGEN_DEVICE_FUNC inline Scalar operator()(const Scalar& a) const { return Scalar(1) / a; }
  810|       |  template <typename Packet>
  811|       |  EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const {
  812|       |    return internal::preciprocal(a);
  813|       |  }
  814|       |};
  815|       |template <typename Scalar>
  816|       |struct functor_traits<scalar_inverse_op<Scalar>> {
  817|       |  enum {
  818|       |    PacketAccess = packet_traits<Scalar>::HasDiv,
  819|       |    // If packet_traits<Scalar>::HasReciprocal then the Estimated cost is that
  820|       |    // of computing an approximation plus a single Newton-Raphson step, which
  821|       |    // consists of 1 pmul + 1 pmadd.
  822|       |    Cost = (packet_traits<Scalar>::HasReciprocal ? 4 * NumTraits<Scalar>::MulCost
  823|       |                                                 : scalar_div_cost<Scalar, PacketAccess>::value)
  824|       |  };
  825|       |};
  826|       |
  827|       |/** \internal
  828|       | * \brief Template functor to compute the square of a scalar
  829|       | * \sa class CwiseUnaryOp, Cwise::square()
  830|       | */
  831|       |template <typename Scalar>
  832|       |struct scalar_square_op {
  833|       |  EIGEN_DEVICE_FUNC inline Scalar operator()(const Scalar& a) const { return a * a; }
  834|       |  template <typename Packet>
  835|       |  EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const {
  836|       |    return internal::pmul(a, a);
  837|       |  }
  838|       |};
  839|       |template <typename Scalar>
  840|       |struct functor_traits<scalar_square_op<Scalar>> {
  841|       |  enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasMul };
  842|       |};
  843|       |
  844|       |// Boolean specialization to avoid -Wint-in-bool-context warnings on GCC.
  845|       |template <>
  846|       |struct scalar_square_op<bool> {
  847|      0|  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline bool operator()(const bool& a) const { return a; }
  848|       |  template <typename Packet>
  849|       |  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const {
  850|       |    return a;
  851|       |  }
  852|       |};
  853|       |template <>
  854|       |struct functor_traits<scalar_square_op<bool>> {
  855|       |  enum { Cost = 0, PacketAccess = packet_traits<bool>::Vectorizable };
  856|       |};
  857|       |
  858|       |/** \internal
  859|       | * \brief Template functor to compute the cube of a scalar
  860|       | * \sa class CwiseUnaryOp, Cwise::cube()
  861|       | */
  862|       |template <typename Scalar>
  863|       |struct scalar_cube_op {
  864|       |  EIGEN_DEVICE_FUNC inline Scalar operator()(const Scalar& a) const { return a * a * a; }
  865|       |  template <typename Packet>
  866|       |  EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const {
  867|       |    return internal::pmul(a, pmul(a, a));
  868|       |  }
  869|       |};
  870|       |template <typename Scalar>
  871|       |struct functor_traits<scalar_cube_op<Scalar>> {
  872|       |  enum { Cost = 2 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasMul };
  873|       |};
  874|       |
  875|       |// Boolean specialization to avoid -Wint-in-bool-context warnings on GCC.
  876|       |template <>
  877|       |struct scalar_cube_op<bool> {
  878|      0|  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline bool operator()(const bool& a) const { return a; }
  879|       |  template <typename Packet>
  880|       |  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const {
  881|       |    return a;
  882|       |  }
  883|       |};
  884|       |template <>
  885|       |struct functor_traits<scalar_cube_op<bool>> {
  886|       |  enum { Cost = 0, PacketAccess = packet_traits<bool>::Vectorizable };
  887|       |};
  888|       |
  889|       |/** \internal
  890|       | * \brief Template functor to compute the rounded value of a scalar
  891|       | * \sa class CwiseUnaryOp, ArrayBase::round()
  892|       | */
  893|       |template <typename Scalar>
  894|       |struct scalar_round_op {
  895|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const { return numext::round(a); }
  896|       |  template <typename Packet>
  897|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  898|       |    return internal::pround(a);
  899|       |  }
  900|       |};
  901|       |template <typename Scalar>
  902|       |struct functor_traits<scalar_round_op<Scalar>> {
  903|       |  enum {
  904|       |    Cost = NumTraits<Scalar>::MulCost,
  905|       |    PacketAccess = packet_traits<Scalar>::HasRound || NumTraits<Scalar>::IsInteger
  906|       |  };
  907|       |};
  908|       |
  909|       |/** \internal
  910|       | * \brief Template functor to compute the floor of a scalar
  911|       | * \sa class CwiseUnaryOp, ArrayBase::floor()
  912|       | */
  913|       |template <typename Scalar>
  914|       |struct scalar_floor_op {
  915|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const { return numext::floor(a); }
  916|       |  template <typename Packet>
  917|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  918|       |    return internal::pfloor(a);
  919|       |  }
  920|       |};
  921|       |template <typename Scalar>
  922|       |struct functor_traits<scalar_floor_op<Scalar>> {
  923|       |  enum {
  924|       |    Cost = NumTraits<Scalar>::MulCost,
  925|       |    PacketAccess = packet_traits<Scalar>::HasRound || NumTraits<Scalar>::IsInteger
  926|       |  };
  927|       |};
  928|       |
  929|       |/** \internal
  930|       | * \brief Template functor to compute the rounded (with current rounding mode)  value of a scalar
  931|       | * \sa class CwiseUnaryOp, ArrayBase::rint()
  932|       | */
  933|       |template <typename Scalar>
  934|       |struct scalar_rint_op {
  935|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const { return numext::rint(a); }
  936|       |  template <typename Packet>
  937|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  938|       |    return internal::print(a);
  939|       |  }
  940|       |};
  941|       |template <typename Scalar>
  942|       |struct functor_traits<scalar_rint_op<Scalar>> {
  943|       |  enum {
  944|       |    Cost = NumTraits<Scalar>::MulCost,
  945|       |    PacketAccess = packet_traits<Scalar>::HasRound || NumTraits<Scalar>::IsInteger
  946|       |  };
  947|       |};
  948|       |
  949|       |/** \internal
  950|       | * \brief Template functor to compute the ceil of a scalar
  951|       | * \sa class CwiseUnaryOp, ArrayBase::ceil()
  952|       | */
  953|       |template <typename Scalar>
  954|       |struct scalar_ceil_op {
  955|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const { return numext::ceil(a); }
  956|       |  template <typename Packet>
  957|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  958|       |    return internal::pceil(a);
  959|       |  }
  960|       |};
  961|       |template <typename Scalar>
  962|       |struct functor_traits<scalar_ceil_op<Scalar>> {
  963|       |  enum {
  964|       |    Cost = NumTraits<Scalar>::MulCost,
  965|       |    PacketAccess = packet_traits<Scalar>::HasRound || NumTraits<Scalar>::IsInteger
  966|       |  };
  967|       |};
  968|       |
  969|       |/** \internal
  970|       | * \brief Template functor to compute the truncation of a scalar
  971|       | * \sa class CwiseUnaryOp, ArrayBase::floor()
  972|       | */
  973|       |template <typename Scalar>
  974|       |struct scalar_trunc_op {
  975|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator()(const Scalar& a) const { return numext::trunc(a); }
  976|       |  template <typename Packet>
  977|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
  978|       |    return internal::ptrunc(a);
  979|       |  }
  980|       |};
  981|       |template <typename Scalar>
  982|       |struct functor_traits<scalar_trunc_op<Scalar>> {
  983|       |  enum {
  984|       |    Cost = NumTraits<Scalar>::MulCost,
  985|       |    PacketAccess = packet_traits<Scalar>::HasRound || NumTraits<Scalar>::IsInteger
  986|       |  };
  987|       |};
  988|       |
  989|       |/** \internal
  990|       | * \brief Template functor to compute whether a scalar is NaN
  991|       | * \sa class CwiseUnaryOp, ArrayBase::isnan()
  992|       | */
  993|       |template <typename Scalar, bool UseTypedPredicate = false>
  994|       |struct scalar_isnan_op {
  995|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool operator()(const Scalar& a) const {
  996|       |#if defined(SYCL_DEVICE_ONLY)
  997|       |    return numext::isnan(a);
  998|       |#else
  999|       |    return numext::isnan EIGEN_NOT_A_MACRO(a);
 1000|       |#endif
 1001|       |  }
 1002|       |};
 1003|       |
 1004|       |template <typename Scalar>
 1005|       |struct scalar_isnan_op<Scalar, true> {
 1006|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a) const {
 1007|       |#if defined(SYCL_DEVICE_ONLY)
 1008|       |    return (numext::isnan(a) ? ptrue(a) : pzero(a));
 1009|       |#else
 1010|       |    return (numext::isnan EIGEN_NOT_A_MACRO(a) ? ptrue(a) : pzero(a));
 1011|       |#endif
 1012|       |  }
 1013|       |  template <typename Packet>
 1014|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
 1015|       |    return pisnan(a);
 1016|       |  }
 1017|       |};
 1018|       |
 1019|       |template <typename Scalar, bool UseTypedPredicate>
 1020|       |struct functor_traits<scalar_isnan_op<Scalar, UseTypedPredicate>> {
 1021|       |  enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasCmp && UseTypedPredicate };
 1022|       |};
 1023|       |
 1024|       |/** \internal
 1025|       | * \brief Template functor to check whether a scalar is +/-inf
 1026|       | * \sa class CwiseUnaryOp, ArrayBase::isinf()
 1027|       | */
 1028|       |template <typename Scalar, bool UseTypedPredicate = false>
 1029|       |struct scalar_isinf_op {
 1030|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool operator()(const Scalar& a) const {
 1031|       |#if defined(SYCL_DEVICE_ONLY)
 1032|       |    return numext::isinf(a);
 1033|       |#else
 1034|       |    return (numext::isinf)(a);
 1035|       |#endif
 1036|       |  }
 1037|       |};
 1038|       |
 1039|       |template <typename Scalar>
 1040|       |struct scalar_isinf_op<Scalar, true> {
 1041|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a) const {
 1042|       |#if defined(SYCL_DEVICE_ONLY)
 1043|       |    return (numext::isinf(a) ? ptrue(a) : pzero(a));
 1044|       |#else
 1045|       |    return (numext::isinf EIGEN_NOT_A_MACRO(a) ? ptrue(a) : pzero(a));
 1046|       |#endif
 1047|       |  }
 1048|       |  template <typename Packet>
 1049|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
 1050|       |    return pisinf(a);
 1051|       |  }
 1052|       |};
 1053|       |template <typename Scalar, bool UseTypedPredicate>
 1054|       |struct functor_traits<scalar_isinf_op<Scalar, UseTypedPredicate>> {
 1055|       |  enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasCmp && UseTypedPredicate };
 1056|       |};
 1057|       |
 1058|       |/** \internal
 1059|       | * \brief Template functor to check whether a scalar has a finite value
 1060|       | * \sa class CwiseUnaryOp, ArrayBase::isfinite()
 1061|       | */
 1062|       |template <typename Scalar, bool UseTypedPredicate = false>
 1063|       |struct scalar_isfinite_op {
 1064|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool operator()(const Scalar& a) const {
 1065|       |#if defined(SYCL_DEVICE_ONLY)
 1066|       |    return numext::isfinite(a);
 1067|       |#else
 1068|       |    return (numext::isfinite)(a);
 1069|       |#endif
 1070|       |  }
 1071|       |};
 1072|       |
 1073|       |template <typename Scalar>
 1074|       |struct scalar_isfinite_op<Scalar, true> {
 1075|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a) const {
 1076|       |#if defined(SYCL_DEVICE_ONLY)
 1077|       |    return (numext::isfinite(a) ? ptrue(a) : pzero(a));
 1078|       |#else
 1079|       |    return (numext::isfinite EIGEN_NOT_A_MACRO(a) ? ptrue(a) : pzero(a));
 1080|       |#endif
 1081|       |  }
 1082|       |  template <typename Packet>
 1083|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
 1084|       |    constexpr Scalar inf = NumTraits<Scalar>::infinity();
 1085|       |    return pcmp_lt(pabs(a), pset1<Packet>(inf));
 1086|       |  }
 1087|       |};
 1088|       |template <typename Scalar, bool UseTypedPredicate>
 1089|       |struct functor_traits<scalar_isfinite_op<Scalar, UseTypedPredicate>> {
 1090|       |  enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasCmp && UseTypedPredicate };
 1091|       |};
 1092|       |
 1093|       |/** \internal
 1094|       | * \brief Template functor to compute the logical not of a scalar as if it were a boolean
 1095|       | *
 1096|       | * \sa class CwiseUnaryOp, ArrayBase::operator!
 1097|       | */
 1098|       |template <typename Scalar>
 1099|       |struct scalar_boolean_not_op {
 1100|       |  using result_type = Scalar;
 1101|       |  // `false` any value `a` that satisfies `a == Scalar(0)`
 1102|       |  // `true` is the complement of `false`
 1103|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a) const {
 1104|       |    return a == Scalar(0) ? Scalar(1) : Scalar(0);
 1105|       |  }
 1106|       |  template <typename Packet>
 1107|       |  EIGEN_STRONG_INLINE Packet packetOp(const Packet& a) const {
 1108|       |    const Packet cst_one = pset1<Packet>(Scalar(1));
 1109|       |    Packet not_a = pcmp_eq(a, pzero(a));
 1110|       |    return pand(not_a, cst_one);
 1111|       |  }
 1112|       |};
 1113|       |template <typename Scalar>
 1114|       |struct functor_traits<scalar_boolean_not_op<Scalar>> {
 1115|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasCmp };
 1116|       |};
 1117|       |
 1118|       |template <typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
 1119|       |struct bitwise_unary_impl {
 1120|       |  static constexpr size_t Size = sizeof(Scalar);
 1121|       |  using uint_t = typename numext::get_integer_by_size<Size>::unsigned_type;
 1122|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_not(const Scalar& a) {
 1123|       |    uint_t a_as_uint = numext::bit_cast<uint_t, Scalar>(a);
 1124|       |    uint_t result = ~a_as_uint;
 1125|       |    return numext::bit_cast<Scalar, uint_t>(result);
 1126|       |  }
 1127|       |};
 1128|       |
 1129|       |template <typename Scalar>
 1130|       |struct bitwise_unary_impl<Scalar, true> {
 1131|       |  using Real = typename NumTraits<Scalar>::Real;
 1132|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar run_not(const Scalar& a) {
 1133|       |    Real real_result = bitwise_unary_impl<Real>::run_not(numext::real(a));
 1134|       |    Real imag_result = bitwise_unary_impl<Real>::run_not(numext::imag(a));
 1135|       |    return Scalar(real_result, imag_result);
 1136|       |  }
 1137|       |};
 1138|       |
 1139|       |/** \internal
 1140|       | * \brief Template functor to compute the bitwise not of a scalar
 1141|       | *
 1142|       | * \sa class CwiseUnaryOp, ArrayBase::operator~
 1143|       | */
 1144|       |template <typename Scalar>
 1145|       |struct scalar_bitwise_not_op {
 1146|       |  EIGEN_STATIC_ASSERT(!NumTraits<Scalar>::RequireInitialization,
 1147|       |                      BITWISE OPERATIONS MAY ONLY BE PERFORMED ON PLAIN DATA TYPES)
 1148|       |  EIGEN_STATIC_ASSERT((!internal::is_same<Scalar, bool>::value), DONT USE BITWISE OPS ON BOOLEAN TYPES)
 1149|       |  using result_type = Scalar;
 1150|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a) const {
 1151|       |    return bitwise_unary_impl<Scalar>::run_not(a);
 1152|       |  }
 1153|       |  template <typename Packet>
 1154|       |  EIGEN_STRONG_INLINE Packet packetOp(const Packet& a) const {
 1155|       |    return pandnot(ptrue(a), a);
 1156|       |  }
 1157|       |};
 1158|       |template <typename Scalar>
 1159|       |struct functor_traits<scalar_bitwise_not_op<Scalar>> {
 1160|       |  enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = true };
 1161|       |};
 1162|       |
 1163|       |/** \internal
 1164|       | * \brief Template functor to compute the signum of a scalar
 1165|       | * \sa class CwiseUnaryOp, Cwise::sign()
 1166|       | */
 1167|       |template <typename Scalar>
 1168|       |struct scalar_sign_op {
 1169|       |  EIGEN_DEVICE_FUNC inline const Scalar operator()(const Scalar& a) const { return numext::sign(a); }
 1170|       |
 1171|       |  template <typename Packet>
 1172|       |  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const {
 1173|       |    return internal::psign(a);
 1174|       |  }
 1175|       |};
 1176|       |
 1177|       |template <typename Scalar>
 1178|       |struct functor_traits<scalar_sign_op<Scalar>> {
 1179|       |  enum {
 1180|       |    Cost = NumTraits<Scalar>::IsComplex ? (8 * NumTraits<Scalar>::MulCost)  // roughly
 1181|       |                                        : (3 * NumTraits<Scalar>::AddCost),
 1182|       |    PacketAccess = packet_traits<Scalar>::HasSign && packet_traits<Scalar>::Vectorizable
 1183|       |  };
 1184|       |};
 1185|       |
 1186|       |// Real-valued implementation.
 1187|       |template <typename T, typename EnableIf = void>
 1188|       |struct scalar_logistic_op_impl {
 1189|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T operator()(const T& x) const { return packetOp(x); }
 1190|       |
 1191|       |  template <typename Packet>
 1192|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& x) const {
 1193|       |    const Packet one = pset1<Packet>(T(1));
 1194|       |    const Packet inf = pset1<Packet>(NumTraits<T>::infinity());
 1195|       |    const Packet e = pexp(x);
 1196|       |    const Packet inf_mask = pcmp_eq(e, inf);
 1197|       |    return pselect(inf_mask, one, pdiv(e, padd(one, e)));
 1198|       |  }
 1199|       |};
 1200|       |
 1201|       |// Complex-valud implementation.
 1202|       |template <typename T>
 1203|       |struct scalar_logistic_op_impl<T, std::enable_if_t<NumTraits<T>::IsComplex>> {
 1204|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T operator()(const T& x) const {
 1205|       |    const T e = numext::exp(x);
 1206|       |    return (numext::isinf)(numext::real(e)) ? T(1) : e / (e + T(1));
 1207|       |  }
 1208|       |};
 1209|       |
 1210|       |/** \internal
 1211|       | * \brief Template functor to compute the logistic function of a scalar
 1212|       | * \sa class CwiseUnaryOp, ArrayBase::logistic()
 1213|       | */
 1214|       |template <typename T>
 1215|       |struct scalar_logistic_op : scalar_logistic_op_impl<T> {};
 1216|       |
 1217|       |// TODO(rmlarsen): Enable the following on host when integer_packet is defined
 1218|       |// for the relevant packet types.
 1219|       |#ifndef EIGEN_GPUCC
 1220|       |
 1221|       |/** \internal
 1222|       | * \brief Template specialization of the logistic function for float.
 1223|       | * Computes S(x) = exp(x) / (1 + exp(x)), where exp(x) is implemented
 1224|       | * using an algorithm partly adopted from the implementation of
 1225|       | * pexp_float. See the individual steps described in the code below.
 1226|       | * Note that compared to pexp, we use an additional outer multiplicative
 1227|       | * range reduction step using the identity exp(x) = exp(x/2)^2.
 1228|       | * This prevert us from having to call ldexp on values that could produce
 1229|       | * a denormal result, which allows us to call the faster implementation in
 1230|       | * pldexp_fast_impl<Packet>::run(p, m).
 1231|       | * The final squaring, however, doubles the error bound on the final
 1232|       | * approximation. Exhaustive testing shows that we have a worst case error
 1233|       | * of 4.5 ulps (compared to computing S(x) in double precision), which is
 1234|       | * acceptable.
 1235|       | */
 1236|       |template <>
 1237|       |struct scalar_logistic_op<float> {
 1238|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float operator()(const float& x) const {
 1239|      0|    // Truncate at the first point where the interpolant is exactly one.
 1240|      0|    const float cst_exp_hi = 16.6355324f;
 1241|      0|    const float e = numext::exp(numext::mini(x, cst_exp_hi));
 1242|      0|    return e / (1.0f + e);
 1243|      0|  }
 1244|       |
 1245|       |  template <typename Packet>
 1246|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& _x) const {
 1247|       |    const Packet cst_zero = pset1<Packet>(0.0f);
 1248|       |    const Packet cst_one = pset1<Packet>(1.0f);
 1249|       |    const Packet cst_half = pset1<Packet>(0.5f);
 1250|       |    // Truncate at the first point where the interpolant is exactly one.
 1251|       |    const Packet cst_exp_hi = pset1<Packet>(16.6355324f);
 1252|       |    const Packet cst_exp_lo = pset1<Packet>(-104.f);
 1253|       |
 1254|       |    // Clamp x to the non-trivial range where S(x). Outside this
 1255|       |    // interval the correctly rounded value of S(x) is either zero
 1256|       |    // or one.
 1257|       |    Packet zero_mask = pcmp_lt(_x, cst_exp_lo);
 1258|       |    Packet x = pmin(_x, cst_exp_hi);
 1259|       |
 1260|       |    // 1. Multiplicative range reduction:
 1261|       |    // Reduce the range of x by a factor of 2. This avoids having
 1262|       |    // to compute exp(x) accurately where the result is a denormalized
 1263|       |    // value.
 1264|       |    x = pmul(x, cst_half);
 1265|       |
 1266|       |    // 2. Subtractive range reduction:
 1267|       |    // Express exp(x) as exp(m*ln(2) + r) = 2^m*exp(r), start by extracting
 1268|       |    // m = floor(x/ln(2) + 0.5), such that x = m*ln(2) + r.
 1269|       |    const Packet cst_cephes_LOG2EF = pset1<Packet>(1.44269504088896341f);
 1270|       |    Packet m = pfloor(pmadd(x, cst_cephes_LOG2EF, cst_half));
 1271|       |    // Get r = x - m*ln(2). We use a trick from Cephes where the term
 1272|       |    // m*ln(2) is subtracted out in two parts, m*C1+m*C2 = m*ln(2),
 1273|       |    // to avoid accumulating truncation errors.
 1274|       |    const Packet cst_cephes_exp_C1 = pset1<Packet>(-0.693359375f);
 1275|       |    const Packet cst_cephes_exp_C2 = pset1<Packet>(2.12194440e-4f);
 1276|       |    Packet r = pmadd(m, cst_cephes_exp_C1, x);
 1277|       |    r = pmadd(m, cst_cephes_exp_C2, r);
 1278|       |
 1279|       |    // 3. Compute an approximation to exp(r) using a degree 5 minimax polynomial.
 1280|       |    // We compute even and odd terms separately to increase instruction level
 1281|       |    // parallelism.
 1282|       |    Packet r2 = pmul(r, r);
 1283|       |    const Packet cst_p2 = pset1<Packet>(0.49999141693115234375f);
 1284|       |    const Packet cst_p3 = pset1<Packet>(0.16666877269744873046875f);
 1285|       |    const Packet cst_p4 = pset1<Packet>(4.1898667812347412109375e-2f);
 1286|       |    const Packet cst_p5 = pset1<Packet>(8.33471305668354034423828125e-3f);
 1287|       |
 1288|       |    const Packet p_even = pmadd(r2, cst_p4, cst_p2);
 1289|       |    const Packet p_odd = pmadd(r2, cst_p5, cst_p3);
 1290|       |    const Packet p_low = padd(r, cst_one);
 1291|       |    Packet p = pmadd(r, p_odd, p_even);
 1292|       |    p = pmadd(r2, p, p_low);
 1293|       |
 1294|       |    // 4. Undo subtractive range reduction exp(m*ln(2) + r) = 2^m * exp(r).
 1295|       |    Packet e = pldexp_fast(p, m);
 1296|       |
 1297|       |    // 5. Undo multiplicative range reduction by using exp(r) = exp(r/2)^2.
 1298|       |    e = pmul(e, e);
 1299|       |
 1300|       |    // Return exp(x) / (1 + exp(x))
 1301|       |    return pselect(zero_mask, cst_zero, pdiv(e, padd(cst_one, e)));
 1302|       |  }
 1303|       |};
 1304|       |#endif  // #ifndef EIGEN_GPU_COMPILE_PHASE
 1305|       |
 1306|       |template <typename T>
 1307|       |struct functor_traits<scalar_logistic_op<T>> {
 1308|       |  enum {
 1309|       |    // The cost estimate for float here here is for the common(?) case where
 1310|       |    // all arguments are greater than -9.
 1311|       |    Cost = scalar_div_cost<T, packet_traits<T>::HasDiv>::value +
 1312|       |           (internal::is_same<T, float>::value ? NumTraits<T>::AddCost * 15 + NumTraits<T>::MulCost * 11
 1313|       |                                               : NumTraits<T>::AddCost * 2 + functor_traits<scalar_exp_op<T>>::Cost),
 1314|       |    PacketAccess = !NumTraits<T>::IsComplex && packet_traits<T>::HasAdd && packet_traits<T>::HasDiv &&
 1315|       |                   (internal::is_same<T, float>::value
 1316|       |                        ? packet_traits<T>::HasMul && packet_traits<T>::HasMax && packet_traits<T>::HasMin
 1317|       |                        : packet_traits<T>::HasNegate && packet_traits<T>::HasExp)
 1318|       |  };
 1319|       |};
 1320|       |
 1321|       |template <typename Scalar, typename ExponentScalar, bool IsBaseInteger = NumTraits<Scalar>::IsInteger,
 1322|       |          bool IsExponentInteger = NumTraits<ExponentScalar>::IsInteger,
 1323|       |          bool IsBaseComplex = NumTraits<Scalar>::IsComplex,
 1324|       |          bool IsExponentComplex = NumTraits<ExponentScalar>::IsComplex>
 1325|       |struct scalar_unary_pow_op {
 1326|       |  typedef typename internal::promote_scalar_arg<
 1327|       |      Scalar, ExponentScalar,
 1328|       |      internal::has_ReturnType<ScalarBinaryOpTraits<Scalar, ExponentScalar, scalar_unary_pow_op>>::value>::type
 1329|       |      PromotedExponent;
 1330|       |  typedef typename ScalarBinaryOpTraits<Scalar, PromotedExponent, scalar_unary_pow_op>::ReturnType result_type;
 1331|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE scalar_unary_pow_op(const ExponentScalar& exponent) : m_exponent(exponent) {}
 1332|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator()(const Scalar& a) const {
 1333|       |    EIGEN_USING_STD(pow);
 1334|       |    return static_cast<result_type>(pow(a, m_exponent));
 1335|       |  }
 1336|       |
 1337|       | private:
 1338|       |  const ExponentScalar m_exponent;
 1339|       |  scalar_unary_pow_op() {}
 1340|       |};
 1341|       |
 1342|       |template <typename T>
 1343|       |constexpr int exponent_digits() {
 1344|       |  return CHAR_BIT * sizeof(T) - NumTraits<T>::digits() - NumTraits<T>::IsSigned;
 1345|       |}
 1346|       |
 1347|       |template <typename From, typename To>
 1348|       |struct is_floating_exactly_representable {
 1349|       |  // TODO(rmlarsen): Add radix to NumTraits and enable this check.
 1350|       |  // (NumTraits<To>::radix == NumTraits<From>::radix) &&
 1351|       |  static constexpr bool value =
 1352|       |      (exponent_digits<To>() >= exponent_digits<From>() && NumTraits<To>::digits() >= NumTraits<From>::digits());
 1353|       |};
 1354|       |
 1355|       |// Specialization for real, non-integer types, non-complex types.
 1356|       |template <typename Scalar, typename ExponentScalar>
 1357|       |struct scalar_unary_pow_op<Scalar, ExponentScalar, false, false, false, false> {
 1358|       |  template <bool IsExactlyRepresentable = is_floating_exactly_representable<ExponentScalar, Scalar>::value>
 1359|       |  std::enable_if_t<IsExactlyRepresentable, void> check_is_representable() const {}
 1360|       |
 1361|       |  // Issue a deprecation warning if we do a narrowing conversion on the exponent.
 1362|       |  template <bool IsExactlyRepresentable = is_floating_exactly_representable<ExponentScalar, Scalar>::value>
 1363|       |  EIGEN_DEPRECATED std::enable_if_t<!IsExactlyRepresentable, void> check_is_representable() const {}
 1364|       |
 1365|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE scalar_unary_pow_op(const ExponentScalar& exponent)
 1366|       |      : m_exponent(static_cast<Scalar>(exponent)) {
 1367|       |    check_is_representable();
 1368|       |  }
 1369|       |
 1370|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a) const {
 1371|       |    EIGEN_USING_STD(pow);
 1372|       |    return static_cast<Scalar>(pow(a, m_exponent));
 1373|       |  }
 1374|       |  template <typename Packet>
 1375|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a) const {
 1376|       |    return unary_pow_impl<Packet, Scalar>::run(a, m_exponent);
 1377|       |  }
 1378|       |
 1379|       | private:
 1380|       |  const Scalar m_exponent;
 1381|       |  scalar_unary_pow_op() {}
 1382|       |};
 1383|       |
 1384|       |template <typename Scalar, typename ExponentScalar, bool BaseIsInteger>
 1385|       |struct scalar_unary_pow_op<Scalar, ExponentScalar, BaseIsInteger, true, false, false> {
 1386|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE scalar_unary_pow_op(const ExponentScalar& exponent) : m_exponent(exponent) {}
 1387|       |  // TODO: error handling logic for complex^real_integer
 1388|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar operator()(const Scalar& a) const {
 1389|       |    return unary_pow_impl<Scalar, ExponentScalar>::run(a, m_exponent);
 1390|       |  }
 1391|       |  template <typename Packet>
 1392|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a) const {
 1393|       |    return unary_pow_impl<Packet, ExponentScalar>::run(a, m_exponent);
 1394|       |  }
 1395|       |
 1396|       | private:
 1397|       |  const ExponentScalar m_exponent;
 1398|       |  scalar_unary_pow_op() {}
 1399|       |};
 1400|       |
 1401|       |template <typename Scalar, typename ExponentScalar>
 1402|       |struct functor_traits<scalar_unary_pow_op<Scalar, ExponentScalar>> {
 1403|       |  enum {
 1404|       |    GenPacketAccess = functor_traits<scalar_pow_op<Scalar, ExponentScalar>>::PacketAccess,
 1405|       |    IntPacketAccess = !NumTraits<Scalar>::IsComplex && packet_traits<Scalar>::HasMul &&
 1406|       |                      (packet_traits<Scalar>::HasDiv || NumTraits<Scalar>::IsInteger) && packet_traits<Scalar>::HasCmp,
 1407|       |    PacketAccess = NumTraits<ExponentScalar>::IsInteger ? IntPacketAccess : (IntPacketAccess && GenPacketAccess),
 1408|       |    Cost = functor_traits<scalar_pow_op<Scalar, ExponentScalar>>::Cost
 1409|       |  };
 1410|       |};
 1411|       |
 1412|       |}  // end namespace internal
 1413|       |
 1414|       |}  // end namespace Eigen
 1415|       |
 1416|       |#endif  // EIGEN_FUNCTORS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/products/GeneralBlockPanelKernel.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2009 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_GENERAL_BLOCK_PANEL_H
   11|       |#define EIGEN_GENERAL_BLOCK_PANEL_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |enum GEBPPacketSizeType { GEBPPacketFull = 0, GEBPPacketHalf, GEBPPacketQuarter };
   21|       |
   22|       |template <typename LhsScalar_, typename RhsScalar_, bool ConjLhs_ = false, bool ConjRhs_ = false,
   23|       |          int Arch = Architecture::Target, int PacketSize_ = GEBPPacketFull>
   24|       |class gebp_traits;
   25|       |
   26|       |/** \internal \returns b if a<=0, and returns a otherwise. */
   27|      3|inline std::ptrdiff_t manage_caching_sizes_helper(std::ptrdiff_t a, std::ptrdiff_t b) { return a <= 0 ? b : a; }
   28|       |
   29|       |#if defined(EIGEN_DEFAULT_L1_CACHE_SIZE)
   30|       |#define EIGEN_SET_DEFAULT_L1_CACHE_SIZE(val) EIGEN_DEFAULT_L1_CACHE_SIZE
   31|       |#else
   32|       |#define EIGEN_SET_DEFAULT_L1_CACHE_SIZE(val) val
   33|       |#endif  // defined(EIGEN_DEFAULT_L1_CACHE_SIZE)
   34|       |
   35|       |#if defined(EIGEN_DEFAULT_L2_CACHE_SIZE)
   36|       |#define EIGEN_SET_DEFAULT_L2_CACHE_SIZE(val) EIGEN_DEFAULT_L2_CACHE_SIZE
   37|       |#else
   38|       |#define EIGEN_SET_DEFAULT_L2_CACHE_SIZE(val) val
   39|       |#endif  // defined(EIGEN_DEFAULT_L2_CACHE_SIZE)
   40|       |
   41|       |#if defined(EIGEN_DEFAULT_L3_CACHE_SIZE)
   42|       |#define EIGEN_SET_DEFAULT_L3_CACHE_SIZE(val) EIGEN_DEFAULT_L3_CACHE_SIZE
   43|       |#else
   44|       |#define EIGEN_SET_DEFAULT_L3_CACHE_SIZE(val) val
   45|       |#endif  // defined(EIGEN_DEFAULT_L3_CACHE_SIZE)
   46|       |
   47|       |#if EIGEN_ARCH_i386_OR_x86_64
   48|       |const std::ptrdiff_t defaultL1CacheSize = EIGEN_SET_DEFAULT_L1_CACHE_SIZE(32 * 1024);
   49|       |const std::ptrdiff_t defaultL2CacheSize = EIGEN_SET_DEFAULT_L2_CACHE_SIZE(256 * 1024);
   50|       |const std::ptrdiff_t defaultL3CacheSize = EIGEN_SET_DEFAULT_L3_CACHE_SIZE(2 * 1024 * 1024);
   51|       |#elif EIGEN_ARCH_PPC
   52|       |const std::ptrdiff_t defaultL1CacheSize = EIGEN_SET_DEFAULT_L1_CACHE_SIZE(64 * 1024);
   53|       |#ifdef _ARCH_PWR10
   54|       |const std::ptrdiff_t defaultL2CacheSize = EIGEN_SET_DEFAULT_L2_CACHE_SIZE(2 * 1024 * 1024);
   55|       |const std::ptrdiff_t defaultL3CacheSize = EIGEN_SET_DEFAULT_L3_CACHE_SIZE(8 * 1024 * 1024);
   56|       |#else
   57|       |const std::ptrdiff_t defaultL2CacheSize = EIGEN_SET_DEFAULT_L2_CACHE_SIZE(512 * 1024);
   58|       |const std::ptrdiff_t defaultL3CacheSize = EIGEN_SET_DEFAULT_L3_CACHE_SIZE(4 * 1024 * 1024);
   59|       |#endif
   60|       |#else
   61|       |const std::ptrdiff_t defaultL1CacheSize = EIGEN_SET_DEFAULT_L1_CACHE_SIZE(16 * 1024);
   62|       |const std::ptrdiff_t defaultL2CacheSize = EIGEN_SET_DEFAULT_L2_CACHE_SIZE(512 * 1024);
   63|       |const std::ptrdiff_t defaultL3CacheSize = EIGEN_SET_DEFAULT_L3_CACHE_SIZE(512 * 1024);
   64|       |#endif
   65|       |
   66|       |#undef EIGEN_SET_DEFAULT_L1_CACHE_SIZE
   67|       |#undef EIGEN_SET_DEFAULT_L2_CACHE_SIZE
   68|       |#undef EIGEN_SET_DEFAULT_L3_CACHE_SIZE
   69|       |
   70|       |/** \internal */
   71|       |struct CacheSizes {
   72|      1|  CacheSizes() : m_l1(-1), m_l2(-1), m_l3(-1) {
   73|      1|    int l1CacheSize, l2CacheSize, l3CacheSize;
   74|      1|    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
   75|      1|    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
   76|      1|    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
   77|      1|    m_l3 = manage_caching_sizes_helper(l3CacheSize, defaultL3CacheSize);
   78|      1|  }
   79|       |
   80|       |  std::ptrdiff_t m_l1;
   81|       |  std::ptrdiff_t m_l2;
   82|       |  std::ptrdiff_t m_l3;
   83|       |};
   84|       |
   85|       |/** \internal */
   86|      2|inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3) {
   87|      2|  static CacheSizes m_cacheSizes;
   88|       |
   89|      2|  if (action == SetAction) {
   90|       |    // set the cpu cache size and cache all block sizes from a global cache size in byte
   91|      0|    eigen_internal_assert(l1 != 0 && l2 != 0);
   92|      0|    m_cacheSizes.m_l1 = *l1;
   93|      0|    m_cacheSizes.m_l2 = *l2;
   94|      0|    m_cacheSizes.m_l3 = *l3;
   95|      2|  } else if (action == GetAction) {
   96|      2|    eigen_internal_assert(l1 != 0 && l2 != 0);
   97|      2|    *l1 = m_cacheSizes.m_l1;
   98|      2|    *l2 = m_cacheSizes.m_l2;
   99|      2|    *l3 = m_cacheSizes.m_l3;
  100|      2|  } else {
  101|      0|    eigen_internal_assert(false);
  102|      0|  }
  103|      2|}
  104|       |
  105|       |/* Helper for computeProductBlockingSizes.
  106|       | *
  107|       | * Given a m x k times k x n matrix product of scalar types \c LhsScalar and \c RhsScalar,
  108|       | * this function computes the blocking size parameters along the respective dimensions
  109|       | * for matrix products and related algorithms. The blocking sizes depends on various
  110|       | * parameters:
  111|       | * - the L1 and L2 cache sizes,
  112|       | * - the register level blocking sizes defined by gebp_traits,
  113|       | * - the number of scalars that fit into a packet (when vectorization is enabled).
  114|       | *
  115|       | * \sa setCpuCacheSizes */
  116|       |
  117|       |template <typename LhsScalar, typename RhsScalar, int KcFactor, typename Index>
  118|      2|void evaluateProductBlockingSizesHeuristic(Index& k, Index& m, Index& n, Index num_threads = 1) {
  119|      2|  typedef gebp_traits<LhsScalar, RhsScalar> Traits;
  120|       |
  121|       |  // Explanations:
  122|       |  // Let's recall that the product algorithms form mc x kc vertical panels A' on the lhs and
  123|       |  // kc x nc blocks B' on the rhs. B' has to fit into L2/L3 cache. Moreover, A' is processed
  124|       |  // per mr x kc horizontal small panels where mr is the blocking size along the m dimension
  125|       |  // at the register level. This small horizontal panel has to stay within L1 cache.
  126|      2|  std::ptrdiff_t l1, l2, l3;
  127|      2|  manage_caching_sizes(GetAction, &l1, &l2, &l3);
  128|       |#ifdef EIGEN_VECTORIZE_AVX512
  129|       |  // We need to find a rationale for that, but without this adjustment,
  130|       |  // performance with AVX512 is pretty bad, like -20% slower.
  131|       |  // One reason is that with increasing packet-size, the blocking size k
  132|       |  // has to become pretty small if we want that 1 lhs panel fit within L1.
  133|       |  // For instance, with the 3pX4 kernel and double, the size of the lhs+rhs panels are:
  134|       |  //   k*(3*64 + 4*8) Bytes, with l1=32kBytes, and k%8=0, we have k=144.
  135|       |  // This is quite small for a good reuse of the accumulation registers.
  136|       |  l1 *= 4;
  137|       |#endif
  138|       |
  139|      2|  if (num_threads > 1) {
  140|      0|    typedef typename Traits::ResScalar ResScalar;
  141|      0|    enum {
  142|      0|      kdiv = KcFactor * (Traits::mr * sizeof(LhsScalar) + Traits::nr * sizeof(RhsScalar)),
  143|      0|      ksub = Traits::mr * (Traits::nr * sizeof(ResScalar)),
  144|      0|      kr = 8,
  145|      0|      mr = Traits::mr,
  146|      0|      nr = Traits::nr
  147|      0|    };
  148|       |    // Increasing k gives us more time to prefetch the content of the "C"
  149|       |    // registers. However once the latency is hidden there is no point in
  150|       |    // increasing the value of k, so we'll cap it at 320 (value determined
  151|       |    // experimentally).
  152|       |    // To avoid that k vanishes, we make k_cache at least as big as kr
  153|      0|    const Index k_cache = numext::maxi<Index>(kr, (numext::mini<Index>)((l1 - ksub) / kdiv, 320));
  154|      0|    if (k_cache < k) {
  155|      0|      k = k_cache - (k_cache % kr);
  156|      0|      eigen_internal_assert(k > 0);
  157|      0|    }
  158|       |
  159|      0|    const Index n_cache = (l2 - l1) / (nr * sizeof(RhsScalar) * k);
  160|      0|    const Index n_per_thread = numext::div_ceil(n, num_threads);
  161|      0|    if (n_cache <= n_per_thread) {
  162|       |      // Don't exceed the capacity of the l2 cache.
  163|      0|      eigen_internal_assert(n_cache >= static_cast<Index>(nr));
  164|      0|      n = n_cache - (n_cache % nr);
  165|      0|      eigen_internal_assert(n > 0);
  166|      0|    } else {
  167|      0|      n = (numext::mini<Index>)(n, (n_per_thread + nr - 1) - ((n_per_thread + nr - 1) % nr));
  168|      0|    }
  169|       |
  170|      0|    if (l3 > l2) {
  171|       |      // l3 is shared between all cores, so we'll give each thread its own chunk of l3.
  172|      0|      const Index m_cache = (l3 - l2) / (sizeof(LhsScalar) * k * num_threads);
  173|      0|      const Index m_per_thread = numext::div_ceil(m, num_threads);
  174|      0|      if (m_cache < m_per_thread && m_cache >= static_cast<Index>(mr)) {
  175|      0|        m = m_cache - (m_cache % mr);
  176|      0|        eigen_internal_assert(m > 0);
  177|      0|      } else {
  178|      0|        m = (numext::mini<Index>)(m, (m_per_thread + mr - 1) - ((m_per_thread + mr - 1) % mr));
  179|      0|      }
  180|      0|    }
  181|      2|  } else {
  182|       |    // In unit tests we do not want to use extra large matrices,
  183|       |    // so we reduce the cache size to check the blocking strategy is not flawed
  184|      2|#ifdef EIGEN_DEBUG_SMALL_PRODUCT_BLOCKS
  185|      2|    l1 = 9 * 1024;
  186|      2|    l2 = 32 * 1024;
  187|      2|    l3 = 512 * 1024;
  188|      2|#endif
  189|       |
  190|       |    // Early return for small problems because the computation below are time consuming for small problems.
  191|       |    // Perhaps it would make more sense to consider k*n*m??
  192|       |    // Note that for very tiny problem, this function should be bypassed anyway
  193|       |    // because we use the coefficient-based implementation for them.
  194|      2|    if ((numext::maxi)(k, (numext::maxi)(m, n)) < 48) return;
  195|       |
  196|      2|    typedef typename Traits::ResScalar ResScalar;
  197|      2|    enum {
  198|      2|      k_peeling = 8,
  199|      2|      k_div = KcFactor * (Traits::mr * sizeof(LhsScalar) + Traits::nr * sizeof(RhsScalar)),
  200|      2|      k_sub = Traits::mr * (Traits::nr * sizeof(ResScalar))
  201|      2|    };
  202|       |
  203|       |    // ---- 1st level of blocking on L1, yields kc ----
  204|       |
  205|       |    // Blocking on the third dimension (i.e., k) is chosen so that an horizontal panel
  206|       |    // of size mr x kc of the lhs plus a vertical panel of kc x nr of the rhs both fits within L1 cache.
  207|       |    // We also include a register-level block of the result (mx x nr).
  208|       |    // (In an ideal world only the lhs panel would stay in L1)
  209|       |    // Moreover, kc has to be a multiple of 8 to be compatible with loop peeling, leading to a maximum blocking size of:
  210|      2|    const Index max_kc = numext::maxi<Index>(((l1 - k_sub) / k_div) & (~(k_peeling - 1)), 1);
  211|      2|    const Index old_k = k;
  212|      2|    if (k > max_kc) {
  213|       |      // We are really blocking on the third dimension:
  214|       |      // -> reduce blocking size to make sure the last block is as large as possible
  215|       |      //    while keeping the same number of sweeps over the result.
  216|      0|      k = (k % max_kc) == 0 ? max_kc
  217|      0|                            : max_kc - k_peeling * ((max_kc - 1 - (k % max_kc)) / (k_peeling * (k / max_kc + 1)));
  218|       |
  219|      0|      eigen_internal_assert(((old_k / k) == (old_k / max_kc)) && "the number of sweeps has to remain the same");
  220|      0|    }
  221|       |
  222|       |// ---- 2nd level of blocking on max(L2,L3), yields nc ----
  223|       |
  224|       |// TODO find a reliable way to get the actual amount of cache per core to use for 2nd level blocking, that is:
  225|       |//      actual_l2 = max(l2, l3/nb_core_sharing_l3)
  226|       |// The number below is quite conservative: it is better to underestimate the cache size rather than overestimating it)
  227|       |// For instance, it corresponds to 6MB of L3 shared among 4 cores.
  228|      2|#ifdef EIGEN_DEBUG_SMALL_PRODUCT_BLOCKS
  229|      2|    const Index actual_l2 = l3;
  230|       |#else
  231|       |    const Index actual_l2 = 1572864;  // == 1.5 MB
  232|       |#endif
  233|       |
  234|       |    // Here, nc is chosen such that a block of kc x nc of the rhs fit within half of L2.
  235|       |    // The second half is implicitly reserved to access the result and lhs coefficients.
  236|       |    // When k<max_kc, then nc can arbitrarily growth. In practice, it seems to be fruitful
  237|       |    // to limit this growth: we bound nc to growth by a factor x1.5.
  238|       |    // However, if the entire lhs block fit within L1, then we are not going to block on the rows at all,
  239|       |    // and it becomes fruitful to keep the packed rhs blocks in L1 if there is enough remaining space.
  240|      2|    Index max_nc;
  241|      2|    const Index lhs_bytes = m * k * sizeof(LhsScalar);
  242|      2|    const Index remaining_l1 = l1 - k_sub - lhs_bytes;
  243|      2|    if (remaining_l1 >= Index(Traits::nr * sizeof(RhsScalar)) * k) {
  244|       |      // L1 blocking
  245|      0|      max_nc = remaining_l1 / (k * sizeof(RhsScalar));
  246|      2|    } else {
  247|       |      // L2 blocking
  248|      2|      max_nc = (3 * actual_l2) / (2 * 2 * max_kc * sizeof(RhsScalar));
  249|      2|    }
  250|       |    // WARNING Below, we assume that Traits::nr is a power of two.
  251|      2|    Index nc = numext::mini<Index>(actual_l2 / (2 * k * sizeof(RhsScalar)), max_nc) & (~(Traits::nr - 1));
  252|      2|    if (n > nc) {
  253|       |      // We are really blocking over the columns:
  254|       |      // -> reduce blocking size to make sure the last block is as large as possible
  255|       |      //    while keeping the same number of sweeps over the packed lhs.
  256|       |      //    Here we allow one more sweep if this gives us a perfect match, thus the commented "-1"
  257|      0|      n = (n % nc) == 0 ? nc : (nc - Traits::nr * ((nc /*-1*/ - (n % nc)) / (Traits::nr * (n / nc + 1))));
  258|      2|    } else if (old_k == k) {
  259|       |      // So far, no blocking at all, i.e., kc==k, and nc==n.
  260|       |      // In this case, let's perform a blocking over the rows such that the packed lhs data is kept in cache L1/L2
  261|       |      // TODO: part of this blocking strategy is now implemented within the kernel itself, so the L1-based heuristic
  262|       |      // here should be obsolete.
  263|      2|      Index problem_size = k * n * sizeof(LhsScalar);
  264|      2|      Index actual_lm = actual_l2;
  265|      2|      Index max_mc = m;
  266|      2|      if (problem_size <= 1024) {
  267|       |        // problem is small enough to keep in L1
  268|       |        // Let's choose m such that lhs's block fit in 1/3 of L1
  269|      0|        actual_lm = l1;
  270|      2|      } else if (l3 != 0 && problem_size <= 32768) {
  271|       |        // we have both L2 and L3, and problem is small enough to be kept in L2
  272|       |        // Let's choose m such that lhs's block fit in 1/3 of L2
  273|      0|        actual_lm = l2;
  274|      0|        max_mc = (numext::mini<Index>)(576, max_mc);
  275|      0|      }
  276|      2|      Index mc = (numext::mini<Index>)(actual_lm / (3 * k * sizeof(LhsScalar)), max_mc);
  277|      2|      if (mc > Traits::mr)
  278|      2|        mc -= mc % Traits::mr;
  279|      0|      else if (mc == 0)
  280|      0|        return;
  281|      2|      m = (m % mc) == 0 ? mc : (mc - Traits::mr * ((mc /*-1*/ - (m % mc)) / (Traits::mr * (m / mc + 1))));
  282|      2|    }
  283|      2|  }
  284|      2|}
  285|       |
  286|       |template <typename Index>
  287|      2|inline bool useSpecificBlockingSizes(Index& k, Index& m, Index& n) {
  288|       |#ifdef EIGEN_TEST_SPECIFIC_BLOCKING_SIZES
  289|       |  if (EIGEN_TEST_SPECIFIC_BLOCKING_SIZES) {
  290|       |    k = numext::mini<Index>(k, EIGEN_TEST_SPECIFIC_BLOCKING_SIZE_K);
  291|       |    m = numext::mini<Index>(m, EIGEN_TEST_SPECIFIC_BLOCKING_SIZE_M);
  292|       |    n = numext::mini<Index>(n, EIGEN_TEST_SPECIFIC_BLOCKING_SIZE_N);
  293|       |    return true;
  294|       |  }
  295|       |#else
  296|      2|  EIGEN_UNUSED_VARIABLE(k)
  297|      2|  EIGEN_UNUSED_VARIABLE(m)
  298|      2|  EIGEN_UNUSED_VARIABLE(n)
  299|      2|#endif
  300|      2|  return false;
  301|      2|}
  302|       |
  303|       |/** \brief Computes the blocking parameters for a m x k times k x n matrix product
  304|       | *
  305|       | * \param[in,out] k Input: the third dimension of the product. Output: the blocking size along the same dimension.
  306|       | * \param[in,out] m Input: the number of rows of the left hand side. Output: the blocking size along the same dimension.
  307|       | * \param[in,out] n Input: the number of columns of the right hand side. Output: the blocking size along the same
  308|       | * dimension.
  309|       | *
  310|       | * Given a m x k times k x n matrix product of scalar types \c LhsScalar and \c RhsScalar,
  311|       | * this function computes the blocking size parameters along the respective dimensions
  312|       | * for matrix products and related algorithms.
  313|       | *
  314|       | * The blocking size parameters may be evaluated:
  315|       | *   - either by a heuristic based on cache sizes;
  316|       | *   - or using fixed prescribed values (for testing purposes).
  317|       | *
  318|       | * \sa setCpuCacheSizes */
  319|       |
  320|       |template <typename LhsScalar, typename RhsScalar, int KcFactor, typename Index>
  321|      2|void computeProductBlockingSizes(Index& k, Index& m, Index& n, Index num_threads = 1) {
  322|      2|  if (!useSpecificBlockingSizes(k, m, n)) {
  323|      2|    evaluateProductBlockingSizesHeuristic<LhsScalar, RhsScalar, KcFactor, Index>(k, m, n, num_threads);
  324|      2|  }
  325|      2|}
  326|       |
  327|       |template <typename LhsScalar, typename RhsScalar, typename Index>
  328|       |inline void computeProductBlockingSizes(Index& k, Index& m, Index& n, Index num_threads = 1) {
  329|       |  computeProductBlockingSizes<LhsScalar, RhsScalar, 1, Index>(k, m, n, num_threads);
  330|       |}
  331|       |
  332|       |template <typename RhsPacket, typename RhsPacketx4, int registers_taken>
  333|       |struct RhsPanelHelper {
  334|       | private:
  335|       |  static constexpr int remaining_registers =
  336|       |      (std::max)(int(EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS) - registers_taken, 0);
  337|       |
  338|       | public:
  339|       |  typedef std::conditional_t<remaining_registers >= 4, RhsPacketx4, RhsPacket> type;
  340|       |};
  341|       |
  342|       |template <typename Packet>
  343|       |struct QuadPacket {
  344|       |  Packet B_0, B1, B2, B3;
  345|     52|  const Packet& get(const FixedInt<0>&) const { return B_0; }
  346|     52|  const Packet& get(const FixedInt<1>&) const { return B1; }
  347|     48|  const Packet& get(const FixedInt<2>&) const { return B2; }
  348|     48|  const Packet& get(const FixedInt<3>&) const { return B3; }
  349|       |};
  350|       |
  351|       |template <int N, typename T1, typename T2, typename T3>
  352|       |struct packet_conditional {
  353|       |  typedef T3 type;
  354|       |};
  355|       |
  356|       |template <typename T1, typename T2, typename T3>
  357|       |struct packet_conditional<GEBPPacketFull, T1, T2, T3> {
  358|       |  typedef T1 type;
  359|       |};
  360|       |
  361|       |template <typename T1, typename T2, typename T3>
  362|       |struct packet_conditional<GEBPPacketHalf, T1, T2, T3> {
  363|       |  typedef T2 type;
  364|       |};
  365|       |
  366|       |#define PACKET_DECL_COND_POSTFIX(postfix, name, packet_size)                                               \
  367|       |  typedef typename packet_conditional<                                                                     \
  368|       |      packet_size, typename packet_traits<name##Scalar>::type, typename packet_traits<name##Scalar>::half, \
  369|       |      typename unpacket_traits<typename packet_traits<name##Scalar>::half>::half>::type name##Packet##postfix
  370|       |
  371|       |#define PACKET_DECL_COND(name, packet_size)                                                                \
  372|       |  typedef typename packet_conditional<                                                                     \
  373|       |      packet_size, typename packet_traits<name##Scalar>::type, typename packet_traits<name##Scalar>::half, \
  374|       |      typename unpacket_traits<typename packet_traits<name##Scalar>::half>::half>::type name##Packet
  375|       |
  376|       |#define PACKET_DECL_COND_SCALAR_POSTFIX(postfix, packet_size)                                  \
  377|       |  typedef typename packet_conditional<                                                         \
  378|       |      packet_size, typename packet_traits<Scalar>::type, typename packet_traits<Scalar>::half, \
  379|       |      typename unpacket_traits<typename packet_traits<Scalar>::half>::half>::type ScalarPacket##postfix
  380|       |
  381|       |#define PACKET_DECL_COND_SCALAR(packet_size)                                                   \
  382|       |  typedef typename packet_conditional<                                                         \
  383|       |      packet_size, typename packet_traits<Scalar>::type, typename packet_traits<Scalar>::half, \
  384|       |      typename unpacket_traits<typename packet_traits<Scalar>::half>::half>::type ScalarPacket
  385|       |
  386|       |/* Vectorization logic
  387|       | *  real*real: unpack rhs to constant packets, ...
  388|       | *
  389|       | *  cd*cd : unpack rhs to (b_r,b_r), (b_i,b_i), mul to get (a_r b_r,a_i b_r) (a_r b_i,a_i b_i),
  390|       | *          storing each res packet into two packets (2x2),
  391|       | *          at the end combine them: swap the second and addsub them
  392|       | *  cf*cf : same but with 2x4 blocks
  393|       | *  cplx*real : unpack rhs to constant packets, ...
  394|       | *  real*cplx : load lhs as (a0,a0,a1,a1), and mul as usual
  395|       | */
  396|       |template <typename LhsScalar_, typename RhsScalar_, bool ConjLhs_, bool ConjRhs_, int Arch, int PacketSize_>
  397|       |class gebp_traits {
  398|       | public:
  399|       |  typedef LhsScalar_ LhsScalar;
  400|       |  typedef RhsScalar_ RhsScalar;
  401|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
  402|       |
  403|       |  PACKET_DECL_COND_POSTFIX(_, Lhs, PacketSize_);
  404|       |  PACKET_DECL_COND_POSTFIX(_, Rhs, PacketSize_);
  405|       |  PACKET_DECL_COND_POSTFIX(_, Res, PacketSize_);
  406|       |
  407|       |  enum {
  408|       |    ConjLhs = ConjLhs_,
  409|       |    ConjRhs = ConjRhs_,
  410|       |    Vectorizable = unpacket_traits<LhsPacket_>::vectorizable && unpacket_traits<RhsPacket_>::vectorizable,
  411|       |    LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
  412|       |    RhsPacketSize = Vectorizable ? unpacket_traits<RhsPacket_>::size : 1,
  413|       |    ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1,
  414|       |
  415|       |    NumberOfRegisters = EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS,
  416|       |
  417|       |    // register block size along the N direction must be 1 or 4
  418|       |    nr = 4,
  419|       |
  420|       |    // register block size along the M direction (currently, this one cannot be modified)
  421|       |    default_mr = (plain_enum_min(16, NumberOfRegisters) / 2 / nr) * LhsPacketSize,
  422|       |#if defined(EIGEN_HAS_SINGLE_INSTRUCTION_MADD) && !defined(EIGEN_VECTORIZE_ALTIVEC) && \
  423|       |    !defined(EIGEN_VECTORIZE_VSX) && ((!EIGEN_COMP_MSVC) || (EIGEN_COMP_MSVC >= 1914))
  424|       |    // we assume 16 registers or more
  425|       |    // See bug 992, if the scalar type is not vectorizable but that EIGEN_HAS_SINGLE_INSTRUCTION_MADD is defined,
  426|       |    // then using 3*LhsPacketSize triggers non-implemented paths in syrk.
  427|       |    // Bug 1515: MSVC prior to v19.14 yields to register spilling.
  428|       |    mr = Vectorizable ? 3 * LhsPacketSize : default_mr,
  429|       |#else
  430|       |    mr = default_mr,
  431|       |#endif
  432|       |
  433|       |    LhsProgress = LhsPacketSize,
  434|       |    RhsProgress = 1
  435|       |  };
  436|       |
  437|       |  typedef std::conditional_t<Vectorizable, LhsPacket_, LhsScalar> LhsPacket;
  438|       |  typedef std::conditional_t<Vectorizable, RhsPacket_, RhsScalar> RhsPacket;
  439|       |  typedef std::conditional_t<Vectorizable, ResPacket_, ResScalar> ResPacket;
  440|       |  typedef LhsPacket LhsPacket4Packing;
  441|       |
  442|       |  typedef QuadPacket<RhsPacket> RhsPacketx4;
  443|       |  typedef ResPacket AccPacket;
  444|       |
  445|     16|  EIGEN_STRONG_INLINE void initAcc(AccPacket& p) { p = pset1<ResPacket>(ResScalar(0)); }
  ------------------
  | _ZN5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE7initAccERS2_:
  |  445|     16|  EIGEN_STRONG_INLINE void initAcc(AccPacket& p) { p = pset1<ResPacket>(ResScalar(0)); }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE7initAccERS2_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE7initAccERS2_
  ------------------
  446|       |
  447|       |  template <typename RhsPacketType>
  448|      0|  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, RhsPacketType& dest) const {
  449|      0|    dest = pset1<RhsPacketType>(*b);
  450|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE7loadRhsIS2_EEvPKS2_RT_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE7loadRhsIS2_EEvPKS2_RT_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE7loadRhsIS2_EEvPKS2_RT_
  ------------------
  451|       |
  452|     26|  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, RhsPacketx4& dest) const {
  453|     26|    pbroadcast4(b, dest.B_0, dest.B1, dest.B2, dest.B3);
  454|     26|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE7loadRhsEPKS2_RNS0_10QuadPacketIS2_EE:
  |  452|     26|  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, RhsPacketx4& dest) const {
  |  453|     26|    pbroadcast4(b, dest.B_0, dest.B1, dest.B2, dest.B3);
  |  454|     26|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE7loadRhsEPKS2_RNS0_10QuadPacketIS2_EE
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE7loadRhsEPKS2_RNS0_10QuadPacketIS2_EE
  ------------------
  455|       |
  456|       |  template <typename RhsPacketType>
  457|      0|  EIGEN_STRONG_INLINE void updateRhs(const RhsScalar* b, RhsPacketType& dest) const {
  458|      0|    loadRhs(b, dest);
  459|      0|  }
  460|       |
  461|       |  EIGEN_STRONG_INLINE void updateRhs(const RhsScalar*, RhsPacketx4&) const {}
  462|       |
  463|      0|  EIGEN_STRONG_INLINE void loadRhsQuad(const RhsScalar* b, RhsPacket& dest) const { dest = ploadquad<RhsPacket>(b); }
  464|       |
  465|       |  template <typename LhsPacketType>
  466|     52|  EIGEN_STRONG_INLINE void loadLhs(const LhsScalar* a, LhsPacketType& dest) const {
  467|     52|    dest = pload<LhsPacketType>(a);
  468|     52|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE7loadLhsIS2_EEvPKS2_RT_:
  |  466|     52|  EIGEN_STRONG_INLINE void loadLhs(const LhsScalar* a, LhsPacketType& dest) const {
  |  467|     52|    dest = pload<LhsPacketType>(a);
  |  468|     52|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE7loadLhsIS2_EEvPKS2_RT_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE7loadLhsIS2_EEvPKS2_RT_
  ------------------
  469|       |
  470|       |  template <typename LhsPacketType>
  471|      0|  EIGEN_STRONG_INLINE void loadLhsUnaligned(const LhsScalar* a, LhsPacketType& dest) const {
  472|      0|    dest = ploadu<LhsPacketType>(a);
  473|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE16loadLhsUnalignedIS2_EEvPKS2_RT_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE16loadLhsUnalignedIS2_EEvPKS2_RT_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE16loadLhsUnalignedIS2_EEvPKS2_RT_
  ------------------
  474|       |
  475|       |  template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType, typename LaneIdType>
  476|       |  EIGEN_STRONG_INLINE void madd(const LhsPacketType& a, const RhsPacketType& b, AccPacketType& c, RhsPacketType& tmp,
  477|    200|                                const LaneIdType&) const {
  478|    200|    conj_helper<LhsPacketType, RhsPacketType, ConjLhs, ConjRhs> cj;
  479|       |    // It would be a lot cleaner to call pmadd all the time. Unfortunately if we
  480|       |    // let gcc allocate the register in which to store the result of the pmul
  481|       |    // (in the case where there is no FMA) gcc fails to figure out how to avoid
  482|       |    // spilling register.
  483|       |#ifdef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
  484|       |    EIGEN_UNUSED_VARIABLE(tmp);
  485|       |    c = cj.pmadd(a, b, c);
  486|       |#else
  487|    200|    tmp = b;
  488|    200|    tmp = cj.pmul(a, tmp);
  489|    200|    c = padd(c, tmp);
  490|    200|#endif
  491|    200|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE4maddIS2_S2_S2_NS0_8FixedIntILi1EEEEEvRKT_RKT0_RT1_RSA_RKT2_:
  |  477|     52|                                const LaneIdType&) const {
  |  478|     52|    conj_helper<LhsPacketType, RhsPacketType, ConjLhs, ConjRhs> cj;
  |  479|       |    // It would be a lot cleaner to call pmadd all the time. Unfortunately if we
  |  480|       |    // let gcc allocate the register in which to store the result of the pmul
  |  481|       |    // (in the case where there is no FMA) gcc fails to figure out how to avoid
  |  482|       |    // spilling register.
  |  483|       |#ifdef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
  |  484|       |    EIGEN_UNUSED_VARIABLE(tmp);
  |  485|       |    c = cj.pmadd(a, b, c);
  |  486|       |#else
  |  487|     52|    tmp = b;
  |  488|     52|    tmp = cj.pmul(a, tmp);
  |  489|     52|    c = padd(c, tmp);
  |  490|     52|#endif
  |  491|     52|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE4maddIS2_S2_S2_NS0_8FixedIntILi2EEEEEvRKT_RKT0_RT1_RSA_RKT2_:
  |  477|     48|                                const LaneIdType&) const {
  |  478|     48|    conj_helper<LhsPacketType, RhsPacketType, ConjLhs, ConjRhs> cj;
  |  479|       |    // It would be a lot cleaner to call pmadd all the time. Unfortunately if we
  |  480|       |    // let gcc allocate the register in which to store the result of the pmul
  |  481|       |    // (in the case where there is no FMA) gcc fails to figure out how to avoid
  |  482|       |    // spilling register.
  |  483|       |#ifdef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
  |  484|       |    EIGEN_UNUSED_VARIABLE(tmp);
  |  485|       |    c = cj.pmadd(a, b, c);
  |  486|       |#else
  |  487|     48|    tmp = b;
  |  488|     48|    tmp = cj.pmul(a, tmp);
  |  489|     48|    c = padd(c, tmp);
  |  490|     48|#endif
  |  491|     48|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE4maddIS2_S2_S2_NS0_8FixedIntILi3EEEEEvRKT_RKT0_RT1_RSA_RKT2_:
  |  477|     48|                                const LaneIdType&) const {
  |  478|     48|    conj_helper<LhsPacketType, RhsPacketType, ConjLhs, ConjRhs> cj;
  |  479|       |    // It would be a lot cleaner to call pmadd all the time. Unfortunately if we
  |  480|       |    // let gcc allocate the register in which to store the result of the pmul
  |  481|       |    // (in the case where there is no FMA) gcc fails to figure out how to avoid
  |  482|       |    // spilling register.
  |  483|       |#ifdef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
  |  484|       |    EIGEN_UNUSED_VARIABLE(tmp);
  |  485|       |    c = cj.pmadd(a, b, c);
  |  486|       |#else
  |  487|     48|    tmp = b;
  |  488|     48|    tmp = cj.pmul(a, tmp);
  |  489|     48|    c = padd(c, tmp);
  |  490|     48|#endif
  |  491|     48|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE4maddIS2_S2_S2_NS0_8FixedIntILi0EEEEEvRKT_RKT0_RT1_RSA_RKT2_:
  |  477|     52|                                const LaneIdType&) const {
  |  478|     52|    conj_helper<LhsPacketType, RhsPacketType, ConjLhs, ConjRhs> cj;
  |  479|       |    // It would be a lot cleaner to call pmadd all the time. Unfortunately if we
  |  480|       |    // let gcc allocate the register in which to store the result of the pmul
  |  481|       |    // (in the case where there is no FMA) gcc fails to figure out how to avoid
  |  482|       |    // spilling register.
  |  483|       |#ifdef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
  |  484|       |    EIGEN_UNUSED_VARIABLE(tmp);
  |  485|       |    c = cj.pmadd(a, b, c);
  |  486|       |#else
  |  487|     52|    tmp = b;
  |  488|     52|    tmp = cj.pmul(a, tmp);
  |  489|     52|    c = padd(c, tmp);
  |  490|     52|#endif
  |  491|     52|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE4maddIS2_S2_S2_NS0_8FixedIntILi1EEEEEvRKT_RKT0_RT1_RSA_RKT2_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE4maddIS2_S2_S2_NS0_8FixedIntILi2EEEEEvRKT_RKT0_RT1_RSA_RKT2_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE4maddIS2_S2_S2_NS0_8FixedIntILi3EEEEEvRKT_RKT0_RT1_RSA_RKT2_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE4maddIS2_S2_S2_NS0_8FixedIntILi0EEEEEvRKT_RKT0_RT1_RSA_RKT2_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE4maddIS2_S2_S2_NS0_8FixedIntILi1EEEEEvRKT_RKT0_RT1_RSA_RKT2_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE4maddIS2_S2_S2_NS0_8FixedIntILi2EEEEEvRKT_RKT0_RT1_RSA_RKT2_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE4maddIS2_S2_S2_NS0_8FixedIntILi3EEEEEvRKT_RKT0_RT1_RSA_RKT2_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE4maddIS2_S2_S2_NS0_8FixedIntILi0EEEEEvRKT_RKT0_RT1_RSA_RKT2_
  ------------------
  492|       |
  493|       |  template <typename LhsPacketType, typename AccPacketType, typename LaneIdType>
  494|       |  EIGEN_STRONG_INLINE void madd(const LhsPacketType& a, const RhsPacketx4& b, AccPacketType& c, RhsPacket& tmp,
  495|    200|                                const LaneIdType& lane) const {
  496|    200|    madd(a, b.get(lane), c, tmp, lane);
  497|    200|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE4maddIS2_S2_NS0_8FixedIntILi0EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_:
  |  495|     52|                                const LaneIdType& lane) const {
  |  496|     52|    madd(a, b.get(lane), c, tmp, lane);
  |  497|     52|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE4maddIS2_S2_NS0_8FixedIntILi1EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_:
  |  495|     52|                                const LaneIdType& lane) const {
  |  496|     52|    madd(a, b.get(lane), c, tmp, lane);
  |  497|     52|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE4maddIS2_S2_NS0_8FixedIntILi2EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_:
  |  495|     48|                                const LaneIdType& lane) const {
  |  496|     48|    madd(a, b.get(lane), c, tmp, lane);
  |  497|     48|  }
  ------------------
  | _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE4maddIS2_S2_NS0_8FixedIntILi3EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_:
  |  495|     48|                                const LaneIdType& lane) const {
  |  496|     48|    madd(a, b.get(lane), c, tmp, lane);
  |  497|     48|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE4maddIS2_S2_NS0_8FixedIntILi0EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE4maddIS2_S2_NS0_8FixedIntILi1EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE4maddIS2_S2_NS0_8FixedIntILi2EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE4maddIS2_S2_NS0_8FixedIntILi3EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE4maddIS2_S2_NS0_8FixedIntILi0EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE4maddIS2_S2_NS0_8FixedIntILi1EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE4maddIS2_S2_NS0_8FixedIntILi2EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE4maddIS2_S2_NS0_8FixedIntILi3EEEEEvRKT_RKNS0_10QuadPacketIS2_EERT0_RS2_RKT1_
  ------------------
  498|       |
  499|      0|  EIGEN_STRONG_INLINE void acc(const AccPacket& c, const ResPacket& alpha, ResPacket& r) const {
  500|      0|    r = pmadd(c, alpha, r);
  501|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi0EE3accERKS2_S5_RS2_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi1EE3accERKS2_S5_RS2_
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal11gebp_traitsI14AnnoyingScalarS2_Lb0ELb0ELi1ELi2EE3accERKS2_S5_RS2_
  ------------------
  502|       |
  503|       |  template <typename ResPacketHalf>
  504|       |  EIGEN_STRONG_INLINE void acc(const ResPacketHalf& c, const ResPacketHalf& alpha, ResPacketHalf& r) const {
  505|       |    r = pmadd(c, alpha, r);
  506|       |  }
  507|       |};
  508|       |
  509|       |template <typename RealScalar, bool ConjLhs_, int Arch, int PacketSize_>
  510|       |class gebp_traits<std::complex<RealScalar>, RealScalar, ConjLhs_, false, Arch, PacketSize_> {
  511|       | public:
  512|       |  typedef std::complex<RealScalar> LhsScalar;
  513|       |  typedef RealScalar RhsScalar;
  514|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
  515|       |
  516|       |  PACKET_DECL_COND_POSTFIX(_, Lhs, PacketSize_);
  517|       |  PACKET_DECL_COND_POSTFIX(_, Rhs, PacketSize_);
  518|       |  PACKET_DECL_COND_POSTFIX(_, Res, PacketSize_);
  519|       |
  520|       |  enum {
  521|       |    ConjLhs = ConjLhs_,
  522|       |    ConjRhs = false,
  523|       |    Vectorizable = unpacket_traits<LhsPacket_>::vectorizable && unpacket_traits<RhsPacket_>::vectorizable,
  524|       |    LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
  525|       |    RhsPacketSize = Vectorizable ? unpacket_traits<RhsPacket_>::size : 1,
  526|       |    ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1,
  527|       |
  528|       |    NumberOfRegisters = EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS,
  529|       |    nr = 4,
  530|       |#if defined(EIGEN_HAS_SINGLE_INSTRUCTION_MADD) && !defined(EIGEN_VECTORIZE_ALTIVEC) && !defined(EIGEN_VECTORIZE_VSX)
  531|       |    // we assume 16 registers
  532|       |    mr = 3 * LhsPacketSize,
  533|       |#else
  534|       |    mr = (plain_enum_min(16, NumberOfRegisters) / 2 / nr) * LhsPacketSize,
  535|       |#endif
  536|       |
  537|       |    LhsProgress = LhsPacketSize,
  538|       |    RhsProgress = 1
  539|       |  };
  540|       |
  541|       |  typedef std::conditional_t<Vectorizable, LhsPacket_, LhsScalar> LhsPacket;
  542|       |  typedef std::conditional_t<Vectorizable, RhsPacket_, RhsScalar> RhsPacket;
  543|       |  typedef std::conditional_t<Vectorizable, ResPacket_, ResScalar> ResPacket;
  544|       |  typedef LhsPacket LhsPacket4Packing;
  545|       |
  546|       |  typedef QuadPacket<RhsPacket> RhsPacketx4;
  547|       |
  548|       |  typedef ResPacket AccPacket;
  549|       |
  550|       |  EIGEN_STRONG_INLINE void initAcc(AccPacket& p) { p = pset1<ResPacket>(ResScalar(0)); }
  551|       |
  552|       |  template <typename RhsPacketType>
  553|       |  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, RhsPacketType& dest) const {
  554|       |    dest = pset1<RhsPacketType>(*b);
  555|       |  }
  556|       |
  557|       |  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, RhsPacketx4& dest) const {
  558|       |    pbroadcast4(b, dest.B_0, dest.B1, dest.B2, dest.B3);
  559|       |  }
  560|       |
  561|       |  template <typename RhsPacketType>
  562|       |  EIGEN_STRONG_INLINE void updateRhs(const RhsScalar* b, RhsPacketType& dest) const {
  563|       |    loadRhs(b, dest);
  564|       |  }
  565|       |
  566|       |  EIGEN_STRONG_INLINE void updateRhs(const RhsScalar*, RhsPacketx4&) const {}
  567|       |
  568|       |  EIGEN_STRONG_INLINE void loadRhsQuad(const RhsScalar* b, RhsPacket& dest) const {
  569|       |    loadRhsQuad_impl(b, dest, std::conditional_t<RhsPacketSize == 16, true_type, false_type>());
  570|       |  }
  571|       |
  572|       |  EIGEN_STRONG_INLINE void loadRhsQuad_impl(const RhsScalar* b, RhsPacket& dest, const true_type&) const {
  573|       |    // FIXME we can do better!
  574|       |    // what we want here is a ploadheight
  575|       |    RhsScalar tmp[4] = {b[0], b[0], b[1], b[1]};
  576|       |    dest = ploadquad<RhsPacket>(tmp);
  577|       |  }
  578|       |
  579|       |  EIGEN_STRONG_INLINE void loadRhsQuad_impl(const RhsScalar* b, RhsPacket& dest, const false_type&) const {
  580|       |    eigen_internal_assert(RhsPacketSize <= 8);
  581|       |    dest = pset1<RhsPacket>(*b);
  582|       |  }
  583|       |
  584|       |  EIGEN_STRONG_INLINE void loadLhs(const LhsScalar* a, LhsPacket& dest) const { dest = pload<LhsPacket>(a); }
  585|       |
  586|       |  template <typename LhsPacketType>
  587|       |  EIGEN_STRONG_INLINE void loadLhsUnaligned(const LhsScalar* a, LhsPacketType& dest) const {
  588|       |    dest = ploadu<LhsPacketType>(a);
  589|       |  }
  590|       |
  591|       |  template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType, typename LaneIdType>
  592|       |  EIGEN_STRONG_INLINE void madd(const LhsPacketType& a, const RhsPacketType& b, AccPacketType& c, RhsPacketType& tmp,
  593|       |                                const LaneIdType&) const {
  594|       |    madd_impl(a, b, c, tmp, std::conditional_t<Vectorizable, true_type, false_type>());
  595|       |  }
  596|       |
  597|       |  template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType>
  598|       |  EIGEN_STRONG_INLINE void madd_impl(const LhsPacketType& a, const RhsPacketType& b, AccPacketType& c,
  599|       |                                     RhsPacketType& tmp, const true_type&) const {
  600|       |#ifdef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
  601|       |    EIGEN_UNUSED_VARIABLE(tmp);
  602|       |    c.v = pmadd(a.v, b, c.v);
  603|       |#else
  604|       |    tmp = b;
  605|       |    tmp = pmul(a.v, tmp);
  606|       |    c.v = padd(c.v, tmp);
  607|       |#endif
  608|       |  }
  609|       |
  610|       |  EIGEN_STRONG_INLINE void madd_impl(const LhsScalar& a, const RhsScalar& b, ResScalar& c, RhsScalar& /*tmp*/,
  611|       |                                     const false_type&) const {
  612|       |    c += a * b;
  613|       |  }
  614|       |
  615|       |  template <typename LhsPacketType, typename AccPacketType, typename LaneIdType>
  616|       |  EIGEN_STRONG_INLINE void madd(const LhsPacketType& a, const RhsPacketx4& b, AccPacketType& c, RhsPacket& tmp,
  617|       |                                const LaneIdType& lane) const {
  618|       |    madd(a, b.get(lane), c, tmp, lane);
  619|       |  }
  620|       |
  621|       |  template <typename ResPacketType, typename AccPacketType>
  622|       |  EIGEN_STRONG_INLINE void acc(const AccPacketType& c, const ResPacketType& alpha, ResPacketType& r) const {
  623|       |    conj_helper<ResPacketType, ResPacketType, ConjLhs, false> cj;
  624|       |    r = cj.pmadd(c, alpha, r);
  625|       |  }
  626|       |
  627|       | protected:
  628|       |};
  629|       |
  630|       |template <typename Packet>
  631|       |struct DoublePacket {
  632|       |  Packet first;
  633|       |  Packet second;
  634|       |};
  635|       |
  636|       |template <typename Packet>
  637|       |DoublePacket<Packet> padd(const DoublePacket<Packet>& a, const DoublePacket<Packet>& b) {
  638|       |  DoublePacket<Packet> res;
  639|       |  res.first = padd(a.first, b.first);
  640|       |  res.second = padd(a.second, b.second);
  641|       |  return res;
  642|       |}
  643|       |
  644|       |// note that for DoublePacket<RealPacket> the "4" in "downto4"
  645|       |// corresponds to the number of complexes, so it means "8"
  646|       |// it terms of real coefficients.
  647|       |
  648|       |template <typename Packet>
  649|       |const DoublePacket<Packet>& predux_half_dowto4(const DoublePacket<Packet>& a,
  650|       |                                               std::enable_if_t<unpacket_traits<Packet>::size <= 8>* = 0) {
  651|       |  return a;
  652|       |}
  653|       |
  654|       |template <typename Packet>
  655|       |DoublePacket<typename unpacket_traits<Packet>::half> predux_half_dowto4(
  656|       |    const DoublePacket<Packet>& a, std::enable_if_t<unpacket_traits<Packet>::size == 16>* = 0) {
  657|       |  // yes, that's pretty hackish :(
  658|       |  DoublePacket<typename unpacket_traits<Packet>::half> res;
  659|       |  typedef std::complex<typename unpacket_traits<Packet>::type> Cplx;
  660|       |  typedef typename packet_traits<Cplx>::type CplxPacket;
  661|       |  res.first = predux_half_dowto4(CplxPacket(a.first)).v;
  662|       |  res.second = predux_half_dowto4(CplxPacket(a.second)).v;
  663|       |  return res;
  664|       |}
  665|       |
  666|       |// same here, "quad" actually means "8" in terms of real coefficients
  667|       |template <typename Scalar, typename RealPacket>
  668|       |void loadQuadToDoublePacket(const Scalar* b, DoublePacket<RealPacket>& dest,
  669|       |                            std::enable_if_t<unpacket_traits<RealPacket>::size <= 8>* = 0) {
  670|       |  dest.first = pset1<RealPacket>(numext::real(*b));
  671|       |  dest.second = pset1<RealPacket>(numext::imag(*b));
  672|       |}
  673|       |
  674|       |template <typename Scalar, typename RealPacket>
  675|       |void loadQuadToDoublePacket(const Scalar* b, DoublePacket<RealPacket>& dest,
  676|       |                            std::enable_if_t<unpacket_traits<RealPacket>::size == 16>* = 0) {
  677|       |  // yes, that's pretty hackish too :(
  678|       |  typedef typename NumTraits<Scalar>::Real RealScalar;
  679|       |  RealScalar r[4] = {numext::real(b[0]), numext::real(b[0]), numext::real(b[1]), numext::real(b[1])};
  680|       |  RealScalar i[4] = {numext::imag(b[0]), numext::imag(b[0]), numext::imag(b[1]), numext::imag(b[1])};
  681|       |  dest.first = ploadquad<RealPacket>(r);
  682|       |  dest.second = ploadquad<RealPacket>(i);
  683|       |}
  684|       |
  685|       |template <typename Packet>
  686|       |struct unpacket_traits<DoublePacket<Packet> > {
  687|       |  typedef DoublePacket<typename unpacket_traits<Packet>::half> half;
  688|       |  enum { size = 2 * unpacket_traits<Packet>::size };
  689|       |};
  690|       |// template<typename Packet>
  691|       |// DoublePacket<Packet> pmadd(const DoublePacket<Packet> &a, const DoublePacket<Packet> &b)
  692|       |// {
  693|       |//   DoublePacket<Packet> res;
  694|       |//   res.first  = padd(a.first, b.first);
  695|       |//   res.second = padd(a.second,b.second);
  696|       |//   return res;
  697|       |// }
  698|       |
  699|       |template <typename RealScalar, bool ConjLhs_, bool ConjRhs_, int Arch, int PacketSize_>
  700|       |class gebp_traits<std::complex<RealScalar>, std::complex<RealScalar>, ConjLhs_, ConjRhs_, Arch, PacketSize_> {
  701|       | public:
  702|       |  typedef std::complex<RealScalar> Scalar;
  703|       |  typedef std::complex<RealScalar> LhsScalar;
  704|       |  typedef std::complex<RealScalar> RhsScalar;
  705|       |  typedef std::complex<RealScalar> ResScalar;
  706|       |
  707|       |  PACKET_DECL_COND_POSTFIX(_, Lhs, PacketSize_);
  708|       |  PACKET_DECL_COND_POSTFIX(_, Rhs, PacketSize_);
  709|       |  PACKET_DECL_COND_POSTFIX(_, Res, PacketSize_);
  710|       |  PACKET_DECL_COND(Real, PacketSize_);
  711|       |  PACKET_DECL_COND_SCALAR(PacketSize_);
  712|       |
  713|       |  enum {
  714|       |    ConjLhs = ConjLhs_,
  715|       |    ConjRhs = ConjRhs_,
  716|       |    Vectorizable = unpacket_traits<RealPacket>::vectorizable && unpacket_traits<ScalarPacket>::vectorizable,
  717|       |    ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1,
  718|       |    LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
  719|       |    RhsPacketSize = Vectorizable ? unpacket_traits<RhsScalar>::size : 1,
  720|       |    RealPacketSize = Vectorizable ? unpacket_traits<RealPacket>::size : 1,
  721|       |    NumberOfRegisters = EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS,
  722|       |
  723|       |    nr = 4,
  724|       |    mr = (plain_enum_min(16, NumberOfRegisters) / 2 / nr) * ResPacketSize,
  725|       |
  726|       |    LhsProgress = ResPacketSize,
  727|       |    RhsProgress = 1
  728|       |  };
  729|       |
  730|       |  typedef DoublePacket<RealPacket> DoublePacketType;
  731|       |
  732|       |  typedef std::conditional_t<Vectorizable, ScalarPacket, Scalar> LhsPacket4Packing;
  733|       |  typedef std::conditional_t<Vectorizable, RealPacket, Scalar> LhsPacket;
  734|       |  typedef std::conditional_t<Vectorizable, DoublePacketType, Scalar> RhsPacket;
  735|       |  typedef std::conditional_t<Vectorizable, ScalarPacket, Scalar> ResPacket;
  736|       |  typedef std::conditional_t<Vectorizable, DoublePacketType, Scalar> AccPacket;
  737|       |
  738|       |  // this actually holds 8 packets!
  739|       |  typedef QuadPacket<RhsPacket> RhsPacketx4;
  740|       |
  741|       |  EIGEN_STRONG_INLINE void initAcc(Scalar& p) { p = Scalar(0); }
  742|       |
  743|       |  EIGEN_STRONG_INLINE void initAcc(DoublePacketType& p) {
  744|       |    p.first = pset1<RealPacket>(RealScalar(0));
  745|       |    p.second = pset1<RealPacket>(RealScalar(0));
  746|       |  }
  747|       |
  748|       |  // Scalar path
  749|       |  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, ScalarPacket& dest) const { dest = pset1<ScalarPacket>(*b); }
  750|       |
  751|       |  // Vectorized path
  752|       |  template <typename RealPacketType>
  753|       |  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, DoublePacket<RealPacketType>& dest) const {
  754|       |    dest.first = pset1<RealPacketType>(numext::real(*b));
  755|       |    dest.second = pset1<RealPacketType>(numext::imag(*b));
  756|       |  }
  757|       |
  758|       |  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, RhsPacketx4& dest) const {
  759|       |    loadRhs(b, dest.B_0);
  760|       |    loadRhs(b + 1, dest.B1);
  761|       |    loadRhs(b + 2, dest.B2);
  762|       |    loadRhs(b + 3, dest.B3);
  763|       |  }
  764|       |
  765|       |  // Scalar path
  766|       |  EIGEN_STRONG_INLINE void updateRhs(const RhsScalar* b, ScalarPacket& dest) const { loadRhs(b, dest); }
  767|       |
  768|       |  // Vectorized path
  769|       |  template <typename RealPacketType>
  770|       |  EIGEN_STRONG_INLINE void updateRhs(const RhsScalar* b, DoublePacket<RealPacketType>& dest) const {
  771|       |    loadRhs(b, dest);
  772|       |  }
  773|       |
  774|       |  EIGEN_STRONG_INLINE void updateRhs(const RhsScalar*, RhsPacketx4&) const {}
  775|       |
  776|       |  EIGEN_STRONG_INLINE void loadRhsQuad(const RhsScalar* b, ResPacket& dest) const { loadRhs(b, dest); }
  777|       |  EIGEN_STRONG_INLINE void loadRhsQuad(const RhsScalar* b, DoublePacketType& dest) const {
  778|       |    loadQuadToDoublePacket(b, dest);
  779|       |  }
  780|       |
  781|       |  // nothing special here
  782|       |  EIGEN_STRONG_INLINE void loadLhs(const LhsScalar* a, LhsPacket& dest) const {
  783|       |    dest = pload<LhsPacket>((const typename unpacket_traits<LhsPacket>::type*)(a));
  784|       |  }
  785|       |
  786|       |  template <typename LhsPacketType>
  787|       |  EIGEN_STRONG_INLINE void loadLhsUnaligned(const LhsScalar* a, LhsPacketType& dest) const {
  788|       |    dest = ploadu<LhsPacketType>((const typename unpacket_traits<LhsPacketType>::type*)(a));
  789|       |  }
  790|       |
  791|       |  template <typename LhsPacketType, typename RhsPacketType, typename ResPacketType, typename TmpType,
  792|       |            typename LaneIdType>
  793|       |  EIGEN_STRONG_INLINE std::enable_if_t<!is_same<RhsPacketType, RhsPacketx4>::value> madd(const LhsPacketType& a,
  794|       |                                                                                         const RhsPacketType& b,
  795|       |                                                                                         DoublePacket<ResPacketType>& c,
  796|       |                                                                                         TmpType& /*tmp*/,
  797|       |                                                                                         const LaneIdType&) const {
  798|       |    c.first = pmadd(a, b.first, c.first);
  799|       |    c.second = pmadd(a, b.second, c.second);
  800|       |  }
  801|       |
  802|       |  template <typename LaneIdType>
  803|       |  EIGEN_STRONG_INLINE void madd(const LhsPacket& a, const RhsPacket& b, ResPacket& c, RhsPacket& /*tmp*/,
  804|       |                                const LaneIdType&) const {
  805|       |    c = cj.pmadd(a, b, c);
  806|       |  }
  807|       |
  808|       |  template <typename LhsPacketType, typename AccPacketType, typename LaneIdType>
  809|       |  EIGEN_STRONG_INLINE void madd(const LhsPacketType& a, const RhsPacketx4& b, AccPacketType& c, RhsPacket& tmp,
  810|       |                                const LaneIdType& lane) const {
  811|       |    madd(a, b.get(lane), c, tmp, lane);
  812|       |  }
  813|       |
  814|       |  EIGEN_STRONG_INLINE void acc(const Scalar& c, const Scalar& alpha, Scalar& r) const { r += alpha * c; }
  815|       |
  816|       |  template <typename RealPacketType, typename ResPacketType>
  817|       |  EIGEN_STRONG_INLINE void acc(const DoublePacket<RealPacketType>& c, const ResPacketType& alpha,
  818|       |                               ResPacketType& r) const {
  819|       |    // assemble c
  820|       |    ResPacketType tmp;
  821|       |    if ((!ConjLhs) && (!ConjRhs)) {
  822|       |      tmp = pcplxflip(pconj(ResPacketType(c.second)));
  823|       |      tmp = padd(ResPacketType(c.first), tmp);
  824|       |    } else if ((!ConjLhs) && (ConjRhs)) {
  825|       |      tmp = pconj(pcplxflip(ResPacketType(c.second)));
  826|       |      tmp = padd(ResPacketType(c.first), tmp);
  827|       |    } else if ((ConjLhs) && (!ConjRhs)) {
  828|       |      tmp = pcplxflip(ResPacketType(c.second));
  829|       |      tmp = padd(pconj(ResPacketType(c.first)), tmp);
  830|       |    } else if ((ConjLhs) && (ConjRhs)) {
  831|       |      tmp = pcplxflip(ResPacketType(c.second));
  832|       |      tmp = psub(pconj(ResPacketType(c.first)), tmp);
  833|       |    }
  834|       |
  835|       |    r = pmadd(tmp, alpha, r);
  836|       |  }
  837|       |
  838|       | protected:
  839|       |  conj_helper<LhsScalar, RhsScalar, ConjLhs, ConjRhs> cj;
  840|       |};
  841|       |
  842|       |template <typename RealScalar, bool ConjRhs_, int Arch, int PacketSize_>
  843|       |class gebp_traits<RealScalar, std::complex<RealScalar>, false, ConjRhs_, Arch, PacketSize_> {
  844|       | public:
  845|       |  typedef std::complex<RealScalar> Scalar;
  846|       |  typedef RealScalar LhsScalar;
  847|       |  typedef Scalar RhsScalar;
  848|       |  typedef Scalar ResScalar;
  849|       |
  850|       |  PACKET_DECL_COND_POSTFIX(_, Lhs, PacketSize_);
  851|       |  PACKET_DECL_COND_POSTFIX(_, Rhs, PacketSize_);
  852|       |  PACKET_DECL_COND_POSTFIX(_, Res, PacketSize_);
  853|       |  PACKET_DECL_COND_POSTFIX(_, Real, PacketSize_);
  854|       |  PACKET_DECL_COND_SCALAR_POSTFIX(_, PacketSize_);
  855|       |
  856|       |#undef PACKET_DECL_COND_SCALAR_POSTFIX
  857|       |#undef PACKET_DECL_COND_POSTFIX
  858|       |#undef PACKET_DECL_COND_SCALAR
  859|       |#undef PACKET_DECL_COND
  860|       |
  861|       |  enum {
  862|       |    ConjLhs = false,
  863|       |    ConjRhs = ConjRhs_,
  864|       |    Vectorizable = unpacket_traits<RealPacket_>::vectorizable && unpacket_traits<ScalarPacket_>::vectorizable,
  865|       |    LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
  866|       |    RhsPacketSize = Vectorizable ? unpacket_traits<RhsPacket_>::size : 1,
  867|       |    ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1,
  868|       |
  869|       |    NumberOfRegisters = EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS,
  870|       |    // FIXME: should depend on NumberOfRegisters
  871|       |    nr = 4,
  872|       |    mr = (plain_enum_min(16, NumberOfRegisters) / 2 / nr) * ResPacketSize,
  873|       |
  874|       |    LhsProgress = ResPacketSize,
  875|       |    RhsProgress = 1
  876|       |  };
  877|       |
  878|       |  typedef std::conditional_t<Vectorizable, LhsPacket_, LhsScalar> LhsPacket;
  879|       |  typedef std::conditional_t<Vectorizable, RhsPacket_, RhsScalar> RhsPacket;
  880|       |  typedef std::conditional_t<Vectorizable, ResPacket_, ResScalar> ResPacket;
  881|       |  typedef LhsPacket LhsPacket4Packing;
  882|       |  typedef QuadPacket<RhsPacket> RhsPacketx4;
  883|       |  typedef ResPacket AccPacket;
  884|       |
  885|       |  EIGEN_STRONG_INLINE void initAcc(AccPacket& p) { p = pset1<ResPacket>(ResScalar(0)); }
  886|       |
  887|       |  template <typename RhsPacketType>
  888|       |  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, RhsPacketType& dest) const {
  889|       |    dest = pset1<RhsPacketType>(*b);
  890|       |  }
  891|       |
  892|       |  EIGEN_STRONG_INLINE void loadRhs(const RhsScalar* b, RhsPacketx4& dest) const {
  893|       |    pbroadcast4(b, dest.B_0, dest.B1, dest.B2, dest.B3);
  894|       |  }
  895|       |
  896|       |  template <typename RhsPacketType>
  897|       |  EIGEN_STRONG_INLINE void updateRhs(const RhsScalar* b, RhsPacketType& dest) const {
  898|       |    loadRhs(b, dest);
  899|       |  }
  900|       |
  901|       |  EIGEN_STRONG_INLINE void updateRhs(const RhsScalar*, RhsPacketx4&) const {}
  902|       |
  903|       |  EIGEN_STRONG_INLINE void loadLhs(const LhsScalar* a, LhsPacket& dest) const { dest = ploaddup<LhsPacket>(a); }
  904|       |
  905|       |  EIGEN_STRONG_INLINE void loadRhsQuad(const RhsScalar* b, RhsPacket& dest) const { dest = ploadquad<RhsPacket>(b); }
  906|       |
  907|       |  template <typename LhsPacketType>
  908|       |  EIGEN_STRONG_INLINE void loadLhsUnaligned(const LhsScalar* a, LhsPacketType& dest) const {
  909|       |    dest = ploaddup<LhsPacketType>(a);
  910|       |  }
  911|       |
  912|       |  template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType, typename LaneIdType>
  913|       |  EIGEN_STRONG_INLINE void madd(const LhsPacketType& a, const RhsPacketType& b, AccPacketType& c, RhsPacketType& tmp,
  914|       |                                const LaneIdType&) const {
  915|       |    madd_impl(a, b, c, tmp, std::conditional_t<Vectorizable, true_type, false_type>());
  916|       |  }
  917|       |
  918|       |  template <typename LhsPacketType, typename RhsPacketType, typename AccPacketType>
  919|       |  EIGEN_STRONG_INLINE void madd_impl(const LhsPacketType& a, const RhsPacketType& b, AccPacketType& c,
  920|       |                                     RhsPacketType& tmp, const true_type&) const {
  921|       |#ifdef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
  922|       |    EIGEN_UNUSED_VARIABLE(tmp);
  923|       |    c.v = pmadd(a, b.v, c.v);
  924|       |#else
  925|       |    tmp = b;
  926|       |    tmp.v = pmul(a, tmp.v);
  927|       |    c = padd(c, tmp);
  928|       |#endif
  929|       |  }
  930|       |
  931|       |  EIGEN_STRONG_INLINE void madd_impl(const LhsScalar& a, const RhsScalar& b, ResScalar& c, RhsScalar& /*tmp*/,
  932|       |                                     const false_type&) const {
  933|       |    c += a * b;
  934|       |  }
  935|       |
  936|       |  template <typename LhsPacketType, typename AccPacketType, typename LaneIdType>
  937|       |  EIGEN_STRONG_INLINE void madd(const LhsPacketType& a, const RhsPacketx4& b, AccPacketType& c, RhsPacket& tmp,
  938|       |                                const LaneIdType& lane) const {
  939|       |    madd(a, b.get(lane), c, tmp, lane);
  940|       |  }
  941|       |
  942|       |  template <typename ResPacketType, typename AccPacketType>
  943|       |  EIGEN_STRONG_INLINE void acc(const AccPacketType& c, const ResPacketType& alpha, ResPacketType& r) const {
  944|       |    conj_helper<ResPacketType, ResPacketType, false, ConjRhs> cj;
  945|       |    r = cj.pmadd(alpha, c, r);
  946|       |  }
  947|       |
  948|       | protected:
  949|       |};
  950|       |
  951|       |/* optimized General packed Block * packed Panel product kernel
  952|       | *
  953|       | * Mixing type logic: C += A * B
  954|       | *  |  A  |  B  | comments
  955|       | *  |real |cplx | no vectorization yet, would require to pack A with duplication
  956|       | *  |cplx |real | easy vectorization
  957|       | */
  958|       |template <typename LhsScalar, typename RhsScalar, typename Index, typename DataMapper, int mr, int nr,
  959|       |          bool ConjugateLhs, bool ConjugateRhs>
  960|       |struct gebp_kernel {
  961|       |  typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target> Traits;
  962|       |  typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target, GEBPPacketHalf>
  963|       |      HalfTraits;
  964|       |  typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target, GEBPPacketQuarter>
  965|       |      QuarterTraits;
  966|       |
  967|       |  typedef typename Traits::ResScalar ResScalar;
  968|       |  typedef typename Traits::LhsPacket LhsPacket;
  969|       |  typedef typename Traits::RhsPacket RhsPacket;
  970|       |  typedef typename Traits::ResPacket ResPacket;
  971|       |  typedef typename Traits::AccPacket AccPacket;
  972|       |  typedef typename Traits::RhsPacketx4 RhsPacketx4;
  973|       |
  974|       |  typedef typename RhsPanelHelper<RhsPacket, RhsPacketx4, 15>::type RhsPanel15;
  975|       |  typedef typename RhsPanelHelper<RhsPacket, RhsPacketx4, 27>::type RhsPanel27;
  976|       |
  977|       |  typedef gebp_traits<RhsScalar, LhsScalar, ConjugateRhs, ConjugateLhs, Architecture::Target> SwappedTraits;
  978|       |
  979|       |  typedef typename SwappedTraits::ResScalar SResScalar;
  980|       |  typedef typename SwappedTraits::LhsPacket SLhsPacket;
  981|       |  typedef typename SwappedTraits::RhsPacket SRhsPacket;
  982|       |  typedef typename SwappedTraits::ResPacket SResPacket;
  983|       |  typedef typename SwappedTraits::AccPacket SAccPacket;
  984|       |
  985|       |  typedef typename HalfTraits::LhsPacket LhsPacketHalf;
  986|       |  typedef typename HalfTraits::RhsPacket RhsPacketHalf;
  987|       |  typedef typename HalfTraits::ResPacket ResPacketHalf;
  988|       |  typedef typename HalfTraits::AccPacket AccPacketHalf;
  989|       |
  990|       |  typedef typename QuarterTraits::LhsPacket LhsPacketQuarter;
  991|       |  typedef typename QuarterTraits::RhsPacket RhsPacketQuarter;
  992|       |  typedef typename QuarterTraits::ResPacket ResPacketQuarter;
  993|       |  typedef typename QuarterTraits::AccPacket AccPacketQuarter;
  994|       |
  995|       |  typedef typename DataMapper::LinearMapper LinearMapper;
  996|       |
  997|       |  enum {
  998|       |    Vectorizable = Traits::Vectorizable,
  999|       |    LhsProgress = Traits::LhsProgress,
 1000|       |    LhsProgressHalf = HalfTraits::LhsProgress,
 1001|       |    LhsProgressQuarter = QuarterTraits::LhsProgress,
 1002|       |    RhsProgress = Traits::RhsProgress,
 1003|       |    RhsProgressHalf = HalfTraits::RhsProgress,
 1004|       |    RhsProgressQuarter = QuarterTraits::RhsProgress,
 1005|       |    ResPacketSize = Traits::ResPacketSize
 1006|       |  };
 1007|       |
 1008|       |  EIGEN_DONT_INLINE void operator()(const DataMapper& res, const LhsScalar* blockA, const RhsScalar* blockB, Index rows,
 1009|       |                                    Index depth, Index cols, ResScalar alpha, Index strideA = -1, Index strideB = -1,
 1010|       |                                    Index offsetA = 0, Index offsetB = 0);
 1011|       |};
 1012|       |
 1013|       |template <typename LhsScalar, typename RhsScalar, typename Index, typename DataMapper, int mr, int nr,
 1014|       |          bool ConjugateLhs, bool ConjugateRhs,
 1015|       |          int SwappedLhsProgress =
 1016|       |              gebp_traits<RhsScalar, LhsScalar, ConjugateRhs, ConjugateLhs, Architecture::Target>::LhsProgress>
 1017|       |struct last_row_process_16_packets {
 1018|       |  typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target> Traits;
 1019|       |  typedef gebp_traits<RhsScalar, LhsScalar, ConjugateRhs, ConjugateLhs, Architecture::Target> SwappedTraits;
 1020|       |
 1021|       |  typedef typename Traits::ResScalar ResScalar;
 1022|       |  typedef typename SwappedTraits::LhsPacket SLhsPacket;
 1023|       |  typedef typename SwappedTraits::RhsPacket SRhsPacket;
 1024|       |  typedef typename SwappedTraits::ResPacket SResPacket;
 1025|       |  typedef typename SwappedTraits::AccPacket SAccPacket;
 1026|       |
 1027|       |  EIGEN_STRONG_INLINE void operator()(const DataMapper& res, SwappedTraits& straits, const LhsScalar* blA,
 1028|       |                                      const RhsScalar* blB, Index depth, const Index endk, Index i, Index j2,
 1029|      0|                                      ResScalar alpha, SAccPacket& C0) {
 1030|      0|    EIGEN_UNUSED_VARIABLE(res);
 1031|      0|    EIGEN_UNUSED_VARIABLE(straits);
 1032|      0|    EIGEN_UNUSED_VARIABLE(blA);
 1033|      0|    EIGEN_UNUSED_VARIABLE(blB);
 1034|      0|    EIGEN_UNUSED_VARIABLE(depth);
 1035|      0|    EIGEN_UNUSED_VARIABLE(endk);
 1036|      0|    EIGEN_UNUSED_VARIABLE(i);
 1037|      0|    EIGEN_UNUSED_VARIABLE(j2);
 1038|      0|    EIGEN_UNUSED_VARIABLE(alpha);
 1039|      0|    EIGEN_UNUSED_VARIABLE(C0);
 1040|      0|  }
 1041|       |};
 1042|       |
 1043|       |template <typename LhsScalar, typename RhsScalar, typename Index, typename DataMapper, int mr, int nr,
 1044|       |          bool ConjugateLhs, bool ConjugateRhs>
 1045|       |struct last_row_process_16_packets<LhsScalar, RhsScalar, Index, DataMapper, mr, nr, ConjugateLhs, ConjugateRhs, 16> {
 1046|       |  typedef gebp_traits<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs, Architecture::Target> Traits;
 1047|       |  typedef gebp_traits<RhsScalar, LhsScalar, ConjugateRhs, ConjugateLhs, Architecture::Target> SwappedTraits;
 1048|       |
 1049|       |  typedef typename Traits::ResScalar ResScalar;
 1050|       |  typedef typename SwappedTraits::LhsPacket SLhsPacket;
 1051|       |  typedef typename SwappedTraits::RhsPacket SRhsPacket;
 1052|       |  typedef typename SwappedTraits::ResPacket SResPacket;
 1053|       |  typedef typename SwappedTraits::AccPacket SAccPacket;
 1054|       |
 1055|       |  EIGEN_STRONG_INLINE void operator()(const DataMapper& res, SwappedTraits& straits, const LhsScalar* blA,
 1056|       |                                      const RhsScalar* blB, Index depth, const Index endk, Index i, Index j2,
 1057|       |                                      ResScalar alpha, SAccPacket& C0) {
 1058|       |    typedef typename unpacket_traits<typename unpacket_traits<SResPacket>::half>::half SResPacketQuarter;
 1059|       |    typedef typename unpacket_traits<typename unpacket_traits<SLhsPacket>::half>::half SLhsPacketQuarter;
 1060|       |    typedef typename unpacket_traits<typename unpacket_traits<SRhsPacket>::half>::half SRhsPacketQuarter;
 1061|       |    typedef typename unpacket_traits<typename unpacket_traits<SAccPacket>::half>::half SAccPacketQuarter;
 1062|       |
 1063|       |    SResPacketQuarter R = res.template gatherPacket<SResPacketQuarter>(i, j2);
 1064|       |    SResPacketQuarter alphav = pset1<SResPacketQuarter>(alpha);
 1065|       |
 1066|       |    if (depth - endk > 0) {
 1067|       |      // We have to handle the last row(s) of the rhs, which
 1068|       |      // correspond to a half-packet
 1069|       |      SAccPacketQuarter c0 = predux_half_dowto4(predux_half_dowto4(C0));
 1070|       |
 1071|       |      for (Index kk = endk; kk < depth; kk++) {
 1072|       |        SLhsPacketQuarter a0;
 1073|       |        SRhsPacketQuarter b0;
 1074|       |        straits.loadLhsUnaligned(blB, a0);
 1075|       |        straits.loadRhs(blA, b0);
 1076|       |        straits.madd(a0, b0, c0, b0, fix<0>);
 1077|       |        blB += SwappedTraits::LhsProgress / 4;
 1078|       |        blA += 1;
 1079|       |      }
 1080|       |      straits.acc(c0, alphav, R);
 1081|       |    } else {
 1082|       |      straits.acc(predux_half_dowto4(predux_half_dowto4(C0)), alphav, R);
 1083|       |    }
 1084|       |    res.scatterPacket(i, j2, R);
 1085|       |  }
 1086|       |};
 1087|       |
 1088|       |template <int nr, Index LhsProgress, Index RhsProgress, typename LhsScalar, typename RhsScalar, typename ResScalar,
 1089|       |          typename AccPacket, typename LhsPacket, typename RhsPacket, typename ResPacket, typename GEBPTraits,
 1090|       |          typename LinearMapper, typename DataMapper>
 1091|       |struct lhs_process_one_packet {
 1092|       |  typedef typename GEBPTraits::RhsPacketx4 RhsPacketx4;
 1093|       |
 1094|       |  EIGEN_STRONG_INLINE void peeled_kc_onestep(Index K, const LhsScalar* blA, const RhsScalar* blB, GEBPTraits traits,
 1095|       |                                             LhsPacket* A0, RhsPacketx4* rhs_panel, RhsPacket* T0, AccPacket* C0,
 1096|      0|                                             AccPacket* C1, AccPacket* C2, AccPacket* C3) {
 1097|      0|    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 1X4");
 1098|      0|    EIGEN_ASM_COMMENT("Note: these asm comments work around bug 935!");
 1099|      0|    traits.loadLhs(&blA[(0 + 1 * K) * LhsProgress], *A0);
 1100|      0|    traits.loadRhs(&blB[(0 + 4 * K) * RhsProgress], *rhs_panel);
 1101|      0|    traits.madd(*A0, *rhs_panel, *C0, *T0, fix<0>);
 1102|      0|    traits.madd(*A0, *rhs_panel, *C1, *T0, fix<1>);
 1103|      0|    traits.madd(*A0, *rhs_panel, *C2, *T0, fix<2>);
 1104|      0|    traits.madd(*A0, *rhs_panel, *C3, *T0, fix<3>);
 1105|       |#if EIGEN_GNUC_STRICT_AT_LEAST(6, 0, 0) && defined(EIGEN_VECTORIZE_SSE) && !(EIGEN_COMP_LCC)
 1106|       |    __asm__("" : "+x,m"(*A0));
 1107|       |#endif
 1108|      0|    EIGEN_ASM_COMMENT("end step of gebp micro kernel 1X4");
 1109|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22lhs_process_one_packetILi4ELl1ELl1E14AnnoyingScalarS2_S2_S2_S2_S2_S2_NS0_11gebp_traitsIS2_S2_Lb0ELb0ELi1ELi0EEENS0_16BlasLinearMapperIS2_lLi0ELi1EEENS0_16blas_data_mapperIS2_lLi0ELi0ELi1EEEE17peeled_kc_onestepElPKS2_SB_S4_PS2_PNS0_10QuadPacketIS2_EESC_SC_SC_SC_SC_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22lhs_process_one_packetILi4ELl1ELl1E14AnnoyingScalarS2_S2_S2_S2_S2_S2_NS0_11gebp_traitsIS2_S2_Lb0ELb0ELi1ELi1EEENS0_16BlasLinearMapperIS2_lLi0ELi1EEENS0_16blas_data_mapperIS2_lLi0ELi0ELi1EEEE17peeled_kc_onestepElPKS2_SB_S4_PS2_PNS0_10QuadPacketIS2_EESC_SC_SC_SC_SC_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22lhs_process_one_packetILi4ELl1ELl1E14AnnoyingScalarS2_S2_S2_S2_S2_S2_NS0_11gebp_traitsIS2_S2_Lb0ELb0ELi1ELi2EEENS0_16BlasLinearMapperIS2_lLi0ELi1EEENS0_16blas_data_mapperIS2_lLi0ELi0ELi1EEEE17peeled_kc_onestepElPKS2_SB_S4_PS2_PNS0_10QuadPacketIS2_EESC_SC_SC_SC_SC_
  ------------------
 1110|       |
 1111|       |  EIGEN_STRONG_INLINE void operator()(const DataMapper& res, const LhsScalar* blockA, const RhsScalar* blockB,
 1112|       |                                      ResScalar alpha, Index peelStart, Index peelEnd, Index strideA, Index strideB,
 1113|       |                                      Index offsetA, Index offsetB, int prefetch_res_offset, Index peeled_kc, Index pk,
 1114|      0|                                      Index cols, Index depth, Index packet_cols4) {
 1115|      0|    GEBPTraits traits;
 1116|      0|    Index packet_cols8 = nr >= 8 ? (cols / 8) * 8 : 0;
 1117|       |    // loops on each largest micro horizontal panel of lhs
 1118|       |    // (LhsProgress x depth)
 1119|      0|    for (Index i = peelStart; i < peelEnd; i += LhsProgress) {
 1120|       |#if EIGEN_ARCH_ARM64 || EIGEN_ARCH_LOONGARCH64
 1121|       |      EIGEN_IF_CONSTEXPR(nr >= 8) {
 1122|       |        for (Index j2 = 0; j2 < packet_cols8; j2 += 8) {
 1123|       |          const LhsScalar* blA = &blockA[i * strideA + offsetA * (LhsProgress)];
 1124|       |          prefetch(&blA[0]);
 1125|       |
 1126|       |          // gets res block as register
 1127|       |          AccPacket C0, C1, C2, C3, C4, C5, C6, C7;
 1128|       |          traits.initAcc(C0);
 1129|       |          traits.initAcc(C1);
 1130|       |          traits.initAcc(C2);
 1131|       |          traits.initAcc(C3);
 1132|       |          traits.initAcc(C4);
 1133|       |          traits.initAcc(C5);
 1134|       |          traits.initAcc(C6);
 1135|       |          traits.initAcc(C7);
 1136|       |
 1137|       |          LinearMapper r0 = res.getLinearMapper(i, j2 + 0);
 1138|       |          LinearMapper r1 = res.getLinearMapper(i, j2 + 1);
 1139|       |          LinearMapper r2 = res.getLinearMapper(i, j2 + 2);
 1140|       |          LinearMapper r3 = res.getLinearMapper(i, j2 + 3);
 1141|       |          LinearMapper r4 = res.getLinearMapper(i, j2 + 4);
 1142|       |          LinearMapper r5 = res.getLinearMapper(i, j2 + 5);
 1143|       |          LinearMapper r6 = res.getLinearMapper(i, j2 + 6);
 1144|       |          LinearMapper r7 = res.getLinearMapper(i, j2 + 7);
 1145|       |          r0.prefetch(prefetch_res_offset);
 1146|       |          r1.prefetch(prefetch_res_offset);
 1147|       |          r2.prefetch(prefetch_res_offset);
 1148|       |          r3.prefetch(prefetch_res_offset);
 1149|       |          r4.prefetch(prefetch_res_offset);
 1150|       |          r5.prefetch(prefetch_res_offset);
 1151|       |          r6.prefetch(prefetch_res_offset);
 1152|       |          r7.prefetch(prefetch_res_offset);
 1153|       |          const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 8];
 1154|       |          prefetch(&blB[0]);
 1155|       |
 1156|       |          LhsPacket A0;
 1157|       |          for (Index k = 0; k < peeled_kc; k += pk) {
 1158|       |            RhsPacketx4 rhs_panel;
 1159|       |            RhsPacket T0;
 1160|       |#define EIGEN_GEBGP_ONESTEP(K)                                    \
 1161|       |  do {                                                            \
 1162|       |    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 1pX8");    \
 1163|       |    traits.loadLhs(&blA[(0 + 1 * K) * LhsProgress], A0);          \
 1164|       |    traits.loadRhs(&blB[(0 + 8 * K) * RhsProgress], rhs_panel);   \
 1165|       |    traits.madd(A0, rhs_panel, C0, T0, fix<0>);                   \
 1166|       |    traits.updateRhs(&blB[(1 + 8 * K) * RhsProgress], rhs_panel); \
 1167|       |    traits.madd(A0, rhs_panel, C1, T0, fix<1>);                   \
 1168|       |    traits.updateRhs(&blB[(2 + 8 * K) * RhsProgress], rhs_panel); \
 1169|       |    traits.madd(A0, rhs_panel, C2, T0, fix<2>);                   \
 1170|       |    traits.updateRhs(&blB[(3 + 8 * K) * RhsProgress], rhs_panel); \
 1171|       |    traits.madd(A0, rhs_panel, C3, T0, fix<3>);                   \
 1172|       |    traits.loadRhs(&blB[(4 + 8 * K) * RhsProgress], rhs_panel);   \
 1173|       |    traits.madd(A0, rhs_panel, C4, T0, fix<0>);                   \
 1174|       |    traits.updateRhs(&blB[(5 + 8 * K) * RhsProgress], rhs_panel); \
 1175|       |    traits.madd(A0, rhs_panel, C5, T0, fix<1>);                   \
 1176|       |    traits.updateRhs(&blB[(6 + 8 * K) * RhsProgress], rhs_panel); \
 1177|       |    traits.madd(A0, rhs_panel, C6, T0, fix<2>);                   \
 1178|       |    traits.updateRhs(&blB[(7 + 8 * K) * RhsProgress], rhs_panel); \
 1179|       |    traits.madd(A0, rhs_panel, C7, T0, fix<3>);                   \
 1180|       |    EIGEN_ASM_COMMENT("end step of gebp micro kernel 1pX8");      \
 1181|       |  } while (false)
 1182|       |
 1183|       |            EIGEN_ASM_COMMENT("begin gebp micro kernel 1pX8");
 1184|       |
 1185|       |            EIGEN_GEBGP_ONESTEP(0);
 1186|       |            EIGEN_GEBGP_ONESTEP(1);
 1187|       |            EIGEN_GEBGP_ONESTEP(2);
 1188|       |            EIGEN_GEBGP_ONESTEP(3);
 1189|       |            EIGEN_GEBGP_ONESTEP(4);
 1190|       |            EIGEN_GEBGP_ONESTEP(5);
 1191|       |            EIGEN_GEBGP_ONESTEP(6);
 1192|       |            EIGEN_GEBGP_ONESTEP(7);
 1193|       |
 1194|       |            blB += pk * 8 * RhsProgress;
 1195|       |            blA += pk * (1 * LhsProgress);
 1196|       |
 1197|       |            EIGEN_ASM_COMMENT("end gebp micro kernel 1pX8");
 1198|       |          }
 1199|       |          // process remaining peeled loop
 1200|       |          for (Index k = peeled_kc; k < depth; k++) {
 1201|       |            RhsPacketx4 rhs_panel;
 1202|       |            RhsPacket T0;
 1203|       |            EIGEN_GEBGP_ONESTEP(0);
 1204|       |            blB += 8 * RhsProgress;
 1205|       |            blA += 1 * LhsProgress;
 1206|       |          }
 1207|       |
 1208|       |#undef EIGEN_GEBGP_ONESTEP
 1209|       |
 1210|       |          ResPacket R0, R1;
 1211|       |          ResPacket alphav = pset1<ResPacket>(alpha);
 1212|       |
 1213|       |          R0 = r0.template loadPacket<ResPacket>(0);
 1214|       |          R1 = r1.template loadPacket<ResPacket>(0);
 1215|       |          traits.acc(C0, alphav, R0);
 1216|       |          traits.acc(C1, alphav, R1);
 1217|       |          r0.storePacket(0, R0);
 1218|       |          r1.storePacket(0, R1);
 1219|       |
 1220|       |          R0 = r2.template loadPacket<ResPacket>(0);
 1221|       |          R1 = r3.template loadPacket<ResPacket>(0);
 1222|       |          traits.acc(C2, alphav, R0);
 1223|       |          traits.acc(C3, alphav, R1);
 1224|       |          r2.storePacket(0, R0);
 1225|       |          r3.storePacket(0, R1);
 1226|       |
 1227|       |          R0 = r4.template loadPacket<ResPacket>(0);
 1228|       |          R1 = r5.template loadPacket<ResPacket>(0);
 1229|       |          traits.acc(C4, alphav, R0);
 1230|       |          traits.acc(C5, alphav, R1);
 1231|       |          r4.storePacket(0, R0);
 1232|       |          r5.storePacket(0, R1);
 1233|       |
 1234|       |          R0 = r6.template loadPacket<ResPacket>(0);
 1235|       |          R1 = r7.template loadPacket<ResPacket>(0);
 1236|       |          traits.acc(C6, alphav, R0);
 1237|       |          traits.acc(C7, alphav, R1);
 1238|       |          r6.storePacket(0, R0);
 1239|       |          r7.storePacket(0, R1);
 1240|       |        }
 1241|       |      }
 1242|       |#endif
 1243|       |
 1244|       |      // loops on each largest micro vertical panel of rhs (depth * nr)
 1245|      0|      for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
 1246|       |        // We select a LhsProgress x nr micro block of res
 1247|       |        // which is entirely stored into 1 x nr registers.
 1248|       |
 1249|      0|        const LhsScalar* blA = &blockA[i * strideA + offsetA * (LhsProgress)];
 1250|      0|        prefetch(&blA[0]);
 1251|       |
 1252|       |        // gets res block as register
 1253|      0|        AccPacket C0, C1, C2, C3;
 1254|      0|        traits.initAcc(C0);
 1255|      0|        traits.initAcc(C1);
 1256|      0|        traits.initAcc(C2);
 1257|      0|        traits.initAcc(C3);
 1258|       |        // To improve instruction pipelining, let's double the accumulation registers:
 1259|       |        //  even k will accumulate in C*, while odd k will accumulate in D*.
 1260|       |        // This trick is crucial to get good performance with FMA, otherwise it is
 1261|       |        // actually faster to perform separated MUL+ADD because of a naturally
 1262|       |        // better instruction-level parallelism.
 1263|      0|        AccPacket D0, D1, D2, D3;
 1264|      0|        traits.initAcc(D0);
 1265|      0|        traits.initAcc(D1);
 1266|      0|        traits.initAcc(D2);
 1267|      0|        traits.initAcc(D3);
 1268|       |
 1269|      0|        LinearMapper r0 = res.getLinearMapper(i, j2 + 0);
 1270|      0|        LinearMapper r1 = res.getLinearMapper(i, j2 + 1);
 1271|      0|        LinearMapper r2 = res.getLinearMapper(i, j2 + 2);
 1272|      0|        LinearMapper r3 = res.getLinearMapper(i, j2 + 3);
 1273|       |
 1274|      0|        r0.prefetch(prefetch_res_offset);
 1275|      0|        r1.prefetch(prefetch_res_offset);
 1276|      0|        r2.prefetch(prefetch_res_offset);
 1277|      0|        r3.prefetch(prefetch_res_offset);
 1278|       |
 1279|       |        // performs "inner" products
 1280|      0|        const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 4];
 1281|      0|        prefetch(&blB[0]);
 1282|      0|        LhsPacket A0, A1;
 1283|       |
 1284|      0|        for (Index k = 0; k < peeled_kc; k += pk) {
 1285|      0|          EIGEN_ASM_COMMENT("begin gebp micro kernel 1/half/quarterX4");
 1286|      0|          RhsPacketx4 rhs_panel;
 1287|      0|          RhsPacket T0;
 1288|       |
 1289|      0|          internal::prefetch(blB + (48 + 0));
 1290|      0|          peeled_kc_onestep(0, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
 1291|      0|          peeled_kc_onestep(1, blA, blB, traits, &A1, &rhs_panel, &T0, &D0, &D1, &D2, &D3);
 1292|      0|          peeled_kc_onestep(2, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
 1293|      0|          peeled_kc_onestep(3, blA, blB, traits, &A1, &rhs_panel, &T0, &D0, &D1, &D2, &D3);
 1294|      0|          internal::prefetch(blB + (48 + 16));
 1295|      0|          peeled_kc_onestep(4, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
 1296|      0|          peeled_kc_onestep(5, blA, blB, traits, &A1, &rhs_panel, &T0, &D0, &D1, &D2, &D3);
 1297|      0|          peeled_kc_onestep(6, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
 1298|      0|          peeled_kc_onestep(7, blA, blB, traits, &A1, &rhs_panel, &T0, &D0, &D1, &D2, &D3);
 1299|       |
 1300|      0|          blB += pk * 4 * RhsProgress;
 1301|      0|          blA += pk * LhsProgress;
 1302|       |
 1303|      0|          EIGEN_ASM_COMMENT("end gebp micro kernel 1/half/quarterX4");
 1304|      0|        }
 1305|      0|        C0 = padd(C0, D0);
 1306|      0|        C1 = padd(C1, D1);
 1307|      0|        C2 = padd(C2, D2);
 1308|      0|        C3 = padd(C3, D3);
 1309|       |
 1310|       |        // process remaining peeled loop
 1311|      0|        for (Index k = peeled_kc; k < depth; k++) {
 1312|      0|          RhsPacketx4 rhs_panel;
 1313|      0|          RhsPacket T0;
 1314|      0|          peeled_kc_onestep(0, blA, blB, traits, &A0, &rhs_panel, &T0, &C0, &C1, &C2, &C3);
 1315|      0|          blB += 4 * RhsProgress;
 1316|      0|          blA += LhsProgress;
 1317|      0|        }
 1318|       |
 1319|      0|        ResPacket R0, R1;
 1320|      0|        ResPacket alphav = pset1<ResPacket>(alpha);
 1321|       |
 1322|      0|        R0 = r0.template loadPacket<ResPacket>(0);
 1323|      0|        R1 = r1.template loadPacket<ResPacket>(0);
 1324|      0|        traits.acc(C0, alphav, R0);
 1325|      0|        traits.acc(C1, alphav, R1);
 1326|      0|        r0.storePacket(0, R0);
 1327|      0|        r1.storePacket(0, R1);
 1328|       |
 1329|      0|        R0 = r2.template loadPacket<ResPacket>(0);
 1330|      0|        R1 = r3.template loadPacket<ResPacket>(0);
 1331|      0|        traits.acc(C2, alphav, R0);
 1332|      0|        traits.acc(C3, alphav, R1);
 1333|      0|        r2.storePacket(0, R0);
 1334|      0|        r3.storePacket(0, R1);
 1335|      0|      }
 1336|       |
 1337|       |      // Deal with remaining columns of the rhs
 1338|      0|      for (Index j2 = packet_cols4; j2 < cols; j2++) {
 1339|       |        // One column at a time
 1340|      0|        const LhsScalar* blA = &blockA[i * strideA + offsetA * (LhsProgress)];
 1341|      0|        prefetch(&blA[0]);
 1342|       |
 1343|       |        // gets res block as register
 1344|      0|        AccPacket C0;
 1345|      0|        traits.initAcc(C0);
 1346|       |
 1347|      0|        LinearMapper r0 = res.getLinearMapper(i, j2);
 1348|       |
 1349|       |        // performs "inner" products
 1350|      0|        const RhsScalar* blB = &blockB[j2 * strideB + offsetB];
 1351|      0|        LhsPacket A0;
 1352|       |
 1353|      0|        for (Index k = 0; k < peeled_kc; k += pk) {
 1354|      0|          EIGEN_ASM_COMMENT("begin gebp micro kernel 1/half/quarterX1");
 1355|      0|          RhsPacket B_0;
 1356|       |
 1357|      0|#define EIGEN_GEBGP_ONESTEP(K)                                             \
 1358|      0|  do {                                                                     \
 1359|      0|    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 1/half/quarterX1"); \
 1360|      0|    EIGEN_ASM_COMMENT("Note: these asm comments work around bug 935!");    \
 1361|       |    /* FIXME: why unaligned???? */                                         \
 1362|      0|    traits.loadLhsUnaligned(&blA[(0 + 1 * K) * LhsProgress], A0);          \
 1363|      0|    traits.loadRhs(&blB[(0 + K) * RhsProgress], B_0);                      \
 1364|      0|    traits.madd(A0, B_0, C0, B_0, fix<0>);                                 \
 1365|      0|    EIGEN_ASM_COMMENT("end step of gebp micro kernel 1/half/quarterX1");   \
 1366|      0|  } while (false);
 1367|       |
 1368|      0|          EIGEN_GEBGP_ONESTEP(0);
 1369|      0|          EIGEN_GEBGP_ONESTEP(1);
 1370|      0|          EIGEN_GEBGP_ONESTEP(2);
 1371|      0|          EIGEN_GEBGP_ONESTEP(3);
 1372|      0|          EIGEN_GEBGP_ONESTEP(4);
 1373|      0|          EIGEN_GEBGP_ONESTEP(5);
 1374|      0|          EIGEN_GEBGP_ONESTEP(6);
 1375|      0|          EIGEN_GEBGP_ONESTEP(7);
 1376|       |
 1377|      0|          blB += pk * RhsProgress;
 1378|      0|          blA += pk * LhsProgress;
 1379|       |
 1380|      0|          EIGEN_ASM_COMMENT("end gebp micro kernel 1/half/quarterX1");
 1381|      0|        }
 1382|       |
 1383|       |        // process remaining peeled loop
 1384|      0|        for (Index k = peeled_kc; k < depth; k++) {
 1385|      0|          RhsPacket B_0;
 1386|      0|          EIGEN_GEBGP_ONESTEP(0);
 1387|      0|          blB += RhsProgress;
 1388|      0|          blA += LhsProgress;
 1389|      0|        }
 1390|      0|#undef EIGEN_GEBGP_ONESTEP
 1391|      0|        ResPacket R0;
 1392|      0|        ResPacket alphav = pset1<ResPacket>(alpha);
 1393|      0|        R0 = r0.template loadPacket<ResPacket>(0);
 1394|      0|        traits.acc(C0, alphav, R0);
 1395|      0|        r0.storePacket(0, R0);
 1396|      0|      }
 1397|      0|    }
 1398|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22lhs_process_one_packetILi4ELl1ELl1E14AnnoyingScalarS2_S2_S2_S2_S2_S2_NS0_11gebp_traitsIS2_S2_Lb0ELb0ELi1ELi0EEENS0_16BlasLinearMapperIS2_lLi0ELi1EEENS0_16blas_data_mapperIS2_lLi0ELi0ELi1EEEEclERKS8_PKS2_SD_S2_llllllilllll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22lhs_process_one_packetILi4ELl1ELl1E14AnnoyingScalarS2_S2_S2_S2_S2_S2_NS0_11gebp_traitsIS2_S2_Lb0ELb0ELi1ELi1EEENS0_16BlasLinearMapperIS2_lLi0ELi1EEENS0_16blas_data_mapperIS2_lLi0ELi0ELi1EEEEclERKS8_PKS2_SD_S2_llllllilllll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22lhs_process_one_packetILi4ELl1ELl1E14AnnoyingScalarS2_S2_S2_S2_S2_S2_NS0_11gebp_traitsIS2_S2_Lb0ELb0ELi1ELi2EEENS0_16BlasLinearMapperIS2_lLi0ELi1EEENS0_16blas_data_mapperIS2_lLi0ELi0ELi1EEEEclERKS8_PKS2_SD_S2_llllllilllll
  ------------------
 1399|       |};
 1400|       |
 1401|       |template <int nr, Index LhsProgress, Index RhsProgress, typename LhsScalar, typename RhsScalar, typename ResScalar,
 1402|       |          typename AccPacket, typename LhsPacket, typename RhsPacket, typename ResPacket, typename GEBPTraits,
 1403|       |          typename LinearMapper, typename DataMapper>
 1404|       |struct lhs_process_fraction_of_packet
 1405|       |    : lhs_process_one_packet<nr, LhsProgress, RhsProgress, LhsScalar, RhsScalar, ResScalar, AccPacket, LhsPacket,
 1406|       |                             RhsPacket, ResPacket, GEBPTraits, LinearMapper, DataMapper> {
 1407|       |  EIGEN_STRONG_INLINE void peeled_kc_onestep(Index K, const LhsScalar* blA, const RhsScalar* blB, GEBPTraits traits,
 1408|       |                                             LhsPacket* A0, RhsPacket* B_0, RhsPacket* B1, RhsPacket* B2, RhsPacket* B3,
 1409|       |                                             AccPacket* C0, AccPacket* C1, AccPacket* C2, AccPacket* C3) {
 1410|       |    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 1X4");
 1411|       |    EIGEN_ASM_COMMENT("Note: these asm comments work around bug 935!");
 1412|       |    traits.loadLhsUnaligned(&blA[(0 + 1 * K) * (LhsProgress)], *A0);
 1413|       |    traits.broadcastRhs(&blB[(0 + 4 * K) * RhsProgress], *B_0, *B1, *B2, *B3);
 1414|       |    traits.madd(*A0, *B_0, *C0, *B_0);
 1415|       |    traits.madd(*A0, *B1, *C1, *B1);
 1416|       |    traits.madd(*A0, *B2, *C2, *B2);
 1417|       |    traits.madd(*A0, *B3, *C3, *B3);
 1418|       |    EIGEN_ASM_COMMENT("end step of gebp micro kernel 1X4");
 1419|       |  }
 1420|       |};
 1421|       |
 1422|       |template <typename LhsScalar, typename RhsScalar, typename Index, typename DataMapper, int mr, int nr,
 1423|       |          bool ConjugateLhs, bool ConjugateRhs>
 1424|       |EIGEN_DONT_INLINE void gebp_kernel<LhsScalar, RhsScalar, Index, DataMapper, mr, nr, ConjugateLhs,
 1425|       |                                   ConjugateRhs>::operator()(const DataMapper& res, const LhsScalar* blockA,
 1426|       |                                                             const RhsScalar* blockB, Index rows, Index depth,
 1427|       |                                                             Index cols, ResScalar alpha, Index strideA, Index strideB,
 1428|      2|                                                             Index offsetA, Index offsetB) {
 1429|      2|  Traits traits;
 1430|      2|  SwappedTraits straits;
 1431|       |
 1432|      2|  if (strideA == -1) strideA = depth;
 1433|      2|  if (strideB == -1) strideB = depth;
 1434|      2|  conj_helper<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs> cj;
 1435|      2|  Index packet_cols4 = nr >= 4 ? (cols / 4) * 4 : 0;
 1436|      2|  Index packet_cols8 = nr >= 8 ? (cols / 8) * 8 : 0;
 1437|      2|  const Index peeled_mc3 = mr >= 3 * Traits::LhsProgress ? (rows / (3 * LhsProgress)) * (3 * LhsProgress) : 0;
 1438|      2|  const Index peeled_mc2 =
 1439|      2|      mr >= 2 * Traits::LhsProgress ? peeled_mc3 + ((rows - peeled_mc3) / (2 * LhsProgress)) * (2 * LhsProgress) : 0;
 1440|      2|  const Index peeled_mc1 =
 1441|      2|      mr >= 1 * Traits::LhsProgress ? peeled_mc2 + ((rows - peeled_mc2) / (1 * LhsProgress)) * (1 * LhsProgress) : 0;
 1442|      2|  const Index peeled_mc_half =
 1443|      2|      mr >= LhsProgressHalf ? peeled_mc1 + ((rows - peeled_mc1) / (LhsProgressHalf)) * (LhsProgressHalf) : 0;
 1444|      2|  const Index peeled_mc_quarter =
 1445|      2|      mr >= LhsProgressQuarter
 1446|      2|          ? peeled_mc_half + ((rows - peeled_mc_half) / (LhsProgressQuarter)) * (LhsProgressQuarter)
 1447|      2|          : 0;
 1448|      2|  enum { pk = 8 };  // NOTE Such a large peeling factor is important for large matrices (~ +5% when >1000 on Haswell)
 1449|      2|  const Index peeled_kc = depth & ~(pk - 1);
 1450|      2|  const int prefetch_res_offset = 32 / sizeof(ResScalar);
 1451|       |  //     const Index depth2     = depth & ~1;
 1452|       |
 1453|       |  //---------- Process 3 * LhsProgress rows at once ----------
 1454|       |  // This corresponds to 3*LhsProgress x nr register blocks.
 1455|       |  // Usually, make sense only with FMA
 1456|      2|  if (mr >= 3 * Traits::LhsProgress) {
 1457|       |    // Here, the general idea is to loop on each largest micro horizontal panel of the lhs (3*Traits::LhsProgress x
 1458|       |    // depth) and on each largest micro vertical panel of the rhs (depth * nr). Blocking sizes, i.e., 'depth' has been
 1459|       |    // computed so that the micro horizontal panel of the lhs fit in L1. However, if depth is too small, we can extend
 1460|       |    // the number of rows of these horizontal panels. This actual number of rows is computed as follow:
 1461|      0|    const Index l1 = defaultL1CacheSize;  // in Bytes, TODO, l1 should be passed to this function.
 1462|       |    // The max(1, ...) here is needed because we may be using blocking params larger than what our known l1 cache size
 1463|       |    // suggests we should be using: either because our known l1 cache size is inaccurate (e.g. on Android, we can only
 1464|       |    // guess), or because we are testing specific blocking sizes.
 1465|      0|    const Index actual_panel_rows =
 1466|      0|        (3 * LhsProgress) * std::max<Index>(1, ((l1 - sizeof(ResScalar) * mr * nr - depth * nr * sizeof(RhsScalar)) /
 1467|      0|                                                (depth * sizeof(LhsScalar) * 3 * LhsProgress)));
 1468|      0|    for (Index i1 = 0; i1 < peeled_mc3; i1 += actual_panel_rows) {
 1469|      0|      const Index actual_panel_end = (std::min)(i1 + actual_panel_rows, peeled_mc3);
 1470|       |#if EIGEN_ARCH_ARM64 || EIGEN_ARCH_LOONGARCH64
 1471|       |      EIGEN_IF_CONSTEXPR(nr >= 8) {
 1472|       |        for (Index j2 = 0; j2 < packet_cols8; j2 += 8) {
 1473|       |          for (Index i = i1; i < actual_panel_end; i += 3 * LhsProgress) {
 1474|       |            const LhsScalar* blA = &blockA[i * strideA + offsetA * (3 * LhsProgress)];
 1475|       |            prefetch(&blA[0]);
 1476|       |            // gets res block as register
 1477|       |            AccPacket C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10, C11, C12, C13, C14, C15, C16, C17, C18, C19, C20,
 1478|       |                C21, C22, C23;
 1479|       |            traits.initAcc(C0);
 1480|       |            traits.initAcc(C1);
 1481|       |            traits.initAcc(C2);
 1482|       |            traits.initAcc(C3);
 1483|       |            traits.initAcc(C4);
 1484|       |            traits.initAcc(C5);
 1485|       |            traits.initAcc(C6);
 1486|       |            traits.initAcc(C7);
 1487|       |            traits.initAcc(C8);
 1488|       |            traits.initAcc(C9);
 1489|       |            traits.initAcc(C10);
 1490|       |            traits.initAcc(C11);
 1491|       |            traits.initAcc(C12);
 1492|       |            traits.initAcc(C13);
 1493|       |            traits.initAcc(C14);
 1494|       |            traits.initAcc(C15);
 1495|       |            traits.initAcc(C16);
 1496|       |            traits.initAcc(C17);
 1497|       |            traits.initAcc(C18);
 1498|       |            traits.initAcc(C19);
 1499|       |            traits.initAcc(C20);
 1500|       |            traits.initAcc(C21);
 1501|       |            traits.initAcc(C22);
 1502|       |            traits.initAcc(C23);
 1503|       |
 1504|       |            LinearMapper r0 = res.getLinearMapper(i, j2 + 0);
 1505|       |            LinearMapper r1 = res.getLinearMapper(i, j2 + 1);
 1506|       |            LinearMapper r2 = res.getLinearMapper(i, j2 + 2);
 1507|       |            LinearMapper r3 = res.getLinearMapper(i, j2 + 3);
 1508|       |            LinearMapper r4 = res.getLinearMapper(i, j2 + 4);
 1509|       |            LinearMapper r5 = res.getLinearMapper(i, j2 + 5);
 1510|       |            LinearMapper r6 = res.getLinearMapper(i, j2 + 6);
 1511|       |            LinearMapper r7 = res.getLinearMapper(i, j2 + 7);
 1512|       |
 1513|       |            r0.prefetch(0);
 1514|       |            r1.prefetch(0);
 1515|       |            r2.prefetch(0);
 1516|       |            r3.prefetch(0);
 1517|       |            r4.prefetch(0);
 1518|       |            r5.prefetch(0);
 1519|       |            r6.prefetch(0);
 1520|       |            r7.prefetch(0);
 1521|       |
 1522|       |            // performs "inner" products
 1523|       |            const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 8];
 1524|       |            prefetch(&blB[0]);
 1525|       |            LhsPacket A0, A1;
 1526|       |            for (Index k = 0; k < peeled_kc; k += pk) {
 1527|       |              EIGEN_ASM_COMMENT("begin gebp micro kernel 3pX8");
 1528|       |              // 27 registers are taken (24 for acc, 3 for lhs).
 1529|       |              RhsPanel27 rhs_panel;
 1530|       |              RhsPacket T0;
 1531|       |              LhsPacket A2;
 1532|       |#if EIGEN_ARCH_ARM64 && defined(EIGEN_VECTORIZE_NEON) && EIGEN_GNUC_STRICT_LESS_THAN(9, 0, 0)
 1533|       |// see http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1633
 1534|       |// without this workaround A0, A1, and A2 are loaded in the same register,
 1535|       |// which is not good for pipelining
 1536|       |#define EIGEN_GEBP_3Px8_REGISTER_ALLOC_WORKAROUND __asm__("" : "+w,m"(A0), "+w,m"(A1), "+w,m"(A2));
 1537|       |#else
 1538|       |#define EIGEN_GEBP_3Px8_REGISTER_ALLOC_WORKAROUND
 1539|       |#endif
 1540|       |
 1541|       |#define EIGEN_GEBP_ONESTEP(K)                                                                                     \
 1542|       |  do {                                                                                                            \
 1543|       |    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 3pX8");                                                    \
 1544|       |    traits.loadLhs(&blA[(0 + 3 * K) * LhsProgress], A0);                                                          \
 1545|       |    traits.loadLhs(&blA[(1 + 3 * K) * LhsProgress], A1);                                                          \
 1546|       |    traits.loadLhs(&blA[(2 + 3 * K) * LhsProgress], A2);                                                          \
 1547|       |    EIGEN_GEBP_3Px8_REGISTER_ALLOC_WORKAROUND traits.loadRhs(blB + (0 + 8 * K) * Traits::RhsProgress, rhs_panel); \
 1548|       |    traits.madd(A0, rhs_panel, C0, T0, fix<0>);                                                                   \
 1549|       |    traits.madd(A1, rhs_panel, C8, T0, fix<0>);                                                                   \
 1550|       |    traits.madd(A2, rhs_panel, C16, T0, fix<0>);                                                                  \
 1551|       |    traits.updateRhs(blB + (1 + 8 * K) * Traits::RhsProgress, rhs_panel);                                         \
 1552|       |    traits.madd(A0, rhs_panel, C1, T0, fix<1>);                                                                   \
 1553|       |    traits.madd(A1, rhs_panel, C9, T0, fix<1>);                                                                   \
 1554|       |    traits.madd(A2, rhs_panel, C17, T0, fix<1>);                                                                  \
 1555|       |    traits.updateRhs(blB + (2 + 8 * K) * Traits::RhsProgress, rhs_panel);                                         \
 1556|       |    traits.madd(A0, rhs_panel, C2, T0, fix<2>);                                                                   \
 1557|       |    traits.madd(A1, rhs_panel, C10, T0, fix<2>);                                                                  \
 1558|       |    traits.madd(A2, rhs_panel, C18, T0, fix<2>);                                                                  \
 1559|       |    traits.updateRhs(blB + (3 + 8 * K) * Traits::RhsProgress, rhs_panel);                                         \
 1560|       |    traits.madd(A0, rhs_panel, C3, T0, fix<3>);                                                                   \
 1561|       |    traits.madd(A1, rhs_panel, C11, T0, fix<3>);                                                                  \
 1562|       |    traits.madd(A2, rhs_panel, C19, T0, fix<3>);                                                                  \
 1563|       |    traits.loadRhs(blB + (4 + 8 * K) * Traits::RhsProgress, rhs_panel);                                           \
 1564|       |    traits.madd(A0, rhs_panel, C4, T0, fix<0>);                                                                   \
 1565|       |    traits.madd(A1, rhs_panel, C12, T0, fix<0>);                                                                  \
 1566|       |    traits.madd(A2, rhs_panel, C20, T0, fix<0>);                                                                  \
 1567|       |    traits.updateRhs(blB + (5 + 8 * K) * Traits::RhsProgress, rhs_panel);                                         \
 1568|       |    traits.madd(A0, rhs_panel, C5, T0, fix<1>);                                                                   \
 1569|       |    traits.madd(A1, rhs_panel, C13, T0, fix<1>);                                                                  \
 1570|       |    traits.madd(A2, rhs_panel, C21, T0, fix<1>);                                                                  \
 1571|       |    traits.updateRhs(blB + (6 + 8 * K) * Traits::RhsProgress, rhs_panel);                                         \
 1572|       |    traits.madd(A0, rhs_panel, C6, T0, fix<2>);                                                                   \
 1573|       |    traits.madd(A1, rhs_panel, C14, T0, fix<2>);                                                                  \
 1574|       |    traits.madd(A2, rhs_panel, C22, T0, fix<2>);                                                                  \
 1575|       |    traits.updateRhs(blB + (7 + 8 * K) * Traits::RhsProgress, rhs_panel);                                         \
 1576|       |    traits.madd(A0, rhs_panel, C7, T0, fix<3>);                                                                   \
 1577|       |    traits.madd(A1, rhs_panel, C15, T0, fix<3>);                                                                  \
 1578|       |    traits.madd(A2, rhs_panel, C23, T0, fix<3>);                                                                  \
 1579|       |    EIGEN_ASM_COMMENT("end step of gebp micro kernel 3pX8");                                                      \
 1580|       |  } while (false)
 1581|       |
 1582|       |              EIGEN_GEBP_ONESTEP(0);
 1583|       |              EIGEN_GEBP_ONESTEP(1);
 1584|       |              EIGEN_GEBP_ONESTEP(2);
 1585|       |              EIGEN_GEBP_ONESTEP(3);
 1586|       |              EIGEN_GEBP_ONESTEP(4);
 1587|       |              EIGEN_GEBP_ONESTEP(5);
 1588|       |              EIGEN_GEBP_ONESTEP(6);
 1589|       |              EIGEN_GEBP_ONESTEP(7);
 1590|       |
 1591|       |              blB += pk * 8 * RhsProgress;
 1592|       |              blA += pk * 3 * Traits::LhsProgress;
 1593|       |              EIGEN_ASM_COMMENT("end gebp micro kernel 3pX8");
 1594|       |            }
 1595|       |
 1596|       |            // process remaining peeled loop
 1597|       |            for (Index k = peeled_kc; k < depth; k++) {
 1598|       |              RhsPanel27 rhs_panel;
 1599|       |              RhsPacket T0;
 1600|       |              LhsPacket A2;
 1601|       |              EIGEN_GEBP_ONESTEP(0);
 1602|       |              blB += 8 * RhsProgress;
 1603|       |              blA += 3 * Traits::LhsProgress;
 1604|       |            }
 1605|       |
 1606|       |#undef EIGEN_GEBP_ONESTEP
 1607|       |
 1608|       |            ResPacket R0, R1, R2;
 1609|       |            ResPacket alphav = pset1<ResPacket>(alpha);
 1610|       |
 1611|       |            R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1612|       |            R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1613|       |            R2 = r0.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1614|       |            traits.acc(C0, alphav, R0);
 1615|       |            traits.acc(C8, alphav, R1);
 1616|       |            traits.acc(C16, alphav, R2);
 1617|       |            r0.storePacket(0 * Traits::ResPacketSize, R0);
 1618|       |            r0.storePacket(1 * Traits::ResPacketSize, R1);
 1619|       |            r0.storePacket(2 * Traits::ResPacketSize, R2);
 1620|       |
 1621|       |            R0 = r1.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1622|       |            R1 = r1.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1623|       |            R2 = r1.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1624|       |            traits.acc(C1, alphav, R0);
 1625|       |            traits.acc(C9, alphav, R1);
 1626|       |            traits.acc(C17, alphav, R2);
 1627|       |            r1.storePacket(0 * Traits::ResPacketSize, R0);
 1628|       |            r1.storePacket(1 * Traits::ResPacketSize, R1);
 1629|       |            r1.storePacket(2 * Traits::ResPacketSize, R2);
 1630|       |
 1631|       |            R0 = r2.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1632|       |            R1 = r2.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1633|       |            R2 = r2.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1634|       |            traits.acc(C2, alphav, R0);
 1635|       |            traits.acc(C10, alphav, R1);
 1636|       |            traits.acc(C18, alphav, R2);
 1637|       |            r2.storePacket(0 * Traits::ResPacketSize, R0);
 1638|       |            r2.storePacket(1 * Traits::ResPacketSize, R1);
 1639|       |            r2.storePacket(2 * Traits::ResPacketSize, R2);
 1640|       |
 1641|       |            R0 = r3.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1642|       |            R1 = r3.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1643|       |            R2 = r3.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1644|       |            traits.acc(C3, alphav, R0);
 1645|       |            traits.acc(C11, alphav, R1);
 1646|       |            traits.acc(C19, alphav, R2);
 1647|       |            r3.storePacket(0 * Traits::ResPacketSize, R0);
 1648|       |            r3.storePacket(1 * Traits::ResPacketSize, R1);
 1649|       |            r3.storePacket(2 * Traits::ResPacketSize, R2);
 1650|       |
 1651|       |            R0 = r4.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1652|       |            R1 = r4.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1653|       |            R2 = r4.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1654|       |            traits.acc(C4, alphav, R0);
 1655|       |            traits.acc(C12, alphav, R1);
 1656|       |            traits.acc(C20, alphav, R2);
 1657|       |            r4.storePacket(0 * Traits::ResPacketSize, R0);
 1658|       |            r4.storePacket(1 * Traits::ResPacketSize, R1);
 1659|       |            r4.storePacket(2 * Traits::ResPacketSize, R2);
 1660|       |
 1661|       |            R0 = r5.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1662|       |            R1 = r5.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1663|       |            R2 = r5.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1664|       |            traits.acc(C5, alphav, R0);
 1665|       |            traits.acc(C13, alphav, R1);
 1666|       |            traits.acc(C21, alphav, R2);
 1667|       |            r5.storePacket(0 * Traits::ResPacketSize, R0);
 1668|       |            r5.storePacket(1 * Traits::ResPacketSize, R1);
 1669|       |            r5.storePacket(2 * Traits::ResPacketSize, R2);
 1670|       |
 1671|       |            R0 = r6.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1672|       |            R1 = r6.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1673|       |            R2 = r6.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1674|       |            traits.acc(C6, alphav, R0);
 1675|       |            traits.acc(C14, alphav, R1);
 1676|       |            traits.acc(C22, alphav, R2);
 1677|       |            r6.storePacket(0 * Traits::ResPacketSize, R0);
 1678|       |            r6.storePacket(1 * Traits::ResPacketSize, R1);
 1679|       |            r6.storePacket(2 * Traits::ResPacketSize, R2);
 1680|       |
 1681|       |            R0 = r7.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1682|       |            R1 = r7.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1683|       |            R2 = r7.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1684|       |            traits.acc(C7, alphav, R0);
 1685|       |            traits.acc(C15, alphav, R1);
 1686|       |            traits.acc(C23, alphav, R2);
 1687|       |            r7.storePacket(0 * Traits::ResPacketSize, R0);
 1688|       |            r7.storePacket(1 * Traits::ResPacketSize, R1);
 1689|       |            r7.storePacket(2 * Traits::ResPacketSize, R2);
 1690|       |          }
 1691|       |        }
 1692|       |      }
 1693|       |#endif
 1694|      0|      for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
 1695|      0|        for (Index i = i1; i < actual_panel_end; i += 3 * LhsProgress) {
 1696|       |          // We selected a 3*Traits::LhsProgress x nr micro block of res which is entirely
 1697|       |          // stored into 3 x nr registers.
 1698|       |
 1699|      0|          const LhsScalar* blA = &blockA[i * strideA + offsetA * (3 * LhsProgress)];
 1700|      0|          prefetch(&blA[0]);
 1701|       |
 1702|       |          // gets res block as register
 1703|      0|          AccPacket C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10, C11;
 1704|      0|          traits.initAcc(C0);
 1705|      0|          traits.initAcc(C1);
 1706|      0|          traits.initAcc(C2);
 1707|      0|          traits.initAcc(C3);
 1708|      0|          traits.initAcc(C4);
 1709|      0|          traits.initAcc(C5);
 1710|      0|          traits.initAcc(C6);
 1711|      0|          traits.initAcc(C7);
 1712|      0|          traits.initAcc(C8);
 1713|      0|          traits.initAcc(C9);
 1714|      0|          traits.initAcc(C10);
 1715|      0|          traits.initAcc(C11);
 1716|       |
 1717|      0|          LinearMapper r0 = res.getLinearMapper(i, j2 + 0);
 1718|      0|          LinearMapper r1 = res.getLinearMapper(i, j2 + 1);
 1719|      0|          LinearMapper r2 = res.getLinearMapper(i, j2 + 2);
 1720|      0|          LinearMapper r3 = res.getLinearMapper(i, j2 + 3);
 1721|       |
 1722|      0|          r0.prefetch(0);
 1723|      0|          r1.prefetch(0);
 1724|      0|          r2.prefetch(0);
 1725|      0|          r3.prefetch(0);
 1726|       |
 1727|       |          // performs "inner" products
 1728|      0|          const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 4];
 1729|      0|          prefetch(&blB[0]);
 1730|      0|          LhsPacket A0, A1;
 1731|       |
 1732|      0|          for (Index k = 0; k < peeled_kc; k += pk) {
 1733|      0|            EIGEN_ASM_COMMENT("begin gebp micro kernel 3pX4");
 1734|       |            // 15 registers are taken (12 for acc, 3 for lhs).
 1735|      0|            RhsPanel15 rhs_panel;
 1736|      0|            RhsPacket T0;
 1737|      0|            LhsPacket A2;
 1738|       |#if EIGEN_ARCH_ARM64 && defined(EIGEN_VECTORIZE_NEON) && EIGEN_GNUC_STRICT_LESS_THAN(9, 0, 0)
 1739|       |// see http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1633
 1740|       |// without this workaround A0, A1, and A2 are loaded in the same register,
 1741|       |// which is not good for pipelining
 1742|       |#define EIGEN_GEBP_3PX4_REGISTER_ALLOC_WORKAROUND __asm__("" : "+w,m"(A0), "+w,m"(A1), "+w,m"(A2));
 1743|       |#else
 1744|      0|#define EIGEN_GEBP_3PX4_REGISTER_ALLOC_WORKAROUND
 1745|      0|#endif
 1746|      0|#define EIGEN_GEBP_ONESTEP(K)                                             \
 1747|      0|  do {                                                                    \
 1748|      0|    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 3pX4");            \
 1749|      0|    EIGEN_ASM_COMMENT("Note: these asm comments work around bug 935!");   \
 1750|      0|    internal::prefetch(blA + (3 * K + 16) * LhsProgress);                 \
 1751|      0|    if (EIGEN_ARCH_ARM || EIGEN_ARCH_MIPS) {                              \
 1752|      0|      internal::prefetch(blB + (4 * K + 16) * RhsProgress);               \
 1753|      0|    } /* Bug 953 */                                                       \
 1754|      0|    traits.loadLhs(&blA[(0 + 3 * K) * LhsProgress], A0);                  \
 1755|      0|    traits.loadLhs(&blA[(1 + 3 * K) * LhsProgress], A1);                  \
 1756|      0|    traits.loadLhs(&blA[(2 + 3 * K) * LhsProgress], A2);                  \
 1757|      0|    EIGEN_GEBP_3PX4_REGISTER_ALLOC_WORKAROUND                             \
 1758|      0|    traits.loadRhs(blB + (0 + 4 * K) * Traits::RhsProgress, rhs_panel);   \
 1759|      0|    traits.madd(A0, rhs_panel, C0, T0, fix<0>);                           \
 1760|      0|    traits.madd(A1, rhs_panel, C4, T0, fix<0>);                           \
 1761|      0|    traits.madd(A2, rhs_panel, C8, T0, fix<0>);                           \
 1762|      0|    traits.updateRhs(blB + (1 + 4 * K) * Traits::RhsProgress, rhs_panel); \
 1763|      0|    traits.madd(A0, rhs_panel, C1, T0, fix<1>);                           \
 1764|      0|    traits.madd(A1, rhs_panel, C5, T0, fix<1>);                           \
 1765|      0|    traits.madd(A2, rhs_panel, C9, T0, fix<1>);                           \
 1766|      0|    traits.updateRhs(blB + (2 + 4 * K) * Traits::RhsProgress, rhs_panel); \
 1767|      0|    traits.madd(A0, rhs_panel, C2, T0, fix<2>);                           \
 1768|      0|    traits.madd(A1, rhs_panel, C6, T0, fix<2>);                           \
 1769|      0|    traits.madd(A2, rhs_panel, C10, T0, fix<2>);                          \
 1770|      0|    traits.updateRhs(blB + (3 + 4 * K) * Traits::RhsProgress, rhs_panel); \
 1771|      0|    traits.madd(A0, rhs_panel, C3, T0, fix<3>);                           \
 1772|      0|    traits.madd(A1, rhs_panel, C7, T0, fix<3>);                           \
 1773|      0|    traits.madd(A2, rhs_panel, C11, T0, fix<3>);                          \
 1774|      0|    EIGEN_ASM_COMMENT("end step of gebp micro kernel 3pX4");              \
 1775|      0|  } while (false)
 1776|       |
 1777|      0|            internal::prefetch(blB);
 1778|      0|            EIGEN_GEBP_ONESTEP(0);
 1779|      0|            EIGEN_GEBP_ONESTEP(1);
 1780|      0|            EIGEN_GEBP_ONESTEP(2);
 1781|      0|            EIGEN_GEBP_ONESTEP(3);
 1782|      0|            EIGEN_GEBP_ONESTEP(4);
 1783|      0|            EIGEN_GEBP_ONESTEP(5);
 1784|      0|            EIGEN_GEBP_ONESTEP(6);
 1785|      0|            EIGEN_GEBP_ONESTEP(7);
 1786|       |
 1787|      0|            blB += pk * 4 * RhsProgress;
 1788|      0|            blA += pk * 3 * Traits::LhsProgress;
 1789|       |
 1790|      0|            EIGEN_ASM_COMMENT("end gebp micro kernel 3pX4");
 1791|      0|          }
 1792|       |          // process remaining peeled loop
 1793|      0|          for (Index k = peeled_kc; k < depth; k++) {
 1794|      0|            RhsPanel15 rhs_panel;
 1795|      0|            RhsPacket T0;
 1796|      0|            LhsPacket A2;
 1797|      0|            EIGEN_GEBP_ONESTEP(0);
 1798|      0|            blB += 4 * RhsProgress;
 1799|      0|            blA += 3 * Traits::LhsProgress;
 1800|      0|          }
 1801|       |
 1802|      0|#undef EIGEN_GEBP_ONESTEP
 1803|       |
 1804|      0|          ResPacket R0, R1, R2;
 1805|      0|          ResPacket alphav = pset1<ResPacket>(alpha);
 1806|       |
 1807|      0|          R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1808|      0|          R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1809|      0|          R2 = r0.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1810|      0|          traits.acc(C0, alphav, R0);
 1811|      0|          traits.acc(C4, alphav, R1);
 1812|      0|          traits.acc(C8, alphav, R2);
 1813|      0|          r0.storePacket(0 * Traits::ResPacketSize, R0);
 1814|      0|          r0.storePacket(1 * Traits::ResPacketSize, R1);
 1815|      0|          r0.storePacket(2 * Traits::ResPacketSize, R2);
 1816|       |
 1817|      0|          R0 = r1.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1818|      0|          R1 = r1.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1819|      0|          R2 = r1.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1820|      0|          traits.acc(C1, alphav, R0);
 1821|      0|          traits.acc(C5, alphav, R1);
 1822|      0|          traits.acc(C9, alphav, R2);
 1823|      0|          r1.storePacket(0 * Traits::ResPacketSize, R0);
 1824|      0|          r1.storePacket(1 * Traits::ResPacketSize, R1);
 1825|      0|          r1.storePacket(2 * Traits::ResPacketSize, R2);
 1826|       |
 1827|      0|          R0 = r2.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1828|      0|          R1 = r2.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1829|      0|          R2 = r2.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1830|      0|          traits.acc(C2, alphav, R0);
 1831|      0|          traits.acc(C6, alphav, R1);
 1832|      0|          traits.acc(C10, alphav, R2);
 1833|      0|          r2.storePacket(0 * Traits::ResPacketSize, R0);
 1834|      0|          r2.storePacket(1 * Traits::ResPacketSize, R1);
 1835|      0|          r2.storePacket(2 * Traits::ResPacketSize, R2);
 1836|       |
 1837|      0|          R0 = r3.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1838|      0|          R1 = r3.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1839|      0|          R2 = r3.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1840|      0|          traits.acc(C3, alphav, R0);
 1841|      0|          traits.acc(C7, alphav, R1);
 1842|      0|          traits.acc(C11, alphav, R2);
 1843|      0|          r3.storePacket(0 * Traits::ResPacketSize, R0);
 1844|      0|          r3.storePacket(1 * Traits::ResPacketSize, R1);
 1845|      0|          r3.storePacket(2 * Traits::ResPacketSize, R2);
 1846|      0|        }
 1847|      0|      }
 1848|       |
 1849|       |      // Deal with remaining columns of the rhs
 1850|      0|      for (Index j2 = packet_cols4; j2 < cols; j2++) {
 1851|      0|        for (Index i = i1; i < actual_panel_end; i += 3 * LhsProgress) {
 1852|       |          // One column at a time
 1853|      0|          const LhsScalar* blA = &blockA[i * strideA + offsetA * (3 * Traits::LhsProgress)];
 1854|      0|          prefetch(&blA[0]);
 1855|       |
 1856|       |          // gets res block as register
 1857|      0|          AccPacket C0, C4, C8;
 1858|      0|          traits.initAcc(C0);
 1859|      0|          traits.initAcc(C4);
 1860|      0|          traits.initAcc(C8);
 1861|       |
 1862|      0|          LinearMapper r0 = res.getLinearMapper(i, j2);
 1863|      0|          r0.prefetch(0);
 1864|       |
 1865|       |          // performs "inner" products
 1866|      0|          const RhsScalar* blB = &blockB[j2 * strideB + offsetB];
 1867|      0|          LhsPacket A0, A1, A2;
 1868|       |
 1869|      0|          for (Index k = 0; k < peeled_kc; k += pk) {
 1870|      0|            EIGEN_ASM_COMMENT("begin gebp micro kernel 3pX1");
 1871|      0|            RhsPacket B_0;
 1872|      0|#define EIGEN_GEBGP_ONESTEP(K)                                          \
 1873|      0|  do {                                                                  \
 1874|      0|    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 3pX1");          \
 1875|      0|    EIGEN_ASM_COMMENT("Note: these asm comments work around bug 935!"); \
 1876|      0|    traits.loadLhs(&blA[(0 + 3 * K) * LhsProgress], A0);                \
 1877|      0|    traits.loadLhs(&blA[(1 + 3 * K) * LhsProgress], A1);                \
 1878|      0|    traits.loadLhs(&blA[(2 + 3 * K) * LhsProgress], A2);                \
 1879|      0|    traits.loadRhs(&blB[(0 + K) * RhsProgress], B_0);                   \
 1880|      0|    traits.madd(A0, B_0, C0, B_0, fix<0>);                              \
 1881|      0|    traits.madd(A1, B_0, C4, B_0, fix<0>);                              \
 1882|      0|    traits.madd(A2, B_0, C8, B_0, fix<0>);                              \
 1883|      0|    EIGEN_ASM_COMMENT("end step of gebp micro kernel 3pX1");            \
 1884|      0|  } while (false)
 1885|       |
 1886|      0|            EIGEN_GEBGP_ONESTEP(0);
 1887|      0|            EIGEN_GEBGP_ONESTEP(1);
 1888|      0|            EIGEN_GEBGP_ONESTEP(2);
 1889|      0|            EIGEN_GEBGP_ONESTEP(3);
 1890|      0|            EIGEN_GEBGP_ONESTEP(4);
 1891|      0|            EIGEN_GEBGP_ONESTEP(5);
 1892|      0|            EIGEN_GEBGP_ONESTEP(6);
 1893|      0|            EIGEN_GEBGP_ONESTEP(7);
 1894|       |
 1895|      0|            blB += int(pk) * int(RhsProgress);
 1896|      0|            blA += int(pk) * 3 * int(Traits::LhsProgress);
 1897|       |
 1898|      0|            EIGEN_ASM_COMMENT("end gebp micro kernel 3pX1");
 1899|      0|          }
 1900|       |
 1901|       |          // process remaining peeled loop
 1902|      0|          for (Index k = peeled_kc; k < depth; k++) {
 1903|      0|            RhsPacket B_0;
 1904|      0|            EIGEN_GEBGP_ONESTEP(0);
 1905|      0|            blB += RhsProgress;
 1906|      0|            blA += 3 * Traits::LhsProgress;
 1907|      0|          }
 1908|      0|#undef EIGEN_GEBGP_ONESTEP
 1909|      0|          ResPacket R0, R1, R2;
 1910|      0|          ResPacket alphav = pset1<ResPacket>(alpha);
 1911|       |
 1912|      0|          R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 1913|      0|          R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 1914|      0|          R2 = r0.template loadPacket<ResPacket>(2 * Traits::ResPacketSize);
 1915|      0|          traits.acc(C0, alphav, R0);
 1916|      0|          traits.acc(C4, alphav, R1);
 1917|      0|          traits.acc(C8, alphav, R2);
 1918|      0|          r0.storePacket(0 * Traits::ResPacketSize, R0);
 1919|      0|          r0.storePacket(1 * Traits::ResPacketSize, R1);
 1920|      0|          r0.storePacket(2 * Traits::ResPacketSize, R2);
 1921|      0|        }
 1922|      0|      }
 1923|      0|    }
 1924|      0|  }
 1925|       |
 1926|       |  //---------- Process 2 * LhsProgress rows at once ----------
 1927|      2|  if (mr >= 2 * Traits::LhsProgress) {
 1928|      2|    const Index l1 = defaultL1CacheSize;  // in Bytes, TODO, l1 should be passed to this function.
 1929|       |    // The max(1, ...) here is needed because we may be using blocking params larger than what our known l1 cache size
 1930|       |    // suggests we should be using: either because our known l1 cache size is inaccurate (e.g. on Android, we can only
 1931|       |    // guess), or because we are testing specific blocking sizes.
 1932|      2|    Index actual_panel_rows =
 1933|      2|        (2 * LhsProgress) * std::max<Index>(1, ((l1 - sizeof(ResScalar) * mr * nr - depth * nr * sizeof(RhsScalar)) /
 1934|      2|                                                (depth * sizeof(LhsScalar) * 2 * LhsProgress)));
 1935|       |
 1936|      4|    for (Index i1 = peeled_mc3; i1 < peeled_mc2; i1 += actual_panel_rows) {
 1937|      2|      Index actual_panel_end = (std::min)(i1 + actual_panel_rows, peeled_mc2);
 1938|       |#if EIGEN_ARCH_ARM64 || EIGEN_ARCH_LOONGARCH64
 1939|       |      EIGEN_IF_CONSTEXPR(nr >= 8) {
 1940|       |        for (Index j2 = 0; j2 < packet_cols8; j2 += 8) {
 1941|       |          for (Index i = i1; i < actual_panel_end; i += 2 * LhsProgress) {
 1942|       |            const LhsScalar* blA = &blockA[i * strideA + offsetA * (2 * Traits::LhsProgress)];
 1943|       |            prefetch(&blA[0]);
 1944|       |
 1945|       |            AccPacket C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10, C11, C12, C13, C14, C15;
 1946|       |            traits.initAcc(C0);
 1947|       |            traits.initAcc(C1);
 1948|       |            traits.initAcc(C2);
 1949|       |            traits.initAcc(C3);
 1950|       |            traits.initAcc(C4);
 1951|       |            traits.initAcc(C5);
 1952|       |            traits.initAcc(C6);
 1953|       |            traits.initAcc(C7);
 1954|       |            traits.initAcc(C8);
 1955|       |            traits.initAcc(C9);
 1956|       |            traits.initAcc(C10);
 1957|       |            traits.initAcc(C11);
 1958|       |            traits.initAcc(C12);
 1959|       |            traits.initAcc(C13);
 1960|       |            traits.initAcc(C14);
 1961|       |            traits.initAcc(C15);
 1962|       |
 1963|       |            LinearMapper r0 = res.getLinearMapper(i, j2 + 0);
 1964|       |            LinearMapper r1 = res.getLinearMapper(i, j2 + 1);
 1965|       |            LinearMapper r2 = res.getLinearMapper(i, j2 + 2);
 1966|       |            LinearMapper r3 = res.getLinearMapper(i, j2 + 3);
 1967|       |            LinearMapper r4 = res.getLinearMapper(i, j2 + 4);
 1968|       |            LinearMapper r5 = res.getLinearMapper(i, j2 + 5);
 1969|       |            LinearMapper r6 = res.getLinearMapper(i, j2 + 6);
 1970|       |            LinearMapper r7 = res.getLinearMapper(i, j2 + 7);
 1971|       |            r0.prefetch(prefetch_res_offset);
 1972|       |            r1.prefetch(prefetch_res_offset);
 1973|       |            r2.prefetch(prefetch_res_offset);
 1974|       |            r3.prefetch(prefetch_res_offset);
 1975|       |            r4.prefetch(prefetch_res_offset);
 1976|       |            r5.prefetch(prefetch_res_offset);
 1977|       |            r6.prefetch(prefetch_res_offset);
 1978|       |            r7.prefetch(prefetch_res_offset);
 1979|       |
 1980|       |            const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 8];
 1981|       |            prefetch(&blB[0]);
 1982|       |            LhsPacket A0, A1;
 1983|       |            for (Index k = 0; k < peeled_kc; k += pk) {
 1984|       |              RhsPacketx4 rhs_panel;
 1985|       |              RhsPacket T0;
 1986|       |// NOTE: the begin/end asm comments below work around bug 935!
 1987|       |// but they are not enough for gcc>=6 without FMA (bug 1637)
 1988|       |#if EIGEN_GNUC_STRICT_AT_LEAST(6, 0, 0) && defined(EIGEN_VECTORIZE_SSE)
 1989|       |#define EIGEN_GEBP_2Px8_SPILLING_WORKAROUND __asm__("" : [a0] "+x,m"(A0), [a1] "+x,m"(A1));
 1990|       |#else
 1991|       |#define EIGEN_GEBP_2Px8_SPILLING_WORKAROUND
 1992|       |#endif
 1993|       |#define EIGEN_GEBGP_ONESTEP(K)                                                                   \
 1994|       |  do {                                                                                           \
 1995|       |    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 2pX8");                                   \
 1996|       |    traits.loadLhs(&blA[(0 + 2 * K) * LhsProgress], A0);                                         \
 1997|       |    traits.loadLhs(&blA[(1 + 2 * K) * LhsProgress], A1);                                         \
 1998|       |    traits.loadRhs(&blB[(0 + 8 * K) * RhsProgress], rhs_panel);                                  \
 1999|       |    traits.madd(A0, rhs_panel, C0, T0, fix<0>);                                                  \
 2000|       |    traits.madd(A1, rhs_panel, C8, T0, fix<0>);                                                  \
 2001|       |    traits.updateRhs(&blB[(1 + 8 * K) * RhsProgress], rhs_panel);                                \
 2002|       |    traits.madd(A0, rhs_panel, C1, T0, fix<1>);                                                  \
 2003|       |    traits.madd(A1, rhs_panel, C9, T0, fix<1>);                                                  \
 2004|       |    traits.updateRhs(&blB[(2 + 8 * K) * RhsProgress], rhs_panel);                                \
 2005|       |    traits.madd(A0, rhs_panel, C2, T0, fix<2>);                                                  \
 2006|       |    traits.madd(A1, rhs_panel, C10, T0, fix<2>);                                                 \
 2007|       |    traits.updateRhs(&blB[(3 + 8 * K) * RhsProgress], rhs_panel);                                \
 2008|       |    traits.madd(A0, rhs_panel, C3, T0, fix<3>);                                                  \
 2009|       |    traits.madd(A1, rhs_panel, C11, T0, fix<3>);                                                 \
 2010|       |    traits.loadRhs(&blB[(4 + 8 * K) * RhsProgress], rhs_panel);                                  \
 2011|       |    traits.madd(A0, rhs_panel, C4, T0, fix<0>);                                                  \
 2012|       |    traits.madd(A1, rhs_panel, C12, T0, fix<0>);                                                 \
 2013|       |    traits.updateRhs(&blB[(5 + 8 * K) * RhsProgress], rhs_panel);                                \
 2014|       |    traits.madd(A0, rhs_panel, C5, T0, fix<1>);                                                  \
 2015|       |    traits.madd(A1, rhs_panel, C13, T0, fix<1>);                                                 \
 2016|       |    traits.updateRhs(&blB[(6 + 8 * K) * RhsProgress], rhs_panel);                                \
 2017|       |    traits.madd(A0, rhs_panel, C6, T0, fix<2>);                                                  \
 2018|       |    traits.madd(A1, rhs_panel, C14, T0, fix<2>);                                                 \
 2019|       |    traits.updateRhs(&blB[(7 + 8 * K) * RhsProgress], rhs_panel);                                \
 2020|       |    traits.madd(A0, rhs_panel, C7, T0, fix<3>);                                                  \
 2021|       |    traits.madd(A1, rhs_panel, C15, T0, fix<3>);                                                 \
 2022|       |    EIGEN_GEBP_2Px8_SPILLING_WORKAROUND EIGEN_ASM_COMMENT("end step of gebp micro kernel 2pX8"); \
 2023|       |  } while (false)
 2024|       |
 2025|       |              EIGEN_ASM_COMMENT("begin gebp micro kernel 2pX8");
 2026|       |
 2027|       |              EIGEN_GEBGP_ONESTEP(0);
 2028|       |              EIGEN_GEBGP_ONESTEP(1);
 2029|       |              EIGEN_GEBGP_ONESTEP(2);
 2030|       |              EIGEN_GEBGP_ONESTEP(3);
 2031|       |              EIGEN_GEBGP_ONESTEP(4);
 2032|       |              EIGEN_GEBGP_ONESTEP(5);
 2033|       |              EIGEN_GEBGP_ONESTEP(6);
 2034|       |              EIGEN_GEBGP_ONESTEP(7);
 2035|       |
 2036|       |              blB += pk * 8 * RhsProgress;
 2037|       |              blA += pk * (2 * Traits::LhsProgress);
 2038|       |
 2039|       |              EIGEN_ASM_COMMENT("end gebp micro kernel 2pX8");
 2040|       |            }
 2041|       |            // process remaining peeled loop
 2042|       |            for (Index k = peeled_kc; k < depth; k++) {
 2043|       |              RhsPacketx4 rhs_panel;
 2044|       |              RhsPacket T0;
 2045|       |              EIGEN_GEBGP_ONESTEP(0);
 2046|       |              blB += 8 * RhsProgress;
 2047|       |              blA += 2 * Traits::LhsProgress;
 2048|       |            }
 2049|       |
 2050|       |#undef EIGEN_GEBGP_ONESTEP
 2051|       |
 2052|       |            ResPacket R0, R1, R2, R3;
 2053|       |            ResPacket alphav = pset1<ResPacket>(alpha);
 2054|       |
 2055|       |            R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2056|       |            R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2057|       |            R2 = r1.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2058|       |            R3 = r1.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2059|       |            traits.acc(C0, alphav, R0);
 2060|       |            traits.acc(C8, alphav, R1);
 2061|       |            traits.acc(C1, alphav, R2);
 2062|       |            traits.acc(C9, alphav, R3);
 2063|       |            r0.storePacket(0 * Traits::ResPacketSize, R0);
 2064|       |            r0.storePacket(1 * Traits::ResPacketSize, R1);
 2065|       |            r1.storePacket(0 * Traits::ResPacketSize, R2);
 2066|       |            r1.storePacket(1 * Traits::ResPacketSize, R3);
 2067|       |
 2068|       |            R0 = r2.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2069|       |            R1 = r2.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2070|       |            R2 = r3.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2071|       |            R3 = r3.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2072|       |            traits.acc(C2, alphav, R0);
 2073|       |            traits.acc(C10, alphav, R1);
 2074|       |            traits.acc(C3, alphav, R2);
 2075|       |            traits.acc(C11, alphav, R3);
 2076|       |            r2.storePacket(0 * Traits::ResPacketSize, R0);
 2077|       |            r2.storePacket(1 * Traits::ResPacketSize, R1);
 2078|       |            r3.storePacket(0 * Traits::ResPacketSize, R2);
 2079|       |            r3.storePacket(1 * Traits::ResPacketSize, R3);
 2080|       |
 2081|       |            R0 = r4.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2082|       |            R1 = r4.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2083|       |            R2 = r5.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2084|       |            R3 = r5.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2085|       |            traits.acc(C4, alphav, R0);
 2086|       |            traits.acc(C12, alphav, R1);
 2087|       |            traits.acc(C5, alphav, R2);
 2088|       |            traits.acc(C13, alphav, R3);
 2089|       |            r4.storePacket(0 * Traits::ResPacketSize, R0);
 2090|       |            r4.storePacket(1 * Traits::ResPacketSize, R1);
 2091|       |            r5.storePacket(0 * Traits::ResPacketSize, R2);
 2092|       |            r5.storePacket(1 * Traits::ResPacketSize, R3);
 2093|       |
 2094|       |            R0 = r6.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2095|       |            R1 = r6.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2096|       |            R2 = r7.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2097|       |            R3 = r7.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2098|       |            traits.acc(C6, alphav, R0);
 2099|       |            traits.acc(C14, alphav, R1);
 2100|       |            traits.acc(C7, alphav, R2);
 2101|       |            traits.acc(C15, alphav, R3);
 2102|       |            r6.storePacket(0 * Traits::ResPacketSize, R0);
 2103|       |            r6.storePacket(1 * Traits::ResPacketSize, R1);
 2104|       |            r7.storePacket(0 * Traits::ResPacketSize, R2);
 2105|       |            r7.storePacket(1 * Traits::ResPacketSize, R3);
 2106|       |          }
 2107|       |        }
 2108|       |      }
 2109|       |#endif
 2110|      4|      for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
 2111|      4|        for (Index i = i1; i < actual_panel_end; i += 2 * LhsProgress) {
 2112|       |          // We selected a 2*Traits::LhsProgress x nr micro block of res which is entirely
 2113|       |          // stored into 2 x nr registers.
 2114|       |
 2115|      2|          const LhsScalar* blA = &blockA[i * strideA + offsetA * (2 * Traits::LhsProgress)];
 2116|      2|          prefetch(&blA[0]);
 2117|       |
 2118|       |          // gets res block as register
 2119|      2|          AccPacket C0, C1, C2, C3, C4, C5, C6, C7;
 2120|      2|          traits.initAcc(C0);
 2121|      2|          traits.initAcc(C1);
 2122|      2|          traits.initAcc(C2);
 2123|      2|          traits.initAcc(C3);
 2124|      2|          traits.initAcc(C4);
 2125|      2|          traits.initAcc(C5);
 2126|      2|          traits.initAcc(C6);
 2127|      2|          traits.initAcc(C7);
 2128|       |
 2129|      2|          LinearMapper r0 = res.getLinearMapper(i, j2 + 0);
 2130|      2|          LinearMapper r1 = res.getLinearMapper(i, j2 + 1);
 2131|      2|          LinearMapper r2 = res.getLinearMapper(i, j2 + 2);
 2132|      2|          LinearMapper r3 = res.getLinearMapper(i, j2 + 3);
 2133|       |
 2134|      2|          r0.prefetch(prefetch_res_offset);
 2135|      2|          r1.prefetch(prefetch_res_offset);
 2136|      2|          r2.prefetch(prefetch_res_offset);
 2137|      2|          r3.prefetch(prefetch_res_offset);
 2138|       |
 2139|       |          // performs "inner" products
 2140|      2|          const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 4];
 2141|      2|          prefetch(&blB[0]);
 2142|      2|          LhsPacket A0, A1;
 2143|       |
 2144|      6|          for (Index k = 0; k < peeled_kc; k += pk) {
 2145|      4|            EIGEN_ASM_COMMENT("begin gebp micro kernel 2pX4");
 2146|      4|            RhsPacketx4 rhs_panel;
 2147|      4|            RhsPacket T0;
 2148|       |
 2149|       |// NOTE: the begin/end asm comments below work around bug 935!
 2150|       |// but they are not enough for gcc>=6 without FMA (bug 1637)
 2151|       |#if EIGEN_GNUC_STRICT_AT_LEAST(6, 0, 0) && defined(EIGEN_VECTORIZE_SSE) && !(EIGEN_COMP_LCC)
 2152|       |#define EIGEN_GEBP_2PX4_SPILLING_WORKAROUND __asm__("" : [a0] "+x,m"(A0), [a1] "+x,m"(A1));
 2153|       |#else
 2154|      4|#define EIGEN_GEBP_2PX4_SPILLING_WORKAROUND
 2155|      4|#endif
 2156|      4|#define EIGEN_GEBGP_ONESTEP(K)                                  \
 2157|     32|  do {                                                          \
 2158|     32|    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 2pX4");  \
 2159|     32|    traits.loadLhs(&blA[(0 + 2 * K) * LhsProgress], A0);        \
 2160|     32|    traits.loadLhs(&blA[(1 + 2 * K) * LhsProgress], A1);        \
 2161|     32|    traits.loadRhs(&blB[(0 + 4 * K) * RhsProgress], rhs_panel); \
 2162|     32|    traits.madd(A0, rhs_panel, C0, T0, fix<0>);                 \
 2163|     32|    traits.madd(A1, rhs_panel, C4, T0, fix<0>);                 \
 2164|     32|    traits.madd(A0, rhs_panel, C1, T0, fix<1>);                 \
 2165|     32|    traits.madd(A1, rhs_panel, C5, T0, fix<1>);                 \
 2166|     32|    traits.madd(A0, rhs_panel, C2, T0, fix<2>);                 \
 2167|     32|    traits.madd(A1, rhs_panel, C6, T0, fix<2>);                 \
 2168|     32|    traits.madd(A0, rhs_panel, C3, T0, fix<3>);                 \
 2169|     32|    traits.madd(A1, rhs_panel, C7, T0, fix<3>);                 \
 2170|     32|    EIGEN_GEBP_2PX4_SPILLING_WORKAROUND                         \
 2171|     32|    EIGEN_ASM_COMMENT("end step of gebp micro kernel 2pX4");    \
 2172|     32|  } while (false)
 2173|       |
 2174|      4|            internal::prefetch(blB + (48 + 0));
 2175|      4|            EIGEN_GEBGP_ONESTEP(0);
 2176|      4|            EIGEN_GEBGP_ONESTEP(1);
 2177|      4|            EIGEN_GEBGP_ONESTEP(2);
 2178|      4|            EIGEN_GEBGP_ONESTEP(3);
 2179|      4|            internal::prefetch(blB + (48 + 16));
 2180|      4|            EIGEN_GEBGP_ONESTEP(4);
 2181|      4|            EIGEN_GEBGP_ONESTEP(5);
 2182|      4|            EIGEN_GEBGP_ONESTEP(6);
 2183|      4|            EIGEN_GEBGP_ONESTEP(7);
 2184|       |
 2185|      4|            blB += pk * 4 * RhsProgress;
 2186|      4|            blA += pk * (2 * Traits::LhsProgress);
 2187|       |
 2188|      4|            EIGEN_ASM_COMMENT("end gebp micro kernel 2pX4");
 2189|      4|          }
 2190|       |          // process remaining peeled loop
 2191|      2|          for (Index k = peeled_kc; k < depth; k++) {
 2192|      0|            RhsPacketx4 rhs_panel;
 2193|      0|            RhsPacket T0;
 2194|      0|            EIGEN_GEBGP_ONESTEP(0);
 2195|      0|            blB += 4 * RhsProgress;
 2196|      0|            blA += 2 * Traits::LhsProgress;
 2197|      0|          }
 2198|      2|#undef EIGEN_GEBGP_ONESTEP
 2199|       |
 2200|      2|          ResPacket R0, R1, R2, R3;
 2201|      2|          ResPacket alphav = pset1<ResPacket>(alpha);
 2202|       |
 2203|      2|          R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2204|      2|          R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2205|      2|          R2 = r1.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2206|      2|          R3 = r1.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2207|      2|          traits.acc(C0, alphav, R0);
 2208|      2|          traits.acc(C4, alphav, R1);
 2209|      2|          traits.acc(C1, alphav, R2);
 2210|      2|          traits.acc(C5, alphav, R3);
 2211|      2|          r0.storePacket(0 * Traits::ResPacketSize, R0);
 2212|      2|          r0.storePacket(1 * Traits::ResPacketSize, R1);
 2213|      2|          r1.storePacket(0 * Traits::ResPacketSize, R2);
 2214|      2|          r1.storePacket(1 * Traits::ResPacketSize, R3);
 2215|       |
 2216|      2|          R0 = r2.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2217|      2|          R1 = r2.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2218|      2|          R2 = r3.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2219|      2|          R3 = r3.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2220|      2|          traits.acc(C2, alphav, R0);
 2221|      2|          traits.acc(C6, alphav, R1);
 2222|      2|          traits.acc(C3, alphav, R2);
 2223|      2|          traits.acc(C7, alphav, R3);
 2224|      2|          r2.storePacket(0 * Traits::ResPacketSize, R0);
 2225|      2|          r2.storePacket(1 * Traits::ResPacketSize, R1);
 2226|      2|          r3.storePacket(0 * Traits::ResPacketSize, R2);
 2227|      2|          r3.storePacket(1 * Traits::ResPacketSize, R3);
 2228|      2|        }
 2229|      2|      }
 2230|       |
 2231|       |      // Deal with remaining columns of the rhs
 2232|      2|      for (Index j2 = packet_cols4; j2 < cols; j2++) {
 2233|      0|        for (Index i = i1; i < actual_panel_end; i += 2 * LhsProgress) {
 2234|       |          // One column at a time
 2235|      0|          const LhsScalar* blA = &blockA[i * strideA + offsetA * (2 * Traits::LhsProgress)];
 2236|      0|          prefetch(&blA[0]);
 2237|       |
 2238|       |          // gets res block as register
 2239|      0|          AccPacket C0, C4;
 2240|      0|          traits.initAcc(C0);
 2241|      0|          traits.initAcc(C4);
 2242|       |
 2243|      0|          LinearMapper r0 = res.getLinearMapper(i, j2);
 2244|      0|          r0.prefetch(prefetch_res_offset);
 2245|       |
 2246|       |          // performs "inner" products
 2247|      0|          const RhsScalar* blB = &blockB[j2 * strideB + offsetB];
 2248|      0|          LhsPacket A0, A1;
 2249|       |
 2250|      0|          for (Index k = 0; k < peeled_kc; k += pk) {
 2251|      0|            EIGEN_ASM_COMMENT("begin gebp micro kernel 2pX1");
 2252|      0|            RhsPacket B_0, B1;
 2253|       |
 2254|      0|#define EIGEN_GEBGP_ONESTEP(K)                                          \
 2255|      0|  do {                                                                  \
 2256|      0|    EIGEN_ASM_COMMENT("begin step of gebp micro kernel 2pX1");          \
 2257|      0|    EIGEN_ASM_COMMENT("Note: these asm comments work around bug 935!"); \
 2258|      0|    traits.loadLhs(&blA[(0 + 2 * K) * LhsProgress], A0);                \
 2259|      0|    traits.loadLhs(&blA[(1 + 2 * K) * LhsProgress], A1);                \
 2260|      0|    traits.loadRhs(&blB[(0 + K) * RhsProgress], B_0);                   \
 2261|      0|    traits.madd(A0, B_0, C0, B1, fix<0>);                               \
 2262|      0|    traits.madd(A1, B_0, C4, B_0, fix<0>);                              \
 2263|      0|    EIGEN_ASM_COMMENT("end step of gebp micro kernel 2pX1");            \
 2264|      0|  } while (false)
 2265|       |
 2266|      0|            EIGEN_GEBGP_ONESTEP(0);
 2267|      0|            EIGEN_GEBGP_ONESTEP(1);
 2268|      0|            EIGEN_GEBGP_ONESTEP(2);
 2269|      0|            EIGEN_GEBGP_ONESTEP(3);
 2270|      0|            EIGEN_GEBGP_ONESTEP(4);
 2271|      0|            EIGEN_GEBGP_ONESTEP(5);
 2272|      0|            EIGEN_GEBGP_ONESTEP(6);
 2273|      0|            EIGEN_GEBGP_ONESTEP(7);
 2274|       |
 2275|      0|            blB += int(pk) * int(RhsProgress);
 2276|      0|            blA += int(pk) * 2 * int(Traits::LhsProgress);
 2277|       |
 2278|      0|            EIGEN_ASM_COMMENT("end gebp micro kernel 2pX1");
 2279|      0|          }
 2280|       |
 2281|       |          // process remaining peeled loop
 2282|      0|          for (Index k = peeled_kc; k < depth; k++) {
 2283|      0|            RhsPacket B_0, B1;
 2284|      0|            EIGEN_GEBGP_ONESTEP(0);
 2285|      0|            blB += RhsProgress;
 2286|      0|            blA += 2 * Traits::LhsProgress;
 2287|      0|          }
 2288|      0|#undef EIGEN_GEBGP_ONESTEP
 2289|      0|          ResPacket R0, R1;
 2290|      0|          ResPacket alphav = pset1<ResPacket>(alpha);
 2291|       |
 2292|      0|          R0 = r0.template loadPacket<ResPacket>(0 * Traits::ResPacketSize);
 2293|      0|          R1 = r0.template loadPacket<ResPacket>(1 * Traits::ResPacketSize);
 2294|      0|          traits.acc(C0, alphav, R0);
 2295|      0|          traits.acc(C4, alphav, R1);
 2296|      0|          r0.storePacket(0 * Traits::ResPacketSize, R0);
 2297|      0|          r0.storePacket(1 * Traits::ResPacketSize, R1);
 2298|      0|        }
 2299|      0|      }
 2300|      2|    }
 2301|      2|  }
 2302|       |  //---------- Process 1 * LhsProgress rows at once ----------
 2303|      2|  if (mr >= 1 * Traits::LhsProgress) {
 2304|      0|    lhs_process_one_packet<nr, LhsProgress, RhsProgress, LhsScalar, RhsScalar, ResScalar, AccPacket, LhsPacket,
 2305|      0|                           RhsPacket, ResPacket, Traits, LinearMapper, DataMapper>
 2306|      0|        p;
 2307|      0|    p(res, blockA, blockB, alpha, peeled_mc2, peeled_mc1, strideA, strideB, offsetA, offsetB, prefetch_res_offset,
 2308|      0|      peeled_kc, pk, cols, depth, packet_cols4);
 2309|      0|  }
 2310|       |  //---------- Process LhsProgressHalf rows at once ----------
 2311|      2|  if ((LhsProgressHalf < LhsProgress) && mr >= LhsProgressHalf) {
 2312|      0|    lhs_process_fraction_of_packet<nr, LhsProgressHalf, RhsProgressHalf, LhsScalar, RhsScalar, ResScalar, AccPacketHalf,
 2313|      0|                                   LhsPacketHalf, RhsPacketHalf, ResPacketHalf, HalfTraits, LinearMapper, DataMapper>
 2314|      0|        p;
 2315|      0|    p(res, blockA, blockB, alpha, peeled_mc1, peeled_mc_half, strideA, strideB, offsetA, offsetB, prefetch_res_offset,
 2316|      0|      peeled_kc, pk, cols, depth, packet_cols4);
 2317|      0|  }
 2318|       |  //---------- Process LhsProgressQuarter rows at once ----------
 2319|      2|  if ((LhsProgressQuarter < LhsProgressHalf) && mr >= LhsProgressQuarter) {
 2320|      0|    lhs_process_fraction_of_packet<nr, LhsProgressQuarter, RhsProgressQuarter, LhsScalar, RhsScalar, ResScalar,
 2321|      0|                                   AccPacketQuarter, LhsPacketQuarter, RhsPacketQuarter, ResPacketQuarter,
 2322|      0|                                   QuarterTraits, LinearMapper, DataMapper>
 2323|      0|        p;
 2324|      0|    p(res, blockA, blockB, alpha, peeled_mc_half, peeled_mc_quarter, strideA, strideB, offsetA, offsetB,
 2325|      0|      prefetch_res_offset, peeled_kc, pk, cols, depth, packet_cols4);
 2326|      0|  }
 2327|       |  //---------- Process remaining rows, 1 at once ----------
 2328|      2|  if (peeled_mc_quarter < rows) {
 2329|       |#if EIGEN_ARCH_ARM64 || EIGEN_ARCH_LOONGARCH64
 2330|       |    EIGEN_IF_CONSTEXPR(nr >= 8) {
 2331|       |      // loop on each panel of the rhs
 2332|       |      for (Index j2 = 0; j2 < packet_cols8; j2 += 8) {
 2333|       |        // loop on each row of the lhs (1*LhsProgress x depth)
 2334|       |        for (Index i = peeled_mc_quarter; i < rows; i += 1) {
 2335|       |          const LhsScalar* blA = &blockA[i * strideA + offsetA];
 2336|       |          prefetch(&blA[0]);
 2337|       |          // gets a 1 x 1 res block as registers
 2338|       |          ResScalar C0(0), C1(0), C2(0), C3(0), C4(0), C5(0), C6(0), C7(0);
 2339|       |          const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 8];
 2340|       |          for (Index k = 0; k < depth; k++) {
 2341|       |            LhsScalar A0 = blA[k];
 2342|       |            RhsScalar B_0;
 2343|       |
 2344|       |            B_0 = blB[0];
 2345|       |            C0 = cj.pmadd(A0, B_0, C0);
 2346|       |
 2347|       |            B_0 = blB[1];
 2348|       |            C1 = cj.pmadd(A0, B_0, C1);
 2349|       |
 2350|       |            B_0 = blB[2];
 2351|       |            C2 = cj.pmadd(A0, B_0, C2);
 2352|       |
 2353|       |            B_0 = blB[3];
 2354|       |            C3 = cj.pmadd(A0, B_0, C3);
 2355|       |
 2356|       |            B_0 = blB[4];
 2357|       |            C4 = cj.pmadd(A0, B_0, C4);
 2358|       |
 2359|       |            B_0 = blB[5];
 2360|       |            C5 = cj.pmadd(A0, B_0, C5);
 2361|       |
 2362|       |            B_0 = blB[6];
 2363|       |            C6 = cj.pmadd(A0, B_0, C6);
 2364|       |
 2365|       |            B_0 = blB[7];
 2366|       |            C7 = cj.pmadd(A0, B_0, C7);
 2367|       |
 2368|       |            blB += 8;
 2369|       |          }
 2370|       |          res(i, j2 + 0) += alpha * C0;
 2371|       |          res(i, j2 + 1) += alpha * C1;
 2372|       |          res(i, j2 + 2) += alpha * C2;
 2373|       |          res(i, j2 + 3) += alpha * C3;
 2374|       |          res(i, j2 + 4) += alpha * C4;
 2375|       |          res(i, j2 + 5) += alpha * C5;
 2376|       |          res(i, j2 + 6) += alpha * C6;
 2377|       |          res(i, j2 + 7) += alpha * C7;
 2378|       |        }
 2379|       |      }
 2380|       |    }
 2381|       |#endif
 2382|       |
 2383|      0|    for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
 2384|       |      // loop on each row of the lhs (1*LhsProgress x depth)
 2385|      0|      for (Index i = peeled_mc_quarter; i < rows; i += 1) {
 2386|      0|        const LhsScalar* blA = &blockA[i * strideA + offsetA];
 2387|      0|        prefetch(&blA[0]);
 2388|      0|        const RhsScalar* blB = &blockB[j2 * strideB + offsetB * 4];
 2389|       |
 2390|       |        // If LhsProgress is 8 or 16, it assumes that there is a
 2391|       |        // half or quarter packet, respectively, of the same size as
 2392|       |        // nr (which is currently 4) for the return type.
 2393|      0|        const int SResPacketHalfSize = unpacket_traits<typename unpacket_traits<SResPacket>::half>::size;
 2394|      0|        const int SResPacketQuarterSize =
 2395|      0|            unpacket_traits<typename unpacket_traits<typename unpacket_traits<SResPacket>::half>::half>::size;
 2396|       |        // The following code assumes we can load SRhsPacket in such a way that
 2397|       |        // it multiplies blocks of 4 elements in SLhsPacket.  This is not the
 2398|       |        // case for some customized kernels (i.e. NEON fp16).  If the assumption
 2399|       |        // fails, drop down to the scalar path.
 2400|      0|        constexpr bool kCanLoadSRhsQuad =
 2401|      0|            (unpacket_traits<SLhsPacket>::size < 4) ||
 2402|      0|            (unpacket_traits<SRhsPacket>::size % ((std::max<int>)(unpacket_traits<SLhsPacket>::size, 4) / 4)) == 0;
 2403|      0|        if (kCanLoadSRhsQuad && (SwappedTraits::LhsProgress % 4) == 0 && (SwappedTraits::LhsProgress <= 16) &&
 2404|      0|            (SwappedTraits::LhsProgress != 8 || SResPacketHalfSize == nr) &&
 2405|      0|            (SwappedTraits::LhsProgress != 16 || SResPacketQuarterSize == nr)) {
 2406|      0|          SAccPacket C0, C1, C2, C3;
 2407|      0|          straits.initAcc(C0);
 2408|      0|          straits.initAcc(C1);
 2409|      0|          straits.initAcc(C2);
 2410|      0|          straits.initAcc(C3);
 2411|       |
 2412|      0|          const Index spk = (std::max)(1, SwappedTraits::LhsProgress / 4);
 2413|      0|          const Index endk = (depth / spk) * spk;
 2414|      0|          const Index endk4 = (depth / (spk * 4)) * (spk * 4);
 2415|       |
 2416|      0|          Index k = 0;
 2417|      0|          for (; k < endk4; k += 4 * spk) {
 2418|      0|            SLhsPacket A0, A1;
 2419|      0|            SRhsPacket B_0, B_1;
 2420|       |
 2421|      0|            straits.loadLhsUnaligned(blB + 0 * SwappedTraits::LhsProgress, A0);
 2422|      0|            straits.loadLhsUnaligned(blB + 1 * SwappedTraits::LhsProgress, A1);
 2423|       |
 2424|      0|            straits.loadRhsQuad(blA + 0 * spk, B_0);
 2425|      0|            straits.loadRhsQuad(blA + 1 * spk, B_1);
 2426|      0|            straits.madd(A0, B_0, C0, B_0, fix<0>);
 2427|      0|            straits.madd(A1, B_1, C1, B_1, fix<0>);
 2428|       |
 2429|      0|            straits.loadLhsUnaligned(blB + 2 * SwappedTraits::LhsProgress, A0);
 2430|      0|            straits.loadLhsUnaligned(blB + 3 * SwappedTraits::LhsProgress, A1);
 2431|      0|            straits.loadRhsQuad(blA + 2 * spk, B_0);
 2432|      0|            straits.loadRhsQuad(blA + 3 * spk, B_1);
 2433|      0|            straits.madd(A0, B_0, C2, B_0, fix<0>);
 2434|      0|            straits.madd(A1, B_1, C3, B_1, fix<0>);
 2435|       |
 2436|      0|            blB += 4 * SwappedTraits::LhsProgress;
 2437|      0|            blA += 4 * spk;
 2438|      0|          }
 2439|      0|          C0 = padd(padd(C0, C1), padd(C2, C3));
 2440|      0|          for (; k < endk; k += spk) {
 2441|      0|            SLhsPacket A0;
 2442|      0|            SRhsPacket B_0;
 2443|       |
 2444|      0|            straits.loadLhsUnaligned(blB, A0);
 2445|      0|            straits.loadRhsQuad(blA, B_0);
 2446|      0|            straits.madd(A0, B_0, C0, B_0, fix<0>);
 2447|       |
 2448|      0|            blB += SwappedTraits::LhsProgress;
 2449|      0|            blA += spk;
 2450|      0|          }
 2451|      0|          if (SwappedTraits::LhsProgress == 8) {
 2452|       |            // Special case where we have to first reduce the accumulation register C0
 2453|      0|            typedef std::conditional_t<SwappedTraits::LhsProgress >= 8, typename unpacket_traits<SResPacket>::half,
 2454|      0|                                       SResPacket>
 2455|      0|                SResPacketHalf;
 2456|      0|            typedef std::conditional_t<SwappedTraits::LhsProgress >= 8, typename unpacket_traits<SLhsPacket>::half,
 2457|      0|                                       SLhsPacket>
 2458|      0|                SLhsPacketHalf;
 2459|      0|            typedef std::conditional_t<SwappedTraits::LhsProgress >= 8, typename unpacket_traits<SRhsPacket>::half,
 2460|      0|                                       SRhsPacket>
 2461|      0|                SRhsPacketHalf;
 2462|      0|            typedef std::conditional_t<SwappedTraits::LhsProgress >= 8, typename unpacket_traits<SAccPacket>::half,
 2463|      0|                                       SAccPacket>
 2464|      0|                SAccPacketHalf;
 2465|       |
 2466|      0|            SResPacketHalf R = res.template gatherPacket<SResPacketHalf>(i, j2);
 2467|      0|            SResPacketHalf alphav = pset1<SResPacketHalf>(alpha);
 2468|       |
 2469|      0|            if (depth - endk > 0) {
 2470|       |              // We have to handle the last row of the rhs which corresponds to a half-packet
 2471|      0|              SLhsPacketHalf a0;
 2472|      0|              SRhsPacketHalf b0;
 2473|      0|              straits.loadLhsUnaligned(blB, a0);
 2474|      0|              straits.loadRhs(blA, b0);
 2475|      0|              SAccPacketHalf c0 = predux_half_dowto4(C0);
 2476|      0|              straits.madd(a0, b0, c0, b0, fix<0>);
 2477|      0|              straits.acc(c0, alphav, R);
 2478|      0|            } else {
 2479|      0|              straits.acc(predux_half_dowto4(C0), alphav, R);
 2480|      0|            }
 2481|      0|            res.scatterPacket(i, j2, R);
 2482|      0|          } else if (SwappedTraits::LhsProgress == 16) {
 2483|       |            // Special case where we have to first reduce the
 2484|       |            // accumulation register C0. We specialize the block in
 2485|       |            // template form, so that LhsProgress < 16 paths don't
 2486|       |            // fail to compile
 2487|      0|            last_row_process_16_packets<LhsScalar, RhsScalar, Index, DataMapper, mr, nr, ConjugateLhs, ConjugateRhs> p;
 2488|      0|            p(res, straits, blA, blB, depth, endk, i, j2, alpha, C0);
 2489|      0|          } else {
 2490|      0|            SResPacket R = res.template gatherPacket<SResPacket>(i, j2);
 2491|      0|            SResPacket alphav = pset1<SResPacket>(alpha);
 2492|      0|            straits.acc(C0, alphav, R);
 2493|      0|            res.scatterPacket(i, j2, R);
 2494|      0|          }
 2495|      0|        } else  // scalar path
 2496|      0|        {
 2497|       |          // get a 1 x 4 res block as registers
 2498|      0|          ResScalar C0(0), C1(0), C2(0), C3(0);
 2499|       |
 2500|      0|          for (Index k = 0; k < depth; k++) {
 2501|      0|            LhsScalar A0;
 2502|      0|            RhsScalar B_0, B_1;
 2503|       |
 2504|      0|            A0 = blA[k];
 2505|       |
 2506|      0|            B_0 = blB[0];
 2507|      0|            B_1 = blB[1];
 2508|      0|            C0 = cj.pmadd(A0, B_0, C0);
 2509|      0|            C1 = cj.pmadd(A0, B_1, C1);
 2510|       |
 2511|      0|            B_0 = blB[2];
 2512|      0|            B_1 = blB[3];
 2513|      0|            C2 = cj.pmadd(A0, B_0, C2);
 2514|      0|            C3 = cj.pmadd(A0, B_1, C3);
 2515|       |
 2516|      0|            blB += 4;
 2517|      0|          }
 2518|      0|          res(i, j2 + 0) += alpha * C0;
 2519|      0|          res(i, j2 + 1) += alpha * C1;
 2520|      0|          res(i, j2 + 2) += alpha * C2;
 2521|      0|          res(i, j2 + 3) += alpha * C3;
 2522|      0|        }
 2523|      0|      }
 2524|      0|    }
 2525|       |    // remaining columns
 2526|      0|    for (Index j2 = packet_cols4; j2 < cols; j2++) {
 2527|       |      // loop on each row of the lhs (1*LhsProgress x depth)
 2528|      0|      for (Index i = peeled_mc_quarter; i < rows; i += 1) {
 2529|      0|        const LhsScalar* blA = &blockA[i * strideA + offsetA];
 2530|      0|        prefetch(&blA[0]);
 2531|       |        // gets a 1 x 1 res block as registers
 2532|      0|        ResScalar C0(0);
 2533|      0|        const RhsScalar* blB = &blockB[j2 * strideB + offsetB];
 2534|      0|        for (Index k = 0; k < depth; k++) {
 2535|      0|          LhsScalar A0 = blA[k];
 2536|      0|          RhsScalar B_0 = blB[k];
 2537|      0|          C0 = cj.pmadd(A0, B_0, C0);
 2538|      0|        }
 2539|      0|        res(i, j2) += alpha * C0;
 2540|      0|      }
 2541|      0|    }
 2542|      0|  }
 2543|      2|}
 2544|       |
 2545|       |// pack a block of the lhs
 2546|       |// The traversal is as follow (mr==4):
 2547|       |//   0  4  8 12 ...
 2548|       |//   1  5  9 13 ...
 2549|       |//   2  6 10 14 ...
 2550|       |//   3  7 11 15 ...
 2551|       |//
 2552|       |//  16 20 24 28 ...
 2553|       |//  17 21 25 29 ...
 2554|       |//  18 22 26 30 ...
 2555|       |//  19 23 27 31 ...
 2556|       |//
 2557|       |//  32 33 34 35 ...
 2558|       |//  36 36 38 39 ...
 2559|       |template <typename Scalar, typename Index, typename DataMapper, int Pack1, int Pack2, typename Packet, bool Conjugate,
 2560|       |          bool PanelMode>
 2561|       |struct gemm_pack_lhs<Scalar, Index, DataMapper, Pack1, Pack2, Packet, ColMajor, Conjugate, PanelMode> {
 2562|       |  typedef typename DataMapper::LinearMapper LinearMapper;
 2563|       |  EIGEN_DONT_INLINE void operator()(Scalar* blockA, const DataMapper& lhs, Index depth, Index rows, Index stride = 0,
 2564|       |                                    Index offset = 0);
 2565|       |};
 2566|       |
 2567|       |template <typename Scalar, typename Index, typename DataMapper, int Pack1, int Pack2, typename Packet, bool Conjugate,
 2568|       |          bool PanelMode>
 2569|       |EIGEN_DONT_INLINE void gemm_pack_lhs<Scalar, Index, DataMapper, Pack1, Pack2, Packet, ColMajor, Conjugate,
 2570|       |                                     PanelMode>::operator()(Scalar* blockA, const DataMapper& lhs, Index depth,
 2571|      2|                                                            Index rows, Index stride, Index offset) {
 2572|      2|  typedef typename unpacket_traits<Packet>::half HalfPacket;
 2573|      2|  typedef typename unpacket_traits<typename unpacket_traits<Packet>::half>::half QuarterPacket;
 2574|      2|  enum {
 2575|      2|    PacketSize = unpacket_traits<Packet>::size,
 2576|      2|    HalfPacketSize = unpacket_traits<HalfPacket>::size,
 2577|      2|    QuarterPacketSize = unpacket_traits<QuarterPacket>::size,
 2578|      2|    HasHalf = (int)HalfPacketSize < (int)PacketSize,
 2579|      2|    HasQuarter = (int)QuarterPacketSize < (int)HalfPacketSize
 2580|      2|  };
 2581|       |
 2582|      2|  EIGEN_ASM_COMMENT("EIGEN PRODUCT PACK LHS");
 2583|      2|  EIGEN_UNUSED_VARIABLE(stride);
 2584|      2|  EIGEN_UNUSED_VARIABLE(offset);
 2585|      2|  eigen_assert(((!PanelMode) && stride == 0 && offset == 0) || (PanelMode && stride >= depth && offset <= stride));
 2586|      2|  eigen_assert(((Pack1 % PacketSize) == 0 && Pack1 <= 4 * PacketSize) || (Pack1 <= 4));
 2587|      2|  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
 2588|      2|  Index count = 0;
 2589|       |
 2590|      2|  const Index peeled_mc3 = Pack1 >= 3 * PacketSize ? (rows / (3 * PacketSize)) * (3 * PacketSize) : 0;
 2591|      2|  const Index peeled_mc2 =
 2592|      2|      Pack1 >= 2 * PacketSize ? peeled_mc3 + ((rows - peeled_mc3) / (2 * PacketSize)) * (2 * PacketSize) : 0;
 2593|      2|  const Index peeled_mc1 =
 2594|      2|      Pack1 >= 1 * PacketSize ? peeled_mc2 + ((rows - peeled_mc2) / (1 * PacketSize)) * (1 * PacketSize) : 0;
 2595|      2|  const Index peeled_mc_half =
 2596|      2|      Pack1 >= HalfPacketSize ? peeled_mc1 + ((rows - peeled_mc1) / (HalfPacketSize)) * (HalfPacketSize) : 0;
 2597|      2|  const Index peeled_mc_quarter = Pack1 >= QuarterPacketSize ? (rows / (QuarterPacketSize)) * (QuarterPacketSize) : 0;
 2598|      2|  const Index last_lhs_progress = rows > peeled_mc_quarter ? (rows - peeled_mc_quarter) & ~1 : 0;
 2599|      2|  const Index peeled_mc0 = Pack2 >= PacketSize              ? peeled_mc_quarter
 2600|      2|                           : Pack2 > 1 && last_lhs_progress ? (rows / last_lhs_progress) * last_lhs_progress
 2601|      0|                                                            : 0;
 2602|       |
 2603|      2|  Index i = 0;
 2604|       |
 2605|       |  // Pack 3 packets
 2606|      2|  if (Pack1 >= 3 * PacketSize) {
 2607|      0|    for (; i < peeled_mc3; i += 3 * PacketSize) {
 2608|      0|      if (PanelMode) count += (3 * PacketSize) * offset;
 2609|       |
 2610|      0|      for (Index k = 0; k < depth; k++) {
 2611|      0|        Packet A, B, C;
 2612|      0|        A = lhs.template loadPacket<Packet>(i + 0 * PacketSize, k);
 2613|      0|        B = lhs.template loadPacket<Packet>(i + 1 * PacketSize, k);
 2614|      0|        C = lhs.template loadPacket<Packet>(i + 2 * PacketSize, k);
 2615|      0|        pstore(blockA + count, cj.pconj(A));
 2616|      0|        count += PacketSize;
 2617|      0|        pstore(blockA + count, cj.pconj(B));
 2618|      0|        count += PacketSize;
 2619|      0|        pstore(blockA + count, cj.pconj(C));
 2620|      0|        count += PacketSize;
 2621|      0|      }
 2622|      0|      if (PanelMode) count += (3 * PacketSize) * (stride - offset - depth);
 2623|      0|    }
 2624|      0|  }
 2625|       |  // Pack 2 packets
 2626|      2|  if (Pack1 >= 2 * PacketSize) {
 2627|     52|    for (; i < peeled_mc2; i += 2 * PacketSize) {
 2628|     50|      if (PanelMode) count += (2 * PacketSize) * offset;
 2629|       |
 2630|  2.55k|      for (Index k = 0; k < depth; k++) {
 2631|  2.50k|        Packet A, B;
 2632|  2.50k|        A = lhs.template loadPacket<Packet>(i + 0 * PacketSize, k);
 2633|  2.50k|        B = lhs.template loadPacket<Packet>(i + 1 * PacketSize, k);
 2634|  2.50k|        pstore(blockA + count, cj.pconj(A));
 2635|  2.50k|        count += PacketSize;
 2636|  2.50k|        pstore(blockA + count, cj.pconj(B));
 2637|  2.50k|        count += PacketSize;
 2638|  2.50k|      }
 2639|     50|      if (PanelMode) count += (2 * PacketSize) * (stride - offset - depth);
 2640|     50|    }
 2641|      2|  }
 2642|       |  // Pack 1 packets
 2643|      2|  if (Pack1 >= 1 * PacketSize) {
 2644|      2|    for (; i < peeled_mc1; i += 1 * PacketSize) {
 2645|      0|      if (PanelMode) count += (1 * PacketSize) * offset;
 2646|       |
 2647|      0|      for (Index k = 0; k < depth; k++) {
 2648|      0|        Packet A;
 2649|      0|        A = lhs.template loadPacket<Packet>(i + 0 * PacketSize, k);
 2650|      0|        pstore(blockA + count, cj.pconj(A));
 2651|      0|        count += PacketSize;
 2652|      0|      }
 2653|      0|      if (PanelMode) count += (1 * PacketSize) * (stride - offset - depth);
 2654|      0|    }
 2655|      2|  }
 2656|       |  // Pack half packets
 2657|      2|  if (HasHalf && Pack1 >= HalfPacketSize) {
 2658|      0|    for (; i < peeled_mc_half; i += HalfPacketSize) {
 2659|      0|      if (PanelMode) count += (HalfPacketSize)*offset;
 2660|       |
 2661|      0|      for (Index k = 0; k < depth; k++) {
 2662|      0|        HalfPacket A;
 2663|      0|        A = lhs.template loadPacket<HalfPacket>(i + 0 * (HalfPacketSize), k);
 2664|      0|        pstoreu(blockA + count, cj.pconj(A));
 2665|      0|        count += HalfPacketSize;
 2666|      0|      }
 2667|      0|      if (PanelMode) count += (HalfPacketSize) * (stride - offset - depth);
 2668|      0|    }
 2669|      0|  }
 2670|       |  // Pack quarter packets
 2671|      2|  if (HasQuarter && Pack1 >= QuarterPacketSize) {
 2672|      0|    for (; i < peeled_mc_quarter; i += QuarterPacketSize) {
 2673|      0|      if (PanelMode) count += (QuarterPacketSize)*offset;
 2674|       |
 2675|      0|      for (Index k = 0; k < depth; k++) {
 2676|      0|        QuarterPacket A;
 2677|      0|        A = lhs.template loadPacket<QuarterPacket>(i + 0 * (QuarterPacketSize), k);
 2678|      0|        pstoreu(blockA + count, cj.pconj(A));
 2679|      0|        count += QuarterPacketSize;
 2680|      0|      }
 2681|      0|      if (PanelMode) count += (QuarterPacketSize) * (stride - offset - depth);
 2682|      0|    }
 2683|      0|  }
 2684|       |  // Pack2 may be *smaller* than PacketSizethat happens for
 2685|       |  // products like real * complex, where we have to go half the
 2686|       |  // progress on the lhs in order to duplicate those operands to
 2687|       |  // address both real & imaginary parts on the rhs. This portion will
 2688|       |  // pack those half ones until they match the number expected on the
 2689|       |  // last peeling loop at this point (for the rhs).
 2690|      2|  if (Pack2 < PacketSize && Pack2 > 1) {
 2691|      0|    for (; i < peeled_mc0; i += last_lhs_progress) {
 2692|      0|      if (PanelMode) count += last_lhs_progress * offset;
 2693|       |
 2694|      0|      for (Index k = 0; k < depth; k++)
 2695|      0|        for (Index w = 0; w < last_lhs_progress; w++) blockA[count++] = cj(lhs(i + w, k));
 2696|       |
 2697|      0|      if (PanelMode) count += last_lhs_progress * (stride - offset - depth);
 2698|      0|    }
 2699|      0|  }
 2700|       |  // Pack scalars
 2701|      2|  for (; i < rows; i++) {
 2702|      0|    if (PanelMode) count += offset;
 2703|      0|    for (Index k = 0; k < depth; k++) blockA[count++] = cj(lhs(i, k));
 2704|      0|    if (PanelMode) count += (stride - offset - depth);
 2705|      0|  }
 2706|      2|}
 2707|       |
 2708|       |template <typename Scalar, typename Index, typename DataMapper, int Pack1, int Pack2, typename Packet, bool Conjugate,
 2709|       |          bool PanelMode>
 2710|       |struct gemm_pack_lhs<Scalar, Index, DataMapper, Pack1, Pack2, Packet, RowMajor, Conjugate, PanelMode> {
 2711|       |  typedef typename DataMapper::LinearMapper LinearMapper;
 2712|       |  EIGEN_DONT_INLINE void operator()(Scalar* blockA, const DataMapper& lhs, Index depth, Index rows, Index stride = 0,
 2713|       |                                    Index offset = 0);
 2714|       |};
 2715|       |
 2716|       |template <typename Scalar, typename Index, typename DataMapper, int Pack1, int Pack2, typename Packet, bool Conjugate,
 2717|       |          bool PanelMode>
 2718|       |EIGEN_DONT_INLINE void gemm_pack_lhs<Scalar, Index, DataMapper, Pack1, Pack2, Packet, RowMajor, Conjugate,
 2719|       |                                     PanelMode>::operator()(Scalar* blockA, const DataMapper& lhs, Index depth,
 2720|       |                                                            Index rows, Index stride, Index offset) {
 2721|       |  typedef typename unpacket_traits<Packet>::half HalfPacket;
 2722|       |  typedef typename unpacket_traits<typename unpacket_traits<Packet>::half>::half QuarterPacket;
 2723|       |  enum {
 2724|       |    PacketSize = unpacket_traits<Packet>::size,
 2725|       |    HalfPacketSize = unpacket_traits<HalfPacket>::size,
 2726|       |    QuarterPacketSize = unpacket_traits<QuarterPacket>::size,
 2727|       |    HasHalf = (int)HalfPacketSize < (int)PacketSize,
 2728|       |    HasQuarter = (int)QuarterPacketSize < (int)HalfPacketSize
 2729|       |  };
 2730|       |
 2731|       |  EIGEN_ASM_COMMENT("EIGEN PRODUCT PACK LHS");
 2732|       |  EIGEN_UNUSED_VARIABLE(stride);
 2733|       |  EIGEN_UNUSED_VARIABLE(offset);
 2734|       |  eigen_assert(((!PanelMode) && stride == 0 && offset == 0) || (PanelMode && stride >= depth && offset <= stride));
 2735|       |  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
 2736|       |  Index count = 0;
 2737|       |  bool gone_half = false, gone_quarter = false, gone_last = false;
 2738|       |
 2739|       |  Index i = 0;
 2740|       |  Index pack = Pack1;
 2741|       |  Index psize = PacketSize;
 2742|       |  while (pack > 0) {
 2743|       |    Index remaining_rows = rows - i;
 2744|       |    Index peeled_mc = gone_last ? Pack2 > 1 ? (rows / pack) * pack : 0 : i + (remaining_rows / pack) * pack;
 2745|       |    Index starting_pos = i;
 2746|       |    for (; i < peeled_mc; i += pack) {
 2747|       |      if (PanelMode) count += pack * offset;
 2748|       |
 2749|       |      Index k = 0;
 2750|       |      if (pack >= psize && psize >= QuarterPacketSize) {
 2751|       |        const Index peeled_k = (depth / psize) * psize;
 2752|       |        for (; k < peeled_k; k += psize) {
 2753|       |          for (Index m = 0; m < pack; m += psize) {
 2754|       |            if (psize == PacketSize) {
 2755|       |              PacketBlock<Packet> kernel;
 2756|       |              for (Index p = 0; p < psize; ++p) kernel.packet[p] = lhs.template loadPacket<Packet>(i + p + m, k);
 2757|       |              ptranspose(kernel);
 2758|       |              for (Index p = 0; p < psize; ++p) pstore(blockA + count + m + (pack)*p, cj.pconj(kernel.packet[p]));
 2759|       |            } else if (HasHalf && psize == HalfPacketSize) {
 2760|       |              gone_half = true;
 2761|       |              PacketBlock<HalfPacket> kernel_half;
 2762|       |              for (Index p = 0; p < psize; ++p)
 2763|       |                kernel_half.packet[p] = lhs.template loadPacket<HalfPacket>(i + p + m, k);
 2764|       |              ptranspose(kernel_half);
 2765|       |              for (Index p = 0; p < psize; ++p) pstore(blockA + count + m + (pack)*p, cj.pconj(kernel_half.packet[p]));
 2766|       |            } else if (HasQuarter && psize == QuarterPacketSize) {
 2767|       |              gone_quarter = true;
 2768|       |              PacketBlock<QuarterPacket> kernel_quarter;
 2769|       |              for (Index p = 0; p < psize; ++p)
 2770|       |                kernel_quarter.packet[p] = lhs.template loadPacket<QuarterPacket>(i + p + m, k);
 2771|       |              ptranspose(kernel_quarter);
 2772|       |              for (Index p = 0; p < psize; ++p)
 2773|       |                pstore(blockA + count + m + (pack)*p, cj.pconj(kernel_quarter.packet[p]));
 2774|       |            }
 2775|       |          }
 2776|       |          count += psize * pack;
 2777|       |        }
 2778|       |      }
 2779|       |
 2780|       |      for (; k < depth; k++) {
 2781|       |        Index w = 0;
 2782|       |        for (; w < pack - 3; w += 4) {
 2783|       |          Scalar a(cj(lhs(i + w + 0, k))), b(cj(lhs(i + w + 1, k))), c(cj(lhs(i + w + 2, k))), d(cj(lhs(i + w + 3, k)));
 2784|       |          blockA[count++] = a;
 2785|       |          blockA[count++] = b;
 2786|       |          blockA[count++] = c;
 2787|       |          blockA[count++] = d;
 2788|       |        }
 2789|       |        if (pack % 4)
 2790|       |          for (; w < pack; ++w) blockA[count++] = cj(lhs(i + w, k));
 2791|       |      }
 2792|       |
 2793|       |      if (PanelMode) count += pack * (stride - offset - depth);
 2794|       |    }
 2795|       |
 2796|       |    pack -= psize;
 2797|       |    Index left = rows - i;
 2798|       |    if (pack <= 0) {
 2799|       |      if (!gone_last && (starting_pos == i || left >= psize / 2 || left >= psize / 4) &&
 2800|       |          ((psize / 2 == HalfPacketSize && HasHalf && !gone_half) ||
 2801|       |           (psize / 2 == QuarterPacketSize && HasQuarter && !gone_quarter))) {
 2802|       |        psize /= 2;
 2803|       |        pack = psize;
 2804|       |        continue;
 2805|       |      }
 2806|       |      // Pack2 may be *smaller* than PacketSizethat happens for
 2807|       |      // products like real * complex, where we have to go half the
 2808|       |      // progress on the lhs in order to duplicate those operands to
 2809|       |      // address both real & imaginary parts on the rhs. This portion will
 2810|       |      // pack those half ones until they match the number expected on the
 2811|       |      // last peeling loop at this point (for the rhs).
 2812|       |      if (Pack2 < PacketSize && !gone_last) {
 2813|       |        gone_last = true;
 2814|       |        psize = pack = left & ~1;
 2815|       |      }
 2816|       |    }
 2817|       |  }
 2818|       |
 2819|       |  for (; i < rows; i++) {
 2820|       |    if (PanelMode) count += offset;
 2821|       |    for (Index k = 0; k < depth; k++) blockA[count++] = cj(lhs(i, k));
 2822|       |    if (PanelMode) count += (stride - offset - depth);
 2823|       |  }
 2824|       |}
 2825|       |
 2826|       |// copy a complete panel of the rhs
 2827|       |// this version is optimized for column major matrices
 2828|       |// The traversal order is as follow: (nr==4):
 2829|       |//  0  1  2  3   12 13 14 15   24 27
 2830|       |//  4  5  6  7   16 17 18 19   25 28
 2831|       |//  8  9 10 11   20 21 22 23   26 29
 2832|       |//  .  .  .  .    .  .  .  .    .  .
 2833|       |template <typename Scalar, typename Index, typename DataMapper, int nr, bool Conjugate, bool PanelMode>
 2834|       |struct gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode> {
 2835|       |  typedef typename packet_traits<Scalar>::type Packet;
 2836|       |  typedef typename DataMapper::LinearMapper LinearMapper;
 2837|       |  enum { PacketSize = packet_traits<Scalar>::size };
 2838|       |  EIGEN_DONT_INLINE void operator()(Scalar* blockB, const DataMapper& rhs, Index depth, Index cols, Index stride = 0,
 2839|       |                                    Index offset = 0);
 2840|       |};
 2841|       |
 2842|       |template <typename Scalar, typename Index, typename DataMapper, int nr, bool Conjugate, bool PanelMode>
 2843|       |EIGEN_DONT_INLINE void gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>::operator()(
 2844|      2|    Scalar* blockB, const DataMapper& rhs, Index depth, Index cols, Index stride, Index offset) {
 2845|      2|  EIGEN_ASM_COMMENT("EIGEN PRODUCT PACK RHS COLMAJOR");
 2846|      2|  EIGEN_UNUSED_VARIABLE(stride);
 2847|      2|  EIGEN_UNUSED_VARIABLE(offset);
 2848|      2|  eigen_assert(((!PanelMode) && stride == 0 && offset == 0) || (PanelMode && stride >= depth && offset <= stride));
 2849|      2|  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
 2850|      2|  Index packet_cols8 = nr >= 8 ? (cols / 8) * 8 : 0;
 2851|      2|  Index packet_cols4 = nr >= 4 ? (cols / 4) * 4 : 0;
 2852|      2|  Index count = 0;
 2853|      2|  const Index peeled_k = (depth / PacketSize) * PacketSize;
 2854|       |
 2855|       |#if EIGEN_ARCH_ARM64 || EIGEN_ARCH_LOONGARCH64
 2856|       |  EIGEN_IF_CONSTEXPR(nr >= 8) {
 2857|       |    for (Index j2 = 0; j2 < packet_cols8; j2 += 8) {
 2858|       |      // skip what we have before
 2859|       |      if (PanelMode) count += 8 * offset;
 2860|       |      const LinearMapper dm0 = rhs.getLinearMapper(0, j2 + 0);
 2861|       |      const LinearMapper dm1 = rhs.getLinearMapper(0, j2 + 1);
 2862|       |      const LinearMapper dm2 = rhs.getLinearMapper(0, j2 + 2);
 2863|       |      const LinearMapper dm3 = rhs.getLinearMapper(0, j2 + 3);
 2864|       |      const LinearMapper dm4 = rhs.getLinearMapper(0, j2 + 4);
 2865|       |      const LinearMapper dm5 = rhs.getLinearMapper(0, j2 + 5);
 2866|       |      const LinearMapper dm6 = rhs.getLinearMapper(0, j2 + 6);
 2867|       |      const LinearMapper dm7 = rhs.getLinearMapper(0, j2 + 7);
 2868|       |      Index k = 0;
 2869|       |      if (PacketSize % 2 == 0 && PacketSize <= 8)  // 2 4 8
 2870|       |      {
 2871|       |        for (; k < peeled_k; k += PacketSize) {
 2872|       |          if (PacketSize == 2) {
 2873|       |            PacketBlock<Packet, PacketSize == 2 ? 2 : PacketSize> kernel0, kernel1, kernel2, kernel3;
 2874|       |            kernel0.packet[0 % PacketSize] = dm0.template loadPacket<Packet>(k);
 2875|       |            kernel0.packet[1 % PacketSize] = dm1.template loadPacket<Packet>(k);
 2876|       |            kernel1.packet[0 % PacketSize] = dm2.template loadPacket<Packet>(k);
 2877|       |            kernel1.packet[1 % PacketSize] = dm3.template loadPacket<Packet>(k);
 2878|       |            kernel2.packet[0 % PacketSize] = dm4.template loadPacket<Packet>(k);
 2879|       |            kernel2.packet[1 % PacketSize] = dm5.template loadPacket<Packet>(k);
 2880|       |            kernel3.packet[0 % PacketSize] = dm6.template loadPacket<Packet>(k);
 2881|       |            kernel3.packet[1 % PacketSize] = dm7.template loadPacket<Packet>(k);
 2882|       |            ptranspose(kernel0);
 2883|       |            ptranspose(kernel1);
 2884|       |            ptranspose(kernel2);
 2885|       |            ptranspose(kernel3);
 2886|       |
 2887|       |            pstoreu(blockB + count + 0 * PacketSize, cj.pconj(kernel0.packet[0 % PacketSize]));
 2888|       |            pstoreu(blockB + count + 1 * PacketSize, cj.pconj(kernel1.packet[0 % PacketSize]));
 2889|       |            pstoreu(blockB + count + 2 * PacketSize, cj.pconj(kernel2.packet[0 % PacketSize]));
 2890|       |            pstoreu(blockB + count + 3 * PacketSize, cj.pconj(kernel3.packet[0 % PacketSize]));
 2891|       |
 2892|       |            pstoreu(blockB + count + 4 * PacketSize, cj.pconj(kernel0.packet[1 % PacketSize]));
 2893|       |            pstoreu(blockB + count + 5 * PacketSize, cj.pconj(kernel1.packet[1 % PacketSize]));
 2894|       |            pstoreu(blockB + count + 6 * PacketSize, cj.pconj(kernel2.packet[1 % PacketSize]));
 2895|       |            pstoreu(blockB + count + 7 * PacketSize, cj.pconj(kernel3.packet[1 % PacketSize]));
 2896|       |            count += 8 * PacketSize;
 2897|       |          } else if (PacketSize == 4) {
 2898|       |            PacketBlock<Packet, PacketSize == 4 ? 4 : PacketSize> kernel0, kernel1;
 2899|       |
 2900|       |            kernel0.packet[0 % PacketSize] = dm0.template loadPacket<Packet>(k);
 2901|       |            kernel0.packet[1 % PacketSize] = dm1.template loadPacket<Packet>(k);
 2902|       |            kernel0.packet[2 % PacketSize] = dm2.template loadPacket<Packet>(k);
 2903|       |            kernel0.packet[3 % PacketSize] = dm3.template loadPacket<Packet>(k);
 2904|       |            kernel1.packet[0 % PacketSize] = dm4.template loadPacket<Packet>(k);
 2905|       |            kernel1.packet[1 % PacketSize] = dm5.template loadPacket<Packet>(k);
 2906|       |            kernel1.packet[2 % PacketSize] = dm6.template loadPacket<Packet>(k);
 2907|       |            kernel1.packet[3 % PacketSize] = dm7.template loadPacket<Packet>(k);
 2908|       |            ptranspose(kernel0);
 2909|       |            ptranspose(kernel1);
 2910|       |
 2911|       |            pstoreu(blockB + count + 0 * PacketSize, cj.pconj(kernel0.packet[0 % PacketSize]));
 2912|       |            pstoreu(blockB + count + 1 * PacketSize, cj.pconj(kernel1.packet[0 % PacketSize]));
 2913|       |            pstoreu(blockB + count + 2 * PacketSize, cj.pconj(kernel0.packet[1 % PacketSize]));
 2914|       |            pstoreu(blockB + count + 3 * PacketSize, cj.pconj(kernel1.packet[1 % PacketSize]));
 2915|       |            pstoreu(blockB + count + 4 * PacketSize, cj.pconj(kernel0.packet[2 % PacketSize]));
 2916|       |            pstoreu(blockB + count + 5 * PacketSize, cj.pconj(kernel1.packet[2 % PacketSize]));
 2917|       |            pstoreu(blockB + count + 6 * PacketSize, cj.pconj(kernel0.packet[3 % PacketSize]));
 2918|       |            pstoreu(blockB + count + 7 * PacketSize, cj.pconj(kernel1.packet[3 % PacketSize]));
 2919|       |            count += 8 * PacketSize;
 2920|       |          } else if (PacketSize == 8) {
 2921|       |            PacketBlock<Packet, PacketSize == 8 ? 8 : PacketSize> kernel0;
 2922|       |
 2923|       |            kernel0.packet[0 % PacketSize] = dm0.template loadPacket<Packet>(k);
 2924|       |            kernel0.packet[1 % PacketSize] = dm1.template loadPacket<Packet>(k);
 2925|       |            kernel0.packet[2 % PacketSize] = dm2.template loadPacket<Packet>(k);
 2926|       |            kernel0.packet[3 % PacketSize] = dm3.template loadPacket<Packet>(k);
 2927|       |            kernel0.packet[4 % PacketSize] = dm4.template loadPacket<Packet>(k);
 2928|       |            kernel0.packet[5 % PacketSize] = dm5.template loadPacket<Packet>(k);
 2929|       |            kernel0.packet[6 % PacketSize] = dm6.template loadPacket<Packet>(k);
 2930|       |            kernel0.packet[7 % PacketSize] = dm7.template loadPacket<Packet>(k);
 2931|       |            ptranspose(kernel0);
 2932|       |
 2933|       |            pstoreu(blockB + count + 0 * PacketSize, cj.pconj(kernel0.packet[0 % PacketSize]));
 2934|       |            pstoreu(blockB + count + 1 * PacketSize, cj.pconj(kernel0.packet[1 % PacketSize]));
 2935|       |            pstoreu(blockB + count + 2 * PacketSize, cj.pconj(kernel0.packet[2 % PacketSize]));
 2936|       |            pstoreu(blockB + count + 3 * PacketSize, cj.pconj(kernel0.packet[3 % PacketSize]));
 2937|       |            pstoreu(blockB + count + 4 * PacketSize, cj.pconj(kernel0.packet[4 % PacketSize]));
 2938|       |            pstoreu(blockB + count + 5 * PacketSize, cj.pconj(kernel0.packet[5 % PacketSize]));
 2939|       |            pstoreu(blockB + count + 6 * PacketSize, cj.pconj(kernel0.packet[6 % PacketSize]));
 2940|       |            pstoreu(blockB + count + 7 * PacketSize, cj.pconj(kernel0.packet[7 % PacketSize]));
 2941|       |            count += 8 * PacketSize;
 2942|       |          }
 2943|       |        }
 2944|       |      }
 2945|       |
 2946|       |      for (; k < depth; k++) {
 2947|       |        blockB[count + 0] = cj(dm0(k));
 2948|       |        blockB[count + 1] = cj(dm1(k));
 2949|       |        blockB[count + 2] = cj(dm2(k));
 2950|       |        blockB[count + 3] = cj(dm3(k));
 2951|       |        blockB[count + 4] = cj(dm4(k));
 2952|       |        blockB[count + 5] = cj(dm5(k));
 2953|       |        blockB[count + 6] = cj(dm6(k));
 2954|       |        blockB[count + 7] = cj(dm7(k));
 2955|       |        count += 8;
 2956|       |      }
 2957|       |      // skip what we have after
 2958|       |      if (PanelMode) count += 8 * (stride - offset - depth);
 2959|       |    }
 2960|       |  }
 2961|       |#endif
 2962|       |
 2963|      2|  EIGEN_IF_CONSTEXPR(nr >= 4) {
 2964|     26|    for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
 2965|       |      // skip what we have before
 2966|     24|      if (PanelMode) count += 4 * offset;
 2967|     24|      const LinearMapper dm0 = rhs.getLinearMapper(0, j2 + 0);
 2968|     24|      const LinearMapper dm1 = rhs.getLinearMapper(0, j2 + 1);
 2969|     24|      const LinearMapper dm2 = rhs.getLinearMapper(0, j2 + 2);
 2970|     24|      const LinearMapper dm3 = rhs.getLinearMapper(0, j2 + 3);
 2971|       |
 2972|     24|      Index k = 0;
 2973|     24|      if ((PacketSize % 4) == 0)  // TODO enable vectorized transposition for PacketSize==2 ??
 2974|      0|      {
 2975|      0|        for (; k < peeled_k; k += PacketSize) {
 2976|      0|          PacketBlock<Packet, (PacketSize % 4) == 0 ? 4 : PacketSize> kernel;
 2977|      0|          kernel.packet[0] = dm0.template loadPacket<Packet>(k);
 2978|      0|          kernel.packet[1 % PacketSize] = dm1.template loadPacket<Packet>(k);
 2979|      0|          kernel.packet[2 % PacketSize] = dm2.template loadPacket<Packet>(k);
 2980|      0|          kernel.packet[3 % PacketSize] = dm3.template loadPacket<Packet>(k);
 2981|      0|          ptranspose(kernel);
 2982|      0|          pstoreu(blockB + count + 0 * PacketSize, cj.pconj(kernel.packet[0]));
 2983|      0|          pstoreu(blockB + count + 1 * PacketSize, cj.pconj(kernel.packet[1 % PacketSize]));
 2984|      0|          pstoreu(blockB + count + 2 * PacketSize, cj.pconj(kernel.packet[2 % PacketSize]));
 2985|      0|          pstoreu(blockB + count + 3 * PacketSize, cj.pconj(kernel.packet[3 % PacketSize]));
 2986|      0|          count += 4 * PacketSize;
 2987|      0|        }
 2988|      0|      }
 2989|  1.22k|      for (; k < depth; k++) {
 2990|  1.20k|        blockB[count + 0] = cj(dm0(k));
 2991|  1.20k|        blockB[count + 1] = cj(dm1(k));
 2992|  1.20k|        blockB[count + 2] = cj(dm2(k));
 2993|  1.20k|        blockB[count + 3] = cj(dm3(k));
 2994|  1.20k|        count += 4;
 2995|  1.20k|      }
 2996|       |      // skip what we have after
 2997|     24|      if (PanelMode) count += 4 * (stride - offset - depth);
 2998|     24|    }
 2999|      2|  }
 3000|       |
 3001|       |  // copy the remaining columns one at a time (nr==1)
 3002|      6|  for (Index j2 = packet_cols4; j2 < cols; ++j2) {
 3003|      4|    if (PanelMode) count += offset;
 3004|      4|    const LinearMapper dm0 = rhs.getLinearMapper(0, j2);
 3005|    204|    for (Index k = 0; k < depth; k++) {
 3006|    200|      blockB[count] = cj(dm0(k));
 3007|    200|      count += 1;
 3008|    200|    }
 3009|      4|    if (PanelMode) count += (stride - offset - depth);
 3010|      4|  }
 3011|      2|}
 3012|       |
 3013|       |// this version is optimized for row major matrices
 3014|       |template <typename Scalar, typename Index, typename DataMapper, int nr, bool Conjugate, bool PanelMode>
 3015|       |struct gemm_pack_rhs<Scalar, Index, DataMapper, nr, RowMajor, Conjugate, PanelMode> {
 3016|       |  typedef typename packet_traits<Scalar>::type Packet;
 3017|       |  typedef typename unpacket_traits<Packet>::half HalfPacket;
 3018|       |  typedef typename unpacket_traits<typename unpacket_traits<Packet>::half>::half QuarterPacket;
 3019|       |  typedef typename DataMapper::LinearMapper LinearMapper;
 3020|       |  enum {
 3021|       |    PacketSize = packet_traits<Scalar>::size,
 3022|       |    HalfPacketSize = unpacket_traits<HalfPacket>::size,
 3023|       |    QuarterPacketSize = unpacket_traits<QuarterPacket>::size
 3024|       |  };
 3025|       |  EIGEN_DONT_INLINE void operator()(Scalar* blockB, const DataMapper& rhs, Index depth, Index cols, Index stride = 0,
 3026|       |                                    Index offset = 0) {
 3027|       |    EIGEN_ASM_COMMENT("EIGEN PRODUCT PACK RHS ROWMAJOR");
 3028|       |    EIGEN_UNUSED_VARIABLE(stride);
 3029|       |    EIGEN_UNUSED_VARIABLE(offset);
 3030|       |    eigen_assert(((!PanelMode) && stride == 0 && offset == 0) || (PanelMode && stride >= depth && offset <= stride));
 3031|       |    const bool HasHalf = (int)HalfPacketSize < (int)PacketSize;
 3032|       |    const bool HasQuarter = (int)QuarterPacketSize < (int)HalfPacketSize;
 3033|       |    conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
 3034|       |    Index packet_cols8 = nr >= 8 ? (cols / 8) * 8 : 0;
 3035|       |    Index packet_cols4 = nr >= 4 ? (cols / 4) * 4 : 0;
 3036|       |    Index count = 0;
 3037|       |
 3038|       |#if EIGEN_ARCH_ARM64 || EIGEN_ARCH_LOONGARCH64
 3039|       |    EIGEN_IF_CONSTEXPR(nr >= 8) {
 3040|       |      for (Index j2 = 0; j2 < packet_cols8; j2 += 8) {
 3041|       |        // skip what we have before
 3042|       |        if (PanelMode) count += 8 * offset;
 3043|       |        for (Index k = 0; k < depth; k++) {
 3044|       |          if (PacketSize == 8) {
 3045|       |            Packet A = rhs.template loadPacket<Packet>(k, j2);
 3046|       |            pstoreu(blockB + count, cj.pconj(A));
 3047|       |            count += PacketSize;
 3048|       |          } else if (PacketSize == 4) {
 3049|       |            Packet A = rhs.template loadPacket<Packet>(k, j2);
 3050|       |            Packet B = rhs.template loadPacket<Packet>(k, j2 + 4);
 3051|       |            pstoreu(blockB + count, cj.pconj(A));
 3052|       |            pstoreu(blockB + count + PacketSize, cj.pconj(B));
 3053|       |            count += 2 * PacketSize;
 3054|       |          } else {
 3055|       |            const LinearMapper dm0 = rhs.getLinearMapper(k, j2);
 3056|       |            blockB[count + 0] = cj(dm0(0));
 3057|       |            blockB[count + 1] = cj(dm0(1));
 3058|       |            blockB[count + 2] = cj(dm0(2));
 3059|       |            blockB[count + 3] = cj(dm0(3));
 3060|       |            blockB[count + 4] = cj(dm0(4));
 3061|       |            blockB[count + 5] = cj(dm0(5));
 3062|       |            blockB[count + 6] = cj(dm0(6));
 3063|       |            blockB[count + 7] = cj(dm0(7));
 3064|       |            count += 8;
 3065|       |          }
 3066|       |        }
 3067|       |        // skip what we have after
 3068|       |        if (PanelMode) count += 8 * (stride - offset - depth);
 3069|       |      }
 3070|       |    }
 3071|       |#endif
 3072|       |
 3073|       |    if (nr >= 4) {
 3074|       |      for (Index j2 = packet_cols8; j2 < packet_cols4; j2 += 4) {
 3075|       |        // skip what we have before
 3076|       |        if (PanelMode) count += 4 * offset;
 3077|       |        for (Index k = 0; k < depth; k++) {
 3078|       |          if (PacketSize == 4) {
 3079|       |            Packet A = rhs.template loadPacket<Packet>(k, j2);
 3080|       |            pstoreu(blockB + count, cj.pconj(A));
 3081|       |            count += PacketSize;
 3082|       |          } else if (HasHalf && HalfPacketSize == 4) {
 3083|       |            HalfPacket A = rhs.template loadPacket<HalfPacket>(k, j2);
 3084|       |            pstoreu(blockB + count, cj.pconj(A));
 3085|       |            count += HalfPacketSize;
 3086|       |          } else if (HasQuarter && QuarterPacketSize == 4) {
 3087|       |            QuarterPacket A = rhs.template loadPacket<QuarterPacket>(k, j2);
 3088|       |            pstoreu(blockB + count, cj.pconj(A));
 3089|       |            count += QuarterPacketSize;
 3090|       |          } else {
 3091|       |            const LinearMapper dm0 = rhs.getLinearMapper(k, j2);
 3092|       |            blockB[count + 0] = cj(dm0(0));
 3093|       |            blockB[count + 1] = cj(dm0(1));
 3094|       |            blockB[count + 2] = cj(dm0(2));
 3095|       |            blockB[count + 3] = cj(dm0(3));
 3096|       |            count += 4;
 3097|       |          }
 3098|       |        }
 3099|       |        // skip what we have after
 3100|       |        if (PanelMode) count += 4 * (stride - offset - depth);
 3101|       |      }
 3102|       |    }
 3103|       |    // copy the remaining columns one at a time (nr==1)
 3104|       |    for (Index j2 = packet_cols4; j2 < cols; ++j2) {
 3105|       |      if (PanelMode) count += offset;
 3106|       |      for (Index k = 0; k < depth; k++) {
 3107|       |        blockB[count] = cj(rhs(k, j2));
 3108|       |        count += 1;
 3109|       |      }
 3110|       |      if (PanelMode) count += stride - offset - depth;
 3111|       |    }
 3112|       |  }
 3113|       |};
 3114|       |
 3115|       |}  // end namespace internal
 3116|       |
 3117|       |/** \returns the currently set level 1 cpu cache size (in bytes) used to estimate the ideal blocking size parameters.
 3118|       | * \sa setCpuCacheSize */
 3119|      0|inline std::ptrdiff_t l1CacheSize() {
 3120|      0|  std::ptrdiff_t l1, l2, l3;
 3121|      0|  internal::manage_caching_sizes(GetAction, &l1, &l2, &l3);
 3122|      0|  return l1;
 3123|      0|}
 3124|       |
 3125|       |/** \returns the currently set level 2 cpu cache size (in bytes) used to estimate the ideal blocking size parameters.
 3126|       | * \sa setCpuCacheSize */
 3127|      0|inline std::ptrdiff_t l2CacheSize() {
 3128|      0|  std::ptrdiff_t l1, l2, l3;
 3129|      0|  internal::manage_caching_sizes(GetAction, &l1, &l2, &l3);
 3130|      0|  return l2;
 3131|      0|}
 3132|       |
 3133|       |/** \returns the currently set level 3 cpu cache size (in bytes) used to estimate the ideal blocking size parameters.
 3134|       | * \sa setCpuCacheSize */
 3135|      0|inline std::ptrdiff_t l3CacheSize() {
 3136|      0|  std::ptrdiff_t l1, l2, l3;
 3137|      0|  internal::manage_caching_sizes(GetAction, &l1, &l2, &l3);
 3138|      0|  return l3;
 3139|      0|}
 3140|       |
 3141|       |/** Set the cpu L1 and L2 cache sizes (in bytes).
 3142|       | * These values are use to adjust the size of the blocks
 3143|       | * for the algorithms working per blocks.
 3144|       | *
 3145|       | * \sa computeProductBlockingSizes */
 3146|      0|inline void setCpuCacheSizes(std::ptrdiff_t l1, std::ptrdiff_t l2, std::ptrdiff_t l3) {
 3147|      0|  internal::manage_caching_sizes(SetAction, &l1, &l2, &l3);
 3148|      0|}
 3149|       |
 3150|       |}  // end namespace Eigen
 3151|       |
 3152|       |#endif  // EIGEN_GENERAL_BLOCK_PANEL_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/products/GeneralMatrixMatrix.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2009 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_GENERAL_MATRIX_MATRIX_H
   11|       |#define EIGEN_GENERAL_MATRIX_MATRIX_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |template <typename LhsScalar_, typename RhsScalar_>
   21|       |class level3_blocking;
   22|       |
   23|       |/* Specialization for a row-major destination matrix => simple transposition of the product */
   24|       |template <typename Index, typename LhsScalar, int LhsStorageOrder, bool ConjugateLhs, typename RhsScalar,
   25|       |          int RhsStorageOrder, bool ConjugateRhs, int ResInnerStride>
   26|       |struct general_matrix_matrix_product<Index, LhsScalar, LhsStorageOrder, ConjugateLhs, RhsScalar, RhsStorageOrder,
   27|       |                                     ConjugateRhs, RowMajor, ResInnerStride> {
   28|       |  typedef gebp_traits<RhsScalar, LhsScalar> Traits;
   29|       |
   30|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
   31|       |  static EIGEN_STRONG_INLINE void run(Index rows, Index cols, Index depth, const LhsScalar* lhs, Index lhsStride,
   32|       |                                      const RhsScalar* rhs, Index rhsStride, ResScalar* res, Index resIncr,
   33|       |                                      Index resStride, ResScalar alpha, level3_blocking<RhsScalar, LhsScalar>& blocking,
   34|       |                                      GemmParallelInfo<Index>* info = 0) {
   35|       |    // transpose the product such that the result is column major
   36|       |    general_matrix_matrix_product<Index, RhsScalar, RhsStorageOrder == RowMajor ? ColMajor : RowMajor, ConjugateRhs,
   37|       |                                  LhsScalar, LhsStorageOrder == RowMajor ? ColMajor : RowMajor, ConjugateLhs, ColMajor,
   38|       |                                  ResInnerStride>::run(cols, rows, depth, rhs, rhsStride, lhs, lhsStride, res, resIncr,
   39|       |                                                       resStride, alpha, blocking, info);
   40|       |  }
   41|       |};
   42|       |
   43|       |/*  Specialization for a col-major destination matrix
   44|       | *    => Blocking algorithm following Goto's paper */
   45|       |template <typename Index, typename LhsScalar, int LhsStorageOrder, bool ConjugateLhs, typename RhsScalar,
   46|       |          int RhsStorageOrder, bool ConjugateRhs, int ResInnerStride>
   47|       |struct general_matrix_matrix_product<Index, LhsScalar, LhsStorageOrder, ConjugateLhs, RhsScalar, RhsStorageOrder,
   48|       |                                     ConjugateRhs, ColMajor, ResInnerStride> {
   49|       |  typedef gebp_traits<LhsScalar, RhsScalar> Traits;
   50|       |
   51|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
   52|       |  static void run(Index rows, Index cols, Index depth, const LhsScalar* lhs_, Index lhsStride, const RhsScalar* rhs_,
   53|       |                  Index rhsStride, ResScalar* res_, Index resIncr, Index resStride, ResScalar alpha,
   54|      2|                  level3_blocking<LhsScalar, RhsScalar>& blocking, GemmParallelInfo<Index>* info = 0) {
   55|      2|    typedef const_blas_data_mapper<LhsScalar, Index, LhsStorageOrder> LhsMapper;
   56|      2|    typedef const_blas_data_mapper<RhsScalar, Index, RhsStorageOrder> RhsMapper;
   57|      2|    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
   58|      2|    LhsMapper lhs(lhs_, lhsStride);
   59|      2|    RhsMapper rhs(rhs_, rhsStride);
   60|      2|    ResMapper res(res_, resStride, resIncr);
   61|       |
   62|      2|    Index kc = blocking.kc();                    // cache block size along the K direction
   63|      2|    Index mc = (std::min)(rows, blocking.mc());  // cache block size along the M direction
   64|      2|    Index nc = (std::min)(cols, blocking.nc());  // cache block size along the N direction
   65|       |
   66|      2|    gemm_pack_lhs<LhsScalar, Index, LhsMapper, Traits::mr, Traits::LhsProgress, typename Traits::LhsPacket4Packing,
   67|      2|                  LhsStorageOrder>
   68|      2|        pack_lhs;
   69|      2|    gemm_pack_rhs<RhsScalar, Index, RhsMapper, Traits::nr, RhsStorageOrder> pack_rhs;
   70|      2|    gebp_kernel<LhsScalar, RhsScalar, Index, ResMapper, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs> gebp;
   71|       |
   72|       |#if !defined(EIGEN_USE_BLAS) && (defined(EIGEN_HAS_OPENMP) || defined(EIGEN_GEMM_THREADPOOL))
   73|       |    if (info) {
   74|       |      // this is the parallel version!
   75|       |      int tid = info->logical_thread_id;
   76|       |      int threads = info->num_threads;
   77|       |
   78|       |      LhsScalar* blockA = blocking.blockA();
   79|       |      eigen_internal_assert(blockA != 0);
   80|       |
   81|       |      std::size_t sizeB = kc * nc;
   82|       |      ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, 0);
   83|       |
   84|       |      // For each horizontal panel of the rhs, and corresponding vertical panel of the lhs...
   85|       |      for (Index k = 0; k < depth; k += kc) {
   86|       |        const Index actual_kc = (std::min)(k + kc, depth) - k;  // => rows of B', and cols of the A'
   87|       |
   88|       |        // In order to reduce the chance that a thread has to wait for the other,
   89|       |        // let's start by packing B'.
   90|       |        pack_rhs(blockB, rhs.getSubMapper(k, 0), actual_kc, nc);
   91|       |
   92|       |        // Pack A_k to A' in a parallel fashion:
   93|       |        // each thread packs the sub block A_k,i to A'_i where i is the thread id.
   94|       |
   95|       |        // However, before copying to A'_i, we have to make sure that no other thread is still using it,
   96|       |        // i.e., we test that info->task_info[tid].users equals 0.
   97|       |        // Then, we set info->task_info[tid].users to the number of threads to mark that all other threads are going to
   98|       |        // use it.
   99|       |        while (info->task_info[tid].users != 0) {
  100|       |          std::this_thread::yield();
  101|       |        }
  102|       |        info->task_info[tid].users = threads;
  103|       |
  104|       |        pack_lhs(blockA + info->task_info[tid].lhs_start * actual_kc,
  105|       |                 lhs.getSubMapper(info->task_info[tid].lhs_start, k), actual_kc, info->task_info[tid].lhs_length);
  106|       |
  107|       |        // Notify the other threads that the part A'_i is ready to go.
  108|       |        info->task_info[tid].sync = k;
  109|       |
  110|       |        // Computes C_i += A' * B' per A'_i
  111|       |        for (int shift = 0; shift < threads; ++shift) {
  112|       |          int i = (tid + shift) % threads;
  113|       |
  114|       |          // At this point we have to make sure that A'_i has been updated by the thread i,
  115|       |          // we use testAndSetOrdered to mimic a volatile access.
  116|       |          // However, no need to wait for the B' part which has been updated by the current thread!
  117|       |          if (shift > 0) {
  118|       |            while (info->task_info[i].sync != k) {
  119|       |              std::this_thread::yield();
  120|       |            }
  121|       |          }
  122|       |
  123|       |          gebp(res.getSubMapper(info->task_info[i].lhs_start, 0), blockA + info->task_info[i].lhs_start * actual_kc,
  124|       |               blockB, info->task_info[i].lhs_length, actual_kc, nc, alpha);
  125|       |        }
  126|       |
  127|       |        // Then keep going as usual with the remaining B'
  128|       |        for (Index j = nc; j < cols; j += nc) {
  129|       |          const Index actual_nc = (std::min)(j + nc, cols) - j;
  130|       |
  131|       |          // pack B_k,j to B'
  132|       |          pack_rhs(blockB, rhs.getSubMapper(k, j), actual_kc, actual_nc);
  133|       |
  134|       |          // C_j += A' * B'
  135|       |          gebp(res.getSubMapper(0, j), blockA, blockB, rows, actual_kc, actual_nc, alpha);
  136|       |        }
  137|       |
  138|       |        // Release all the sub blocks A'_i of A' for the current thread,
  139|       |        // i.e., we simply decrement the number of users by 1
  140|       |        for (Index i = 0; i < threads; ++i) info->task_info[i].users -= 1;
  141|       |      }
  142|       |    } else
  143|       |#endif  // defined(EIGEN_HAS_OPENMP) || defined(EIGEN_GEMM_THREADPOOL)
  144|      2|    {
  145|      2|      EIGEN_UNUSED_VARIABLE(info);
  146|       |
  147|       |      // this is the sequential version!
  148|      2|      std::size_t sizeA = kc * mc;
  149|      2|      std::size_t sizeB = kc * nc;
  150|       |
  151|      2|      ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
  152|      2|      ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());
  153|       |
  154|      2|      const bool pack_rhs_once = mc != rows && kc == depth && nc == cols;
  155|       |
  156|       |      // For each horizontal panel of the rhs, and corresponding panel of the lhs...
  157|      4|      for (Index i2 = 0; i2 < rows; i2 += mc) {
  158|      2|        const Index actual_mc = (std::min)(i2 + mc, rows) - i2;
  159|       |
  160|      4|        for (Index k2 = 0; k2 < depth; k2 += kc) {
  161|      2|          const Index actual_kc = (std::min)(k2 + kc, depth) - k2;
  162|       |
  163|       |          // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
  164|       |          // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
  165|       |          // Note that this panel will be read as many times as the number of blocks in the rhs's
  166|       |          // horizontal panel which is, in practice, a very low number.
  167|      2|          pack_lhs(blockA, lhs.getSubMapper(i2, k2), actual_kc, actual_mc);
  168|       |
  169|       |          // For each kc x nc block of the rhs's horizontal panel...
  170|      4|          for (Index j2 = 0; j2 < cols; j2 += nc) {
  171|      2|            const Index actual_nc = (std::min)(j2 + nc, cols) - j2;
  172|       |
  173|       |            // We pack the rhs's block into a sequential chunk of memory (L2 caching)
  174|       |            // Note that this block will be read a very high number of times, which is equal to the number of
  175|       |            // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
  176|      2|            if ((!pack_rhs_once) || i2 == 0) pack_rhs(blockB, rhs.getSubMapper(k2, j2), actual_kc, actual_nc);
  177|       |
  178|       |            // Everything is packed, we can now call the panel * block kernel:
  179|      2|            gebp(res.getSubMapper(i2, j2), blockA, blockB, actual_mc, actual_kc, actual_nc, alpha);
  180|      2|          }
  181|      2|        }
  182|      2|      }
  183|      2|    }
  184|      2|  }
  185|       |};
  186|       |
  187|       |/*********************************************************************************
  188|       | *  Specialization of generic_product_impl for "large" GEMM, i.e.,
  189|       | *  implementation of the high level wrapper to general_matrix_matrix_product
  190|       | **********************************************************************************/
  191|       |
  192|       |template <typename Scalar, typename Index, typename Gemm, typename Lhs, typename Rhs, typename Dest,
  193|       |          typename BlockingType>
  194|       |struct gemm_functor {
  195|       |  gemm_functor(const Lhs& lhs, const Rhs& rhs, Dest& dest, const Scalar& actualAlpha, BlockingType& blocking)
  196|      2|      : m_lhs(lhs), m_rhs(rhs), m_dest(dest), m_actualAlpha(actualAlpha), m_blocking(blocking) {}
  197|       |
  198|       |  void initParallelSession(Index num_threads) const {
  199|       |    m_blocking.initParallel(m_lhs.rows(), m_rhs.cols(), m_lhs.cols(), num_threads);
  200|       |    m_blocking.allocateA();
  201|       |  }
  202|       |
  203|      2|  void operator()(Index row, Index rows, Index col = 0, Index cols = -1, GemmParallelInfo<Index>* info = 0) const {
  204|      2|    if (cols == -1) cols = m_rhs.cols();
  205|       |
  206|      2|    Gemm::run(rows, cols, m_lhs.cols(), &m_lhs.coeffRef(row, 0), m_lhs.outerStride(), &m_rhs.coeffRef(0, col),
  207|      2|              m_rhs.outerStride(), (Scalar*)&(m_dest.coeffRef(row, col)), m_dest.innerStride(), m_dest.outerStride(),
  208|      2|              m_actualAlpha, m_blocking, info);
  209|      2|  }
  210|       |
  211|       |  typedef typename Gemm::Traits Traits;
  212|       |
  213|       | protected:
  214|       |  const Lhs& m_lhs;
  215|       |  const Rhs& m_rhs;
  216|       |  Dest& m_dest;
  217|       |  Scalar m_actualAlpha;
  218|       |  BlockingType& m_blocking;
  219|       |};
  220|       |
  221|       |template <int StorageOrder, typename LhsScalar, typename RhsScalar, int MaxRows, int MaxCols, int MaxDepth,
  222|       |          int KcFactor = 1, bool FiniteAtCompileTime = MaxRows != Dynamic && MaxCols != Dynamic && MaxDepth != Dynamic>
  223|       |class gemm_blocking_space;
  224|       |
  225|       |template <typename LhsScalar_, typename RhsScalar_>
  226|       |class level3_blocking {
  227|       |  typedef LhsScalar_ LhsScalar;
  228|       |  typedef RhsScalar_ RhsScalar;
  229|       |
  230|       | protected:
  231|       |  LhsScalar* m_blockA;
  232|       |  RhsScalar* m_blockB;
  233|       |
  234|       |  Index m_mc;
  235|       |  Index m_nc;
  236|       |  Index m_kc;
  237|       |
  238|       | public:
  239|      2|  level3_blocking() : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0) {}
  240|       |
  241|      2|  inline Index mc() const { return m_mc; }
  242|      2|  inline Index nc() const { return m_nc; }
  243|      2|  inline Index kc() const { return m_kc; }
  244|       |
  245|      4|  inline LhsScalar* blockA() { return m_blockA; }
  246|      4|  inline RhsScalar* blockB() { return m_blockB; }
  247|       |};
  248|       |
  249|       |template <int StorageOrder, typename LhsScalar_, typename RhsScalar_, int MaxRows, int MaxCols, int MaxDepth,
  250|       |          int KcFactor>
  251|       |class gemm_blocking_space<StorageOrder, LhsScalar_, RhsScalar_, MaxRows, MaxCols, MaxDepth, KcFactor,
  252|       |                          true /* == FiniteAtCompileTime */>
  253|       |    : public level3_blocking<std::conditional_t<StorageOrder == RowMajor, RhsScalar_, LhsScalar_>,
  254|       |                             std::conditional_t<StorageOrder == RowMajor, LhsScalar_, RhsScalar_>> {
  255|       |  enum {
  256|       |    Transpose = StorageOrder == RowMajor,
  257|       |    ActualRows = Transpose ? MaxCols : MaxRows,
  258|       |    ActualCols = Transpose ? MaxRows : MaxCols
  259|       |  };
  260|       |  typedef std::conditional_t<Transpose, RhsScalar_, LhsScalar_> LhsScalar;
  261|       |  typedef std::conditional_t<Transpose, LhsScalar_, RhsScalar_> RhsScalar;
  262|       |  enum { SizeA = ActualRows * MaxDepth, SizeB = ActualCols * MaxDepth };
  263|       |
  264|       |#if EIGEN_MAX_STATIC_ALIGN_BYTES >= EIGEN_DEFAULT_ALIGN_BYTES
  265|       |  EIGEN_ALIGN_MAX LhsScalar m_staticA[SizeA];
  266|       |  EIGEN_ALIGN_MAX RhsScalar m_staticB[SizeB];
  267|       |#else
  268|       |  EIGEN_ALIGN_MAX char m_staticA[SizeA * sizeof(LhsScalar) + EIGEN_DEFAULT_ALIGN_BYTES - 1];
  269|       |  EIGEN_ALIGN_MAX char m_staticB[SizeB * sizeof(RhsScalar) + EIGEN_DEFAULT_ALIGN_BYTES - 1];
  270|       |#endif
  271|       |
  272|       | public:
  273|       |  gemm_blocking_space(Index /*rows*/, Index /*cols*/, Index /*depth*/, Index /*num_threads*/,
  274|       |                      bool /*full_rows = false*/) {
  275|       |    this->m_mc = ActualRows;
  276|       |    this->m_nc = ActualCols;
  277|       |    this->m_kc = MaxDepth;
  278|       |#if EIGEN_MAX_STATIC_ALIGN_BYTES >= EIGEN_DEFAULT_ALIGN_BYTES
  279|       |    this->m_blockA = m_staticA;
  280|       |    this->m_blockB = m_staticB;
  281|       |#else
  282|       |    this->m_blockA = reinterpret_cast<LhsScalar*>((std::uintptr_t(m_staticA) + (EIGEN_DEFAULT_ALIGN_BYTES - 1)) &
  283|       |                                                  ~std::size_t(EIGEN_DEFAULT_ALIGN_BYTES - 1));
  284|       |    this->m_blockB = reinterpret_cast<RhsScalar*>((std::uintptr_t(m_staticB) + (EIGEN_DEFAULT_ALIGN_BYTES - 1)) &
  285|       |                                                  ~std::size_t(EIGEN_DEFAULT_ALIGN_BYTES - 1));
  286|       |#endif
  287|       |  }
  288|       |
  289|       |  void initParallel(Index, Index, Index, Index) {}
  290|       |
  291|       |  inline void allocateA() {}
  292|       |  inline void allocateB() {}
  293|       |  inline void allocateAll() {}
  294|       |};
  295|       |
  296|       |template <int StorageOrder, typename LhsScalar_, typename RhsScalar_, int MaxRows, int MaxCols, int MaxDepth,
  297|       |          int KcFactor>
  298|       |class gemm_blocking_space<StorageOrder, LhsScalar_, RhsScalar_, MaxRows, MaxCols, MaxDepth, KcFactor, false>
  299|       |    : public level3_blocking<std::conditional_t<StorageOrder == RowMajor, RhsScalar_, LhsScalar_>,
  300|       |                             std::conditional_t<StorageOrder == RowMajor, LhsScalar_, RhsScalar_>> {
  301|       |  enum { Transpose = StorageOrder == RowMajor };
  302|       |  typedef std::conditional_t<Transpose, RhsScalar_, LhsScalar_> LhsScalar;
  303|       |  typedef std::conditional_t<Transpose, LhsScalar_, RhsScalar_> RhsScalar;
  304|       |
  305|       |  Index m_sizeA;
  306|       |  Index m_sizeB;
  307|       |
  308|       | public:
  309|      2|  gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking) {
  310|      2|    this->m_mc = Transpose ? cols : rows;
  311|      2|    this->m_nc = Transpose ? rows : cols;
  312|      2|    this->m_kc = depth;
  313|       |
  314|      2|    if (l3_blocking) {
  315|      2|      computeProductBlockingSizes<LhsScalar, RhsScalar, KcFactor>(this->m_kc, this->m_mc, this->m_nc, num_threads);
  316|      2|    } else  // no l3 blocking
  317|      0|    {
  318|      0|      Index n = this->m_nc;
  319|      0|      computeProductBlockingSizes<LhsScalar, RhsScalar, KcFactor>(this->m_kc, this->m_mc, n, num_threads);
  320|      0|    }
  321|       |
  322|      2|    m_sizeA = this->m_mc * this->m_kc;
  323|      2|    m_sizeB = this->m_kc * this->m_nc;
  324|      2|  }
  325|       |
  326|       |  void initParallel(Index rows, Index cols, Index depth, Index num_threads) {
  327|       |    this->m_mc = Transpose ? cols : rows;
  328|       |    this->m_nc = Transpose ? rows : cols;
  329|       |    this->m_kc = depth;
  330|       |
  331|       |    eigen_internal_assert(this->m_blockA == 0 && this->m_blockB == 0);
  332|       |    Index m = this->m_mc;
  333|       |    computeProductBlockingSizes<LhsScalar, RhsScalar, KcFactor>(this->m_kc, m, this->m_nc, num_threads);
  334|       |    m_sizeA = this->m_mc * this->m_kc;
  335|       |    m_sizeB = this->m_kc * this->m_nc;
  336|       |  }
  337|       |
  338|       |  void allocateA() {
  339|       |    if (this->m_blockA == 0) this->m_blockA = aligned_new<LhsScalar>(m_sizeA);
  340|       |  }
  341|       |
  342|       |  void allocateB() {
  343|       |    if (this->m_blockB == 0) this->m_blockB = aligned_new<RhsScalar>(m_sizeB);
  344|       |  }
  345|       |
  346|       |  void allocateAll() {
  347|       |    allocateA();
  348|       |    allocateB();
  349|       |  }
  350|       |
  351|      2|  ~gemm_blocking_space() {
  352|      2|    aligned_delete(this->m_blockA, m_sizeA);
  353|      2|    aligned_delete(this->m_blockB, m_sizeB);
  354|      2|  }
  355|       |};
  356|       |
  357|       |}  // end namespace internal
  358|       |
  359|       |namespace internal {
  360|       |
  361|       |template <typename Lhs, typename Rhs>
  362|       |struct generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, GemmProduct>
  363|       |    : generic_product_impl_base<Lhs, Rhs, generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, GemmProduct>> {
  364|       |  typedef typename Product<Lhs, Rhs>::Scalar Scalar;
  365|       |  typedef typename Lhs::Scalar LhsScalar;
  366|       |  typedef typename Rhs::Scalar RhsScalar;
  367|       |
  368|       |  typedef internal::blas_traits<Lhs> LhsBlasTraits;
  369|       |  typedef typename LhsBlasTraits::DirectLinearAccessType ActualLhsType;
  370|       |  typedef internal::remove_all_t<ActualLhsType> ActualLhsTypeCleaned;
  371|       |
  372|       |  typedef internal::blas_traits<Rhs> RhsBlasTraits;
  373|       |  typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
  374|       |  typedef internal::remove_all_t<ActualRhsType> ActualRhsTypeCleaned;
  375|       |
  376|       |  enum { MaxDepthAtCompileTime = min_size_prefer_fixed(Lhs::MaxColsAtCompileTime, Rhs::MaxRowsAtCompileTime) };
  377|       |
  378|       |  typedef generic_product_impl<Lhs, Rhs, DenseShape, DenseShape, CoeffBasedProductMode> lazyproduct;
  379|       |
  380|       |  template <typename Dst>
  381|      3|  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  382|       |    // See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=404 for a discussion and helper program
  383|       |    // to determine the following heuristic.
  384|       |    // EIGEN_GEMM_TO_COEFFBASED_THRESHOLD is typically defined to 20 in GeneralProduct.h,
  385|       |    // unless it has been specialized by the user or for a given architecture.
  386|       |    // Note that the condition rhs.rows()>0 was required because lazy product is (was?) not happy with empty inputs.
  387|       |    // I'm not sure it is still required.
  388|      3|    if ((rhs.rows() + dst.rows() + dst.cols()) < EIGEN_GEMM_TO_COEFFBASED_THRESHOLD && rhs.rows() > 0)
  389|      0|      lazyproduct::eval_dynamic(dst, lhs, rhs, internal::assign_op<typename Dst::Scalar, Scalar>());
  390|      3|    else {
  391|      3|      dst.setZero();
  392|      3|      scaleAndAddTo(dst, lhs, rhs, Scalar(1));
  393|      3|    }
  394|      3|  }
  ------------------
  | _ZN5Eigen8internal20generic_product_implINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_NS_10DenseShapeES5_Li8EE6evalToIS4_EEvRT_RKS4_SB_:
  |  381|      2|  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  |  382|       |    // See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=404 for a discussion and helper program
  |  383|       |    // to determine the following heuristic.
  |  384|       |    // EIGEN_GEMM_TO_COEFFBASED_THRESHOLD is typically defined to 20 in GeneralProduct.h,
  |  385|       |    // unless it has been specialized by the user or for a given architecture.
  |  386|       |    // Note that the condition rhs.rows()>0 was required because lazy product is (was?) not happy with empty inputs.
  |  387|       |    // I'm not sure it is still required.
  |  388|      2|    if ((rhs.rows() + dst.rows() + dst.cols()) < EIGEN_GEMM_TO_COEFFBASED_THRESHOLD && rhs.rows() > 0)
  |  389|      0|      lazyproduct::eval_dynamic(dst, lhs, rhs, internal::assign_op<typename Dst::Scalar, Scalar>());
  |  390|      2|    else {
  |  391|      2|      dst.setZero();
  |  392|      2|      scaleAndAddTo(dst, lhs, rhs, Scalar(1));
  |  393|      2|    }
  |  394|      2|  }
  ------------------
  | _ZN5Eigen8internal20generic_product_implINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_NS_10DenseShapeES7_Li8EE6evalToIS5_EEvRT_RKS6_RKS5_:
  |  381|      1|  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  |  382|       |    // See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=404 for a discussion and helper program
  |  383|       |    // to determine the following heuristic.
  |  384|       |    // EIGEN_GEMM_TO_COEFFBASED_THRESHOLD is typically defined to 20 in GeneralProduct.h,
  |  385|       |    // unless it has been specialized by the user or for a given architecture.
  |  386|       |    // Note that the condition rhs.rows()>0 was required because lazy product is (was?) not happy with empty inputs.
  |  387|       |    // I'm not sure it is still required.
  |  388|      1|    if ((rhs.rows() + dst.rows() + dst.cols()) < EIGEN_GEMM_TO_COEFFBASED_THRESHOLD && rhs.rows() > 0)
  |  389|      0|      lazyproduct::eval_dynamic(dst, lhs, rhs, internal::assign_op<typename Dst::Scalar, Scalar>());
  |  390|      1|    else {
  |  391|      1|      dst.setZero();
  |  392|      1|      scaleAndAddTo(dst, lhs, rhs, Scalar(1));
  |  393|      1|    }
  |  394|      1|  }
  ------------------
  395|       |
  396|       |  template <typename Dst>
  397|       |  static void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  398|       |    if ((rhs.rows() + dst.rows() + dst.cols()) < EIGEN_GEMM_TO_COEFFBASED_THRESHOLD && rhs.rows() > 0)
  399|       |      lazyproduct::eval_dynamic(dst, lhs, rhs, internal::add_assign_op<typename Dst::Scalar, Scalar>());
  400|       |    else
  401|       |      scaleAndAddTo(dst, lhs, rhs, Scalar(1));
  402|       |  }
  403|       |
  404|       |  template <typename Dst>
  405|       |  static void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs) {
  406|       |    if ((rhs.rows() + dst.rows() + dst.cols()) < EIGEN_GEMM_TO_COEFFBASED_THRESHOLD && rhs.rows() > 0)
  407|       |      lazyproduct::eval_dynamic(dst, lhs, rhs, internal::sub_assign_op<typename Dst::Scalar, Scalar>());
  408|       |    else
  409|       |      scaleAndAddTo(dst, lhs, rhs, Scalar(-1));
  410|       |  }
  411|       |
  412|       |  template <typename Dest>
  413|      3|  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha) {
  414|      3|    eigen_assert(dst.rows() == a_lhs.rows() && dst.cols() == a_rhs.cols());
  415|      3|    if (a_lhs.cols() == 0 || a_lhs.rows() == 0 || a_rhs.cols() == 0) return;
  416|       |
  417|      3|    if (dst.cols() == 1) {
  418|       |      // Fallback to GEMV if either the lhs or rhs is a runtime vector
  419|      0|      typename Dest::ColXpr dst_vec(dst.col(0));
  420|      0|      return internal::generic_product_impl<Lhs, typename Rhs::ConstColXpr, DenseShape, DenseShape,
  421|      0|                                            GemvProduct>::scaleAndAddTo(dst_vec, a_lhs, a_rhs.col(0), alpha);
  422|      3|    } else if (dst.rows() == 1) {
  423|       |      // Fallback to GEMV if either the lhs or rhs is a runtime vector
  424|      0|      typename Dest::RowXpr dst_vec(dst.row(0));
  425|      0|      return internal::generic_product_impl<typename Lhs::ConstRowXpr, Rhs, DenseShape, DenseShape,
  426|      0|                                            GemvProduct>::scaleAndAddTo(dst_vec, a_lhs.row(0), a_rhs, alpha);
  427|      0|    }
  428|       |
  429|      3|    add_const_on_value_type_t<ActualLhsType> lhs = LhsBlasTraits::extract(a_lhs);
  430|      3|    add_const_on_value_type_t<ActualRhsType> rhs = RhsBlasTraits::extract(a_rhs);
  431|       |
  432|      3|    Scalar actualAlpha = combine_scalar_factors(alpha, a_lhs, a_rhs);
  433|       |
  434|      3|    typedef internal::gemm_blocking_space<(Dest::Flags & RowMajorBit) ? RowMajor : ColMajor, LhsScalar, RhsScalar,
  435|      3|                                          Dest::MaxRowsAtCompileTime, Dest::MaxColsAtCompileTime, MaxDepthAtCompileTime>
  436|      3|        BlockingType;
  437|       |
  438|      3|    typedef internal::gemm_functor<
  439|      3|        Scalar, Index,
  440|      3|        internal::general_matrix_matrix_product<
  441|      3|            Index, LhsScalar, (ActualLhsTypeCleaned::Flags & RowMajorBit) ? RowMajor : ColMajor,
  442|      3|            bool(LhsBlasTraits::NeedToConjugate), RhsScalar,
  443|      3|            (ActualRhsTypeCleaned::Flags & RowMajorBit) ? RowMajor : ColMajor, bool(RhsBlasTraits::NeedToConjugate),
  444|      3|            (Dest::Flags & RowMajorBit) ? RowMajor : ColMajor, Dest::InnerStrideAtCompileTime>,
  445|      3|        ActualLhsTypeCleaned, ActualRhsTypeCleaned, Dest, BlockingType>
  446|      3|        GemmFunctor;
  447|       |
  448|      3|    BlockingType blocking(dst.rows(), dst.cols(), lhs.cols(), 1, true);
  449|      3|    internal::parallelize_gemm<(Dest::MaxRowsAtCompileTime > 32 || Dest::MaxRowsAtCompileTime == Dynamic)>(
  450|      3|        GemmFunctor(lhs, rhs, dst, actualAlpha, blocking), a_lhs.rows(), a_rhs.cols(), a_lhs.cols(),
  451|      3|        Dest::Flags & RowMajorBit);
  452|      3|  }
  ------------------
  | _ZN5Eigen8internal20generic_product_implINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_NS_10DenseShapeES5_Li8EE13scaleAndAddToIS4_EEvRT_RKS4_SB_RKS3_:
  |  413|      2|  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha) {
  |  414|      2|    eigen_assert(dst.rows() == a_lhs.rows() && dst.cols() == a_rhs.cols());
  |  415|      2|    if (a_lhs.cols() == 0 || a_lhs.rows() == 0 || a_rhs.cols() == 0) return;
  |  416|       |
  |  417|      2|    if (dst.cols() == 1) {
  |  418|       |      // Fallback to GEMV if either the lhs or rhs is a runtime vector
  |  419|      0|      typename Dest::ColXpr dst_vec(dst.col(0));
  |  420|      0|      return internal::generic_product_impl<Lhs, typename Rhs::ConstColXpr, DenseShape, DenseShape,
  |  421|      0|                                            GemvProduct>::scaleAndAddTo(dst_vec, a_lhs, a_rhs.col(0), alpha);
  |  422|      2|    } else if (dst.rows() == 1) {
  |  423|       |      // Fallback to GEMV if either the lhs or rhs is a runtime vector
  |  424|      0|      typename Dest::RowXpr dst_vec(dst.row(0));
  |  425|      0|      return internal::generic_product_impl<typename Lhs::ConstRowXpr, Rhs, DenseShape, DenseShape,
  |  426|      0|                                            GemvProduct>::scaleAndAddTo(dst_vec, a_lhs.row(0), a_rhs, alpha);
  |  427|      0|    }
  |  428|       |
  |  429|      2|    add_const_on_value_type_t<ActualLhsType> lhs = LhsBlasTraits::extract(a_lhs);
  |  430|      2|    add_const_on_value_type_t<ActualRhsType> rhs = RhsBlasTraits::extract(a_rhs);
  |  431|       |
  |  432|      2|    Scalar actualAlpha = combine_scalar_factors(alpha, a_lhs, a_rhs);
  |  433|       |
  |  434|      2|    typedef internal::gemm_blocking_space<(Dest::Flags & RowMajorBit) ? RowMajor : ColMajor, LhsScalar, RhsScalar,
  |  435|      2|                                          Dest::MaxRowsAtCompileTime, Dest::MaxColsAtCompileTime, MaxDepthAtCompileTime>
  |  436|      2|        BlockingType;
  |  437|       |
  |  438|      2|    typedef internal::gemm_functor<
  |  439|      2|        Scalar, Index,
  |  440|      2|        internal::general_matrix_matrix_product<
  |  441|      2|            Index, LhsScalar, (ActualLhsTypeCleaned::Flags & RowMajorBit) ? RowMajor : ColMajor,
  |  442|      2|            bool(LhsBlasTraits::NeedToConjugate), RhsScalar,
  |  443|      2|            (ActualRhsTypeCleaned::Flags & RowMajorBit) ? RowMajor : ColMajor, bool(RhsBlasTraits::NeedToConjugate),
  |  444|      2|            (Dest::Flags & RowMajorBit) ? RowMajor : ColMajor, Dest::InnerStrideAtCompileTime>,
  |  445|      2|        ActualLhsTypeCleaned, ActualRhsTypeCleaned, Dest, BlockingType>
  |  446|      2|        GemmFunctor;
  |  447|       |
  |  448|      2|    BlockingType blocking(dst.rows(), dst.cols(), lhs.cols(), 1, true);
  |  449|      2|    internal::parallelize_gemm<(Dest::MaxRowsAtCompileTime > 32 || Dest::MaxRowsAtCompileTime == Dynamic)>(
  |  450|      2|        GemmFunctor(lhs, rhs, dst, actualAlpha, blocking), a_lhs.rows(), a_rhs.cols(), a_lhs.cols(),
  |  451|      2|        Dest::Flags & RowMajorBit);
  |  452|      2|  }
  ------------------
  | _ZN5Eigen8internal20generic_product_implINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_NS_10DenseShapeES7_Li8EE13scaleAndAddToIS5_EEvRT_RKS6_RKS5_RKS4_:
  |  413|      1|  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha) {
  |  414|      1|    eigen_assert(dst.rows() == a_lhs.rows() && dst.cols() == a_rhs.cols());
  |  415|      1|    if (a_lhs.cols() == 0 || a_lhs.rows() == 0 || a_rhs.cols() == 0) return;
  |  416|       |
  |  417|      1|    if (dst.cols() == 1) {
  |  418|       |      // Fallback to GEMV if either the lhs or rhs is a runtime vector
  |  419|      0|      typename Dest::ColXpr dst_vec(dst.col(0));
  |  420|      0|      return internal::generic_product_impl<Lhs, typename Rhs::ConstColXpr, DenseShape, DenseShape,
  |  421|      0|                                            GemvProduct>::scaleAndAddTo(dst_vec, a_lhs, a_rhs.col(0), alpha);
  |  422|      1|    } else if (dst.rows() == 1) {
  |  423|       |      // Fallback to GEMV if either the lhs or rhs is a runtime vector
  |  424|      0|      typename Dest::RowXpr dst_vec(dst.row(0));
  |  425|      0|      return internal::generic_product_impl<typename Lhs::ConstRowXpr, Rhs, DenseShape, DenseShape,
  |  426|      0|                                            GemvProduct>::scaleAndAddTo(dst_vec, a_lhs.row(0), a_rhs, alpha);
  |  427|      0|    }
  |  428|       |
  |  429|      1|    add_const_on_value_type_t<ActualLhsType> lhs = LhsBlasTraits::extract(a_lhs);
  |  430|      1|    add_const_on_value_type_t<ActualRhsType> rhs = RhsBlasTraits::extract(a_rhs);
  |  431|       |
  |  432|      1|    Scalar actualAlpha = combine_scalar_factors(alpha, a_lhs, a_rhs);
  |  433|       |
  |  434|      1|    typedef internal::gemm_blocking_space<(Dest::Flags & RowMajorBit) ? RowMajor : ColMajor, LhsScalar, RhsScalar,
  |  435|      1|                                          Dest::MaxRowsAtCompileTime, Dest::MaxColsAtCompileTime, MaxDepthAtCompileTime>
  |  436|      1|        BlockingType;
  |  437|       |
  |  438|      1|    typedef internal::gemm_functor<
  |  439|      1|        Scalar, Index,
  |  440|      1|        internal::general_matrix_matrix_product<
  |  441|      1|            Index, LhsScalar, (ActualLhsTypeCleaned::Flags & RowMajorBit) ? RowMajor : ColMajor,
  |  442|      1|            bool(LhsBlasTraits::NeedToConjugate), RhsScalar,
  |  443|      1|            (ActualRhsTypeCleaned::Flags & RowMajorBit) ? RowMajor : ColMajor, bool(RhsBlasTraits::NeedToConjugate),
  |  444|      1|            (Dest::Flags & RowMajorBit) ? RowMajor : ColMajor, Dest::InnerStrideAtCompileTime>,
  |  445|      1|        ActualLhsTypeCleaned, ActualRhsTypeCleaned, Dest, BlockingType>
  |  446|      1|        GemmFunctor;
  |  447|       |
  |  448|      1|    BlockingType blocking(dst.rows(), dst.cols(), lhs.cols(), 1, true);
  |  449|      1|    internal::parallelize_gemm<(Dest::MaxRowsAtCompileTime > 32 || Dest::MaxRowsAtCompileTime == Dynamic)>(
  |  450|      1|        GemmFunctor(lhs, rhs, dst, actualAlpha, blocking), a_lhs.rows(), a_rhs.cols(), a_lhs.cols(),
  |  451|      1|        Dest::Flags & RowMajorBit);
  |  452|      1|  }
  ------------------
  453|       |};
  454|       |
  455|       |}  // end namespace internal
  456|       |
  457|       |}  // end namespace Eigen
  458|       |
  459|       |#endif  // EIGEN_GENERAL_MATRIX_MATRIX_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/products/GeneralMatrixVector.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2016 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_GENERAL_MATRIX_VECTOR_H
   11|       |#define EIGEN_GENERAL_MATRIX_VECTOR_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |enum GEMVPacketSizeType { GEMVPacketFull = 0, GEMVPacketHalf, GEMVPacketQuarter };
   21|       |
   22|       |template <int N, typename T1, typename T2, typename T3>
   23|       |struct gemv_packet_cond {
   24|       |  typedef T3 type;
   25|       |};
   26|       |
   27|       |template <typename T1, typename T2, typename T3>
   28|       |struct gemv_packet_cond<GEMVPacketFull, T1, T2, T3> {
   29|       |  typedef T1 type;
   30|       |};
   31|       |
   32|       |template <typename T1, typename T2, typename T3>
   33|       |struct gemv_packet_cond<GEMVPacketHalf, T1, T2, T3> {
   34|       |  typedef T2 type;
   35|       |};
   36|       |
   37|       |template <typename LhsScalar, typename RhsScalar, int PacketSize_ = GEMVPacketFull>
   38|       |class gemv_traits {
   39|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
   40|       |
   41|       |#define PACKET_DECL_COND_POSTFIX(postfix, name, packet_size)                                               \
   42|       |  typedef typename gemv_packet_cond<                                                                       \
   43|       |      packet_size, typename packet_traits<name##Scalar>::type, typename packet_traits<name##Scalar>::half, \
   44|       |      typename unpacket_traits<typename packet_traits<name##Scalar>::half>::half>::type name##Packet##postfix
   45|       |
   46|       |  PACKET_DECL_COND_POSTFIX(_, Lhs, PacketSize_);
   47|       |  PACKET_DECL_COND_POSTFIX(_, Rhs, PacketSize_);
   48|       |  PACKET_DECL_COND_POSTFIX(_, Res, PacketSize_);
   49|       |#undef PACKET_DECL_COND_POSTFIX
   50|       |
   51|       | public:
   52|       |  enum {
   53|       |    Vectorizable = unpacket_traits<LhsPacket_>::vectorizable && unpacket_traits<RhsPacket_>::vectorizable &&
   54|       |                   int(unpacket_traits<LhsPacket_>::size) == int(unpacket_traits<RhsPacket_>::size),
   55|       |    LhsPacketSize = Vectorizable ? unpacket_traits<LhsPacket_>::size : 1,
   56|       |    RhsPacketSize = Vectorizable ? unpacket_traits<RhsPacket_>::size : 1,
   57|       |    ResPacketSize = Vectorizable ? unpacket_traits<ResPacket_>::size : 1
   58|       |  };
   59|       |
   60|       |  typedef std::conditional_t<Vectorizable, LhsPacket_, LhsScalar> LhsPacket;
   61|       |  typedef std::conditional_t<Vectorizable, RhsPacket_, RhsScalar> RhsPacket;
   62|       |  typedef std::conditional_t<Vectorizable, ResPacket_, ResScalar> ResPacket;
   63|       |};
   64|       |
   65|       |/* Optimized col-major matrix * vector product:
   66|       | * This algorithm processes the matrix per vertical panels,
   67|       | * which are then processed horizontally per chunk of 8*PacketSize x 1 vertical segments.
   68|       | *
   69|       | * Mixing type logic: C += alpha * A * B
   70|       | *  |  A  |  B  |alpha| comments
   71|       | *  |real |cplx |cplx | no vectorization
   72|       | *  |real |cplx |real | alpha is converted to a cplx when calling the run function, no vectorization
   73|       | *  |cplx |real |cplx | invalid, the caller has to do tmp: = A * B; C += alpha*tmp
   74|       | *  |cplx |real |real | optimal case, vectorization possible via real-cplx mul
   75|       | *
   76|       | * The same reasoning apply for the transposed case.
   77|       | */
   78|       |template <typename Index, typename LhsScalar, typename LhsMapper, bool ConjugateLhs, typename RhsScalar,
   79|       |          typename RhsMapper, bool ConjugateRhs, int Version>
   80|       |struct general_matrix_vector_product<Index, LhsScalar, LhsMapper, ColMajor, ConjugateLhs, RhsScalar, RhsMapper,
   81|       |                                     ConjugateRhs, Version> {
   82|       |  typedef gemv_traits<LhsScalar, RhsScalar> Traits;
   83|       |  typedef gemv_traits<LhsScalar, RhsScalar, GEMVPacketHalf> HalfTraits;
   84|       |  typedef gemv_traits<LhsScalar, RhsScalar, GEMVPacketQuarter> QuarterTraits;
   85|       |
   86|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
   87|       |
   88|       |  typedef typename Traits::LhsPacket LhsPacket;
   89|       |  typedef typename Traits::RhsPacket RhsPacket;
   90|       |  typedef typename Traits::ResPacket ResPacket;
   91|       |
   92|       |  typedef typename HalfTraits::LhsPacket LhsPacketHalf;
   93|       |  typedef typename HalfTraits::RhsPacket RhsPacketHalf;
   94|       |  typedef typename HalfTraits::ResPacket ResPacketHalf;
   95|       |
   96|       |  typedef typename QuarterTraits::LhsPacket LhsPacketQuarter;
   97|       |  typedef typename QuarterTraits::RhsPacket RhsPacketQuarter;
   98|       |  typedef typename QuarterTraits::ResPacket ResPacketQuarter;
   99|       |
  100|       |  EIGEN_DEVICE_FUNC EIGEN_DONT_INLINE static void run(Index rows, Index cols, const LhsMapper& lhs,
  101|       |                                                      const RhsMapper& rhs, ResScalar* res, Index resIncr,
  102|       |                                                      RhsScalar alpha);
  103|       |};
  104|       |
  105|       |template <typename Index, typename LhsScalar, typename LhsMapper, bool ConjugateLhs, typename RhsScalar,
  106|       |          typename RhsMapper, bool ConjugateRhs, int Version>
  107|       |EIGEN_DEVICE_FUNC EIGEN_DONT_INLINE void
  108|       |general_matrix_vector_product<Index, LhsScalar, LhsMapper, ColMajor, ConjugateLhs, RhsScalar, RhsMapper, ConjugateRhs,
  109|       |                              Version>::run(Index rows, Index cols, const LhsMapper& alhs, const RhsMapper& rhs,
  110|      0|                                            ResScalar* res, Index resIncr, RhsScalar alpha) {
  111|      0|  EIGEN_UNUSED_VARIABLE(resIncr);
  112|      0|  eigen_internal_assert(resIncr == 1);
  113|       |
  114|       |  // The following copy tells the compiler that lhs's attributes are not modified outside this function
  115|       |  // This helps GCC to generate proper code.
  116|      0|  LhsMapper lhs(alhs);
  117|       |
  118|      0|  conj_helper<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs> cj;
  119|      0|  conj_helper<LhsPacket, RhsPacket, ConjugateLhs, ConjugateRhs> pcj;
  120|      0|  conj_helper<LhsPacketHalf, RhsPacketHalf, ConjugateLhs, ConjugateRhs> pcj_half;
  121|      0|  conj_helper<LhsPacketQuarter, RhsPacketQuarter, ConjugateLhs, ConjugateRhs> pcj_quarter;
  122|       |
  123|      0|  const Index lhsStride = lhs.stride();
  124|       |  // TODO: for padded aligned inputs, we could enable aligned reads
  125|      0|  enum {
  126|      0|    LhsAlignment = Unaligned,
  127|      0|    ResPacketSize = Traits::ResPacketSize,
  128|      0|    ResPacketSizeHalf = HalfTraits::ResPacketSize,
  129|      0|    ResPacketSizeQuarter = QuarterTraits::ResPacketSize,
  130|      0|    LhsPacketSize = Traits::LhsPacketSize,
  131|      0|    HasHalf = (int)ResPacketSizeHalf < (int)ResPacketSize,
  132|      0|    HasQuarter = (int)ResPacketSizeQuarter < (int)ResPacketSizeHalf
  133|      0|  };
  134|       |
  135|      0|  const Index n8 = rows - 8 * ResPacketSize + 1;
  136|      0|  const Index n4 = rows - 4 * ResPacketSize + 1;
  137|      0|  const Index n3 = rows - 3 * ResPacketSize + 1;
  138|      0|  const Index n2 = rows - 2 * ResPacketSize + 1;
  139|      0|  const Index n1 = rows - 1 * ResPacketSize + 1;
  140|      0|  const Index n_half = rows - 1 * ResPacketSizeHalf + 1;
  141|      0|  const Index n_quarter = rows - 1 * ResPacketSizeQuarter + 1;
  142|       |
  143|       |  // TODO: improve the following heuristic:
  144|      0|  const Index block_cols = cols < 128 ? cols : (lhsStride * sizeof(LhsScalar) < 32000 ? 16 : 4);
  145|      0|  ResPacket palpha = pset1<ResPacket>(alpha);
  146|      0|  ResPacketHalf palpha_half = pset1<ResPacketHalf>(alpha);
  147|      0|  ResPacketQuarter palpha_quarter = pset1<ResPacketQuarter>(alpha);
  148|       |
  149|      0|  for (Index j2 = 0; j2 < cols; j2 += block_cols) {
  150|      0|    Index jend = numext::mini(j2 + block_cols, cols);
  151|      0|    Index i = 0;
  152|      0|    for (; i < n8; i += ResPacketSize * 8) {
  153|      0|      ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
  154|      0|                c2 = pset1<ResPacket>(ResScalar(0)), c3 = pset1<ResPacket>(ResScalar(0)),
  155|      0|                c4 = pset1<ResPacket>(ResScalar(0)), c5 = pset1<ResPacket>(ResScalar(0)),
  156|      0|                c6 = pset1<ResPacket>(ResScalar(0)), c7 = pset1<ResPacket>(ResScalar(0));
  157|       |
  158|      0|      for (Index j = j2; j < jend; j += 1) {
  159|      0|        RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
  160|      0|        c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 0, j), b0, c0);
  161|      0|        c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 1, j), b0, c1);
  162|      0|        c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 2, j), b0, c2);
  163|      0|        c3 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 3, j), b0, c3);
  164|      0|        c4 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 4, j), b0, c4);
  165|      0|        c5 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 5, j), b0, c5);
  166|      0|        c6 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 6, j), b0, c6);
  167|      0|        c7 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 7, j), b0, c7);
  168|      0|      }
  169|      0|      pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
  170|      0|      pstoreu(res + i + ResPacketSize * 1, pmadd(c1, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 1)));
  171|      0|      pstoreu(res + i + ResPacketSize * 2, pmadd(c2, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 2)));
  172|      0|      pstoreu(res + i + ResPacketSize * 3, pmadd(c3, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 3)));
  173|      0|      pstoreu(res + i + ResPacketSize * 4, pmadd(c4, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 4)));
  174|      0|      pstoreu(res + i + ResPacketSize * 5, pmadd(c5, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 5)));
  175|      0|      pstoreu(res + i + ResPacketSize * 6, pmadd(c6, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 6)));
  176|      0|      pstoreu(res + i + ResPacketSize * 7, pmadd(c7, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 7)));
  177|      0|    }
  178|      0|    if (i < n4) {
  179|      0|      ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
  180|      0|                c2 = pset1<ResPacket>(ResScalar(0)), c3 = pset1<ResPacket>(ResScalar(0));
  181|       |
  182|      0|      for (Index j = j2; j < jend; j += 1) {
  183|      0|        RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
  184|      0|        c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 0, j), b0, c0);
  185|      0|        c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 1, j), b0, c1);
  186|      0|        c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 2, j), b0, c2);
  187|      0|        c3 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 3, j), b0, c3);
  188|      0|      }
  189|      0|      pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
  190|      0|      pstoreu(res + i + ResPacketSize * 1, pmadd(c1, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 1)));
  191|      0|      pstoreu(res + i + ResPacketSize * 2, pmadd(c2, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 2)));
  192|      0|      pstoreu(res + i + ResPacketSize * 3, pmadd(c3, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 3)));
  193|       |
  194|      0|      i += ResPacketSize * 4;
  195|      0|    }
  196|      0|    if (i < n3) {
  197|      0|      ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
  198|      0|                c2 = pset1<ResPacket>(ResScalar(0));
  199|       |
  200|      0|      for (Index j = j2; j < jend; j += 1) {
  201|      0|        RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
  202|      0|        c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 0, j), b0, c0);
  203|      0|        c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 1, j), b0, c1);
  204|      0|        c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 2, j), b0, c2);
  205|      0|      }
  206|      0|      pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
  207|      0|      pstoreu(res + i + ResPacketSize * 1, pmadd(c1, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 1)));
  208|      0|      pstoreu(res + i + ResPacketSize * 2, pmadd(c2, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 2)));
  209|       |
  210|      0|      i += ResPacketSize * 3;
  211|      0|    }
  212|      0|    if (i < n2) {
  213|      0|      ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0));
  214|       |
  215|      0|      for (Index j = j2; j < jend; j += 1) {
  216|      0|        RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
  217|      0|        c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 0, j), b0, c0);
  218|      0|        c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 1, j), b0, c1);
  219|      0|      }
  220|      0|      pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
  221|      0|      pstoreu(res + i + ResPacketSize * 1, pmadd(c1, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 1)));
  222|      0|      i += ResPacketSize * 2;
  223|      0|    }
  224|      0|    if (i < n1) {
  225|      0|      ResPacket c0 = pset1<ResPacket>(ResScalar(0));
  226|      0|      for (Index j = j2; j < jend; j += 1) {
  227|      0|        RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
  228|      0|        c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 0, j), b0, c0);
  229|      0|      }
  230|      0|      pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
  231|      0|      i += ResPacketSize;
  232|      0|    }
  233|      0|    if (HasHalf && i < n_half) {
  234|      0|      ResPacketHalf c0 = pset1<ResPacketHalf>(ResScalar(0));
  235|      0|      for (Index j = j2; j < jend; j += 1) {
  236|      0|        RhsPacketHalf b0 = pset1<RhsPacketHalf>(rhs(j, 0));
  237|      0|        c0 = pcj_half.pmadd(lhs.template load<LhsPacketHalf, LhsAlignment>(i + 0, j), b0, c0);
  238|      0|      }
  239|      0|      pstoreu(res + i + ResPacketSizeHalf * 0,
  240|      0|              pmadd(c0, palpha_half, ploadu<ResPacketHalf>(res + i + ResPacketSizeHalf * 0)));
  241|      0|      i += ResPacketSizeHalf;
  242|      0|    }
  243|      0|    if (HasQuarter && i < n_quarter) {
  244|      0|      ResPacketQuarter c0 = pset1<ResPacketQuarter>(ResScalar(0));
  245|      0|      for (Index j = j2; j < jend; j += 1) {
  246|      0|        RhsPacketQuarter b0 = pset1<RhsPacketQuarter>(rhs(j, 0));
  247|      0|        c0 = pcj_quarter.pmadd(lhs.template load<LhsPacketQuarter, LhsAlignment>(i + 0, j), b0, c0);
  248|      0|      }
  249|      0|      pstoreu(res + i + ResPacketSizeQuarter * 0,
  250|      0|              pmadd(c0, palpha_quarter, ploadu<ResPacketQuarter>(res + i + ResPacketSizeQuarter * 0)));
  251|      0|      i += ResPacketSizeQuarter;
  252|      0|    }
  253|      0|    for (; i < rows; ++i) {
  254|      0|      ResScalar c0(0);
  255|      0|      for (Index j = j2; j < jend; j += 1) c0 += cj.pmul(lhs(i, j), rhs(j, 0));
  256|      0|      res[i] += alpha * c0;
  257|      0|    }
  258|      0|  }
  259|      0|}
  260|       |
  261|       |/* Optimized row-major matrix * vector product:
  262|       | * This algorithm processes 4 rows at once that allows to both reduce
  263|       | * the number of load/stores of the result by a factor 4 and to reduce
  264|       | * the instruction dependency. Moreover, we know that all bands have the
  265|       | * same alignment pattern.
  266|       | *
  267|       | * Mixing type logic:
  268|       | *  - alpha is always a complex (or converted to a complex)
  269|       | *  - no vectorization
  270|       | */
  271|       |template <typename Index, typename LhsScalar, typename LhsMapper, bool ConjugateLhs, typename RhsScalar,
  272|       |          typename RhsMapper, bool ConjugateRhs, int Version>
  273|       |struct general_matrix_vector_product<Index, LhsScalar, LhsMapper, RowMajor, ConjugateLhs, RhsScalar, RhsMapper,
  274|       |                                     ConjugateRhs, Version> {
  275|       |  typedef gemv_traits<LhsScalar, RhsScalar> Traits;
  276|       |  typedef gemv_traits<LhsScalar, RhsScalar, GEMVPacketHalf> HalfTraits;
  277|       |  typedef gemv_traits<LhsScalar, RhsScalar, GEMVPacketQuarter> QuarterTraits;
  278|       |
  279|       |  typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
  280|       |
  281|       |  typedef typename Traits::LhsPacket LhsPacket;
  282|       |  typedef typename Traits::RhsPacket RhsPacket;
  283|       |  typedef typename Traits::ResPacket ResPacket;
  284|       |
  285|       |  typedef typename HalfTraits::LhsPacket LhsPacketHalf;
  286|       |  typedef typename HalfTraits::RhsPacket RhsPacketHalf;
  287|       |  typedef typename HalfTraits::ResPacket ResPacketHalf;
  288|       |
  289|       |  typedef typename QuarterTraits::LhsPacket LhsPacketQuarter;
  290|       |  typedef typename QuarterTraits::RhsPacket RhsPacketQuarter;
  291|       |  typedef typename QuarterTraits::ResPacket ResPacketQuarter;
  292|       |
  293|       |  EIGEN_DEVICE_FUNC EIGEN_DONT_INLINE static void run(Index rows, Index cols, const LhsMapper& lhs,
  294|       |                                                      const RhsMapper& rhs, ResScalar* res, Index resIncr,
  295|       |                                                      ResScalar alpha);
  296|       |};
  297|       |
  298|       |template <typename Index, typename LhsScalar, typename LhsMapper, bool ConjugateLhs, typename RhsScalar,
  299|       |          typename RhsMapper, bool ConjugateRhs, int Version>
  300|       |EIGEN_DEVICE_FUNC EIGEN_DONT_INLINE void
  301|       |general_matrix_vector_product<Index, LhsScalar, LhsMapper, RowMajor, ConjugateLhs, RhsScalar, RhsMapper, ConjugateRhs,
  302|       |                              Version>::run(Index rows, Index cols, const LhsMapper& alhs, const RhsMapper& rhs,
  303|      0|                                            ResScalar* res, Index resIncr, ResScalar alpha) {
  304|       |  // The following copy tells the compiler that lhs's attributes are not modified outside this function
  305|       |  // This helps GCC to generate proper code.
  306|      0|  LhsMapper lhs(alhs);
  307|       |
  308|      0|  eigen_internal_assert(rhs.stride() == 1);
  309|      0|  conj_helper<LhsScalar, RhsScalar, ConjugateLhs, ConjugateRhs> cj;
  310|      0|  conj_helper<LhsPacket, RhsPacket, ConjugateLhs, ConjugateRhs> pcj;
  311|      0|  conj_helper<LhsPacketHalf, RhsPacketHalf, ConjugateLhs, ConjugateRhs> pcj_half;
  312|      0|  conj_helper<LhsPacketQuarter, RhsPacketQuarter, ConjugateLhs, ConjugateRhs> pcj_quarter;
  313|       |
  314|       |  // TODO: fine tune the following heuristic. The rationale is that if the matrix is very large,
  315|       |  //       processing 8 rows at once might be counter productive wrt cache.
  316|      0|  const Index n8 = lhs.stride() * sizeof(LhsScalar) > 32000 ? 0 : rows - 7;
  317|      0|  const Index n4 = rows - 3;
  318|      0|  const Index n2 = rows - 1;
  319|       |
  320|       |  // TODO: for padded aligned inputs, we could enable aligned reads
  321|      0|  enum {
  322|      0|    LhsAlignment = Unaligned,
  323|      0|    ResPacketSize = Traits::ResPacketSize,
  324|      0|    ResPacketSizeHalf = HalfTraits::ResPacketSize,
  325|      0|    ResPacketSizeQuarter = QuarterTraits::ResPacketSize,
  326|      0|    LhsPacketSize = Traits::LhsPacketSize,
  327|      0|    LhsPacketSizeHalf = HalfTraits::LhsPacketSize,
  328|      0|    LhsPacketSizeQuarter = QuarterTraits::LhsPacketSize,
  329|      0|    HasHalf = (int)ResPacketSizeHalf < (int)ResPacketSize,
  330|      0|    HasQuarter = (int)ResPacketSizeQuarter < (int)ResPacketSizeHalf
  331|      0|  };
  332|       |
  333|      0|  using UnsignedIndex = typename make_unsigned<Index>::type;
  334|      0|  const Index fullColBlockEnd = LhsPacketSize * (UnsignedIndex(cols) / LhsPacketSize);
  335|      0|  const Index halfColBlockEnd = LhsPacketSizeHalf * (UnsignedIndex(cols) / LhsPacketSizeHalf);
  336|      0|  const Index quarterColBlockEnd = LhsPacketSizeQuarter * (UnsignedIndex(cols) / LhsPacketSizeQuarter);
  337|       |
  338|      0|  Index i = 0;
  339|      0|  for (; i < n8; i += 8) {
  340|      0|    ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
  341|      0|              c2 = pset1<ResPacket>(ResScalar(0)), c3 = pset1<ResPacket>(ResScalar(0)),
  342|      0|              c4 = pset1<ResPacket>(ResScalar(0)), c5 = pset1<ResPacket>(ResScalar(0)),
  343|      0|              c6 = pset1<ResPacket>(ResScalar(0)), c7 = pset1<ResPacket>(ResScalar(0));
  344|       |
  345|      0|    for (Index j = 0; j < fullColBlockEnd; j += LhsPacketSize) {
  346|      0|      RhsPacket b0 = rhs.template load<RhsPacket, Unaligned>(j, 0);
  347|       |
  348|      0|      c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 0, j), b0, c0);
  349|      0|      c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 1, j), b0, c1);
  350|      0|      c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 2, j), b0, c2);
  351|      0|      c3 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 3, j), b0, c3);
  352|      0|      c4 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 4, j), b0, c4);
  353|      0|      c5 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 5, j), b0, c5);
  354|      0|      c6 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 6, j), b0, c6);
  355|      0|      c7 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 7, j), b0, c7);
  356|      0|    }
  357|      0|    ResScalar cc0 = predux(c0);
  358|      0|    ResScalar cc1 = predux(c1);
  359|      0|    ResScalar cc2 = predux(c2);
  360|      0|    ResScalar cc3 = predux(c3);
  361|      0|    ResScalar cc4 = predux(c4);
  362|      0|    ResScalar cc5 = predux(c5);
  363|      0|    ResScalar cc6 = predux(c6);
  364|      0|    ResScalar cc7 = predux(c7);
  365|       |
  366|      0|    for (Index j = fullColBlockEnd; j < cols; ++j) {
  367|      0|      RhsScalar b0 = rhs(j, 0);
  368|       |
  369|      0|      cc0 += cj.pmul(lhs(i + 0, j), b0);
  370|      0|      cc1 += cj.pmul(lhs(i + 1, j), b0);
  371|      0|      cc2 += cj.pmul(lhs(i + 2, j), b0);
  372|      0|      cc3 += cj.pmul(lhs(i + 3, j), b0);
  373|      0|      cc4 += cj.pmul(lhs(i + 4, j), b0);
  374|      0|      cc5 += cj.pmul(lhs(i + 5, j), b0);
  375|      0|      cc6 += cj.pmul(lhs(i + 6, j), b0);
  376|      0|      cc7 += cj.pmul(lhs(i + 7, j), b0);
  377|      0|    }
  378|      0|    res[(i + 0) * resIncr] += alpha * cc0;
  379|      0|    res[(i + 1) * resIncr] += alpha * cc1;
  380|      0|    res[(i + 2) * resIncr] += alpha * cc2;
  381|      0|    res[(i + 3) * resIncr] += alpha * cc3;
  382|      0|    res[(i + 4) * resIncr] += alpha * cc4;
  383|      0|    res[(i + 5) * resIncr] += alpha * cc5;
  384|      0|    res[(i + 6) * resIncr] += alpha * cc6;
  385|      0|    res[(i + 7) * resIncr] += alpha * cc7;
  386|      0|  }
  387|      0|  for (; i < n4; i += 4) {
  388|      0|    ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
  389|      0|              c2 = pset1<ResPacket>(ResScalar(0)), c3 = pset1<ResPacket>(ResScalar(0));
  390|       |
  391|      0|    for (Index j = 0; j < fullColBlockEnd; j += LhsPacketSize) {
  392|      0|      RhsPacket b0 = rhs.template load<RhsPacket, Unaligned>(j, 0);
  393|       |
  394|      0|      c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 0, j), b0, c0);
  395|      0|      c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 1, j), b0, c1);
  396|      0|      c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 2, j), b0, c2);
  397|      0|      c3 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 3, j), b0, c3);
  398|      0|    }
  399|      0|    ResScalar cc0 = predux(c0);
  400|      0|    ResScalar cc1 = predux(c1);
  401|      0|    ResScalar cc2 = predux(c2);
  402|      0|    ResScalar cc3 = predux(c3);
  403|       |
  404|      0|    for (Index j = fullColBlockEnd; j < cols; ++j) {
  405|      0|      RhsScalar b0 = rhs(j, 0);
  406|       |
  407|      0|      cc0 += cj.pmul(lhs(i + 0, j), b0);
  408|      0|      cc1 += cj.pmul(lhs(i + 1, j), b0);
  409|      0|      cc2 += cj.pmul(lhs(i + 2, j), b0);
  410|      0|      cc3 += cj.pmul(lhs(i + 3, j), b0);
  411|      0|    }
  412|      0|    res[(i + 0) * resIncr] += alpha * cc0;
  413|      0|    res[(i + 1) * resIncr] += alpha * cc1;
  414|      0|    res[(i + 2) * resIncr] += alpha * cc2;
  415|      0|    res[(i + 3) * resIncr] += alpha * cc3;
  416|      0|  }
  417|      0|  for (; i < n2; i += 2) {
  418|      0|    ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0));
  419|       |
  420|      0|    for (Index j = 0; j < fullColBlockEnd; j += LhsPacketSize) {
  421|      0|      RhsPacket b0 = rhs.template load<RhsPacket, Unaligned>(j, 0);
  422|       |
  423|      0|      c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 0, j), b0, c0);
  424|      0|      c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + 1, j), b0, c1);
  425|      0|    }
  426|      0|    ResScalar cc0 = predux(c0);
  427|      0|    ResScalar cc1 = predux(c1);
  428|       |
  429|      0|    for (Index j = fullColBlockEnd; j < cols; ++j) {
  430|      0|      RhsScalar b0 = rhs(j, 0);
  431|       |
  432|      0|      cc0 += cj.pmul(lhs(i + 0, j), b0);
  433|      0|      cc1 += cj.pmul(lhs(i + 1, j), b0);
  434|      0|    }
  435|      0|    res[(i + 0) * resIncr] += alpha * cc0;
  436|      0|    res[(i + 1) * resIncr] += alpha * cc1;
  437|      0|  }
  438|      0|  for (; i < rows; ++i) {
  439|      0|    ResPacket c0 = pset1<ResPacket>(ResScalar(0));
  440|      0|    ResPacketHalf c0_h = pset1<ResPacketHalf>(ResScalar(0));
  441|      0|    ResPacketQuarter c0_q = pset1<ResPacketQuarter>(ResScalar(0));
  442|       |
  443|      0|    for (Index j = 0; j < fullColBlockEnd; j += LhsPacketSize) {
  444|      0|      RhsPacket b0 = rhs.template load<RhsPacket, Unaligned>(j, 0);
  445|      0|      c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i, j), b0, c0);
  446|      0|    }
  447|      0|    ResScalar cc0 = predux(c0);
  448|      0|    if (HasHalf) {
  449|      0|      for (Index j = fullColBlockEnd; j < halfColBlockEnd; j += LhsPacketSizeHalf) {
  450|      0|        RhsPacketHalf b0 = rhs.template load<RhsPacketHalf, Unaligned>(j, 0);
  451|      0|        c0_h = pcj_half.pmadd(lhs.template load<LhsPacketHalf, LhsAlignment>(i, j), b0, c0_h);
  452|      0|      }
  453|      0|      cc0 += predux(c0_h);
  454|      0|    }
  455|      0|    if (HasQuarter) {
  456|      0|      for (Index j = halfColBlockEnd; j < quarterColBlockEnd; j += LhsPacketSizeQuarter) {
  457|      0|        RhsPacketQuarter b0 = rhs.template load<RhsPacketQuarter, Unaligned>(j, 0);
  458|      0|        c0_q = pcj_quarter.pmadd(lhs.template load<LhsPacketQuarter, LhsAlignment>(i, j), b0, c0_q);
  459|      0|      }
  460|      0|      cc0 += predux(c0_q);
  461|      0|    }
  462|      0|    for (Index j = quarterColBlockEnd; j < cols; ++j) {
  463|      0|      cc0 += cj.pmul(lhs(i, j), rhs(j, 0));
  464|      0|    }
  465|      0|    res[i * resIncr] += alpha * cc0;
  466|      0|  }
  467|      0|}
  468|       |
  469|       |}  // end namespace internal
  470|       |
  471|       |}  // end namespace Eigen
  472|       |
  473|       |#endif  // EIGEN_GENERAL_MATRIX_VECTOR_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/products/Parallelizer.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2010 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_PARALLELIZER_H
   11|       |#define EIGEN_PARALLELIZER_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |// Note that in the following, there are 3 different uses of the concept
   17|       |// "number of threads":
   18|       |//  1. Max number of threads used by OpenMP or ThreadPool.
   19|       |//     * For OpenMP this is typically the value set by the OMP_NUM_THREADS
   20|       |//       environment variable, or by a call to omp_set_num_threads() prior to
   21|       |//       calling Eigen.
   22|       |//     * For ThreadPool, this is the number of threads in the ThreadPool.
   23|       |//  2. Max number of threads currently allowed to be used by parallel Eigen
   24|       |//     operations. This is set by setNbThreads(), and cannot exceed the value
   25|       |//     in 1.
   26|       |//  3. The actual number of threads used for a given parallel Eigen operation.
   27|       |//     This is typically computed on the fly using a cost model and cannot exceed
   28|       |//     the value in 2.
   29|       |//     * For OpenMP, this is typically the number of threads specified in individual
   30|       |//       "omp parallel" pragmas associated with an Eigen operation.
   31|       |//     * For ThreadPool, it is the number of concurrent tasks scheduled in the
   32|       |//       threadpool for a given Eigen operation. Notice that since the threadpool
   33|       |//       uses task stealing, there is no way to limit the number of concurrently
   34|       |//       executing tasks to below the number in 1. except by limiting the total
   35|       |//       number of tasks in flight.
   36|       |
   37|       |#if defined(EIGEN_HAS_OPENMP) && defined(EIGEN_GEMM_THREADPOOL)
   38|       |#error "EIGEN_HAS_OPENMP and EIGEN_GEMM_THREADPOOL may not both be defined."
   39|       |#endif
   40|       |
   41|       |namespace Eigen {
   42|       |
   43|       |namespace internal {
   44|       |inline void manage_multi_threading(Action action, int* v);
   45|       |}
   46|       |
   47|       |// Public APIs.
   48|       |
   49|       |/** Must be call first when calling Eigen from multiple threads */
   50|      0|EIGEN_DEPRECATED inline void initParallel() {}
   51|       |
   52|       |/** \returns the max number of threads reserved for Eigen
   53|       | * \sa setNbThreads */
   54|      0|inline int nbThreads() {
   55|      0|  int ret;
   56|      0|  internal::manage_multi_threading(GetAction, &ret);
   57|      0|  return ret;
   58|      0|}
   59|       |
   60|       |/** Sets the max number of threads reserved for Eigen
   61|       | * \sa nbThreads */
   62|      0|inline void setNbThreads(int v) { internal::manage_multi_threading(SetAction, &v); }
   63|       |
   64|       |#ifdef EIGEN_GEMM_THREADPOOL
   65|       |// Sets the ThreadPool used by Eigen parallel Gemm.
   66|       |//
   67|       |// NOTICE: This function has a known race condition with
   68|       |// parallelize_gemm below, and should not be called while
   69|       |// an instance of that function is running.
   70|       |//
   71|       |// TODO(rmlarsen): Make the device API available instead of
   72|       |// storing a local static pointer variable to avoid this issue.
   73|       |inline ThreadPool* setGemmThreadPool(ThreadPool* new_pool) {
   74|       |  static ThreadPool* pool = nullptr;
   75|       |  if (new_pool != nullptr) {
   76|       |    // This will wait for work in all threads in *pool to finish,
   77|       |    // then destroy the old ThreadPool, and then replace it with new_pool.
   78|       |    pool = new_pool;
   79|       |    // Reset the number of threads to the number of threads on the new pool.
   80|       |    setNbThreads(pool->NumThreads());
   81|       |  }
   82|       |  return pool;
   83|       |}
   84|       |
   85|       |// Gets the ThreadPool used by Eigen parallel Gemm.
   86|       |inline ThreadPool* getGemmThreadPool() { return setGemmThreadPool(nullptr); }
   87|       |#endif
   88|       |
   89|       |namespace internal {
   90|       |
   91|       |// Implementation.
   92|       |
   93|       |#if defined(EIGEN_USE_BLAS) || (!defined(EIGEN_HAS_OPENMP) && !defined(EIGEN_GEMM_THREADPOOL))
   94|       |
   95|      0|inline void manage_multi_threading(Action action, int* v) {
   96|      0|  if (action == SetAction) {
   97|      0|    eigen_internal_assert(v != nullptr);
   98|      0|  } else if (action == GetAction) {
   99|      0|    eigen_internal_assert(v != nullptr);
  100|      0|    *v = 1;
  101|      0|  } else {
  102|      0|    eigen_internal_assert(false);
  103|      0|  }
  104|      0|}
  105|       |template <typename Index>
  106|       |struct GemmParallelInfo {};
  107|       |template <bool Condition, typename Functor, typename Index>
  108|       |EIGEN_STRONG_INLINE void parallelize_gemm(const Functor& func, Index rows, Index cols, Index /*unused*/,
  109|      2|                                          bool /*unused*/) {
  110|      2|  func(0, rows, 0, cols);
  111|      2|}
  112|       |
  113|       |#else
  114|       |
  115|       |template <typename Index>
  116|       |struct GemmParallelTaskInfo {
  117|       |  GemmParallelTaskInfo() : sync(-1), users(0), lhs_start(0), lhs_length(0) {}
  118|       |  std::atomic<Index> sync;
  119|       |  std::atomic<int> users;
  120|       |  Index lhs_start;
  121|       |  Index lhs_length;
  122|       |};
  123|       |
  124|       |template <typename Index>
  125|       |struct GemmParallelInfo {
  126|       |  const int logical_thread_id;
  127|       |  const int num_threads;
  128|       |  GemmParallelTaskInfo<Index>* task_info;
  129|       |
  130|       |  GemmParallelInfo(int logical_thread_id_, int num_threads_, GemmParallelTaskInfo<Index>* task_info_)
  131|       |      : logical_thread_id(logical_thread_id_), num_threads(num_threads_), task_info(task_info_) {}
  132|       |};
  133|       |
  134|       |inline void manage_multi_threading(Action action, int* v) {
  135|       |  static int m_maxThreads = -1;
  136|       |  if (action == SetAction) {
  137|       |    eigen_internal_assert(v != nullptr);
  138|       |#if defined(EIGEN_HAS_OPENMP)
  139|       |    // Calling action == SetAction and *v = 0 means
  140|       |    // restoring m_maxThreads to the maximum number of threads specified
  141|       |    // for OpenMP.
  142|       |    eigen_internal_assert(*v >= 0);
  143|       |    int omp_threads = omp_get_max_threads();
  144|       |    m_maxThreads = (*v == 0 ? omp_threads : std::min(*v, omp_threads));
  145|       |#elif defined(EIGEN_GEMM_THREADPOOL)
  146|       |    // Calling action == SetAction and *v = 0 means
  147|       |    // restoring m_maxThreads to the number of threads in the ThreadPool,
  148|       |    // which defaults to 1 if no pool was provided.
  149|       |    eigen_internal_assert(*v >= 0);
  150|       |    ThreadPool* pool = getGemmThreadPool();
  151|       |    int pool_threads = pool != nullptr ? pool->NumThreads() : 1;
  152|       |    m_maxThreads = (*v == 0 ? pool_threads : numext::mini(pool_threads, *v));
  153|       |#endif
  154|       |  } else if (action == GetAction) {
  155|       |    eigen_internal_assert(v != nullptr);
  156|       |#if defined(EIGEN_HAS_OPENMP)
  157|       |    if (m_maxThreads > 0)
  158|       |      *v = m_maxThreads;
  159|       |    else
  160|       |      *v = omp_get_max_threads();
  161|       |#else
  162|       |    *v = m_maxThreads;
  163|       |#endif
  164|       |  } else {
  165|       |    eigen_internal_assert(false);
  166|       |  }
  167|       |}
  168|       |
  169|       |template <bool Condition, typename Functor, typename Index>
  170|       |EIGEN_STRONG_INLINE void parallelize_gemm(const Functor& func, Index rows, Index cols, Index depth, bool transpose) {
  171|       |  // Dynamically check whether we should even try to execute in parallel.
  172|       |  // The conditions are:
  173|       |  // - the max number of threads we can create is greater than 1
  174|       |  // - we are not already in a parallel code
  175|       |  // - the sizes are large enough
  176|       |
  177|       |  // compute the maximal number of threads from the size of the product:
  178|       |  // This first heuristic takes into account that the product kernel is fully optimized when working with nr columns at
  179|       |  // once.
  180|       |  Index size = transpose ? rows : cols;
  181|       |  Index pb_max_threads = std::max<Index>(1, size / Functor::Traits::nr);
  182|       |
  183|       |  // compute the maximal number of threads from the total amount of work:
  184|       |  double work = static_cast<double>(rows) * static_cast<double>(cols) * static_cast<double>(depth);
  185|       |  double kMinTaskSize = 50000;  // FIXME improve this heuristic.
  186|       |  pb_max_threads = std::max<Index>(1, std::min<Index>(pb_max_threads, static_cast<Index>(work / kMinTaskSize)));
  187|       |
  188|       |  // compute the number of threads we are going to use
  189|       |  int threads = std::min<int>(nbThreads(), static_cast<int>(pb_max_threads));
  190|       |
  191|       |  // if multi-threading is explicitly disabled, not useful, or if we already are
  192|       |  // inside a parallel session, then abort multi-threading
  193|       |  bool dont_parallelize = (!Condition) || (threads <= 1);
  194|       |#if defined(EIGEN_HAS_OPENMP)
  195|       |  // don't parallelize if we are executing in a parallel context already.
  196|       |  dont_parallelize |= omp_get_num_threads() > 1;
  197|       |#elif defined(EIGEN_GEMM_THREADPOOL)
  198|       |  // don't parallelize if we have a trivial threadpool or the current thread id
  199|       |  // is != -1, indicating that we are already executing on a thread inside the pool.
  200|       |  // In other words, we do not allow nested parallelism, since this would lead to
  201|       |  // deadlocks due to the workstealing nature of the threadpool.
  202|       |  ThreadPool* pool = getGemmThreadPool();
  203|       |  dont_parallelize |= (pool == nullptr || pool->CurrentThreadId() != -1);
  204|       |#endif
  205|       |  if (dont_parallelize) return func(0, rows, 0, cols);
  206|       |
  207|       |  func.initParallelSession(threads);
  208|       |
  209|       |  if (transpose) std::swap(rows, cols);
  210|       |
  211|       |  ei_declare_aligned_stack_constructed_variable(GemmParallelTaskInfo<Index>, task_info, threads, 0);
  212|       |
  213|       |#if defined(EIGEN_HAS_OPENMP)
  214|       |#pragma omp parallel num_threads(threads)
  215|       |  {
  216|       |    Index i = omp_get_thread_num();
  217|       |    // Note that the actual number of threads might be lower than the number of
  218|       |    // requested ones
  219|       |    Index actual_threads = omp_get_num_threads();
  220|       |    GemmParallelInfo<Index> info(i, static_cast<int>(actual_threads), task_info);
  221|       |
  222|       |    Index blockCols = (cols / actual_threads) & ~Index(0x3);
  223|       |    Index blockRows = (rows / actual_threads);
  224|       |    blockRows = (blockRows / Functor::Traits::mr) * Functor::Traits::mr;
  225|       |
  226|       |    Index r0 = i * blockRows;
  227|       |    Index actualBlockRows = (i + 1 == actual_threads) ? rows - r0 : blockRows;
  228|       |
  229|       |    Index c0 = i * blockCols;
  230|       |    Index actualBlockCols = (i + 1 == actual_threads) ? cols - c0 : blockCols;
  231|       |
  232|       |    info.task_info[i].lhs_start = r0;
  233|       |    info.task_info[i].lhs_length = actualBlockRows;
  234|       |
  235|       |    if (transpose)
  236|       |      func(c0, actualBlockCols, 0, rows, &info);
  237|       |    else
  238|       |      func(0, rows, c0, actualBlockCols, &info);
  239|       |  }
  240|       |
  241|       |#elif defined(EIGEN_GEMM_THREADPOOL)
  242|       |  Barrier barrier(threads);
  243|       |  auto task = [=, &func, &barrier, &task_info](int i) {
  244|       |    Index actual_threads = threads;
  245|       |    GemmParallelInfo<Index> info(i, static_cast<int>(actual_threads), task_info);
  246|       |    Index blockCols = (cols / actual_threads) & ~Index(0x3);
  247|       |    Index blockRows = (rows / actual_threads);
  248|       |    blockRows = (blockRows / Functor::Traits::mr) * Functor::Traits::mr;
  249|       |
  250|       |    Index r0 = i * blockRows;
  251|       |    Index actualBlockRows = (i + 1 == actual_threads) ? rows - r0 : blockRows;
  252|       |
  253|       |    Index c0 = i * blockCols;
  254|       |    Index actualBlockCols = (i + 1 == actual_threads) ? cols - c0 : blockCols;
  255|       |
  256|       |    info.task_info[i].lhs_start = r0;
  257|       |    info.task_info[i].lhs_length = actualBlockRows;
  258|       |
  259|       |    if (transpose)
  260|       |      func(c0, actualBlockCols, 0, rows, &info);
  261|       |    else
  262|       |      func(0, rows, c0, actualBlockCols, &info);
  263|       |
  264|       |    barrier.Notify();
  265|       |  };
  266|       |  // Notice that we do not schedule more than "threads" tasks, which allows us to
  267|       |  // limit number of running threads, even if the threadpool itself was constructed
  268|       |  // with a larger number of threads.
  269|       |  for (int i = 0; i < threads - 1; ++i) {
  270|       |    pool->Schedule([=, task = std::move(task)] { task(i); });
  271|       |  }
  272|       |  task(threads - 1);
  273|       |  barrier.Wait();
  274|       |#endif
  275|       |}
  276|       |
  277|       |#endif
  278|       |
  279|       |}  // end namespace internal
  280|       |}  // end namespace Eigen
  281|       |
  282|       |#endif  // EIGEN_PARALLELIZER_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/Assert.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2022, The Eigen authors.
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_CORE_UTIL_ASSERT_H
   11|       |#define EIGEN_CORE_UTIL_ASSERT_H
   12|       |
   13|       |// Eigen custom assert function.
   14|       |//
   15|       |// The combination of Eigen's relative includes and cassert's `assert` function
   16|       |// (or any usage of the __FILE__ macro) can lead to ODR issues:
   17|       |// a header included using different relative paths in two different TUs will
   18|       |// have two different token-for-token definitions, since __FILE__ is expanded
   19|       |// as an in-line string with different values.  Normally this would be
   20|       |// harmless - the linker would just choose one definition. However, it breaks
   21|       |// with C++20 modules when functions in different modules have different
   22|       |// definitions.
   23|       |//
   24|       |// To get around this, we need to use __builtin_FILE() when available, which is
   25|       |// considered a single token, and thus satisfies the ODR.
   26|       |
   27|       |// Only define eigen_plain_assert if we are debugging, and either
   28|       |//  - we are not compiling for GPU, or
   29|       |//  - gpu debugging is enabled.
   30|       |#if !defined(EIGEN_NO_DEBUG) && (!defined(EIGEN_GPU_COMPILE_PHASE) || !defined(EIGEN_NO_DEBUG_GPU))
   31|       |
   32|       |#include <cassert>
   33|       |
   34|       |#ifndef EIGEN_USE_CUSTOM_PLAIN_ASSERT
   35|       |// Disable new custom asserts by default for now.
   36|       |#define EIGEN_USE_CUSTOM_PLAIN_ASSERT 0
   37|       |#endif
   38|       |
   39|       |#if EIGEN_USE_CUSTOM_PLAIN_ASSERT
   40|       |
   41|       |#ifndef EIGEN_HAS_BUILTIN_FILE
   42|       |// Clang can check if __builtin_FILE() is supported.
   43|       |// GCC > 5, MSVC 2019 14.26 (1926) all have __builtin_FILE().
   44|       |//
   45|       |// For NVCC, it's more complicated.  Through trial-and-error:
   46|       |//   - nvcc+gcc supports __builtin_FILE() on host, and on device after CUDA 11.
   47|       |//   - nvcc+msvc supports __builtin_FILE() only after CUDA 11.
   48|       |#if (EIGEN_HAS_BUILTIN(__builtin_FILE) && (EIGEN_COMP_CLANG || !defined(EIGEN_CUDA_ARCH))) ||            \
   49|       |    (EIGEN_GNUC_STRICT_AT_LEAST(5, 0, 0) && (EIGEN_COMP_NVCC >= 110000 || !defined(EIGEN_CUDA_ARCH))) || \
   50|       |    (EIGEN_COMP_MSVC >= 1926 && (!EIGEN_COMP_NVCC || EIGEN_COMP_NVCC >= 110000))
   51|       |#define EIGEN_HAS_BUILTIN_FILE 1
   52|       |#else
   53|       |#define EIGEN_HAS_BUILTIN_FILE 0
   54|       |#endif
   55|       |#endif  // EIGEN_HAS_BUILTIN_FILE
   56|       |
   57|       |#if EIGEN_HAS_BUILTIN_FILE
   58|       |#define EIGEN_BUILTIN_FILE __builtin_FILE()
   59|       |#define EIGEN_BUILTIN_LINE __builtin_LINE()
   60|       |#else
   61|       |// Default (potentially unsafe) values.
   62|       |#define EIGEN_BUILTIN_FILE __FILE__
   63|       |#define EIGEN_BUILTIN_LINE __LINE__
   64|       |#endif
   65|       |
   66|       |// Use __PRETTY_FUNCTION__ when available, since it is more descriptive, as
   67|       |// __builtin_FUNCTION() only returns the undecorated function name.
   68|       |// This should still be okay ODR-wise since it is a compiler-specific fixed
   69|       |// value.  Mixing compilers will likely lead to ODR violations anyways.
   70|       |#if EIGEN_COMP_MSVC
   71|       |#define EIGEN_BUILTIN_FUNCTION __FUNCSIG__
   72|       |#elif EIGEN_COMP_GNUC
   73|       |#define EIGEN_BUILTIN_FUNCTION __PRETTY_FUNCTION__
   74|       |#else
   75|       |#define EIGEN_BUILTIN_FUNCTION __func__
   76|       |#endif
   77|       |
   78|       |namespace Eigen {
   79|       |namespace internal {
   80|       |
   81|       |// Generic default assert handler.
   82|       |template <typename EnableIf = void, typename... EmptyArgs>
   83|       |struct assert_handler_impl {
   84|       |  EIGEN_DEVICE_FUNC EIGEN_DONT_INLINE static inline void run(const char* expression, const char* file, unsigned line,
   85|       |                                                             const char* function) {
   86|       |#ifdef EIGEN_GPU_COMPILE_PHASE
   87|       |    // GPU device code doesn't allow stderr or abort, so use printf and raise an
   88|       |    // illegal instruction exception to trigger a kernel failure.
   89|       |#ifndef EIGEN_NO_IO
   90|       |    printf("Assertion failed at %s:%u in %s: %s\n", file == nullptr ? "<file>" : file, line,
   91|       |           function == nullptr ? "<function>" : function, expression);
   92|       |#endif
   93|       |    __trap();
   94|       |
   95|       |#else  // EIGEN_GPU_COMPILE_PHASE
   96|       |
   97|       |    // Print to stderr and abort, as specified in <cassert>.
   98|       |#ifndef EIGEN_NO_IO
   99|       |    fprintf(stderr, "Assertion failed at %s:%u in %s: %s\n", file == nullptr ? "<file>" : file, line,
  100|       |            function == nullptr ? "<function>" : function, expression);
  101|       |#endif
  102|       |    std::abort();
  103|       |
  104|       |#endif  // EIGEN_GPU_COMPILE_PHASE
  105|       |  }
  106|       |};
  107|       |
  108|       |// Use POSIX __assert_fail handler when available.
  109|       |//
  110|       |// This allows us to integrate with systems that have custom handlers.
  111|       |//
  112|       |// NOTE: this handler is not always available on all POSIX systems (otherwise
  113|       |// we could simply test for __unix__ or similar).  The handler function name
  114|       |// seems to depend on the specific toolchain implementation, and differs between
  115|       |// compilers, platforms, OSes, etc.  Hence, we detect support via SFINAE.
  116|       |template <typename... EmptyArgs>
  117|       |struct assert_handler_impl<void_t<decltype(__assert_fail((const char*)nullptr,         // expression
  118|       |                                                         (const char*)nullptr,         // file
  119|       |                                                         0,                            // line
  120|       |                                                         (const char*)nullptr,         // function
  121|       |                                                         std::declval<EmptyArgs>()...  // Empty substitution required
  122|       |                                                                                       // for SFINAE.
  123|       |                                                         ))>,
  124|       |                           EmptyArgs...> {
  125|       |  EIGEN_DEVICE_FUNC EIGEN_DONT_INLINE static inline void run(const char* expression, const char* file, unsigned line,
  126|       |                                                             const char* function) {
  127|       |    // GCC requires this call to be dependent on the template parameters.
  128|       |    __assert_fail(expression, file, line, function, std::declval<EmptyArgs>()...);
  129|       |  }
  130|       |};
  131|       |
  132|       |EIGEN_DEVICE_FUNC EIGEN_DONT_INLINE inline void __assert_handler(const char* expression, const char* file,
  133|       |                                                                 unsigned line, const char* function) {
  134|       |  assert_handler_impl<>::run(expression, file, line, function);
  135|       |}
  136|       |
  137|       |}  // namespace internal
  138|       |}  // namespace Eigen
  139|       |
  140|       |#define eigen_plain_assert(expression)                                                                                \
  141|       |  (EIGEN_PREDICT_FALSE(!(expression)) ? Eigen::internal::__assert_handler(#expression, EIGEN_BUILTIN_FILE,            \
  142|       |                                                                          EIGEN_BUILTIN_LINE, EIGEN_BUILTIN_FUNCTION) \
  143|       |                                      : (void)0)
  144|       |
  145|       |#else  // EIGEN_USE_CUSTOM_PLAIN_ASSERT
  146|       |
  147|       |// Use regular assert.
  148|      0|#define eigen_plain_assert(condition) assert(condition)
  149|       |
  150|       |#endif  // EIGEN_USE_CUSTOM_PLAIN_ASSERT
  151|       |
  152|       |#else  // EIGEN_NO_DEBUG
  153|       |
  154|       |#define eigen_plain_assert(condition) ((void)0)
  155|       |
  156|       |#endif  // EIGEN_NO_DEBUG
  157|       |
  158|       |#endif  // EIGEN_CORE_UTIL_ASSERT_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/BlasUtil.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2009-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_BLASUTIL_H
   11|       |#define EIGEN_BLASUTIL_H
   12|       |
   13|       |// This file contains many lightweight helper classes used to
   14|       |// implement and control fast level 2 and level 3 BLAS-like routines.
   15|       |
   16|       |// IWYU pragma: private
   17|       |#include "../InternalHeaderCheck.h"
   18|       |
   19|       |namespace Eigen {
   20|       |
   21|       |namespace internal {
   22|       |
   23|       |// forward declarations
   24|       |template <typename LhsScalar, typename RhsScalar, typename Index, typename DataMapper, int mr, int nr,
   25|       |          bool ConjugateLhs = false, bool ConjugateRhs = false>
   26|       |struct gebp_kernel;
   27|       |
   28|       |template <typename Scalar, typename Index, typename DataMapper, int nr, int StorageOrder, bool Conjugate = false,
   29|       |          bool PanelMode = false>
   30|       |struct gemm_pack_rhs;
   31|       |
   32|       |template <typename Scalar, typename Index, typename DataMapper, int Pack1, int Pack2, typename Packet, int StorageOrder,
   33|       |          bool Conjugate = false, bool PanelMode = false>
   34|       |struct gemm_pack_lhs;
   35|       |
   36|       |template <typename Index, typename LhsScalar, int LhsStorageOrder, bool ConjugateLhs, typename RhsScalar,
   37|       |          int RhsStorageOrder, bool ConjugateRhs, int ResStorageOrder, int ResInnerStride>
   38|       |struct general_matrix_matrix_product;
   39|       |
   40|       |template <typename Index, typename LhsScalar, typename LhsMapper, int LhsStorageOrder, bool ConjugateLhs,
   41|       |          typename RhsScalar, typename RhsMapper, bool ConjugateRhs, int Version = Specialized>
   42|       |struct general_matrix_vector_product;
   43|       |
   44|       |template <typename From, typename To>
   45|       |struct get_factor {
   46|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE To run(const From& x) { return To(x); }
   47|       |};
   48|       |
   49|       |template <typename Scalar>
   50|       |struct get_factor<Scalar, typename NumTraits<Scalar>::Real> {
   51|      0|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE typename NumTraits<Scalar>::Real run(const Scalar& x) {
   52|      0|    return numext::real(x);
   53|      0|  }
   54|       |};
   55|       |
   56|       |template <typename Scalar, typename Index>
   57|       |class BlasVectorMapper {
   58|       | public:
   59|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BlasVectorMapper(Scalar* data) : m_data(data) {}
   60|       |
   61|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar operator()(Index i) const { return m_data[i]; }
   62|       |  template <typename Packet, int AlignmentType>
   63|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet load(Index i) const {
   64|       |    return ploadt<Packet, AlignmentType>(m_data + i);
   65|       |  }
   66|       |
   67|       |  template <typename Packet>
   68|       |  EIGEN_DEVICE_FUNC bool aligned(Index i) const {
   69|       |    return (std::uintptr_t(m_data + i) % sizeof(Packet)) == 0;
   70|       |  }
   71|       |
   72|       | protected:
   73|       |  Scalar* m_data;
   74|       |};
   75|       |
   76|       |template <typename Scalar, typename Index, int AlignmentType, int Incr = 1>
   77|       |class BlasLinearMapper;
   78|       |
   79|       |template <typename Scalar, typename Index, int AlignmentType>
   80|       |class BlasLinearMapper<Scalar, Index, AlignmentType> {
   81|       | public:
   82|    108|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BlasLinearMapper(Scalar* data, Index incr = 1) : m_data(data) {
   83|    108|    EIGEN_ONLY_USED_FOR_DEBUG(incr);
   84|    108|    eigen_assert(incr == 1);
   85|    108|  }
  ------------------
  | _ZN5Eigen8internal16BlasLinearMapperIK14AnnoyingScalarlLi0ELi1EEC2EPS3_l:
  |   82|    100|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BlasLinearMapper(Scalar* data, Index incr = 1) : m_data(data) {
  |   83|    100|    EIGEN_ONLY_USED_FOR_DEBUG(incr);
  |   84|    100|    eigen_assert(incr == 1);
  |   85|    100|  }
  ------------------
  | _ZN5Eigen8internal16BlasLinearMapperI14AnnoyingScalarlLi0ELi1EEC2EPS2_l:
  |   82|      8|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BlasLinearMapper(Scalar* data, Index incr = 1) : m_data(data) {
  |   83|      8|    EIGEN_ONLY_USED_FOR_DEBUG(incr);
  |   84|      8|    eigen_assert(incr == 1);
  |   85|      8|  }
  ------------------
   86|       |
   87|      8|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void prefetch(Index i) const { internal::prefetch(&operator()(i)); }
   88|       |
   89|  5.00k|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i) const { return m_data[i]; }
  ------------------
  | _ZNK5Eigen8internal16BlasLinearMapperIK14AnnoyingScalarlLi0ELi1EEclEl:
  |   89|  5.00k|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i) const { return m_data[i]; }
  ------------------
  | _ZNK5Eigen8internal16BlasLinearMapperI14AnnoyingScalarlLi0ELi1EEclEl:
  |   89|      8|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i) const { return m_data[i]; }
  ------------------
   90|       |
   91|       |  template <typename PacketType>
   92|      0|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacket(Index i) const {
   93|      0|    return ploadt<PacketType, AlignmentType>(m_data + i);
   94|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16BlasLinearMapperI14AnnoyingScalarlLi0ELi1EE10loadPacketIS2_EET_l
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16BlasLinearMapperIK14AnnoyingScalarlLi0ELi1EE10loadPacketIS2_EET_l
  ------------------
   95|       |
   96|       |  template <typename PacketType>
   97|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacketPartial(Index i, Index n, Index offset = 0) const {
   98|       |    return ploadt_partial<PacketType, AlignmentType>(m_data + i, n, offset);
   99|       |  }
  100|       |
  101|       |  template <typename PacketType, int AlignmentT>
  102|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType load(Index i) const {
  103|       |    return ploadt<PacketType, AlignmentT>(m_data + i);
  104|       |  }
  105|       |
  106|       |  template <typename PacketType>
  107|      0|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacket(Index i, const PacketType& p) const {
  108|      0|    pstoret<Scalar, PacketType, AlignmentType>(m_data + i, p);
  109|      0|  }
  110|       |
  111|       |  template <typename PacketType>
  112|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacketPartial(Index i, const PacketType& p, Index n,
  113|       |                                                                Index offset = 0) const {
  114|       |    pstoret_partial<Scalar, PacketType, AlignmentType>(m_data + i, p, n, offset);
  115|       |  }
  116|       |
  117|       | protected:
  118|       |  Scalar* m_data;
  119|       |};
  120|       |
  121|       |// Lightweight helper class to access matrix coefficients.
  122|       |template <typename Scalar, typename Index, int StorageOrder, int AlignmentType = Unaligned, int Incr = 1>
  123|       |class blas_data_mapper;
  124|       |
  125|       |// TMP to help PacketBlock store implementation.
  126|       |// There's currently no known use case for PacketBlock load.
  127|       |// The default implementation assumes ColMajor order.
  128|       |// It always store each packet sequentially one `stride` apart.
  129|       |template <typename Index, typename Scalar, typename Packet, int n, int idx, int StorageOrder>
  130|       |struct PacketBlockManagement {
  131|       |  PacketBlockManagement<Index, Scalar, Packet, n, idx - 1, StorageOrder> pbm;
  132|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(Scalar* to, const Index stride, Index i, Index j,
  133|       |                                                   const PacketBlock<Packet, n>& block) const {
  134|       |    pbm.store(to, stride, i, j, block);
  135|       |    pstoreu<Scalar>(to + i + (j + idx) * stride, block.packet[idx]);
  136|       |  }
  137|       |};
  138|       |
  139|       |// PacketBlockManagement specialization to take care of RowMajor order without ifs.
  140|       |template <typename Index, typename Scalar, typename Packet, int n, int idx>
  141|       |struct PacketBlockManagement<Index, Scalar, Packet, n, idx, RowMajor> {
  142|       |  PacketBlockManagement<Index, Scalar, Packet, n, idx - 1, RowMajor> pbm;
  143|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(Scalar* to, const Index stride, Index i, Index j,
  144|       |                                                   const PacketBlock<Packet, n>& block) const {
  145|       |    pbm.store(to, stride, i, j, block);
  146|       |    pstoreu<Scalar>(to + j + (i + idx) * stride, block.packet[idx]);
  147|       |  }
  148|       |};
  149|       |
  150|       |template <typename Index, typename Scalar, typename Packet, int n, int StorageOrder>
  151|       |struct PacketBlockManagement<Index, Scalar, Packet, n, -1, StorageOrder> {
  152|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(Scalar* to, const Index stride, Index i, Index j,
  153|       |                                                   const PacketBlock<Packet, n>& block) const {
  154|       |    EIGEN_UNUSED_VARIABLE(to);
  155|       |    EIGEN_UNUSED_VARIABLE(stride);
  156|       |    EIGEN_UNUSED_VARIABLE(i);
  157|       |    EIGEN_UNUSED_VARIABLE(j);
  158|       |    EIGEN_UNUSED_VARIABLE(block);
  159|       |  }
  160|       |};
  161|       |
  162|       |template <typename Index, typename Scalar, typename Packet, int n>
  163|       |struct PacketBlockManagement<Index, Scalar, Packet, n, -1, RowMajor> {
  164|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(Scalar* to, const Index stride, Index i, Index j,
  165|       |                                                   const PacketBlock<Packet, n>& block) const {
  166|       |    EIGEN_UNUSED_VARIABLE(to);
  167|       |    EIGEN_UNUSED_VARIABLE(stride);
  168|       |    EIGEN_UNUSED_VARIABLE(i);
  169|       |    EIGEN_UNUSED_VARIABLE(j);
  170|       |    EIGEN_UNUSED_VARIABLE(block);
  171|       |  }
  172|       |};
  173|       |
  174|       |template <typename Scalar, typename Index, int StorageOrder, int AlignmentType>
  175|       |class blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, 1> {
  176|       | public:
  177|       |  typedef BlasLinearMapper<Scalar, Index, AlignmentType> LinearMapper;
  178|       |  typedef blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType> SubMapper;
  179|       |  typedef BlasVectorMapper<Scalar, Index> VectorMapper;
  180|       |
  181|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE blas_data_mapper(Scalar* data, Index stride, Index incr = 1)
  182|     12|      : m_data(data), m_stride(stride) {
  183|     12|    EIGEN_ONLY_USED_FOR_DEBUG(incr);
  184|     12|    eigen_assert(incr == 1);
  185|     12|  }
  ------------------
  | _ZN5Eigen8internal16blas_data_mapperIK14AnnoyingScalarlLi0ELi0ELi1EEC2EPS3_ll:
  |  182|      8|      : m_data(data), m_stride(stride) {
  |  183|      8|    EIGEN_ONLY_USED_FOR_DEBUG(incr);
  |  184|      8|    eigen_assert(incr == 1);
  |  185|      8|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal16blas_data_mapperIK14AnnoyingScalarlLi1ELi0ELi1EEC2EPS3_ll
  ------------------
  | _ZN5Eigen8internal16blas_data_mapperI14AnnoyingScalarlLi0ELi0ELi1EEC2EPS2_ll:
  |  182|      4|      : m_data(data), m_stride(stride) {
  |  183|      4|    EIGEN_ONLY_USED_FOR_DEBUG(incr);
  |  184|      4|    eigen_assert(incr == 1);
  |  185|      4|  }
  ------------------
  186|       |
  187|      2|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE SubMapper getSubMapper(Index i, Index j) const {
  188|      2|    return SubMapper(&operator()(i, j), m_stride);
  189|      2|  }
  190|       |
  191|    108|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE LinearMapper getLinearMapper(Index i, Index j) const {
  192|    108|    return LinearMapper(&operator()(i, j));
  193|    108|  }
  ------------------
  | _ZNK5Eigen8internal16blas_data_mapperIK14AnnoyingScalarlLi0ELi0ELi1EE15getLinearMapperEll:
  |  191|    100|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE LinearMapper getLinearMapper(Index i, Index j) const {
  |  192|    100|    return LinearMapper(&operator()(i, j));
  |  193|    100|  }
  ------------------
  | _ZNK5Eigen8internal16blas_data_mapperI14AnnoyingScalarlLi0ELi0ELi1EE15getLinearMapperEll:
  |  191|      8|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE LinearMapper getLinearMapper(Index i, Index j) const {
  |  192|      8|    return LinearMapper(&operator()(i, j));
  |  193|      8|  }
  ------------------
  194|       |
  195|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE VectorMapper getVectorMapper(Index i, Index j) const {
  196|       |    return VectorMapper(&operator()(i, j));
  197|       |  }
  198|       |
  199|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void prefetch(Index i, Index j) const { internal::prefetch(&operator()(i, j)); }
  200|       |
  201|  5.11k|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i, Index j) const {
  202|  5.11k|    return m_data[StorageOrder == RowMajor ? j + i * m_stride : i + j * m_stride];
  203|  5.11k|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16blas_data_mapperIK14AnnoyingScalarlLi1ELi0ELi1EEclEll
  ------------------
  | _ZNK5Eigen8internal16blas_data_mapperIK14AnnoyingScalarlLi0ELi0ELi1EEclEll:
  |  201|  5.10k|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i, Index j) const {
  |  202|  5.10k|    return m_data[StorageOrder == RowMajor ? j + i * m_stride : i + j * m_stride];
  |  203|  5.10k|  }
  ------------------
  | _ZNK5Eigen8internal16blas_data_mapperI14AnnoyingScalarlLi0ELi0ELi1EEclEll:
  |  201|     10|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i, Index j) const {
  |  202|     10|    return m_data[StorageOrder == RowMajor ? j + i * m_stride : i + j * m_stride];
  |  203|     10|  }
  ------------------
  204|       |
  205|       |  template <typename PacketType>
  206|  5.00k|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacket(Index i, Index j) const {
  207|  5.00k|    return ploadt<PacketType, AlignmentType>(&operator()(i, j));
  208|  5.00k|  }
  209|       |
  210|       |  template <typename PacketType>
  211|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacketPartial(Index i, Index j, Index n,
  212|       |                                                                     Index offset = 0) const {
  213|       |    return ploadt_partial<PacketType, AlignmentType>(&operator()(i, j), n, offset);
  214|       |  }
  215|       |
  216|       |  template <typename PacketT, int AlignmentT>
  217|      0|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketT load(Index i, Index j) const {
  218|      0|    return ploadt<PacketT, AlignmentT>(&operator()(i, j));
  219|      0|  }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16blas_data_mapperIK14AnnoyingScalarlLi0ELi0ELi1EE4loadIS2_Li0EEET_ll
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16blas_data_mapperIK14AnnoyingScalarlLi1ELi0ELi1EE4loadIS2_Li0EEET_ll
  ------------------
  220|       |
  221|       |  template <typename PacketType>
  222|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacket(Index i, Index j, const PacketType& p) const {
  223|       |    pstoret<Scalar, PacketType, AlignmentType>(&operator()(i, j), p);
  224|       |  }
  225|       |
  226|       |  template <typename PacketType>
  227|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacketPartial(Index i, Index j, const PacketType& p, Index n,
  228|       |                                                                Index offset = 0) const {
  229|       |    pstoret_partial<Scalar, PacketType, AlignmentType>(&operator()(i, j), p, n, offset);
  230|       |  }
  231|       |
  232|       |  template <typename SubPacket>
  233|      0|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void scatterPacket(Index i, Index j, const SubPacket& p) const {
  234|      0|    pscatter<Scalar, SubPacket>(&operator()(i, j), p, m_stride);
  235|      0|  }
  236|       |
  237|       |  template <typename SubPacket>
  238|      0|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE SubPacket gatherPacket(Index i, Index j) const {
  239|      0|    return pgather<Scalar, SubPacket>(&operator()(i, j), m_stride);
  240|      0|  }
  241|       |
  242|      0|  EIGEN_DEVICE_FUNC const Index stride() const { return m_stride; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16blas_data_mapperIK14AnnoyingScalarlLi0ELi0ELi1EE6strideEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal16blas_data_mapperIK14AnnoyingScalarlLi1ELi0ELi1EE6strideEv
  ------------------
  243|       |  EIGEN_DEVICE_FUNC const Index incr() const { return 1; }
  244|       |  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const { return m_data; }
  245|       |
  246|       |  EIGEN_DEVICE_FUNC Index firstAligned(Index size) const {
  247|       |    if (std::uintptr_t(m_data) % sizeof(Scalar)) {
  248|       |      return -1;
  249|       |    }
  250|       |    return internal::first_default_aligned(m_data, size);
  251|       |  }
  252|       |
  253|       |  template <typename SubPacket, int n>
  254|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacketBlock(Index i, Index j,
  255|       |                                                              const PacketBlock<SubPacket, n>& block) const {
  256|       |    PacketBlockManagement<Index, Scalar, SubPacket, n, n - 1, StorageOrder> pbm;
  257|       |    pbm.store(m_data, m_stride, i, j, block);
  258|       |  }
  259|       |
  260|       | protected:
  261|       |  Scalar* EIGEN_RESTRICT m_data;
  262|       |  const Index m_stride;
  263|       |};
  264|       |
  265|       |// Implementation of non-natural increment (i.e. inner-stride != 1)
  266|       |// The exposed API is not complete yet compared to the Incr==1 case
  267|       |// because some features makes less sense in this case.
  268|       |template <typename Scalar, typename Index, int AlignmentType, int Incr>
  269|       |class BlasLinearMapper {
  270|       | public:
  271|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BlasLinearMapper(Scalar* data, Index incr) : m_data(data), m_incr(incr) {}
  272|       |
  273|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void prefetch(int i) const { internal::prefetch(&operator()(i)); }
  274|       |
  275|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i) const { return m_data[i * m_incr.value()]; }
  276|       |
  277|       |  template <typename PacketType>
  278|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacket(Index i) const {
  279|       |    return pgather<Scalar, PacketType>(m_data + i * m_incr.value(), m_incr.value());
  280|       |  }
  281|       |
  282|       |  template <typename PacketType>
  283|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacketPartial(Index i, Index n, Index /*offset*/ = 0) const {
  284|       |    return pgather_partial<Scalar, PacketType>(m_data + i * m_incr.value(), m_incr.value(), n);
  285|       |  }
  286|       |
  287|       |  template <typename PacketType>
  288|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacket(Index i, const PacketType& p) const {
  289|       |    pscatter<Scalar, PacketType>(m_data + i * m_incr.value(), p, m_incr.value());
  290|       |  }
  291|       |
  292|       |  template <typename PacketType>
  293|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacketPartial(Index i, const PacketType& p, Index n,
  294|       |                                                                Index /*offset*/ = 0) const {
  295|       |    pscatter_partial<Scalar, PacketType>(m_data + i * m_incr.value(), p, m_incr.value(), n);
  296|       |  }
  297|       |
  298|       | protected:
  299|       |  Scalar* m_data;
  300|       |  const internal::variable_if_dynamic<Index, Incr> m_incr;
  301|       |};
  302|       |
  303|       |template <typename Scalar, typename Index, int StorageOrder, int AlignmentType, int Incr>
  304|       |class blas_data_mapper {
  305|       | public:
  306|       |  typedef BlasLinearMapper<Scalar, Index, AlignmentType, Incr> LinearMapper;
  307|       |  typedef blas_data_mapper SubMapper;
  308|       |
  309|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE blas_data_mapper(Scalar* data, Index stride, Index incr)
  310|       |      : m_data(data), m_stride(stride), m_incr(incr) {}
  311|       |
  312|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE SubMapper getSubMapper(Index i, Index j) const {
  313|       |    return SubMapper(&operator()(i, j), m_stride, m_incr.value());
  314|       |  }
  315|       |
  316|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE LinearMapper getLinearMapper(Index i, Index j) const {
  317|       |    return LinearMapper(&operator()(i, j), m_incr.value());
  318|       |  }
  319|       |
  320|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void prefetch(Index i, Index j) const { internal::prefetch(&operator()(i, j)); }
  321|       |
  322|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i, Index j) const {
  323|       |    return m_data[StorageOrder == RowMajor ? j * m_incr.value() + i * m_stride : i * m_incr.value() + j * m_stride];
  324|       |  }
  325|       |
  326|       |  template <typename PacketType>
  327|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacket(Index i, Index j) const {
  328|       |    return pgather<Scalar, PacketType>(&operator()(i, j), m_incr.value());
  329|       |  }
  330|       |
  331|       |  template <typename PacketType>
  332|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacketPartial(Index i, Index j, Index n,
  333|       |                                                                     Index /*offset*/ = 0) const {
  334|       |    return pgather_partial<Scalar, PacketType>(&operator()(i, j), m_incr.value(), n);
  335|       |  }
  336|       |
  337|       |  template <typename PacketT, int AlignmentT>
  338|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketT load(Index i, Index j) const {
  339|       |    return pgather<Scalar, PacketT>(&operator()(i, j), m_incr.value());
  340|       |  }
  341|       |
  342|       |  template <typename PacketType>
  343|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacket(Index i, Index j, const PacketType& p) const {
  344|       |    pscatter<Scalar, PacketType>(&operator()(i, j), p, m_incr.value());
  345|       |  }
  346|       |
  347|       |  template <typename PacketType>
  348|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacketPartial(Index i, Index j, const PacketType& p, Index n,
  349|       |                                                                Index /*offset*/ = 0) const {
  350|       |    pscatter_partial<Scalar, PacketType>(&operator()(i, j), p, m_incr.value(), n);
  351|       |  }
  352|       |
  353|       |  template <typename SubPacket>
  354|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void scatterPacket(Index i, Index j, const SubPacket& p) const {
  355|       |    pscatter<Scalar, SubPacket>(&operator()(i, j), p, m_stride);
  356|       |  }
  357|       |
  358|       |  template <typename SubPacket>
  359|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE SubPacket gatherPacket(Index i, Index j) const {
  360|       |    return pgather<Scalar, SubPacket>(&operator()(i, j), m_stride);
  361|       |  }
  362|       |
  363|       |  // storePacketBlock_helper defines a way to access values inside the PacketBlock, this is essentially required by the
  364|       |  // Complex types.
  365|       |  template <typename SubPacket, typename Scalar_, int n, int idx>
  366|       |  struct storePacketBlock_helper {
  367|       |    storePacketBlock_helper<SubPacket, Scalar_, n, idx - 1> spbh;
  368|       |    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(
  369|       |        const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup, Index i, Index j,
  370|       |        const PacketBlock<SubPacket, n>& block) const {
  371|       |      spbh.store(sup, i, j, block);
  372|       |      sup->template storePacket<SubPacket>(i, j + idx, block.packet[idx]);
  373|       |    }
  374|       |  };
  375|       |
  376|       |  template <typename SubPacket, int n, int idx>
  377|       |  struct storePacketBlock_helper<SubPacket, std::complex<float>, n, idx> {
  378|       |    storePacketBlock_helper<SubPacket, std::complex<float>, n, idx - 1> spbh;
  379|       |    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(
  380|       |        const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup, Index i, Index j,
  381|       |        const PacketBlock<SubPacket, n>& block) const {
  382|       |      spbh.store(sup, i, j, block);
  383|       |      sup->template storePacket<SubPacket>(i, j + idx, block.packet[idx]);
  384|       |    }
  385|       |  };
  386|       |
  387|       |  template <typename SubPacket, int n, int idx>
  388|       |  struct storePacketBlock_helper<SubPacket, std::complex<double>, n, idx> {
  389|       |    storePacketBlock_helper<SubPacket, std::complex<double>, n, idx - 1> spbh;
  390|       |    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(
  391|       |        const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup, Index i, Index j,
  392|       |        const PacketBlock<SubPacket, n>& block) const {
  393|       |      spbh.store(sup, i, j, block);
  394|       |      for (int l = 0; l < unpacket_traits<SubPacket>::size; l++) {
  395|       |        std::complex<double>* v = &sup->operator()(i + l, j + idx);
  396|       |        v->real(block.packet[idx].v[2 * l + 0]);
  397|       |        v->imag(block.packet[idx].v[2 * l + 1]);
  398|       |      }
  399|       |    }
  400|       |  };
  401|       |
  402|       |  template <typename SubPacket, typename Scalar_, int n>
  403|       |  struct storePacketBlock_helper<SubPacket, Scalar_, n, -1> {
  404|       |    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(
  405|       |        const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*, Index, Index,
  406|       |        const PacketBlock<SubPacket, n>&) const {}
  407|       |  };
  408|       |
  409|       |  template <typename SubPacket, int n>
  410|       |  struct storePacketBlock_helper<SubPacket, std::complex<float>, n, -1> {
  411|       |    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(
  412|       |        const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*, Index, Index,
  413|       |        const PacketBlock<SubPacket, n>&) const {}
  414|       |  };
  415|       |
  416|       |  template <typename SubPacket, int n>
  417|       |  struct storePacketBlock_helper<SubPacket, std::complex<double>, n, -1> {
  418|       |    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(
  419|       |        const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*, Index, Index,
  420|       |        const PacketBlock<SubPacket, n>&) const {}
  421|       |  };
  422|       |  // This function stores a PacketBlock on m_data, this approach is really quite slow compare to Incr=1 and should be
  423|       |  // avoided when possible.
  424|       |  template <typename SubPacket, int n>
  425|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacketBlock(Index i, Index j,
  426|       |                                                              const PacketBlock<SubPacket, n>& block) const {
  427|       |    storePacketBlock_helper<SubPacket, Scalar, n, n - 1> spb;
  428|       |    spb.store(this, i, j, block);
  429|       |  }
  430|       |
  431|       |  EIGEN_DEVICE_FUNC const Index stride() const { return m_stride; }
  432|       |  EIGEN_DEVICE_FUNC const Index incr() const { return m_incr.value(); }
  433|       |  EIGEN_DEVICE_FUNC constexpr Scalar* data() const { return m_data; }
  434|       |
  435|       | protected:
  436|       |  Scalar* EIGEN_RESTRICT m_data;
  437|       |  const Index m_stride;
  438|       |  const internal::variable_if_dynamic<Index, Incr> m_incr;
  439|       |};
  440|       |
  441|       |// lightweight helper class to access matrix coefficients (const version)
  442|       |template <typename Scalar, typename Index, int StorageOrder>
  443|       |class const_blas_data_mapper : public blas_data_mapper<const Scalar, Index, StorageOrder> {
  444|       | public:
  445|       |  typedef const_blas_data_mapper<Scalar, Index, StorageOrder> SubMapper;
  446|       |
  447|       |  EIGEN_ALWAYS_INLINE const_blas_data_mapper(const Scalar* data, Index stride)
  448|      8|      : blas_data_mapper<const Scalar, Index, StorageOrder>(data, stride) {}
  ------------------
  | _ZN5Eigen8internal22const_blas_data_mapperI14AnnoyingScalarlLi0EEC2EPKS2_l:
  |  448|      8|      : blas_data_mapper<const Scalar, Index, StorageOrder>(data, stride) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22const_blas_data_mapperI14AnnoyingScalarlLi1EEC2EPKS2_l
  ------------------
  449|       |
  450|      4|  EIGEN_ALWAYS_INLINE SubMapper getSubMapper(Index i, Index j) const {
  451|      4|    return SubMapper(&(this->operator()(i, j)), this->m_stride);
  452|      4|  }
  453|       |};
  454|       |
  455|       |/* Helper class to analyze the factors of a Product expression.
  456|       | * In particular it allows to pop out operator-, scalar multiples,
  457|       | * and conjugate */
  458|       |template <typename XprType>
  459|       |struct blas_traits {
  460|       |  typedef typename traits<XprType>::Scalar Scalar;
  461|       |  typedef const XprType& ExtractType;
  462|       |  typedef XprType ExtractType_;
  463|       |  enum {
  464|       |    IsComplex = NumTraits<Scalar>::IsComplex,
  465|       |    IsTransposed = false,
  466|       |    NeedToConjugate = false,
  467|       |    HasUsableDirectAccess =
  468|       |        ((int(XprType::Flags) & DirectAccessBit) &&
  469|       |         (bool(XprType::IsVectorAtCompileTime) || int(inner_stride_at_compile_time<XprType>::ret) == 1))
  470|       |            ? 1
  471|       |            : 0,
  472|       |    HasScalarFactor = false
  473|       |  };
  474|       |  typedef std::conditional_t<bool(HasUsableDirectAccess), ExtractType, typename ExtractType_::PlainObject>
  475|       |      DirectLinearAccessType;
  476|      5|  EIGEN_DEVICE_FUNC static inline EIGEN_DEVICE_FUNC ExtractType extract(const XprType& x) { return x; }
  ------------------
  | _ZN5Eigen8internal11blas_traitsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE7extractERKS4_:
  |  476|      4|  EIGEN_DEVICE_FUNC static inline EIGEN_DEVICE_FUNC ExtractType extract(const XprType& x) { return x; }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE7extractERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE7extractERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE7extractERKS4_
  ------------------
  | _ZN5Eigen8internal11blas_traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEEE7extractERKS6_:
  |  476|      1|  EIGEN_DEVICE_FUNC static inline EIGEN_DEVICE_FUNC ExtractType extract(const XprType& x) { return x; }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE7extractERKS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEE7extractERKS8_
  ------------------
  477|      4|  EIGEN_DEVICE_FUNC static inline EIGEN_DEVICE_FUNC const Scalar extractScalarFactor(const XprType&) {
  478|      4|    return Scalar(1);
  479|      4|  }
  ------------------
  | _ZN5Eigen8internal11blas_traitsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE19extractScalarFactorERKS4_:
  |  477|      4|  EIGEN_DEVICE_FUNC static inline EIGEN_DEVICE_FUNC const Scalar extractScalarFactor(const XprType&) {
  |  478|      4|    return Scalar(1);
  |  479|      4|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE19extractScalarFactorERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE19extractScalarFactorERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE19extractScalarFactorERKS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEEE19extractScalarFactorERKS6_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEE19extractScalarFactorERKS4_
  ------------------
  480|       |};
  481|       |
  482|       |// pop conjugate
  483|       |template <typename Scalar, typename NestedXpr>
  484|       |struct blas_traits<CwiseUnaryOp<scalar_conjugate_op<Scalar>, NestedXpr> > : blas_traits<NestedXpr> {
  485|       |  typedef blas_traits<NestedXpr> Base;
  486|       |  typedef CwiseUnaryOp<scalar_conjugate_op<Scalar>, NestedXpr> XprType;
  487|       |  typedef typename Base::ExtractType ExtractType;
  488|       |
  489|       |  enum { IsComplex = NumTraits<Scalar>::IsComplex, NeedToConjugate = Base::NeedToConjugate ? 0 : IsComplex };
  490|       |  EIGEN_DEVICE_FUNC static inline ExtractType extract(const XprType& x) { return Base::extract(x.nestedExpression()); }
  491|       |  EIGEN_DEVICE_FUNC static inline Scalar extractScalarFactor(const XprType& x) {
  492|       |    return conj(Base::extractScalarFactor(x.nestedExpression()));
  493|       |  }
  494|       |};
  495|       |
  496|       |// pop scalar multiple
  497|       |template <typename Scalar, typename NestedXpr, typename Plain>
  498|       |struct blas_traits<
  499|       |    CwiseBinaryOp<scalar_product_op<Scalar>, const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain>, NestedXpr> >
  500|       |    : blas_traits<NestedXpr> {
  501|       |  enum { HasScalarFactor = true };
  502|       |  typedef blas_traits<NestedXpr> Base;
  503|       |  typedef CwiseBinaryOp<scalar_product_op<Scalar>, const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain>, NestedXpr>
  504|       |      XprType;
  505|       |  typedef typename Base::ExtractType ExtractType;
  506|       |  EIGEN_DEVICE_FUNC static inline EIGEN_DEVICE_FUNC ExtractType extract(const XprType& x) {
  507|       |    return Base::extract(x.rhs());
  508|       |  }
  509|       |  EIGEN_DEVICE_FUNC static inline EIGEN_DEVICE_FUNC Scalar extractScalarFactor(const XprType& x) {
  510|       |    return x.lhs().functor().m_other * Base::extractScalarFactor(x.rhs());
  511|       |  }
  512|       |};
  513|       |template <typename Scalar, typename NestedXpr, typename Plain>
  514|       |struct blas_traits<
  515|       |    CwiseBinaryOp<scalar_product_op<Scalar>, NestedXpr, const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain> > >
  516|       |    : blas_traits<NestedXpr> {
  517|       |  enum { HasScalarFactor = true };
  518|       |  typedef blas_traits<NestedXpr> Base;
  519|       |  typedef CwiseBinaryOp<scalar_product_op<Scalar>, NestedXpr, const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain> >
  520|       |      XprType;
  521|       |  typedef typename Base::ExtractType ExtractType;
  522|       |  EIGEN_DEVICE_FUNC static inline ExtractType extract(const XprType& x) { return Base::extract(x.lhs()); }
  523|       |  EIGEN_DEVICE_FUNC static inline Scalar extractScalarFactor(const XprType& x) {
  524|       |    return Base::extractScalarFactor(x.lhs()) * x.rhs().functor().m_other;
  525|       |  }
  526|       |};
  527|       |template <typename Scalar, typename Plain1, typename Plain2>
  528|       |struct blas_traits<CwiseBinaryOp<scalar_product_op<Scalar>, const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain1>,
  529|       |                                 const CwiseNullaryOp<scalar_constant_op<Scalar>, Plain2> > >
  530|       |    : blas_traits<CwiseNullaryOp<scalar_constant_op<Scalar>, Plain1> > {};
  531|       |
  532|       |// pop opposite
  533|       |template <typename Scalar, typename NestedXpr>
  534|       |struct blas_traits<CwiseUnaryOp<scalar_opposite_op<Scalar>, NestedXpr> > : blas_traits<NestedXpr> {
  535|       |  enum { HasScalarFactor = true };
  536|       |  typedef blas_traits<NestedXpr> Base;
  537|       |  typedef CwiseUnaryOp<scalar_opposite_op<Scalar>, NestedXpr> XprType;
  538|       |  typedef typename Base::ExtractType ExtractType;
  539|       |  EIGEN_DEVICE_FUNC static inline ExtractType extract(const XprType& x) { return Base::extract(x.nestedExpression()); }
  540|       |  EIGEN_DEVICE_FUNC static inline Scalar extractScalarFactor(const XprType& x) {
  541|       |    return -Base::extractScalarFactor(x.nestedExpression());
  542|       |  }
  543|       |};
  544|       |
  545|       |// pop/push transpose
  546|       |template <typename NestedXpr>
  547|       |struct blas_traits<Transpose<NestedXpr> > : blas_traits<NestedXpr> {
  548|       |  typedef typename NestedXpr::Scalar Scalar;
  549|       |  typedef blas_traits<NestedXpr> Base;
  550|       |  typedef Transpose<NestedXpr> XprType;
  551|       |  typedef Transpose<const typename Base::ExtractType_>
  552|       |      ExtractType;  // const to get rid of a compile error; anyway blas traits are only used on the RHS
  553|       |  typedef Transpose<const typename Base::ExtractType_> ExtractType_;
  554|       |  typedef std::conditional_t<bool(Base::HasUsableDirectAccess), ExtractType, typename ExtractType::PlainObject>
  555|       |      DirectLinearAccessType;
  556|       |  enum { IsTransposed = Base::IsTransposed ? 0 : 1 };
  557|      0|  EIGEN_DEVICE_FUNC static inline ExtractType extract(const XprType& x) {
  558|      0|    return ExtractType(Base::extract(x.nestedExpression()));
  559|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEE7extractERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE7extractERKSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEE7extractERKS7_
  ------------------
  560|      0|  EIGEN_DEVICE_FUNC static inline Scalar extractScalarFactor(const XprType& x) {
  561|      0|    return Base::extractScalarFactor(x.nestedExpression());
  562|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEE19extractScalarFactorERKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE19extractScalarFactorERKSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal11blas_traitsINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEE19extractScalarFactorERKS7_
  ------------------
  563|       |};
  564|       |
  565|       |template <typename T>
  566|       |struct blas_traits<const T> : blas_traits<T> {};
  567|       |
  568|       |template <typename T, bool HasUsableDirectAccess = blas_traits<T>::HasUsableDirectAccess>
  569|       |struct extract_data_selector {
  570|      0|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static const typename T::Scalar* run(const T& m) {
  571|      0|    return blas_traits<T>::extract(m).data();
  572|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21extract_data_selectorINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELb1EE3runERKSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21extract_data_selectorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEELb1EE3runERKS8_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21extract_data_selectorINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEELb1EE3runERKS7_
  ------------------
  573|       |};
  574|       |
  575|       |template <typename T>
  576|       |struct extract_data_selector<T, false> {
  577|       |  EIGEN_DEVICE_FUNC static typename T::Scalar* run(const T&) { return 0; }
  578|       |};
  579|       |
  580|       |template <typename T>
  581|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE const typename T::Scalar* extract_data(const T& m) {
  582|      0|  return extract_data_selector<T>::run(m);
  583|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12extract_dataINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEEPKNT_6ScalarERKSB_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12extract_dataINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEEPKNT_6ScalarERKS9_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal12extract_dataINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEEEPKNT_6ScalarERKS8_
  ------------------
  584|       |
  585|       |/**
  586|       | * \c combine_scalar_factors extracts and multiplies factors from GEMM and GEMV products.
  587|       | * There is a specialization for booleans
  588|       | */
  589|       |template <typename ResScalar, typename Lhs, typename Rhs>
  590|       |struct combine_scalar_factors_impl {
  591|      0|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static ResScalar run(const Lhs& lhs, const Rhs& rhs) {
  592|      0|    return blas_traits<Lhs>::extractScalarFactor(lhs) * blas_traits<Rhs>::extractScalarFactor(rhs);
  593|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27combine_scalar_factors_implI14AnnoyingScalarNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEES4_E3runERKS4_S7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27combine_scalar_factors_implI14AnnoyingScalarNS_7ProductINS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_E3runERKS6_RKS5_
  ------------------
  594|      2|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static ResScalar run(const ResScalar& alpha, const Lhs& lhs, const Rhs& rhs) {
  595|      2|    return alpha * blas_traits<Lhs>::extractScalarFactor(lhs) * blas_traits<Rhs>::extractScalarFactor(rhs);
  596|      2|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27combine_scalar_factors_implI14AnnoyingScalarNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEENS_5BlockIKS4_Lin1ELi1ELb1EEEE3runERKS2_RS6_RKS7_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27combine_scalar_factors_implI14AnnoyingScalarNS_9TransposeIKNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEEEENS3_IKNS_5BlockIS6_Li1ELin1ELb0EEEEEE3runERKS2_RKS7_RKSB_
  ------------------
  | _ZN5Eigen8internal27combine_scalar_factors_implI14AnnoyingScalarNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEES4_E3runERKS2_RKS4_S9_:
  |  594|      2|  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static ResScalar run(const ResScalar& alpha, const Lhs& lhs, const Rhs& rhs) {
  |  595|      2|    return alpha * blas_traits<Lhs>::extractScalarFactor(lhs) * blas_traits<Rhs>::extractScalarFactor(rhs);
  |  596|      2|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27combine_scalar_factors_implI14AnnoyingScalarNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEENS3_IS2_Lin1ELi1ELi0ELin1ELi1EEEE3runERKS2_RKS4_RKS5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27combine_scalar_factors_implI14AnnoyingScalarNS_9TransposeIKNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEEEENS3_IKNS4_IS2_Li1ELin1ELi1ELi1ELin1EEEEEE3runERKS2_RKS7_RKSA_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal27combine_scalar_factors_implI14AnnoyingScalarNS_7ProductINS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_E3runERKS2_RKS6_RKS5_
  ------------------
  597|       |};
  598|       |template <typename Lhs, typename Rhs>
  599|       |struct combine_scalar_factors_impl<bool, Lhs, Rhs> {
  600|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static bool run(const Lhs& lhs, const Rhs& rhs) {
  601|       |    return blas_traits<Lhs>::extractScalarFactor(lhs) && blas_traits<Rhs>::extractScalarFactor(rhs);
  602|       |  }
  603|       |  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static bool run(const bool& alpha, const Lhs& lhs, const Rhs& rhs) {
  604|       |    return alpha && blas_traits<Lhs>::extractScalarFactor(lhs) && blas_traits<Rhs>::extractScalarFactor(rhs);
  605|       |  }
  606|       |};
  607|       |
  608|       |template <typename ResScalar, typename Lhs, typename Rhs>
  609|       |EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE ResScalar combine_scalar_factors(const ResScalar& alpha, const Lhs& lhs,
  610|      2|                                                                       const Rhs& rhs) {
  611|      2|  return combine_scalar_factors_impl<ResScalar, Lhs, Rhs>::run(alpha, lhs, rhs);
  612|      2|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22combine_scalar_factorsI14AnnoyingScalarNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEENS_5BlockIKS4_Lin1ELi1ELb1EEEEET_RKS8_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22combine_scalar_factorsI14AnnoyingScalarNS_9TransposeIKNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEEEENS3_IKNS_5BlockIS6_Li1ELin1ELb0EEEEEEET_RKSC_RKT0_RKT1_
  ------------------
  | _ZN5Eigen8internal22combine_scalar_factorsI14AnnoyingScalarNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEES4_EET_RKS5_RKT0_RKT1_:
  |  610|      2|                                                                       const Rhs& rhs) {
  |  611|      2|  return combine_scalar_factors_impl<ResScalar, Lhs, Rhs>::run(alpha, lhs, rhs);
  |  612|      2|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22combine_scalar_factorsI14AnnoyingScalarNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEENS3_IS2_Lin1ELi1ELi0ELin1ELi1EEEEET_RKS6_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22combine_scalar_factorsI14AnnoyingScalarNS_9TransposeIKNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEEEENS3_IKNS4_IS2_Li1ELin1ELi1ELi1ELin1EEEEEEET_RKSB_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22combine_scalar_factorsI14AnnoyingScalarNS_7ProductINS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_EET_RKS7_RKT0_RKT1_
  ------------------
  613|       |template <typename ResScalar, typename Lhs, typename Rhs>
  614|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE ResScalar combine_scalar_factors(const Lhs& lhs, const Rhs& rhs) {
  615|      0|  return combine_scalar_factors_impl<ResScalar, Lhs, Rhs>::run(lhs, rhs);
  616|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22combine_scalar_factorsI14AnnoyingScalarNS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEES4_EET_RKT0_RKT1_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22combine_scalar_factorsI14AnnoyingScalarNS_7ProductINS_6MatrixIS2_Lin1ELin1ELi0ELin1ELin1EEES5_Li0EEES5_EET_RKT0_RKT1_
  ------------------
  617|       |
  618|       |}  // end namespace internal
  619|       |
  620|       |}  // end namespace Eigen
  621|       |
  622|       |#endif  // EIGEN_BLASUTIL_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/ConfigureVectorization.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2018 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2020, Arm Limited and Contributors
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_CONFIGURE_VECTORIZATION_H
   12|       |#define EIGEN_CONFIGURE_VECTORIZATION_H
   13|       |
   14|       |//------------------------------------------------------------------------------------------
   15|       |// Static and dynamic alignment control
   16|       |//
   17|       |// The main purpose of this section is to define EIGEN_MAX_ALIGN_BYTES and EIGEN_MAX_STATIC_ALIGN_BYTES
   18|       |// as the maximal boundary in bytes on which dynamically and statically allocated data may be alignment respectively.
   19|       |// The values of EIGEN_MAX_ALIGN_BYTES and EIGEN_MAX_STATIC_ALIGN_BYTES can be specified by the user. If not,
   20|       |// a default value is automatically computed based on architecture, compiler, and OS.
   21|       |//
   22|       |// This section also defines macros EIGEN_ALIGN_TO_BOUNDARY(N) and the shortcuts EIGEN_ALIGN{8,16,32,_MAX}
   23|       |// to be used to declare statically aligned buffers.
   24|       |//------------------------------------------------------------------------------------------
   25|       |
   26|       |/* EIGEN_ALIGN_TO_BOUNDARY(n) forces data to be n-byte aligned. This is used to satisfy SIMD requirements.
   27|       | * However, we do that EVEN if vectorization (EIGEN_VECTORIZE) is disabled,
   28|       | * so that vectorization doesn't affect binary compatibility.
   29|       | *
   30|       | * If we made alignment depend on whether or not EIGEN_VECTORIZE is defined, it would be impossible to link
   31|       | * vectorized and non-vectorized code.
   32|       | */
   33|       |#if (defined EIGEN_CUDACC)
   34|       |#define EIGEN_ALIGN_TO_BOUNDARY(n) __align__(n)
   35|       |#define EIGEN_ALIGNOF(x) __alignof(x)
   36|       |#else
   37|       |#define EIGEN_ALIGN_TO_BOUNDARY(n) alignas(n)
   38|       |#define EIGEN_ALIGNOF(x) alignof(x)
   39|       |#endif
   40|       |
   41|       |// Align to the boundary that avoids false sharing.
   42|       |// https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size
   43|       |#ifdef __cpp_lib_hardware_interference_size
   44|       |#include <new>
   45|       |#define EIGEN_ALIGN_TO_AVOID_FALSE_SHARING EIGEN_ALIGN_TO_BOUNDARY(std::hardware_destructive_interference_size)
   46|       |#else
   47|       |// Overalign for the cache line size of 128 bytes (Apple M1)
   48|       |#define EIGEN_ALIGN_TO_AVOID_FALSE_SHARING EIGEN_ALIGN_TO_BOUNDARY(128)
   49|       |#endif
   50|       |
   51|       |// If the user explicitly disable vectorization, then we also disable alignment
   52|       |#if defined(EIGEN_DONT_VECTORIZE)
   53|       |#if defined(EIGEN_GPUCC)
   54|       |// GPU code is always vectorized and requires memory alignment for
   55|       |// statically allocated buffers.
   56|       |#define EIGEN_IDEAL_MAX_ALIGN_BYTES 16
   57|       |#else
   58|       |#define EIGEN_IDEAL_MAX_ALIGN_BYTES 0
   59|       |#endif
   60|       |#elif defined(__AVX512F__)
   61|       |// 64 bytes static alignment is preferred only if really required
   62|       |#define EIGEN_IDEAL_MAX_ALIGN_BYTES 64
   63|       |#elif defined(__AVX__)
   64|       |// 32 bytes static alignment is preferred only if really required
   65|       |#define EIGEN_IDEAL_MAX_ALIGN_BYTES 32
   66|       |#elif defined __HVX__ && (__HVX_LENGTH__ == 128)
   67|       |#define EIGEN_IDEAL_MAX_ALIGN_BYTES 128
   68|       |#else
   69|      4|#define EIGEN_IDEAL_MAX_ALIGN_BYTES 16
   70|       |#endif
   71|       |
   72|       |// EIGEN_MIN_ALIGN_BYTES defines the minimal value for which the notion of explicit alignment makes sense
   73|       |#define EIGEN_MIN_ALIGN_BYTES 16
   74|       |
   75|       |// Defined the boundary (in bytes) on which the data needs to be aligned. Note
   76|       |// that unless EIGEN_ALIGN is defined and not equal to 0, the data may not be
   77|       |// aligned at all regardless of the value of this #define.
   78|       |
   79|       |#if (defined(EIGEN_DONT_ALIGN_STATICALLY) || defined(EIGEN_DONT_ALIGN)) && defined(EIGEN_MAX_STATIC_ALIGN_BYTES) && \
   80|       |    EIGEN_MAX_STATIC_ALIGN_BYTES > 0
   81|       |#error EIGEN_MAX_STATIC_ALIGN_BYTES and EIGEN_DONT_ALIGN[_STATICALLY] are both defined with EIGEN_MAX_STATIC_ALIGN_BYTES!=0. Use EIGEN_MAX_STATIC_ALIGN_BYTES=0 as a synonym of EIGEN_DONT_ALIGN_STATICALLY.
   82|       |#endif
   83|       |
   84|       |// EIGEN_DONT_ALIGN_STATICALLY and EIGEN_DONT_ALIGN are deprecated
   85|       |// They imply EIGEN_MAX_STATIC_ALIGN_BYTES=0
   86|       |#if defined(EIGEN_DONT_ALIGN_STATICALLY) || defined(EIGEN_DONT_ALIGN)
   87|       |#ifdef EIGEN_MAX_STATIC_ALIGN_BYTES
   88|       |#undef EIGEN_MAX_STATIC_ALIGN_BYTES
   89|       |#endif
   90|       |#define EIGEN_MAX_STATIC_ALIGN_BYTES 0
   91|       |#endif
   92|       |
   93|       |#ifndef EIGEN_MAX_STATIC_ALIGN_BYTES
   94|       |
   95|       |// Try to automatically guess what is the best default value for EIGEN_MAX_STATIC_ALIGN_BYTES
   96|       |
   97|       |// 16 byte alignment is only useful for vectorization. Since it affects the ABI, we need to enable
   98|       |// 16 byte alignment on all platforms where vectorization might be enabled. In theory we could always
   99|       |// enable alignment, but it can be a cause of problems on some platforms, so we just disable it in
  100|       |// certain common platform (compiler+architecture combinations) to avoid these problems.
  101|       |// Only static alignment is really problematic (relies on nonstandard compiler extensions),
  102|       |// try to keep heap alignment even when we have to disable static alignment.
  103|       |#if EIGEN_COMP_GNUC && !(EIGEN_ARCH_i386_OR_x86_64 || EIGEN_ARCH_ARM_OR_ARM64 || EIGEN_ARCH_PPC || EIGEN_ARCH_IA64 || \
  104|       |                         EIGEN_ARCH_MIPS || EIGEN_ARCH_LOONGARCH64)
  105|       |#define EIGEN_GCC_AND_ARCH_DOESNT_WANT_STACK_ALIGNMENT 1
  106|       |#else
  107|       |#define EIGEN_GCC_AND_ARCH_DOESNT_WANT_STACK_ALIGNMENT 0
  108|       |#endif
  109|       |
  110|       |// static alignment is completely disabled with GCC 3, Sun Studio, and QCC/QNX
  111|       |#if !EIGEN_GCC_AND_ARCH_DOESNT_WANT_STACK_ALIGNMENT && !EIGEN_COMP_SUNCC && !EIGEN_OS_QNX
  112|       |#define EIGEN_ARCH_WANTS_STACK_ALIGNMENT 1
  113|       |#else
  114|       |#define EIGEN_ARCH_WANTS_STACK_ALIGNMENT 0
  115|       |#endif
  116|       |
  117|       |#if EIGEN_ARCH_WANTS_STACK_ALIGNMENT
  118|       |#define EIGEN_MAX_STATIC_ALIGN_BYTES EIGEN_IDEAL_MAX_ALIGN_BYTES
  119|       |#else
  120|       |#define EIGEN_MAX_STATIC_ALIGN_BYTES 0
  121|       |#endif
  122|       |
  123|       |#endif
  124|       |
  125|       |// If EIGEN_MAX_ALIGN_BYTES is defined, then it is considered as an upper bound for EIGEN_MAX_STATIC_ALIGN_BYTES
  126|       |#if defined(EIGEN_MAX_ALIGN_BYTES) && EIGEN_MAX_ALIGN_BYTES < EIGEN_MAX_STATIC_ALIGN_BYTES
  127|       |#undef EIGEN_MAX_STATIC_ALIGN_BYTES
  128|       |#define EIGEN_MAX_STATIC_ALIGN_BYTES EIGEN_MAX_ALIGN_BYTES
  129|       |#endif
  130|       |
  131|       |#if EIGEN_MAX_STATIC_ALIGN_BYTES == 0 && !defined(EIGEN_DISABLE_UNALIGNED_ARRAY_ASSERT)
  132|       |#define EIGEN_DISABLE_UNALIGNED_ARRAY_ASSERT
  133|       |#endif
  134|       |
  135|       |// At this stage, EIGEN_MAX_STATIC_ALIGN_BYTES>0 is the true test whether we want to align arrays on the stack or not.
  136|       |// It takes into account both the user choice to explicitly enable/disable alignment (by setting
  137|       |// EIGEN_MAX_STATIC_ALIGN_BYTES) and the architecture config (EIGEN_ARCH_WANTS_STACK_ALIGNMENT). Henceforth, only
  138|       |// EIGEN_MAX_STATIC_ALIGN_BYTES should be used.
  139|       |
  140|       |// Shortcuts to EIGEN_ALIGN_TO_BOUNDARY
  141|       |#define EIGEN_ALIGN8 EIGEN_ALIGN_TO_BOUNDARY(8)
  142|       |#define EIGEN_ALIGN16 EIGEN_ALIGN_TO_BOUNDARY(16)
  143|       |#define EIGEN_ALIGN32 EIGEN_ALIGN_TO_BOUNDARY(32)
  144|       |#define EIGEN_ALIGN64 EIGEN_ALIGN_TO_BOUNDARY(64)
  145|       |#if EIGEN_MAX_STATIC_ALIGN_BYTES > 0
  146|       |#define EIGEN_ALIGN_MAX EIGEN_ALIGN_TO_BOUNDARY(EIGEN_MAX_STATIC_ALIGN_BYTES)
  147|       |#else
  148|       |#define EIGEN_ALIGN_MAX
  149|       |#endif
  150|       |
  151|       |// Dynamic alignment control
  152|       |
  153|       |#if defined(EIGEN_DONT_ALIGN) && defined(EIGEN_MAX_ALIGN_BYTES) && EIGEN_MAX_ALIGN_BYTES > 0
  154|       |#error EIGEN_MAX_ALIGN_BYTES and EIGEN_DONT_ALIGN are both defined with EIGEN_MAX_ALIGN_BYTES!=0. Use EIGEN_MAX_ALIGN_BYTES=0 as a synonym of EIGEN_DONT_ALIGN.
  155|       |#endif
  156|       |
  157|       |#ifdef EIGEN_DONT_ALIGN
  158|       |#ifdef EIGEN_MAX_ALIGN_BYTES
  159|       |#undef EIGEN_MAX_ALIGN_BYTES
  160|       |#endif
  161|       |#define EIGEN_MAX_ALIGN_BYTES 0
  162|       |#elif !defined(EIGEN_MAX_ALIGN_BYTES)
  163|      4|#define EIGEN_MAX_ALIGN_BYTES EIGEN_IDEAL_MAX_ALIGN_BYTES
  164|       |#endif
  165|       |
  166|       |#if EIGEN_IDEAL_MAX_ALIGN_BYTES > EIGEN_MAX_ALIGN_BYTES
  167|       |#define EIGEN_DEFAULT_ALIGN_BYTES EIGEN_IDEAL_MAX_ALIGN_BYTES
  168|       |#else
  169|      4|#define EIGEN_DEFAULT_ALIGN_BYTES EIGEN_MAX_ALIGN_BYTES
  170|       |#endif
  171|       |
  172|       |#ifndef EIGEN_UNALIGNED_VECTORIZE
  173|       |#define EIGEN_UNALIGNED_VECTORIZE 1
  174|       |#endif
  175|       |
  176|       |//----------------------------------------------------------------------
  177|       |
  178|       |// if alignment is disabled, then disable vectorization. Note: EIGEN_MAX_ALIGN_BYTES is the proper check, it takes into
  179|       |// account both the user's will (EIGEN_MAX_ALIGN_BYTES,EIGEN_DONT_ALIGN) and our own platform checks
  180|       |#if EIGEN_MAX_ALIGN_BYTES == 0
  181|       |#ifndef EIGEN_DONT_VECTORIZE
  182|       |#define EIGEN_DONT_VECTORIZE
  183|       |#endif
  184|       |#endif
  185|       |
  186|       |// The following (except #include <malloc.h> and _M_IX86_FP ??) can likely be
  187|       |// removed as gcc 4.1 and msvc 2008 are not supported anyways.
  188|       |#if EIGEN_COMP_MSVC
  189|       |#include <malloc.h>  // for _aligned_malloc -- need it regardless of whether vectorization is enabled
  190|       |// a user reported that in 64-bit mode, MSVC doesn't care to define _M_IX86_FP.
  191|       |#if (defined(_M_IX86_FP) && (_M_IX86_FP >= 2)) || EIGEN_ARCH_x86_64
  192|       |#define EIGEN_SSE2_ON_MSVC_2008_OR_LATER
  193|       |#endif
  194|       |#else
  195|       |#if defined(__SSE2__)
  196|       |#define EIGEN_SSE2_ON_NON_MSVC
  197|       |#endif
  198|       |#endif
  199|       |
  200|       |#if !(defined(EIGEN_DONT_VECTORIZE) || defined(EIGEN_GPUCC))
  201|       |
  202|       |#if defined(EIGEN_SSE2_ON_NON_MSVC) || defined(EIGEN_SSE2_ON_MSVC_2008_OR_LATER)
  203|       |
  204|       |// Defines symbols for compile-time detection of which instructions are
  205|       |// used.
  206|       |// EIGEN_VECTORIZE_YY is defined if and only if the instruction set YY is used
  207|       |#define EIGEN_VECTORIZE
  208|       |#define EIGEN_VECTORIZE_SSE
  209|       |#define EIGEN_VECTORIZE_SSE2
  210|       |
  211|       |// Detect sse3/ssse3/sse4:
  212|       |// gcc and icc defines __SSE3__, ...
  213|       |// there is no way to know about this on msvc. You can define EIGEN_VECTORIZE_SSE* if you
  214|       |// want to force the use of those instructions with msvc.
  215|       |#ifdef __SSE3__
  216|       |#define EIGEN_VECTORIZE_SSE3
  217|       |#endif
  218|       |#ifdef __SSSE3__
  219|       |#define EIGEN_VECTORIZE_SSSE3
  220|       |#endif
  221|       |#ifdef __SSE4_1__
  222|       |#define EIGEN_VECTORIZE_SSE4_1
  223|       |#endif
  224|       |#ifdef __SSE4_2__
  225|       |#define EIGEN_VECTORIZE_SSE4_2
  226|       |#endif
  227|       |#ifdef __AVX__
  228|       |#ifndef EIGEN_USE_SYCL
  229|       |#define EIGEN_VECTORIZE_AVX
  230|       |#endif
  231|       |#define EIGEN_VECTORIZE_SSE3
  232|       |#define EIGEN_VECTORIZE_SSSE3
  233|       |#define EIGEN_VECTORIZE_SSE4_1
  234|       |#define EIGEN_VECTORIZE_SSE4_2
  235|       |#endif
  236|       |#ifdef __AVX2__
  237|       |#ifndef EIGEN_USE_SYCL
  238|       |#define EIGEN_VECTORIZE_AVX2
  239|       |#define EIGEN_VECTORIZE_AVX
  240|       |#endif
  241|       |#define EIGEN_VECTORIZE_SSE3
  242|       |#define EIGEN_VECTORIZE_SSSE3
  243|       |#define EIGEN_VECTORIZE_SSE4_1
  244|       |#define EIGEN_VECTORIZE_SSE4_2
  245|       |#endif
  246|       |#if defined(__FMA__) || (EIGEN_COMP_MSVC && defined(__AVX2__))
  247|       |// MSVC does not expose a switch dedicated for FMA
  248|       |// For MSVC, AVX2 => FMA
  249|       |#define EIGEN_VECTORIZE_FMA
  250|       |#endif
  251|       |#if defined(__AVX512F__)
  252|       |#ifndef EIGEN_VECTORIZE_FMA
  253|       |#if EIGEN_COMP_GNUC
  254|       |#error Please add -mfma to your compiler flags: compiling with -mavx512f alone without SSE/AVX FMA is not supported (bug 1638).
  255|       |#else
  256|       |#error Please enable FMA in your compiler flags (e.g. -mfma): compiling with AVX512 alone without SSE/AVX FMA is not supported (bug 1638).
  257|       |#endif
  258|       |#endif
  259|       |#ifndef EIGEN_USE_SYCL
  260|       |#define EIGEN_VECTORIZE_AVX512
  261|       |#define EIGEN_VECTORIZE_AVX2
  262|       |#define EIGEN_VECTORIZE_AVX
  263|       |#endif
  264|       |#define EIGEN_VECTORIZE_FMA
  265|       |#define EIGEN_VECTORIZE_SSE3
  266|       |#define EIGEN_VECTORIZE_SSSE3
  267|       |#define EIGEN_VECTORIZE_SSE4_1
  268|       |#define EIGEN_VECTORIZE_SSE4_2
  269|       |#ifndef EIGEN_USE_SYCL
  270|       |#ifdef __AVX512DQ__
  271|       |#define EIGEN_VECTORIZE_AVX512DQ
  272|       |#endif
  273|       |#ifdef __AVX512ER__
  274|       |#define EIGEN_VECTORIZE_AVX512ER
  275|       |#endif
  276|       |#ifdef __AVX512BF16__
  277|       |#define EIGEN_VECTORIZE_AVX512BF16
  278|       |#endif
  279|       |#ifdef __AVX512VL__
  280|       |#define EIGEN_VECTORIZE_AVX512VL
  281|       |#endif
  282|       |#ifdef __AVX512FP16__
  283|       |#ifdef __AVX512VL__
  284|       |#define EIGEN_VECTORIZE_AVX512FP16
  285|       |#else
  286|       |#if EIGEN_COMP_GNUC
  287|       |#error Please add -mavx512vl to your compiler flags: compiling with -mavx512fp16 alone without AVX512-VL is not supported.
  288|       |#else
  289|       |#error Please enable AVX512-VL in your compiler flags (e.g. -mavx512vl): compiling with AVX512-FP16 alone without AVX512-VL is not supported.
  290|       |#endif
  291|       |#endif
  292|       |#endif
  293|       |#endif
  294|       |#endif
  295|       |
  296|       |// Disable AVX support on broken xcode versions
  297|       |#if (EIGEN_COMP_CLANGAPPLE == 11000033) && (__MAC_OS_X_VERSION_MIN_REQUIRED == 101500)
  298|       |// A nasty bug in the clang compiler shipped with xcode in a common compilation situation
  299|       |// when XCode 11.0 and Mac deployment target macOS 10.15 is https://trac.macports.org/ticket/58776#no1
  300|       |#ifdef EIGEN_VECTORIZE_AVX
  301|       |#undef EIGEN_VECTORIZE_AVX
  302|       |#warning \
  303|       |    "Disabling AVX support: clang compiler shipped with XCode 11.[012] generates broken assembly with -macosx-version-min=10.15 and AVX enabled. "
  304|       |#ifdef EIGEN_VECTORIZE_AVX2
  305|       |#undef EIGEN_VECTORIZE_AVX2
  306|       |#endif
  307|       |#ifdef EIGEN_VECTORIZE_FMA
  308|       |#undef EIGEN_VECTORIZE_FMA
  309|       |#endif
  310|       |#ifdef EIGEN_VECTORIZE_AVX512
  311|       |#undef EIGEN_VECTORIZE_AVX512
  312|       |#endif
  313|       |#ifdef EIGEN_VECTORIZE_AVX512DQ
  314|       |#undef EIGEN_VECTORIZE_AVX512DQ
  315|       |#endif
  316|       |#ifdef EIGEN_VECTORIZE_AVX512ER
  317|       |#undef EIGEN_VECTORIZE_AVX512ER
  318|       |#endif
  319|       |#endif
  320|       |// NOTE: Confirmed test failures in XCode 11.0, and XCode 11.2 with  -macosx-version-min=10.15 and AVX
  321|       |// NOTE using -macosx-version-min=10.15 with Xcode 11.0 results in runtime segmentation faults in many tests, 11.2
  322|       |// produce core dumps in 3 tests NOTE using -macosx-version-min=10.14 produces functioning and passing tests in all
  323|       |// cases NOTE __clang_version__ "11.0.0 (clang-1100.0.33.8)"  XCode 11.0 <- Produces many segfault and core dumping
  324|       |// tests
  325|       |//                                                                    with  -macosx-version-min=10.15 and AVX
  326|       |// NOTE __clang_version__ "11.0.0 (clang-1100.0.33.12)" XCode 11.2 <- Produces 3 core dumping tests with
  327|       |//                                                                    -macosx-version-min=10.15 and AVX
  328|       |#endif
  329|       |
  330|       |// include files
  331|       |
  332|       |// This extern "C" works around a MINGW-w64 compilation issue
  333|       |// https://sourceforge.net/tracker/index.php?func=detail&aid=3018394&group_id=202880&atid=983354
  334|       |// In essence, intrin.h is included by windows.h and also declares intrinsics (just as emmintrin.h etc. below do).
  335|       |// However, intrin.h uses an extern "C" declaration, and g++ thus complains of duplicate declarations
  336|       |// with conflicting linkage.  The linkage for intrinsics doesn't matter, but at that stage the compiler doesn't know;
  337|       |// so, to avoid compile errors when windows.h is included after Eigen/Core, ensure intrinsics are extern "C" here too.
  338|       |// notice that since these are C headers, the extern "C" is theoretically needed anyways.
  339|       |extern "C" {
  340|       |// In theory we should only include immintrin.h and not the other *mmintrin.h header files directly.
  341|       |// Doing so triggers some issues with ICC. However old gcc versions seems to not have this file, thus:
  342|       |#if EIGEN_COMP_ICC >= 1110 || EIGEN_COMP_EMSCRIPTEN
  343|       |#include <immintrin.h>
  344|       |#else
  345|       |#include <mmintrin.h>
  346|       |#include <emmintrin.h>
  347|       |#include <xmmintrin.h>
  348|       |#ifdef EIGEN_VECTORIZE_SSE3
  349|       |#include <pmmintrin.h>
  350|       |#endif
  351|       |#ifdef EIGEN_VECTORIZE_SSSE3
  352|       |#include <tmmintrin.h>
  353|       |#endif
  354|       |#ifdef EIGEN_VECTORIZE_SSE4_1
  355|       |#include <smmintrin.h>
  356|       |#endif
  357|       |#ifdef EIGEN_VECTORIZE_SSE4_2
  358|       |#include <nmmintrin.h>
  359|       |#endif
  360|       |#if defined(EIGEN_VECTORIZE_AVX) || defined(EIGEN_VECTORIZE_AVX512)
  361|       |#include <immintrin.h>
  362|       |#endif
  363|       |#endif
  364|       |}  // end extern "C"
  365|       |
  366|       |#elif defined(__VSX__) && !defined(__APPLE__)
  367|       |
  368|       |#define EIGEN_VECTORIZE
  369|       |#define EIGEN_VECTORIZE_VSX 1
  370|       |#define EIGEN_VECTORIZE_FMA
  371|       |#include <altivec.h>
  372|       |// We need to #undef all these ugly tokens defined in <altivec.h>
  373|       |// => use __vector instead of vector
  374|       |#undef bool
  375|       |#undef vector
  376|       |#undef pixel
  377|       |
  378|       |#elif defined __ALTIVEC__
  379|       |
  380|       |#define EIGEN_VECTORIZE
  381|       |#define EIGEN_VECTORIZE_ALTIVEC
  382|       |#define EIGEN_VECTORIZE_FMA
  383|       |#include <altivec.h>
  384|       |// We need to #undef all these ugly tokens defined in <altivec.h>
  385|       |// => use __vector instead of vector
  386|       |#undef bool
  387|       |#undef vector
  388|       |#undef pixel
  389|       |
  390|       |#elif ((defined __ARM_NEON) || (defined __ARM_NEON__)) && !(defined EIGEN_ARM64_USE_SVE)
  391|       |
  392|       |#define EIGEN_VECTORIZE
  393|       |#define EIGEN_VECTORIZE_NEON
  394|       |#include <arm_neon.h>
  395|       |
  396|       |// We currently require SVE to be enabled explicitly via EIGEN_ARM64_USE_SVE and
  397|       |// will not select the backend automatically
  398|       |#elif (defined __ARM_FEATURE_SVE) && (defined EIGEN_ARM64_USE_SVE)
  399|       |
  400|       |#define EIGEN_VECTORIZE
  401|       |#define EIGEN_VECTORIZE_SVE
  402|       |#include <arm_sve.h>
  403|       |
  404|       |// Since we depend on knowing SVE vector lengths at compile-time, we need
  405|       |// to ensure a fixed lengths is set
  406|       |#if defined __ARM_FEATURE_SVE_BITS
  407|       |#define EIGEN_ARM64_SVE_VL __ARM_FEATURE_SVE_BITS
  408|       |#else
  409|       |#error "Eigen requires a fixed SVE lector length but EIGEN_ARM64_SVE_VL is not set."
  410|       |#endif
  411|       |
  412|       |#elif (defined __s390x__ && defined __VEC__)
  413|       |
  414|       |#define EIGEN_VECTORIZE
  415|       |#define EIGEN_VECTORIZE_ZVECTOR
  416|       |#include <vecintrin.h>
  417|       |
  418|       |#elif defined __mips_msa
  419|       |
  420|       |// Limit MSA optimizations to little-endian CPUs for now.
  421|       |// TODO: Perhaps, eventually support MSA optimizations on big-endian CPUs?
  422|       |#if defined(__BYTE_ORDER__) && (__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)
  423|       |#if defined(__LP64__)
  424|       |#define EIGEN_MIPS_64
  425|       |#else
  426|       |#define EIGEN_MIPS_32
  427|       |#endif
  428|       |#define EIGEN_VECTORIZE
  429|       |#define EIGEN_VECTORIZE_MSA
  430|       |#include <msa.h>
  431|       |#endif
  432|       |
  433|       |#elif (defined __loongarch64 && defined __loongarch_sx)
  434|       |
  435|       |#define EIGEN_VECTORIZE
  436|       |#define EIGEN_VECTORIZE_LSX
  437|       |#include <lsxintrin.h>
  438|       |
  439|       |#elif defined __HVX__ && (__HVX_LENGTH__ == 128)
  440|       |
  441|       |#define EIGEN_VECTORIZE
  442|       |#define EIGEN_VECTORIZE_HVX
  443|       |#include <hexagon_types.h>
  444|       |
  445|       |#endif
  446|       |#endif
  447|       |
  448|       |// Following the Arm ACLE arm_neon.h should also include arm_fp16.h but not all
  449|       |// compilers seem to follow this. We therefore include it explicitly.
  450|       |// See also: https://bugs.llvm.org/show_bug.cgi?id=47955
  451|       |#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
  452|       |#include <arm_fp16.h>
  453|       |#endif
  454|       |
  455|       |// Enable FMA for ARM.
  456|       |#if defined(__ARM_FEATURE_FMA)
  457|       |#define EIGEN_VECTORIZE_FMA
  458|       |#endif
  459|       |
  460|       |#if defined(__F16C__) && !defined(EIGEN_GPUCC) && (!EIGEN_COMP_CLANG_STRICT || EIGEN_CLANG_STRICT_AT_LEAST(3, 8, 0))
  461|       |// We can use the optimized fp16 to float and float to fp16 conversion routines
  462|       |#define EIGEN_HAS_FP16_C
  463|       |
  464|       |#if EIGEN_COMP_GNUC
  465|       |// Make sure immintrin.h is included, even if e.g. vectorization is
  466|       |// explicitly disabled (see also issue #2395).
  467|       |// Note that FP16C intrinsics for gcc and clang are included by immintrin.h,
  468|       |// as opposed to emmintrin.h as suggested by Intel:
  469|       |// https://software.intel.com/sites/landingpage/IntrinsicsGuide/#othertechs=FP16C&expand=1711
  470|       |#include <immintrin.h>
  471|       |#endif
  472|       |#endif
  473|       |
  474|       |#if defined EIGEN_CUDACC
  475|       |#define EIGEN_VECTORIZE_GPU
  476|       |#include <vector_types.h>
  477|       |#if EIGEN_CUDA_SDK_VER >= 70500
  478|       |#define EIGEN_HAS_CUDA_FP16
  479|       |#endif
  480|       |#endif
  481|       |
  482|       |#if defined(EIGEN_HAS_CUDA_FP16)
  483|       |#include <cuda_runtime_api.h>
  484|       |#include <cuda_fp16.h>
  485|       |#endif
  486|       |
  487|       |#if defined(EIGEN_HIPCC)
  488|       |#define EIGEN_VECTORIZE_GPU
  489|       |#include <hip/hip_vector_types.h>
  490|       |#define EIGEN_HAS_HIP_FP16
  491|       |#include <hip/hip_fp16.h>
  492|       |#define EIGEN_HAS_HIP_BF16
  493|       |#include <hip/hip_bfloat16.h>
  494|       |#endif
  495|       |
  496|       |/** \brief Namespace containing all symbols from the %Eigen library. */
  497|       |// IWYU pragma: private
  498|       |#include "../InternalHeaderCheck.h"
  499|       |
  500|       |namespace Eigen {
  501|       |
  502|      0|inline static const char *SimdInstructionSetsInUse(void) {
  503|      0|#if defined(EIGEN_VECTORIZE_AVX512)
  504|      0|  return "AVX512, FMA, AVX2, AVX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2";
  505|      0|#elif defined(EIGEN_VECTORIZE_AVX)
  506|      0|  return "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2";
  507|      0|#elif defined(EIGEN_VECTORIZE_SSE4_2)
  508|      0|  return "SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2";
  509|      0|#elif defined(EIGEN_VECTORIZE_SSE4_1)
  510|      0|  return "SSE, SSE2, SSE3, SSSE3, SSE4.1";
  511|      0|#elif defined(EIGEN_VECTORIZE_SSSE3)
  512|      0|  return "SSE, SSE2, SSE3, SSSE3";
  513|      0|#elif defined(EIGEN_VECTORIZE_SSE3)
  514|      0|  return "SSE, SSE2, SSE3";
  515|      0|#elif defined(EIGEN_VECTORIZE_SSE2)
  516|      0|  return "SSE, SSE2";
  517|      0|#elif defined(EIGEN_VECTORIZE_ALTIVEC)
  518|      0|  return "AltiVec";
  519|      0|#elif defined(EIGEN_VECTORIZE_VSX)
  520|      0|  return "VSX";
  521|      0|#elif defined(EIGEN_VECTORIZE_NEON)
  522|      0|  return "ARM NEON";
  523|      0|#elif defined(EIGEN_VECTORIZE_SVE)
  524|      0|  return "ARM SVE";
  525|      0|#elif defined(EIGEN_VECTORIZE_ZVECTOR)
  526|      0|  return "S390X ZVECTOR";
  527|      0|#elif defined(EIGEN_VECTORIZE_MSA)
  528|      0|  return "MIPS MSA";
  529|      0|#elif defined(EIGEN_VECTORIZE_LSX)
  530|      0|  return "LOONGARCH64 LSX";
  531|      0|#else
  532|      0|  return "None";
  533|      0|#endif
  534|      0|}
  535|       |
  536|       |}  // end namespace Eigen
  537|       |
  538|       |#endif  // EIGEN_CONFIGURE_VECTORIZATION_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/Constants.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2015 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2007-2009 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |// Copyright (C) 2020, Arm Limited and Contributors
    7|       |//
    8|       |// This Source Code Form is subject to the terms of the Mozilla
    9|       |// Public License v. 2.0. If a copy of the MPL was not distributed
   10|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   11|       |
   12|       |#ifndef EIGEN_CONSTANTS_H
   13|       |#define EIGEN_CONSTANTS_H
   14|       |
   15|       |// IWYU pragma: private
   16|       |#include "../InternalHeaderCheck.h"
   17|       |
   18|       |namespace Eigen {
   19|       |
   20|       |/** This value means that a positive quantity (e.g., a size) is not known at compile-time, and that instead the value is
   21|       | * stored in some runtime variable.
   22|       | *
   23|       | * Changing the value of Dynamic breaks the ABI, as Dynamic is often used as a template parameter for Matrix.
   24|       | */
   25|       |const int Dynamic = -1;
   26|       |
   27|       |/** This value means that a signed quantity (e.g., a signed index) is not known at compile-time, and that instead its
   28|       | * value has to be specified at runtime.
   29|       | */
   30|       |const int DynamicIndex = 0xffffff;
   31|       |
   32|       |/** This value means that the requested value is not defined.
   33|       | */
   34|       |const int Undefined = 0xfffffe;
   35|       |
   36|       |/** This value means +Infinity; it is currently used only as the p parameter to MatrixBase::lpNorm<int>().
   37|       | * The value Infinity there means the L-infinity norm.
   38|       | */
   39|       |const int Infinity = -1;
   40|       |
   41|       |/** This value means that the cost to evaluate an expression coefficient is either very expensive or
   42|       | * cannot be known at compile time.
   43|       | *
   44|       | * This value has to be positive to (1) simplify cost computation, and (2) allow to distinguish between a very expensive
   45|       | * and very very expensive expressions. It thus must also be large enough to make sure unrolling won't happen and that
   46|       | * sub expressions will be evaluated, but not too large to avoid overflow.
   47|       | */
   48|       |const int HugeCost = 10000;
   49|       |
   50|       |/** \defgroup flags Flags
   51|       | * \ingroup Core_Module
   52|       | *
   53|       | * These are the possible bits which can be OR'ed to constitute the flags of a matrix or
   54|       | * expression.
   55|       | *
   56|       | * It is important to note that these flags are a purely compile-time notion. They are a compile-time property of
   57|       | * an expression type, implemented as enum's. They are not stored in memory at runtime, and they do not incur any
   58|       | * runtime overhead.
   59|       | *
   60|       | * \sa MatrixBase::Flags
   61|       | */
   62|       |
   63|       |/** \ingroup flags
   64|       | *
   65|       | * for a matrix, this means that the storage order is row-major.
   66|       | * If this bit is not set, the storage order is column-major.
   67|       | * For an expression, this determines the storage order of
   68|       | * the matrix created by evaluation of that expression.
   69|       | * \sa \blank  \ref TopicStorageOrders */
   70|       |const unsigned int RowMajorBit = 0x1;
   71|       |
   72|       |/** \ingroup flags
   73|       | * means the expression should be evaluated by the calling expression */
   74|       |const unsigned int EvalBeforeNestingBit = 0x2;
   75|       |
   76|       |/** \ingroup flags
   77|       | * \deprecated
   78|       | * means the expression should be evaluated before any assignment */
   79|       |EIGEN_DEPRECATED const unsigned int EvalBeforeAssigningBit = 0x4;  // FIXME deprecated
   80|       |
   81|       |/** \ingroup flags
   82|       | *
   83|       | * Short version: means the expression might be vectorized
   84|       | *
   85|       | * Long version: means that the coefficients can be handled by packets
   86|       | * and start at a memory location whose alignment meets the requirements
   87|       | * of the present CPU architecture for optimized packet access. In the fixed-size
   88|       | * case, there is the additional condition that it be possible to access all the
   89|       | * coefficients by packets (this implies the requirement that the size be a multiple of 16 bytes,
   90|       | * and that any nontrivial strides don't break the alignment). In the dynamic-size case,
   91|       | * there is no such condition on the total size and strides, so it might not be possible to access
   92|       | * all coeffs by packets.
   93|       | *
   94|       | * \note This bit can be set regardless of whether vectorization is actually enabled.
   95|       | *       To check for actual vectorizability, see \a ActualPacketAccessBit.
   96|       | */
   97|       |const unsigned int PacketAccessBit = 0x8;
   98|       |
   99|       |#ifdef EIGEN_VECTORIZE
  100|       |/** \ingroup flags
  101|       | *
  102|       | * If vectorization is enabled (EIGEN_VECTORIZE is defined) this constant
  103|       | * is set to the value \a PacketAccessBit.
  104|       | *
  105|       | * If vectorization is not enabled (EIGEN_VECTORIZE is not defined) this constant
  106|       | * is set to the value 0.
  107|       | */
  108|       |const unsigned int ActualPacketAccessBit = PacketAccessBit;
  109|       |#else
  110|       |const unsigned int ActualPacketAccessBit = 0x0;
  111|       |#endif
  112|       |
  113|       |/** \ingroup flags
  114|       | *
  115|       | * Short version: means the expression can be seen as 1D vector.
  116|       | *
  117|       | * Long version: means that one can access the coefficients
  118|       | * of this expression by coeff(int), and coeffRef(int) in the case of a lvalue expression. These
  119|       | * index-based access methods are guaranteed
  120|       | * to not have to do any runtime computation of a (row, col)-pair from the index, so that it
  121|       | * is guaranteed that whenever it is available, index-based access is at least as fast as
  122|       | * (row,col)-based access. Expressions for which that isn't possible don't have the LinearAccessBit.
  123|       | *
  124|       | * If both PacketAccessBit and LinearAccessBit are set, then the
  125|       | * packets of this expression can be accessed by packet(int), and writePacket(int) in the case of a
  126|       | * lvalue expression.
  127|       | *
  128|       | * Typically, all vector expressions have the LinearAccessBit, but there is one exception:
  129|       | * Product expressions don't have it, because it would be troublesome for vectorization, even when the
  130|       | * Product is a vector expression. Thus, vector Product expressions allow index-based coefficient access but
  131|       | * not index-based packet access, so they don't have the LinearAccessBit.
  132|       | */
  133|       |const unsigned int LinearAccessBit = 0x10;
  134|       |
  135|       |/** \ingroup flags
  136|       | *
  137|       | * Means the expression has a coeffRef() method, i.e. is writable as its individual coefficients are directly
  138|       | * addressable. This rules out read-only expressions.
  139|       | *
  140|       | * Note that DirectAccessBit and LvalueBit are mutually orthogonal, as there are examples of expression having one but
  141|       | * not the other: \li writable expressions that don't have a very simple memory layout as a strided array, have
  142|       | * LvalueBit but not DirectAccessBit \li Map-to-const expressions, for example Map<const Matrix>, have DirectAccessBit
  143|       | * but not LvalueBit
  144|       | *
  145|       | * Expressions having LvalueBit also have their coeff() method returning a const reference instead of returning a new
  146|       | * value.
  147|       | */
  148|       |const unsigned int LvalueBit = 0x20;
  149|       |
  150|       |/** \ingroup flags
  151|       | *
  152|       | * Means that the underlying array of coefficients can be directly accessed as a plain strided array. The memory layout
  153|       | * of the array of coefficients must be exactly the natural one suggested by rows(), cols(),
  154|       | * outerStride(), innerStride(), and the RowMajorBit. This rules out expressions such as Diagonal, whose coefficients,
  155|       | * though referenceable, do not have such a regular memory layout.
  156|       | *
  157|       | * See the comment on LvalueBit for an explanation of how LvalueBit and DirectAccessBit are mutually orthogonal.
  158|       | */
  159|       |const unsigned int DirectAccessBit = 0x40;
  160|       |
  161|       |/** \deprecated \ingroup flags
  162|       | *
  163|       | * means the first coefficient packet is guaranteed to be aligned.
  164|       | * An expression cannot have the AlignedBit without the PacketAccessBit flag.
  165|       | * In other words, this means we are allow to perform an aligned packet access to the first element regardless
  166|       | * of the expression kind:
  167|       | * \code
  168|       | * expression.packet<Aligned>(0);
  169|       | * \endcode
  170|       | */
  171|       |EIGEN_DEPRECATED const unsigned int AlignedBit = 0x80;
  172|       |
  173|       |const unsigned int NestByRefBit = 0x100;
  174|       |
  175|       |/** \ingroup flags
  176|       | *
  177|       | * for an expression, this means that the storage order
  178|       | * can be either row-major or column-major.
  179|       | * The precise choice will be decided at evaluation time or when
  180|       | * combined with other expressions.
  181|       | * \sa \blank  \ref RowMajorBit, \ref TopicStorageOrders */
  182|       |const unsigned int NoPreferredStorageOrderBit = 0x200;
  183|       |
  184|       |/** \ingroup flags
  185|       |  *
  186|       |  * Means that the underlying coefficients can be accessed through pointers to the sparse (un)compressed storage format,
  187|       |  * that is, the expression provides:
  188|       |  * \code
  189|       |    inline const Scalar* valuePtr() const;
  190|       |    inline const Index* innerIndexPtr() const;
  191|       |    inline const Index* outerIndexPtr() const;
  192|       |    inline const Index* innerNonZeroPtr() const;
  193|       |    \endcode
  194|       |  */
  195|       |const unsigned int CompressedAccessBit = 0x400;
  196|       |
  197|       |// list of flags that are inherited by default
  198|       |const unsigned int HereditaryBits = RowMajorBit | EvalBeforeNestingBit;
  199|       |
  200|       |/** \defgroup enums Enumerations
  201|       | * \ingroup Core_Module
  202|       | *
  203|       | * Various enumerations used in %Eigen. Many of these are used as template parameters.
  204|       | */
  205|       |
  206|       |/** \ingroup enums
  207|       | * Enum containing possible values for the \c Mode or \c UpLo parameter of
  208|       | * MatrixBase::selfadjointView() and MatrixBase::triangularView(), and selfadjoint solvers. */
  209|       |enum UpLoType {
  210|       |  /** View matrix as a lower triangular matrix. */
  211|       |  Lower = 0x1,
  212|       |  /** View matrix as an upper triangular matrix. */
  213|       |  Upper = 0x2,
  214|       |  /** %Matrix has ones on the diagonal; to be used in combination with #Lower or #Upper. */
  215|       |  UnitDiag = 0x4,
  216|       |  /** %Matrix has zeros on the diagonal; to be used in combination with #Lower or #Upper. */
  217|       |  ZeroDiag = 0x8,
  218|       |  /** View matrix as a lower triangular matrix with ones on the diagonal. */
  219|       |  UnitLower = UnitDiag | Lower,
  220|       |  /** View matrix as an upper triangular matrix with ones on the diagonal. */
  221|       |  UnitUpper = UnitDiag | Upper,
  222|       |  /** View matrix as a lower triangular matrix with zeros on the diagonal. */
  223|       |  StrictlyLower = ZeroDiag | Lower,
  224|       |  /** View matrix as an upper triangular matrix with zeros on the diagonal. */
  225|       |  StrictlyUpper = ZeroDiag | Upper,
  226|       |  /** Used in BandMatrix and SelfAdjointView to indicate that the matrix is self-adjoint. */
  227|       |  SelfAdjoint = 0x10,
  228|       |  /** Used to support symmetric, non-selfadjoint, complex matrices. */
  229|       |  Symmetric = 0x20
  230|       |};
  231|       |
  232|       |/** \ingroup enums
  233|       | * Enum for indicating whether a buffer is aligned or not. */
  234|       |enum AlignmentType {
  235|       |  Unaligned = 0,    /**< Data pointer has no specific alignment. */
  236|       |  Aligned8 = 8,     /**< Data pointer is aligned on a 8 bytes boundary. */
  237|       |  Aligned16 = 16,   /**< Data pointer is aligned on a 16 bytes boundary. */
  238|       |  Aligned32 = 32,   /**< Data pointer is aligned on a 32 bytes boundary. */
  239|       |  Aligned64 = 64,   /**< Data pointer is aligned on a 64 bytes boundary. */
  240|       |  Aligned128 = 128, /**< Data pointer is aligned on a 128 bytes boundary. */
  241|       |  AlignedMask = 255,
  242|       |  Aligned = 16, /**< \deprecated Synonym for Aligned16. */
  243|       |#if EIGEN_MAX_ALIGN_BYTES == 128
  244|       |  AlignedMax = Aligned128
  245|       |#elif EIGEN_MAX_ALIGN_BYTES == 64
  246|       |  AlignedMax = Aligned64
  247|       |#elif EIGEN_MAX_ALIGN_BYTES == 32
  248|       |  AlignedMax = Aligned32
  249|       |#elif EIGEN_MAX_ALIGN_BYTES == 16
  250|       |  AlignedMax = Aligned16
  251|       |#elif EIGEN_MAX_ALIGN_BYTES == 8
  252|       |  AlignedMax = Aligned8
  253|       |#elif EIGEN_MAX_ALIGN_BYTES == 0
  254|       |  AlignedMax = Unaligned
  255|       |#else
  256|       |#error Invalid value for EIGEN_MAX_ALIGN_BYTES
  257|       |#endif
  258|       |};
  259|       |
  260|       |/** \ingroup enums
  261|       | * Enum containing possible values for the \p Direction parameter of
  262|       | * Reverse, PartialReduxExpr and VectorwiseOp. */
  263|       |enum DirectionType {
  264|       |  /** For Reverse, all columns are reversed;
  265|       |   * for PartialReduxExpr and VectorwiseOp, act on columns. */
  266|       |  Vertical,
  267|       |  /** For Reverse, all rows are reversed;
  268|       |   * for PartialReduxExpr and VectorwiseOp, act on rows. */
  269|       |  Horizontal,
  270|       |  /** For Reverse, both rows and columns are reversed;
  271|       |   * not used for PartialReduxExpr and VectorwiseOp. */
  272|       |  BothDirections
  273|       |};
  274|       |
  275|       |/** \internal \ingroup enums
  276|       | * Enum to specify how to traverse the entries of a matrix. */
  277|       |enum TraversalType {
  278|       |  /** \internal Default traversal, no vectorization, no index-based access */
  279|       |  DefaultTraversal,
  280|       |  /** \internal No vectorization, use index-based access to have only one for loop instead of 2 nested loops */
  281|       |  LinearTraversal,
  282|       |  /** \internal Equivalent to a slice vectorization for fixed-size matrices having good alignment
  283|       |   * and good size */
  284|       |  InnerVectorizedTraversal,
  285|       |  /** \internal Vectorization path using a single loop plus scalar loops for the
  286|       |   * unaligned boundaries */
  287|       |  LinearVectorizedTraversal,
  288|       |  /** \internal Generic vectorization path using one vectorized loop per row/column with some
  289|       |   * scalar loops to handle the unaligned boundaries */
  290|       |  SliceVectorizedTraversal,
  291|       |  /** \internal Special case to properly handle incompatible scalar types or other defecting cases*/
  292|       |  InvalidTraversal,
  293|       |  /** \internal Evaluate all entries at once */
  294|       |  AllAtOnceTraversal
  295|       |};
  296|       |
  297|       |/** \internal \ingroup enums
  298|       | * Enum to specify whether to unroll loops when traversing over the entries of a matrix. */
  299|       |enum UnrollingType {
  300|       |  /** \internal Do not unroll loops. */
  301|       |  NoUnrolling,
  302|       |  /** \internal Unroll only the inner loop, but not the outer loop. */
  303|       |  InnerUnrolling,
  304|       |  /** \internal Unroll both the inner and the outer loop. If there is only one loop,
  305|       |   * because linear traversal is used, then unroll that loop. */
  306|       |  CompleteUnrolling
  307|       |};
  308|       |
  309|       |/** \internal \ingroup enums
  310|       | * Enum to specify whether to use the default (built-in) implementation or the specialization. */
  311|       |enum SpecializedType { Specialized, BuiltIn };
  312|       |
  313|       |/** \ingroup enums
  314|       | * Enum containing possible values for the \p Options_ template parameter of
  315|       | * Matrix, Array and BandMatrix. */
  316|       |enum StorageOptions {
  317|       |  /** Storage order is column major (see \ref TopicStorageOrders). */
  318|       |  ColMajor = 0,
  319|       |  /** Storage order is row major (see \ref TopicStorageOrders). */
  320|       |  RowMajor = 0x1,  // it is only a coincidence that this is equal to RowMajorBit -- don't rely on that
  321|       |  /** Align the matrix itself if it is vectorizable fixed-size */
  322|       |  AutoAlign = 0,
  323|       |  /** Don't require alignment for the matrix itself (the array of coefficients, if dynamically allocated, may still be requested to be aligned) */ // FIXME --- clarify the situation
  324|       |  DontAlign = 0x2
  325|       |};
  326|       |
  327|       |/** \ingroup enums
  328|       | * Enum for specifying whether to apply or solve on the left or right. */
  329|       |enum SideType {
  330|       |  /** Apply transformation on the left. */
  331|       |  OnTheLeft = 1,
  332|       |  /** Apply transformation on the right. */
  333|       |  OnTheRight = 2
  334|       |};
  335|       |
  336|       |/** \ingroup enums
  337|       | * Enum for specifying NaN-propagation behavior, e.g. for coeff-wise min/max. */
  338|       |enum NaNPropagationOptions {
  339|       |  /**  Implementation defined behavior if NaNs are present. */
  340|       |  PropagateFast = 0,
  341|       |  /**  Always propagate NaNs. */
  342|       |  PropagateNaN,
  343|       |  /**  Always propagate not-NaNs. */
  344|       |  PropagateNumbers
  345|       |};
  346|       |
  347|       |/* the following used to be written as:
  348|       | *
  349|       | *   struct NoChange_t {};
  350|       | *   namespace {
  351|       | *     EIGEN_UNUSED NoChange_t NoChange;
  352|       | *   }
  353|       | *
  354|       | * on the ground that it feels dangerous to disambiguate overloaded functions on enum/integer types.
  355|       | * However, this leads to "variable declared but never referenced" warnings on Intel Composer XE,
  356|       | * and we do not know how to get rid of them (bug 450).
  357|       | */
  358|       |
  359|       |enum NoChange_t { NoChange };
  360|       |enum Sequential_t { Sequential };
  361|       |enum Default_t { Default };
  362|       |
  363|       |/** \internal \ingroup enums
  364|       | * Used in AmbiVector. */
  365|       |enum AmbiVectorMode { IsDense = 0, IsSparse };
  366|       |
  367|       |/** \ingroup enums
  368|       | * Used as template parameter in DenseCoeffBase and MapBase to indicate
  369|       | * which accessors should be provided. */
  370|       |enum AccessorLevels {
  371|       |  /** Read-only access via a member function. */
  372|       |  ReadOnlyAccessors,
  373|       |  /** Read/write access via member functions. */
  374|       |  WriteAccessors,
  375|       |  /** Direct read-only access to the coefficients. */
  376|       |  DirectAccessors,
  377|       |  /** Direct read/write access to the coefficients. */
  378|       |  DirectWriteAccessors
  379|       |};
  380|       |
  381|       |/** \ingroup enums
  382|       | * Enum with options to give to various decompositions. */
  383|       |enum DecompositionOptions {
  384|       |  /** \internal Not used (meant for LDLT?). */
  385|       |  Pivoting = 0x01,
  386|       |  /** \internal Not used (meant for LDLT?). */
  387|       |  NoPivoting = 0x02,
  388|       |  /** Used in JacobiSVD to indicate that the square matrix U is to be computed. */
  389|       |  ComputeFullU = 0x04,
  390|       |  /** Used in JacobiSVD to indicate that the thin matrix U is to be computed. */
  391|       |  ComputeThinU = 0x08,
  392|       |  /** Used in JacobiSVD to indicate that the square matrix V is to be computed. */
  393|       |  ComputeFullV = 0x10,
  394|       |  /** Used in JacobiSVD to indicate that the thin matrix V is to be computed. */
  395|       |  ComputeThinV = 0x20,
  396|       |  /** Used in SelfAdjointEigenSolver and GeneralizedSelfAdjointEigenSolver to specify
  397|       |   * that only the eigenvalues are to be computed and not the eigenvectors. */
  398|       |  EigenvaluesOnly = 0x40,
  399|       |  /** Used in SelfAdjointEigenSolver and GeneralizedSelfAdjointEigenSolver to specify
  400|       |   * that both the eigenvalues and the eigenvectors are to be computed. */
  401|       |  ComputeEigenvectors = 0x80,
  402|       |  /** \internal */
  403|       |  EigVecMask = EigenvaluesOnly | ComputeEigenvectors,
  404|       |  /** Used in GeneralizedSelfAdjointEigenSolver to indicate that it should
  405|       |   * solve the generalized eigenproblem \f$ Ax = \lambda B x \f$. */
  406|       |  Ax_lBx = 0x100,
  407|       |  /** Used in GeneralizedSelfAdjointEigenSolver to indicate that it should
  408|       |   * solve the generalized eigenproblem \f$ ABx = \lambda x \f$. */
  409|       |  ABx_lx = 0x200,
  410|       |  /** Used in GeneralizedSelfAdjointEigenSolver to indicate that it should
  411|       |   * solve the generalized eigenproblem \f$ BAx = \lambda x \f$. */
  412|       |  BAx_lx = 0x400,
  413|       |  /** \internal */
  414|       |  GenEigMask = Ax_lBx | ABx_lx | BAx_lx
  415|       |};
  416|       |
  417|       |/** \ingroup enums
  418|       | * Possible values for the \p QRPreconditioner template parameter of JacobiSVD. */
  419|       |enum QRPreconditioners {
  420|       |  /** Use a QR decomposition with column pivoting as the first step. */
  421|       |  ColPivHouseholderQRPreconditioner = 0x0,
  422|       |  /** Do not specify what is to be done if the SVD of a non-square matrix is asked for. */
  423|       |  NoQRPreconditioner = 0x40,
  424|       |  /** Use a QR decomposition without pivoting as the first step. */
  425|       |  HouseholderQRPreconditioner = 0x80,
  426|       |  /** Use a QR decomposition with full pivoting as the first step. */
  427|       |  FullPivHouseholderQRPreconditioner = 0xC0,
  428|       |  /** Used to disable the QR Preconditioner in BDCSVD. */
  429|       |  DisableQRDecomposition = NoQRPreconditioner
  430|       |};
  431|       |
  432|       |#ifdef Success
  433|       |#error The preprocessor symbol 'Success' is defined, possibly by the X11 header file X.h
  434|       |#endif
  435|       |
  436|       |/** \ingroup enums
  437|       | * Enum for reporting the status of a computation. */
  438|       |enum ComputationInfo {
  439|       |  /** Computation was successful. */
  440|       |  Success = 0,
  441|       |  /** The provided data did not satisfy the prerequisites. */
  442|       |  NumericalIssue = 1,
  443|       |  /** Iterative procedure did not converge. */
  444|       |  NoConvergence = 2,
  445|       |  /** The inputs are invalid, or the algorithm has been improperly called.
  446|       |   * When assertions are enabled, such errors trigger an assert. */
  447|       |  InvalidInput = 3
  448|       |};
  449|       |
  450|       |/** \ingroup enums
  451|       | * Enum used to specify how a particular transformation is stored in a matrix.
  452|       | * \sa Transform, Hyperplane::transform(). */
  453|       |enum TransformTraits {
  454|       |  /** Transformation is an isometry. */
  455|       |  Isometry = 0x1,
  456|       |  /** Transformation is an affine transformation stored as a (Dim+1)^2 matrix whose last row is
  457|       |   * assumed to be [0 ... 0 1]. */
  458|       |  Affine = 0x2,
  459|       |  /** Transformation is an affine transformation stored as a (Dim) x (Dim+1) matrix. */
  460|       |  AffineCompact = 0x10 | Affine,
  461|       |  /** Transformation is a general projective transformation stored as a (Dim+1)^2 matrix. */
  462|       |  Projective = 0x20
  463|       |};
  464|       |
  465|       |/** \internal \ingroup enums
  466|       | * Enum used to choose between implementation depending on the computer architecture. */
  467|       |namespace Architecture {
  468|       |enum Type {
  469|       |  Generic = 0x0,
  470|       |  SSE = 0x1,
  471|       |  AltiVec = 0x2,
  472|       |  VSX = 0x3,
  473|       |  NEON = 0x4,
  474|       |  MSA = 0x5,
  475|       |  SVE = 0x6,
  476|       |  HVX = 0x7,
  477|       |  LSX = 0x8,
  478|       |#if defined EIGEN_VECTORIZE_SSE
  479|       |  Target = SSE
  480|       |#elif defined EIGEN_VECTORIZE_ALTIVEC
  481|       |  Target = AltiVec
  482|       |#elif defined EIGEN_VECTORIZE_VSX
  483|       |  Target = VSX
  484|       |#elif defined EIGEN_VECTORIZE_NEON
  485|       |  Target = NEON
  486|       |#elif defined EIGEN_VECTORIZE_SVE
  487|       |  Target = SVE
  488|       |#elif defined EIGEN_VECTORIZE_MSA
  489|       |  Target = MSA
  490|       |#elif defined EIGEN_VECTORIZE_HVX
  491|       |  Target = HVX
  492|       |#elif defined EIGEN_VECTORIZE_LSX
  493|       |  Target = LSX
  494|       |#else
  495|       |  Target = Generic
  496|       |#endif
  497|       |};
  498|       |}  // namespace Architecture
  499|       |
  500|       |/** \internal \ingroup enums
  501|       | * Enum used as template parameter in Product and product evaluators. */
  502|       |enum ProductImplType {
  503|       |  DefaultProduct = 0,
  504|       |  LazyProduct,
  505|       |  AliasFreeProduct,
  506|       |  CoeffBasedProductMode,
  507|       |  LazyCoeffBasedProductMode,
  508|       |  OuterProduct,
  509|       |  InnerProduct,
  510|       |  GemvProduct,
  511|       |  GemmProduct
  512|       |};
  513|       |
  514|       |/** \internal \ingroup enums
  515|       | * Enum used in experimental parallel implementation. */
  516|       |enum Action { GetAction, SetAction };
  517|       |
  518|       |/** The type used to identify a dense storage. */
  519|       |struct Dense {};
  520|       |
  521|       |/** The type used to identify a general sparse storage. */
  522|       |struct Sparse {};
  523|       |
  524|       |/** The type used to identify a general solver (factored) storage. */
  525|       |struct SolverStorage {};
  526|       |
  527|       |/** The type used to identify a permutation storage. */
  528|       |struct PermutationStorage {};
  529|       |
  530|       |/** The type used to identify a permutation storage. */
  531|       |struct TranspositionsStorage {};
  532|       |
  533|       |/** The type used to identify a matrix expression */
  534|       |struct MatrixXpr {};
  535|       |
  536|       |/** The type used to identify an array expression */
  537|       |struct ArrayXpr {};
  538|       |
  539|       |// An evaluator must define its shape. By default, it can be one of the following:
  540|       |struct DenseShape {
  541|      0|  static std::string debugName() { return "DenseShape"; }
  542|       |};
  543|       |struct SolverShape {
  544|      0|  static std::string debugName() { return "SolverShape"; }
  545|       |};
  546|       |struct HomogeneousShape {
  547|      0|  static std::string debugName() { return "HomogeneousShape"; }
  548|       |};
  549|       |struct DiagonalShape {
  550|      0|  static std::string debugName() { return "DiagonalShape"; }
  551|       |};
  552|       |struct SkewSymmetricShape {
  553|      0|  static std::string debugName() { return "SkewSymmetricShape"; }
  554|       |};
  555|       |struct BandShape {
  556|      0|  static std::string debugName() { return "BandShape"; }
  557|       |};
  558|       |struct TriangularShape {
  559|      0|  static std::string debugName() { return "TriangularShape"; }
  560|       |};
  561|       |struct SelfAdjointShape {
  562|      0|  static std::string debugName() { return "SelfAdjointShape"; }
  563|       |};
  564|       |struct PermutationShape {
  565|      0|  static std::string debugName() { return "PermutationShape"; }
  566|       |};
  567|       |struct TranspositionsShape {
  568|      0|  static std::string debugName() { return "TranspositionsShape"; }
  569|       |};
  570|       |struct SparseShape {
  571|      0|  static std::string debugName() { return "SparseShape"; }
  572|       |};
  573|       |
  574|       |namespace internal {
  575|       |
  576|       |// random access iterators based on coeff*() accessors.
  577|       |struct IndexBased {};
  578|       |
  579|       |// evaluator based on iterators to access coefficients.
  580|       |struct IteratorBased {};
  581|       |
  582|       |/** \internal
  583|       | * Constants for comparison functors
  584|       | */
  585|       |enum ComparisonName : unsigned int {
  586|       |  cmp_EQ = 0,
  587|       |  cmp_LT = 1,
  588|       |  cmp_LE = 2,
  589|       |  cmp_UNORD = 3,
  590|       |  cmp_NEQ = 4,
  591|       |  cmp_GT = 5,
  592|       |  cmp_GE = 6
  593|       |};
  594|       |}  // end namespace internal
  595|       |
  596|       |}  // end namespace Eigen
  597|       |
  598|       |#endif  // EIGEN_CONSTANTS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/IntegralConstant.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2017 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_INTEGRAL_CONSTANT_H
   11|       |#define EIGEN_INTEGRAL_CONSTANT_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |namespace internal {
   19|       |
   20|       |template <int N>
   21|       |class FixedInt;
   22|       |template <int N>
   23|       |class VariableAndFixedInt;
   24|       |
   25|       |/** \internal
   26|       | * \class FixedInt
   27|       | *
   28|       | * This class embeds a compile-time integer \c N.
   29|       | *
   30|       | * It is similar to c++11 std::integral_constant<int,N> but with some additional features
   31|       | * such as:
   32|       | *  - implicit conversion to int
   33|       | *  - arithmetic and some bitwise operators: -, +, *, /, %, &, |
   34|       | *  - c++98/14 compatibility with fix<N> and fix<N>() syntax to define integral constants.
   35|       | *
   36|       | * It is strongly discouraged to directly deal with this class FixedInt. Instances are expected to
   37|       | * be created by the user using Eigen::fix<N> or Eigen::fix<N>().
   38|       | * \code
   39|       | * internal::cleanup_index_type<T>::type
   40|       | * internal::cleanup_index_type<T,DynamicKey>::type
   41|       | * \endcode
   42|       | * where T can a FixedInt<N>, a pointer to function FixedInt<N> (*)(), or numerous other integer-like representations.
   43|       | * \c DynamicKey is either Dynamic (default) or DynamicIndex and used to identify true compile-time values.
   44|       | *
   45|       | * For convenience, you can extract the compile-time value \c N in a generic way using the following helper:
   46|       | * \code
   47|       | * internal::get_fixed_value<T,DefaultVal>::value
   48|       | * \endcode
   49|       | * that will give you \c N if T equals FixedInt<N> or FixedInt<N> (*)(), and \c DefaultVal if T does not embed any
   50|       | * compile-time value (e.g., T==int).
   51|       | *
   52|       | * \sa fix<N>, class VariableAndFixedInt
   53|       | */
   54|       |template <int N>
   55|       |class FixedInt {
   56|       | public:
   57|       |  static constexpr int value = N;
   58|       |  constexpr operator int() const { return N; }
   59|       |
   60|       |  constexpr FixedInt() = default;
   61|       |  constexpr FixedInt(std::integral_constant<int, N>) {}
   62|       |
   63|       |  constexpr FixedInt(VariableAndFixedInt<N> other) {
   64|       |#ifndef EIGEN_INTERNAL_DEBUGGING
   65|       |    EIGEN_UNUSED_VARIABLE(other);
   66|       |#endif
   67|       |    eigen_internal_assert(int(other) == N);
   68|       |  }
   69|       |
   70|       |  constexpr FixedInt<-N> operator-() const { return FixedInt<-N>(); }
   71|       |
   72|       |  template <int M>
   73|       |  constexpr FixedInt<N + M> operator+(FixedInt<M>) const {
   74|       |    return FixedInt<N + M>();
   75|       |  }
   76|       |
   77|       |  template <int M>
   78|       |  constexpr FixedInt<N - M> operator-(FixedInt<M>) const {
   79|       |    return FixedInt<N - M>();
   80|       |  }
   81|       |
   82|       |  template <int M>
   83|       |  constexpr FixedInt<N * M> operator*(FixedInt<M>) const {
   84|       |    return FixedInt<N * M>();
   85|       |  }
   86|       |
   87|       |  template <int M>
   88|       |  constexpr FixedInt<N / M> operator/(FixedInt<M>) const {
   89|       |    return FixedInt<N / M>();
   90|       |  }
   91|       |
   92|       |  template <int M>
   93|       |  constexpr FixedInt<N % M> operator%(FixedInt<M>) const {
   94|       |    return FixedInt<N % M>();
   95|       |  }
   96|       |
   97|       |  template <int M>
   98|       |  constexpr FixedInt<N | M> operator|(FixedInt<M>) const {
   99|       |    return FixedInt<N | M>();
  100|       |  }
  101|       |
  102|       |  template <int M>
  103|       |  constexpr FixedInt<N & M> operator&(FixedInt<M>) const {
  104|       |    return FixedInt<N & M>();
  105|       |  }
  106|       |
  107|       |  // Needed in C++14 to allow fix<N>():
  108|      0|  constexpr FixedInt operator()() const { return *this; }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal8FixedIntILin1EEclEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen8internal8FixedIntILi1EEclEv
  ------------------
  109|       |
  110|       |  constexpr VariableAndFixedInt<N> operator()(int val) const { return VariableAndFixedInt<N>(val); }
  111|       |};
  112|       |
  113|       |/** \internal
  114|       | * \class VariableAndFixedInt
  115|       | *
  116|       | * This class embeds both a compile-time integer \c N and a runtime integer.
  117|       | * Both values are supposed to be equal unless the compile-time value \c N has a special
  118|       | * value meaning that the runtime-value should be used. Depending on the context, this special
  119|       | * value can be either Eigen::Dynamic (for positive quantities) or Eigen::DynamicIndex (for
  120|       | * quantities that can be negative).
  121|       | *
  122|       | * It is the return-type of the function Eigen::fix<N>(int), and most of the time this is the only
  123|       | * way it is used. It is strongly discouraged to directly deal with instances of VariableAndFixedInt.
  124|       | * Indeed, in order to write generic code, it is the responsibility of the callee to properly convert
  125|       | * it to either a true compile-time quantity (i.e. a FixedInt<N>), or to a runtime quantity (e.g., an Index)
  126|       | * using the following generic helper:
  127|       | * \code
  128|       | * internal::cleanup_index_type<T>::type
  129|       | * internal::cleanup_index_type<T,DynamicKey>::type
  130|       | * \endcode
  131|       | * where T can be a template instantiation of VariableAndFixedInt or numerous other integer-like representations.
  132|       | * \c DynamicKey is either Dynamic (default) or DynamicIndex and used to identify true compile-time values.
  133|       | *
  134|       | * For convenience, you can also extract the compile-time value \c N using the following helper:
  135|       | * \code
  136|       | * internal::get_fixed_value<T,DefaultVal>::value
  137|       | * \endcode
  138|       | * that will give you \c N if T equals VariableAndFixedInt<N>, and \c DefaultVal if T does not embed any compile-time
  139|       | * value (e.g., T==int).
  140|       | *
  141|       | * \sa fix<N>(int), class FixedInt
  142|       | */
  143|       |template <int N>
  144|       |class VariableAndFixedInt {
  145|       | public:
  146|       |  static const int value = N;
  147|       |  operator int() const { return m_value; }
  148|       |  VariableAndFixedInt(int val) { m_value = val; }
  149|       |
  150|       | protected:
  151|       |  int m_value;
  152|       |};
  153|       |
  154|       |template <typename T, int Default = Dynamic>
  155|       |struct get_fixed_value {
  156|       |  static const int value = Default;
  157|       |};
  158|       |
  159|       |template <int N, int Default>
  160|       |struct get_fixed_value<FixedInt<N>, Default> {
  161|       |  static const int value = N;
  162|       |};
  163|       |
  164|       |template <int N, int Default>
  165|       |struct get_fixed_value<VariableAndFixedInt<N>, Default> {
  166|       |  static const int value = N;
  167|       |};
  168|       |
  169|       |template <typename T, int N, int Default>
  170|       |struct get_fixed_value<variable_if_dynamic<T, N>, Default> {
  171|       |  static const int value = N;
  172|       |};
  173|       |
  174|       |template <typename T>
  175|       |EIGEN_DEVICE_FUNC Index get_runtime_value(const T &x) {
  176|       |  return x;
  177|       |}
  178|       |
  179|       |// Cleanup integer/FixedInt/VariableAndFixedInt/etc types:
  180|       |
  181|       |// By default, no cleanup:
  182|       |template <typename T, int DynamicKey = Dynamic, typename EnableIf = void>
  183|       |struct cleanup_index_type {
  184|       |  typedef T type;
  185|       |};
  186|       |
  187|       |// Convert any integral type (e.g., short, int, unsigned int, etc.) to Eigen::Index
  188|       |template <typename T, int DynamicKey>
  189|       |struct cleanup_index_type<T, DynamicKey, std::enable_if_t<internal::is_integral<T>::value>> {
  190|       |  typedef Index type;
  191|       |};
  192|       |
  193|       |// If VariableAndFixedInt does not match DynamicKey, then we turn it to a pure compile-time value:
  194|       |template <int N, int DynamicKey>
  195|       |struct cleanup_index_type<VariableAndFixedInt<N>, DynamicKey> {
  196|       |  typedef FixedInt<N> type;
  197|       |};
  198|       |// If VariableAndFixedInt matches DynamicKey, then we turn it to a pure runtime-value (aka Index):
  199|       |template <int DynamicKey>
  200|       |struct cleanup_index_type<VariableAndFixedInt<DynamicKey>, DynamicKey> {
  201|       |  typedef Index type;
  202|       |};
  203|       |
  204|       |template <int N, int DynamicKey>
  205|       |struct cleanup_index_type<std::integral_constant<int, N>, DynamicKey> {
  206|       |  typedef FixedInt<N> type;
  207|       |};
  208|       |
  209|       |}  // end namespace internal
  210|       |
  211|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  212|       |
  213|       |template <int N>
  214|       |constexpr internal::FixedInt<N> fix{};
  215|       |
  216|       |#else  // EIGEN_PARSED_BY_DOXYGEN
  217|       |
  218|       |/** \var fix<N>()
  219|       | * \ingroup Core_Module
  220|       | *
  221|       | * This \em identifier permits to construct an object embedding a compile-time integer \c N.
  222|       | *
  223|       | * \tparam N the compile-time integer value
  224|       | *
  225|       | * It is typically used in conjunction with the Eigen::seq and Eigen::seqN functions to pass compile-time values to
  226|       | * them: \code seqN(10,fix<4>,fix<-3>)   // <=> [10 7 4 1] \endcode
  227|       | *
  228|       | * See also the function fix(int) to pass both a compile-time and runtime value.
  229|       | *
  230|       | * In c++14, it is implemented as:
  231|       | * \code
  232|       | * template<int N> static const internal::FixedInt<N> fix{};
  233|       | * \endcode
  234|       | * where internal::FixedInt<N> is an internal template class similar to
  235|       | * <a href="http://en.cppreference.com/w/cpp/types/integral_constant">\c std::integral_constant </a><tt> <int,N> </tt>
  236|       | * Here, \c fix<N> is thus an object of type \c internal::FixedInt<N>.
  237|       | *
  238|       | * \sa fix<N>(int), seq, seqN
  239|       | */
  240|       |template <int N>
  241|       |static const auto fix();
  242|       |
  243|       |/** \fn fix<N>(int)
  244|       | * \ingroup Core_Module
  245|       | *
  246|       | * This function returns an object embedding both a compile-time integer \c N, and a fallback runtime value \a val.
  247|       | *
  248|       | * \tparam N the compile-time integer value
  249|       | * \param  val the fallback runtime integer value
  250|       | *
  251|       | * This function is a more general version of the \ref fix identifier/function that can be used in template code
  252|       | * where the compile-time value could turn out to actually mean "undefined at compile-time". For positive integers
  253|       | * such as a size or a dimension, this case is identified by Eigen::Dynamic, whereas runtime signed integers
  254|       | * (e.g., an increment/stride) are identified as Eigen::DynamicIndex. In such a case, the runtime value \a val
  255|       | * will be used as a fallback.
  256|       | *
  257|       | * A typical use case would be:
  258|       | * \code
  259|       | * template<typename Derived> void foo(const MatrixBase<Derived> &mat) {
  260|       | *   const int N = Derived::RowsAtCompileTime==Dynamic ? Dynamic : Derived::RowsAtCompileTime/2;
  261|       | *   const int n = mat.rows()/2;
  262|       | *   ... mat( seqN(0,fix<N>(n) ) ...;
  263|       | * }
  264|       | * \endcode
  265|       | * In this example, the function Eigen::seqN knows that the second argument is expected to be a size.
  266|       | * If the passed compile-time value N equals Eigen::Dynamic, then the proxy object returned by fix will be dismissed,
  267|       | * and converted to an Eigen::Index of value \c n. Otherwise, the runtime-value \c n will be dismissed, and the
  268|       | * returned ArithmeticSequence will be of the exact same type as <tt> seqN(0,fix<N>) </tt>.
  269|       | *
  270|       | * \sa fix, seqN, class ArithmeticSequence
  271|       | */
  272|       |template <int N>
  273|       |static const auto fix(int val);
  274|       |
  275|       |#endif  // EIGEN_PARSED_BY_DOXYGEN
  276|       |
  277|       |}  // end namespace Eigen
  278|       |
  279|       |#endif  // EIGEN_INTEGRAL_CONSTANT_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/Macros.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2015 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_MACROS_H
   12|       |#define EIGEN_MACROS_H
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |//------------------------------------------------------------------------------------------
   17|       |// Eigen version and basic defaults
   18|       |//------------------------------------------------------------------------------------------
   19|       |
   20|       |#define EIGEN_WORLD_VERSION 3
   21|       |#define EIGEN_MAJOR_VERSION 4
   22|       |#define EIGEN_MINOR_VERSION 90
   23|       |
   24|       |#define EIGEN_VERSION_AT_LEAST(x, y, z) \
   25|       |  (EIGEN_WORLD_VERSION > x ||           \
   26|       |   (EIGEN_WORLD_VERSION >= x && (EIGEN_MAJOR_VERSION > y || (EIGEN_MAJOR_VERSION >= y && EIGEN_MINOR_VERSION >= z))))
   27|       |
   28|       |#ifdef EIGEN_DEFAULT_TO_ROW_MAJOR
   29|       |#define EIGEN_DEFAULT_MATRIX_STORAGE_ORDER_OPTION Eigen::RowMajor
   30|       |#else
   31|       |#define EIGEN_DEFAULT_MATRIX_STORAGE_ORDER_OPTION Eigen::ColMajor
   32|       |#endif
   33|       |
   34|       |#ifndef EIGEN_DEFAULT_DENSE_INDEX_TYPE
   35|       |#define EIGEN_DEFAULT_DENSE_INDEX_TYPE std::ptrdiff_t
   36|       |#endif
   37|       |
   38|       |// Upperbound on the C++ version to use.
   39|       |// Expected values are 03, 11, 14, 17, etc.
   40|       |// By default, let's use an arbitrarily large C++ version.
   41|       |#ifndef EIGEN_MAX_CPP_VER
   42|       |#define EIGEN_MAX_CPP_VER 99
   43|       |#endif
   44|       |
   45|       |/** Allows to disable some optimizations which might affect the accuracy of the result.
   46|       | * Such optimization are enabled by default, and set EIGEN_FAST_MATH to 0 to disable them.
   47|       | * They currently include:
   48|       | *   - single precision ArrayBase::sin() and ArrayBase::cos() for SSE and AVX vectorization.
   49|       | */
   50|       |#ifndef EIGEN_FAST_MATH
   51|       |#define EIGEN_FAST_MATH 1
   52|       |#endif
   53|       |
   54|       |#ifndef EIGEN_STACK_ALLOCATION_LIMIT
   55|       |// 131072 == 128 KB
   56|       |#define EIGEN_STACK_ALLOCATION_LIMIT 131072
   57|       |#endif
   58|       |
   59|       |//------------------------------------------------------------------------------------------
   60|       |// Compiler identification, EIGEN_COMP_*
   61|       |//------------------------------------------------------------------------------------------
   62|       |
   63|       |/// \internal EIGEN_COMP_GNUC set to version (e.g., 951 for GCC 9.5.1) for all compilers compatible with GCC
   64|       |#ifdef __GNUC__
   65|       |#define EIGEN_COMP_GNUC (__GNUC__ * 100 + __GNUC_MINOR__ * 10 + __GNUC_PATCHLEVEL__)
   66|       |#else
   67|       |#define EIGEN_COMP_GNUC 0
   68|       |#endif
   69|       |
   70|       |/// \internal EIGEN_COMP_CLANG set to version (e.g., 372 for clang 3.7.2) if the compiler is clang
   71|       |#if defined(__clang__)
   72|       |#define EIGEN_COMP_CLANG (__clang_major__ * 100 + __clang_minor__ * 10 + __clang_patchlevel__)
   73|       |#else
   74|       |#define EIGEN_COMP_CLANG 0
   75|       |#endif
   76|       |
   77|       |/// \internal EIGEN_COMP_CLANGAPPLE set to the version number (e.g. 9000000 for AppleClang 9.0) if the compiler is
   78|       |/// AppleClang
   79|       |#if defined(__clang__) && defined(__apple_build_version__)
   80|       |#define EIGEN_COMP_CLANGAPPLE __apple_build_version__
   81|       |#else
   82|       |#define EIGEN_COMP_CLANGAPPLE 0
   83|       |#endif
   84|       |
   85|       |/// \internal EIGEN_COMP_CASTXML set to 1 if being preprocessed by CastXML
   86|       |#if defined(__castxml__)
   87|       |#define EIGEN_COMP_CASTXML 1
   88|       |#else
   89|       |#define EIGEN_COMP_CASTXML 0
   90|       |#endif
   91|       |
   92|       |/// \internal EIGEN_COMP_LLVM set to 1 if the compiler backend is llvm
   93|       |#if defined(__llvm__)
   94|       |#define EIGEN_COMP_LLVM 1
   95|       |#else
   96|       |#define EIGEN_COMP_LLVM 0
   97|       |#endif
   98|       |
   99|       |/// \internal EIGEN_COMP_ICC set to __INTEL_COMPILER if the compiler is Intel icc compiler, 0 otherwise
  100|       |#if defined(__INTEL_COMPILER)
  101|       |#define EIGEN_COMP_ICC __INTEL_COMPILER
  102|       |#else
  103|       |#define EIGEN_COMP_ICC 0
  104|       |#endif
  105|       |
  106|       |/// \internal EIGEN_COMP_CLANGICC set to __INTEL_CLANG_COMPILER if the compiler is Intel icx compiler, 0 otherwise
  107|       |#if defined(__INTEL_CLANG_COMPILER)
  108|       |#define EIGEN_COMP_CLANGICC __INTEL_CLANG_COMPILER
  109|       |#else
  110|       |#define EIGEN_COMP_CLANGICC 0
  111|       |#endif
  112|       |
  113|       |/// \internal EIGEN_COMP_MINGW set to 1 if the compiler is mingw
  114|       |#if defined(__MINGW32__)
  115|       |#define EIGEN_COMP_MINGW 1
  116|       |#else
  117|       |#define EIGEN_COMP_MINGW 0
  118|       |#endif
  119|       |
  120|       |/// \internal EIGEN_COMP_SUNCC set to 1 if the compiler is Solaris Studio
  121|       |#if defined(__SUNPRO_CC)
  122|       |#define EIGEN_COMP_SUNCC 1
  123|       |#else
  124|       |#define EIGEN_COMP_SUNCC 0
  125|       |#endif
  126|       |
  127|       |/// \internal EIGEN_COMP_MSVC set to _MSC_VER if the compiler is Microsoft Visual C++, 0 otherwise.
  128|       |#if defined(_MSC_VER)
  129|       |#define EIGEN_COMP_MSVC _MSC_VER
  130|       |#else
  131|       |#define EIGEN_COMP_MSVC 0
  132|       |#endif
  133|       |
  134|       |#if defined(__NVCC__)
  135|       |#if defined(__CUDACC_VER_MAJOR__) && (__CUDACC_VER_MAJOR__ >= 9)
  136|       |#define EIGEN_COMP_NVCC ((__CUDACC_VER_MAJOR__ * 10000) + (__CUDACC_VER_MINOR__ * 100))
  137|       |#elif defined(__CUDACC_VER__)
  138|       |#define EIGEN_COMP_NVCC __CUDACC_VER__
  139|       |#else
  140|       |#error "NVCC did not define compiler version."
  141|       |#endif
  142|       |#else
  143|       |#define EIGEN_COMP_NVCC 0
  144|       |#endif
  145|       |
  146|       |// For the record, here is a table summarizing the possible values for EIGEN_COMP_MSVC:
  147|       |//  name        ver   MSC_VER
  148|       |//  2015        14      1900
  149|       |//  "15"        15      1900
  150|       |//  2017-14.1   15.0    1910
  151|       |//  2017-14.11  15.3    1911
  152|       |//  2017-14.12  15.5    1912
  153|       |//  2017-14.13  15.6    1913
  154|       |//  2017-14.14  15.7    1914
  155|       |//  2017        15.8    1915
  156|       |//  2017        15.9    1916
  157|       |//  2019 RTW    16.0    1920
  158|       |
  159|       |/// \internal EIGEN_COMP_MSVC_LANG set to _MSVC_LANG if the compiler is Microsoft Visual C++, 0 otherwise.
  160|       |#if defined(_MSVC_LANG)
  161|       |#define EIGEN_COMP_MSVC_LANG _MSVC_LANG
  162|       |#else
  163|       |#define EIGEN_COMP_MSVC_LANG 0
  164|       |#endif
  165|       |
  166|       |// For the record, here is a table summarizing the possible values for EIGEN_COMP_MSVC_LANG:
  167|       |// MSVC option                          Standard  MSVC_LANG
  168|       |// /std:c++14 (default as of VS 2019)   C++14     201402L
  169|       |// /std:c++17                           C++17     201703L
  170|       |// /std:c++latest                       >C++17    >201703L
  171|       |
  172|       |/// \internal EIGEN_COMP_MSVC_STRICT set to 1 if the compiler is really Microsoft Visual C++ and not ,e.g., ICC or
  173|       |/// clang-cl
  174|       |#if EIGEN_COMP_MSVC && !(EIGEN_COMP_ICC || EIGEN_COMP_LLVM || EIGEN_COMP_CLANG)
  175|       |#define EIGEN_COMP_MSVC_STRICT _MSC_VER
  176|       |#else
  177|       |#define EIGEN_COMP_MSVC_STRICT 0
  178|       |#endif
  179|       |
  180|       |/// \internal EIGEN_COMP_IBM set to xlc version if the compiler is IBM XL C++
  181|       |// XLC   version
  182|       |// 3.1   0x0301
  183|       |// 4.5   0x0405
  184|       |// 5.0   0x0500
  185|       |// 12.1  0x0C01
  186|       |#if defined(__IBMCPP__) || defined(__xlc__) || defined(__ibmxl__)
  187|       |#define EIGEN_COMP_IBM __xlC__
  188|       |#else
  189|       |#define EIGEN_COMP_IBM 0
  190|       |#endif
  191|       |
  192|       |/// \internal EIGEN_COMP_PGI set to PGI version if the compiler is Portland Group Compiler
  193|       |#if defined(__PGI)
  194|       |#define EIGEN_COMP_PGI (__PGIC__ * 100 + __PGIC_MINOR__)
  195|       |#else
  196|       |#define EIGEN_COMP_PGI 0
  197|       |#endif
  198|       |
  199|       |/// \internal EIGEN_COMP_NVHPC set to NVHPC version if the compiler is nvc++
  200|       |#if defined(__NVCOMPILER)
  201|       |#define EIGEN_COMP_NVHPC (__NVCOMPILER_MAJOR__ * 100 + __NVCOMPILER_MINOR__)
  202|       |#else
  203|       |#define EIGEN_COMP_NVHPC 0
  204|       |#endif
  205|       |
  206|       |/// \internal EIGEN_COMP_ARM set to 1 if the compiler is ARM Compiler
  207|       |#if defined(__CC_ARM) || defined(__ARMCC_VERSION)
  208|       |#define EIGEN_COMP_ARM 1
  209|       |#else
  210|       |#define EIGEN_COMP_ARM 0
  211|       |#endif
  212|       |
  213|       |/// \internal EIGEN_COMP_EMSCRIPTEN set to 1 if the compiler is Emscripten Compiler
  214|       |#if defined(__EMSCRIPTEN__)
  215|       |#define EIGEN_COMP_EMSCRIPTEN 1
  216|       |#else
  217|       |#define EIGEN_COMP_EMSCRIPTEN 0
  218|       |#endif
  219|       |
  220|       |/// \internal EIGEN_COMP_FCC set to FCC version if the compiler is Fujitsu Compiler (traditional mode)
  221|       |/// \note The Fujitsu C/C++ compiler uses the traditional mode based
  222|       |/// on EDG g++ 6.1 by default or if invoked with the -Nnoclang flag
  223|       |#if defined(__FUJITSU)
  224|       |#define EIGEN_COMP_FCC (__FCC_major__ * 100 + __FCC_minor__ * 10 + __FCC_patchlevel__)
  225|       |#else
  226|       |#define EIGEN_COMP_FCC 0
  227|       |#endif
  228|       |
  229|       |/// \internal EIGEN_COMP_CLANGFCC set to FCC version if the compiler is Fujitsu Compiler (Clang mode)
  230|       |/// \note The Fujitsu C/C++ compiler uses the non-traditional mode
  231|       |/// based on Clang 7.1.0 if invoked with the -Nclang flag
  232|       |#if defined(__CLANG_FUJITSU)
  233|       |#define EIGEN_COMP_CLANGFCC (__FCC_major__ * 100 + __FCC_minor__ * 10 + __FCC_patchlevel__)
  234|       |#else
  235|       |#define EIGEN_COMP_CLANGFCC 0
  236|       |#endif
  237|       |
  238|       |/// \internal EIGEN_COMP_CPE set to CPE version if the compiler is HPE Cray Compiler (GCC based)
  239|       |/// \note This is the SVE-enabled C/C++ compiler from the HPE Cray
  240|       |/// Programming Environment (CPE) based on Cray GCC 8.1
  241|       |#if defined(_CRAYC) && !defined(__clang__)
  242|       |#define EIGEN_COMP_CPE (_RELEASE_MAJOR * 100 + _RELEASE_MINOR * 10 + _RELEASE_PATCHLEVEL)
  243|       |#else
  244|       |#define EIGEN_COMP_CPE 0
  245|       |#endif
  246|       |
  247|       |/// \internal EIGEN_COMP_CLANGCPE set to CPE version if the compiler is HPE Cray Compiler (Clang based)
  248|       |/// \note This is the C/C++ compiler from the HPE Cray Programming
  249|       |/// Environment (CPE) based on Cray Clang 11.0 without SVE-support
  250|       |#if defined(_CRAYC) && defined(__clang__)
  251|       |#define EIGEN_COMP_CLANGCPE (_RELEASE_MAJOR * 100 + _RELEASE_MINOR * 10 + _RELEASE_PATCHLEVEL)
  252|       |#else
  253|       |#define EIGEN_COMP_CLANGCPE 0
  254|       |#endif
  255|       |
  256|       |/// \internal EIGEN_COMP_LCC set to 1 if the compiler is MCST-LCC (MCST eLbrus Compiler Collection)
  257|       |#if defined(__LCC__) && defined(__MCST__)
  258|       |#define EIGEN_COMP_LCC (__LCC__ * 100 + __LCC_MINOR__)
  259|       |#else
  260|       |#define EIGEN_COMP_LCC 0
  261|       |#endif
  262|       |
  263|       |/// \internal EIGEN_COMP_GNUC_STRICT set to 1 if the compiler is really GCC and not a compatible compiler (e.g., ICC,
  264|       |/// clang, mingw, etc.)
  265|       |#if EIGEN_COMP_GNUC &&                                                                                      \
  266|       |    !(EIGEN_COMP_CLANG || EIGEN_COMP_ICC || EIGEN_COMP_CLANGICC || EIGEN_COMP_MINGW || EIGEN_COMP_PGI ||    \
  267|       |      EIGEN_COMP_IBM || EIGEN_COMP_ARM || EIGEN_COMP_EMSCRIPTEN || EIGEN_COMP_FCC || EIGEN_COMP_CLANGFCC || \
  268|       |      EIGEN_COMP_CPE || EIGEN_COMP_CLANGCPE || EIGEN_COMP_LCC)
  269|       |#define EIGEN_COMP_GNUC_STRICT 1
  270|       |#else
  271|       |#define EIGEN_COMP_GNUC_STRICT 0
  272|       |#endif
  273|       |
  274|       |// GCC, and compilers that pretend to be it, have different version schemes, so this only makes sense to use with the
  275|       |// real GCC.
  276|       |#if EIGEN_COMP_GNUC_STRICT
  277|       |#define EIGEN_GNUC_STRICT_AT_LEAST(x, y, z)                   \
  278|       |  ((__GNUC__ > x) || (__GNUC__ == x && __GNUC_MINOR__ > y) || \
  279|       |   (__GNUC__ == x && __GNUC_MINOR__ == y && __GNUC_PATCHLEVEL__ >= z))
  280|       |#define EIGEN_GNUC_STRICT_LESS_THAN(x, y, z)                  \
  281|       |  ((__GNUC__ < x) || (__GNUC__ == x && __GNUC_MINOR__ < y) || \
  282|       |   (__GNUC__ == x && __GNUC_MINOR__ == y && __GNUC_PATCHLEVEL__ < z))
  283|       |#else
  284|       |#define EIGEN_GNUC_STRICT_AT_LEAST(x, y, z) 0
  285|       |#define EIGEN_GNUC_STRICT_LESS_THAN(x, y, z) 0
  286|       |#endif
  287|       |
  288|       |/// \internal EIGEN_COMP_CLANG_STRICT set to 1 if the compiler is really Clang and not a compatible compiler (e.g.,
  289|       |/// AppleClang, etc.)
  290|       |#if EIGEN_COMP_CLANG && !(EIGEN_COMP_CLANGAPPLE || EIGEN_COMP_CLANGICC || EIGEN_COMP_CLANGFCC || EIGEN_COMP_CLANGCPE)
  291|       |#define EIGEN_COMP_CLANG_STRICT 1
  292|       |#else
  293|       |#define EIGEN_COMP_CLANG_STRICT 0
  294|       |#endif
  295|       |
  296|       |// Clang, and compilers forked from it, have different version schemes, so this only makes sense to use with the real
  297|       |// Clang.
  298|       |#if EIGEN_COMP_CLANG_STRICT
  299|       |#define EIGEN_CLANG_STRICT_AT_LEAST(x, y, z)                                 \
  300|       |  ((__clang_major__ > x) || (__clang_major__ == x && __clang_minor__ > y) || \
  301|       |   (__clang_major__ == x && __clang_minor__ == y && __clang_patchlevel__ >= z))
  302|       |#define EIGEN_CLANG_STRICT_LESS_THAN(x, y, z)                                \
  303|       |  ((__clang_major__ < x) || (__clang_major__ == x && __clang_minor__ < y) || \
  304|       |   (__clang_major__ == x && __clang_minor__ == y && __clang_patchlevel__ < z))
  305|       |#else
  306|       |#define EIGEN_CLANG_STRICT_AT_LEAST(x, y, z) 0
  307|       |#define EIGEN_CLANG_STRICT_LESS_THAN(x, y, z) 0
  308|       |#endif
  309|       |
  310|       |//------------------------------------------------------------------------------------------
  311|       |// Architecture identification, EIGEN_ARCH_*
  312|       |//------------------------------------------------------------------------------------------
  313|       |
  314|       |#if defined(__x86_64__) || (defined(_M_X64) && !defined(_M_ARM64EC)) || defined(__amd64)
  315|       |#define EIGEN_ARCH_x86_64 1
  316|       |#else
  317|       |#define EIGEN_ARCH_x86_64 0
  318|       |#endif
  319|       |
  320|       |#if defined(__i386__) || defined(_M_IX86) || defined(_X86_) || defined(__i386)
  321|       |#define EIGEN_ARCH_i386 1
  322|       |#else
  323|       |#define EIGEN_ARCH_i386 0
  324|       |#endif
  325|       |
  326|       |#if EIGEN_ARCH_x86_64 || EIGEN_ARCH_i386
  327|       |#define EIGEN_ARCH_i386_OR_x86_64 1
  328|       |#else
  329|       |#define EIGEN_ARCH_i386_OR_x86_64 0
  330|       |#endif
  331|       |
  332|       |/// \internal EIGEN_ARCH_ARM set to 1 if the architecture is ARM
  333|       |#if defined(__arm__)
  334|       |#define EIGEN_ARCH_ARM 1
  335|       |#else
  336|      0|#define EIGEN_ARCH_ARM 0
  337|       |#endif
  338|       |
  339|       |/// \internal EIGEN_ARCH_ARM64 set to 1 if the architecture is ARM64
  340|       |#if defined(__aarch64__) || defined(_M_ARM64) || defined(_M_ARM64EC)
  341|       |#define EIGEN_ARCH_ARM64 1
  342|       |#else
  343|       |#define EIGEN_ARCH_ARM64 0
  344|       |#endif
  345|       |
  346|       |/// \internal EIGEN_ARCH_ARM_OR_ARM64 set to 1 if the architecture is ARM or ARM64
  347|       |#if EIGEN_ARCH_ARM || EIGEN_ARCH_ARM64
  348|       |#define EIGEN_ARCH_ARM_OR_ARM64 1
  349|       |#else
  350|       |#define EIGEN_ARCH_ARM_OR_ARM64 0
  351|       |#endif
  352|       |
  353|       |/// \internal EIGEN_ARCH_ARMV8 set to 1 if the architecture is armv8 or greater.
  354|       |#if EIGEN_ARCH_ARM_OR_ARM64 && defined(__ARM_ARCH) && __ARM_ARCH >= 8
  355|       |#define EIGEN_ARCH_ARMV8 1
  356|       |#else
  357|       |#define EIGEN_ARCH_ARMV8 0
  358|       |#endif
  359|       |
  360|       |/// \internal EIGEN_HAS_ARM64_FP16 set to 1 if the architecture provides an IEEE
  361|       |/// compliant Arm fp16 type
  362|       |#if EIGEN_ARCH_ARM_OR_ARM64
  363|       |#ifndef EIGEN_HAS_ARM64_FP16
  364|       |#if defined(__ARM_FP16_FORMAT_IEEE)
  365|       |#define EIGEN_HAS_ARM64_FP16 1
  366|       |#else
  367|       |#define EIGEN_HAS_ARM64_FP16 0
  368|       |#endif
  369|       |#endif
  370|       |#endif
  371|       |
  372|       |/// \internal EIGEN_ARCH_MIPS set to 1 if the architecture is MIPS
  373|       |#if defined(__mips__) || defined(__mips)
  374|       |#define EIGEN_ARCH_MIPS 1
  375|       |#else
  376|      0|#define EIGEN_ARCH_MIPS 0
  377|       |#endif
  378|       |
  379|       |/// \internal EIGEN_ARCH_LOONGARCH64 set to 1 if the architecture is LOONGARCH64
  380|       |#if defined(__loongarch64)
  381|       |#define EIGEN_ARCH_LOONGARCH64 1
  382|       |#else
  383|       |#define EIGEN_ARCH_LOONGARCH64 0
  384|       |#endif
  385|       |
  386|       |/// \internal EIGEN_ARCH_SPARC set to 1 if the architecture is SPARC
  387|       |#if defined(__sparc__) || defined(__sparc)
  388|       |#define EIGEN_ARCH_SPARC 1
  389|       |#else
  390|       |#define EIGEN_ARCH_SPARC 0
  391|       |#endif
  392|       |
  393|       |/// \internal EIGEN_ARCH_IA64 set to 1 if the architecture is Intel Itanium
  394|       |#if defined(__ia64__)
  395|       |#define EIGEN_ARCH_IA64 1
  396|       |#else
  397|       |#define EIGEN_ARCH_IA64 0
  398|       |#endif
  399|       |
  400|       |/// \internal EIGEN_ARCH_PPC set to 1 if the architecture is PowerPC
  401|       |#if defined(__powerpc__) || defined(__ppc__) || defined(_M_PPC) || defined(__POWERPC__)
  402|       |#define EIGEN_ARCH_PPC 1
  403|       |#else
  404|       |#define EIGEN_ARCH_PPC 0
  405|       |#endif
  406|       |
  407|       |//------------------------------------------------------------------------------------------
  408|       |// Operating system identification, EIGEN_OS_*
  409|       |//------------------------------------------------------------------------------------------
  410|       |
  411|       |/// \internal EIGEN_OS_UNIX set to 1 if the OS is a unix variant
  412|       |#if defined(__unix__) || defined(__unix)
  413|       |#define EIGEN_OS_UNIX 1
  414|       |#else
  415|       |#define EIGEN_OS_UNIX 0
  416|       |#endif
  417|       |
  418|       |/// \internal EIGEN_OS_LINUX set to 1 if the OS is based on Linux kernel
  419|       |#if defined(__linux__)
  420|       |#define EIGEN_OS_LINUX 1
  421|       |#else
  422|       |#define EIGEN_OS_LINUX 0
  423|       |#endif
  424|       |
  425|       |/// \internal EIGEN_OS_ANDROID set to 1 if the OS is Android
  426|       |// note: ANDROID is defined when using ndk_build, __ANDROID__ is defined when using a standalone toolchain.
  427|       |#if defined(__ANDROID__) || defined(ANDROID)
  428|       |#define EIGEN_OS_ANDROID 1
  429|       |#else
  430|       |#define EIGEN_OS_ANDROID 0
  431|       |#endif
  432|       |
  433|       |/// \internal EIGEN_OS_GNULINUX set to 1 if the OS is GNU Linux and not Linux-based OS (e.g., not android)
  434|       |#if defined(__gnu_linux__) && !(EIGEN_OS_ANDROID)
  435|       |#define EIGEN_OS_GNULINUX 1
  436|       |#else
  437|       |#define EIGEN_OS_GNULINUX 0
  438|       |#endif
  439|       |
  440|       |/// \internal EIGEN_OS_BSD set to 1 if the OS is a BSD variant
  441|       |#if defined(__FreeBSD__) || defined(__NetBSD__) || defined(__OpenBSD__) || defined(__bsdi__) || defined(__DragonFly__)
  442|       |#define EIGEN_OS_BSD 1
  443|       |#else
  444|       |#define EIGEN_OS_BSD 0
  445|       |#endif
  446|       |
  447|       |/// \internal EIGEN_OS_MAC set to 1 if the OS is MacOS
  448|       |#if defined(__APPLE__)
  449|       |#define EIGEN_OS_MAC 1
  450|       |#else
  451|       |#define EIGEN_OS_MAC 0
  452|       |#endif
  453|       |
  454|       |/// \internal EIGEN_OS_QNX set to 1 if the OS is QNX
  455|       |#if defined(__QNX__)
  456|       |#define EIGEN_OS_QNX 1
  457|       |#else
  458|       |#define EIGEN_OS_QNX 0
  459|       |#endif
  460|       |
  461|       |/// \internal EIGEN_OS_WIN set to 1 if the OS is Windows based
  462|       |#if defined(_WIN32)
  463|       |#define EIGEN_OS_WIN 1
  464|       |#else
  465|       |#define EIGEN_OS_WIN 0
  466|       |#endif
  467|       |
  468|       |/// \internal EIGEN_OS_WIN64 set to 1 if the OS is Windows 64bits
  469|       |#if defined(_WIN64)
  470|       |#define EIGEN_OS_WIN64 1
  471|       |#else
  472|       |#define EIGEN_OS_WIN64 0
  473|       |#endif
  474|       |
  475|       |/// \internal EIGEN_OS_WINCE set to 1 if the OS is Windows CE
  476|       |#if defined(_WIN32_WCE)
  477|       |#define EIGEN_OS_WINCE 1
  478|       |#else
  479|       |#define EIGEN_OS_WINCE 0
  480|       |#endif
  481|       |
  482|       |/// \internal EIGEN_OS_CYGWIN set to 1 if the OS is Windows/Cygwin
  483|       |#if defined(__CYGWIN__)
  484|       |#define EIGEN_OS_CYGWIN 1
  485|       |#else
  486|       |#define EIGEN_OS_CYGWIN 0
  487|       |#endif
  488|       |
  489|       |/// \internal EIGEN_OS_WIN_STRICT set to 1 if the OS is really Windows and not some variants
  490|       |#if EIGEN_OS_WIN && !(EIGEN_OS_WINCE || EIGEN_OS_CYGWIN)
  491|       |#define EIGEN_OS_WIN_STRICT 1
  492|       |#else
  493|       |#define EIGEN_OS_WIN_STRICT 0
  494|       |#endif
  495|       |
  496|       |/// \internal EIGEN_OS_SUN set to __SUNPRO_C if the OS is SUN
  497|       |// compiler  solaris   __SUNPRO_C
  498|       |// version   studio
  499|       |// 5.7       10        0x570
  500|       |// 5.8       11        0x580
  501|       |// 5.9       12        0x590
  502|       |// 5.10	     12.1      0x5100
  503|       |// 5.11	     12.2      0x5110
  504|       |// 5.12	     12.3      0x5120
  505|       |#if (defined(sun) || defined(__sun)) && !(defined(__SVR4) || defined(__svr4__))
  506|       |#define EIGEN_OS_SUN __SUNPRO_C
  507|       |#else
  508|       |#define EIGEN_OS_SUN 0
  509|       |#endif
  510|       |
  511|       |/// \internal EIGEN_OS_SOLARIS set to 1 if the OS is Solaris
  512|       |#if (defined(sun) || defined(__sun)) && (defined(__SVR4) || defined(__svr4__))
  513|       |#define EIGEN_OS_SOLARIS 1
  514|       |#else
  515|       |#define EIGEN_OS_SOLARIS 0
  516|       |#endif
  517|       |
  518|       |//------------------------------------------------------------------------------------------
  519|       |// Detect GPU compilers and architectures
  520|       |//------------------------------------------------------------------------------------------
  521|       |
  522|       |// NVCC is not supported as the target platform for HIPCC
  523|       |// Note that this also makes EIGEN_CUDACC and EIGEN_HIPCC mutually exclusive
  524|       |#if defined(__NVCC__) && defined(__HIPCC__)
  525|       |#error "NVCC as the target platform for HIPCC is currently not supported."
  526|       |#endif
  527|       |
  528|       |#if defined(__CUDACC__) && !defined(EIGEN_NO_CUDA) && !defined(__SYCL_DEVICE_ONLY__)
  529|       |// Means the compiler is either nvcc or clang with CUDA enabled
  530|       |#define EIGEN_CUDACC __CUDACC__
  531|       |#endif
  532|       |
  533|       |#if defined(__CUDA_ARCH__) && !defined(EIGEN_NO_CUDA) && !defined(__SYCL_DEVICE_ONLY__)
  534|       |// Means we are generating code for the device
  535|       |#define EIGEN_CUDA_ARCH __CUDA_ARCH__
  536|       |#endif
  537|       |
  538|       |#if defined(EIGEN_CUDACC)
  539|       |#include <cuda.h>
  540|       |#define EIGEN_CUDA_SDK_VER (CUDA_VERSION * 10)
  541|       |#else
  542|       |#define EIGEN_CUDA_SDK_VER 0
  543|       |#endif
  544|       |
  545|       |#if defined(__HIPCC__) && !defined(EIGEN_NO_HIP) && !defined(__SYCL_DEVICE_ONLY__)
  546|       |// Means the compiler is HIPCC (analogous to EIGEN_CUDACC, but for HIP)
  547|       |#define EIGEN_HIPCC __HIPCC__
  548|       |
  549|       |// We need to include hip_runtime.h here because it pulls in
  550|       |// ++ hip_common.h which contains the define for  __HIP_DEVICE_COMPILE__
  551|       |// ++ host_defines.h which contains the defines for the __host__ and __device__ macros
  552|       |#include <hip/hip_runtime.h>
  553|       |
  554|       |#if defined(__HIP_DEVICE_COMPILE__) && !defined(__SYCL_DEVICE_ONLY__)
  555|       |// analogous to EIGEN_CUDA_ARCH, but for HIP
  556|       |#define EIGEN_HIP_DEVICE_COMPILE __HIP_DEVICE_COMPILE__
  557|       |#endif
  558|       |
  559|       |// For HIP (ROCm 3.5 and higher), we need to explicitly set the launch_bounds attribute
  560|       |// value to 1024. The compiler assigns a default value of 256 when the attribute is not
  561|       |// specified. This results in failures on the HIP platform, for cases when a GPU kernel
  562|       |// without an explicit launch_bounds attribute is called with a threads_per_block value
  563|       |// greater than 256.
  564|       |//
  565|       |// This is a regression in functioanlity and is expected to be fixed within the next
  566|       |// couple of ROCm releases (compiler will go back to using 1024 value as the default)
  567|       |//
  568|       |// In the meantime, we will use a "only enabled for HIP" macro to set the launch_bounds
  569|       |// attribute.
  570|       |
  571|       |#define EIGEN_HIP_LAUNCH_BOUNDS_1024 __launch_bounds__(1024)
  572|       |
  573|       |#endif
  574|       |
  575|       |#if !defined(EIGEN_HIP_LAUNCH_BOUNDS_1024)
  576|       |#define EIGEN_HIP_LAUNCH_BOUNDS_1024
  577|       |#endif  // !defined(EIGEN_HIP_LAUNCH_BOUNDS_1024)
  578|       |
  579|       |// Unify CUDA/HIPCC
  580|       |
  581|       |#if defined(EIGEN_CUDACC) || defined(EIGEN_HIPCC)
  582|       |//
  583|       |// If either EIGEN_CUDACC or EIGEN_HIPCC is defined, then define EIGEN_GPUCC
  584|       |//
  585|       |#define EIGEN_GPUCC
  586|       |//
  587|       |// EIGEN_HIPCC implies the HIP compiler and is used to tweak Eigen code for use in HIP kernels
  588|       |// EIGEN_CUDACC implies the CUDA compiler and is used to tweak Eigen code for use in CUDA kernels
  589|       |//
  590|       |// In most cases the same tweaks are required to the Eigen code to enable in both the HIP and CUDA kernels.
  591|       |// For those cases, the corresponding code should be guarded with
  592|       |//      #if defined(EIGEN_GPUCC)
  593|       |// instead of
  594|       |//      #if defined(EIGEN_CUDACC) || defined(EIGEN_HIPCC)
  595|       |//
  596|       |// For cases where the tweak is specific to HIP, the code should be guarded with
  597|       |//      #if defined(EIGEN_HIPCC)
  598|       |//
  599|       |// For cases where the tweak is specific to CUDA, the code should be guarded with
  600|       |//      #if defined(EIGEN_CUDACC)
  601|       |//
  602|       |#endif
  603|       |
  604|       |#if defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIP_DEVICE_COMPILE)
  605|       |//
  606|       |// If either EIGEN_CUDA_ARCH or EIGEN_HIP_DEVICE_COMPILE is defined, then define EIGEN_GPU_COMPILE_PHASE
  607|       |//
  608|       |#define EIGEN_GPU_COMPILE_PHASE
  609|       |//
  610|       |// GPU compilers (HIPCC, NVCC) typically do two passes over the source code,
  611|       |//   + one to compile the source for the "host" (ie CPU)
  612|       |//   + another to compile the source for the "device" (ie. GPU)
  613|       |//
  614|       |// Code that needs to enabled only during the either the "host" or "device" compilation phase
  615|       |// needs to be guarded with a macro that indicates the current compilation phase
  616|       |//
  617|       |// EIGEN_HIP_DEVICE_COMPILE implies the device compilation phase in HIP
  618|       |// EIGEN_CUDA_ARCH implies the device compilation phase in CUDA
  619|       |//
  620|       |// In most cases, the "host" / "device" specific code is the same for both HIP and CUDA
  621|       |// For those cases, the code should be guarded with
  622|       |//       #if defined(EIGEN_GPU_COMPILE_PHASE)
  623|       |// instead of
  624|       |//       #if defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIP_DEVICE_COMPILE)
  625|       |//
  626|       |// For cases where the tweak is specific to HIP, the code should be guarded with
  627|       |//      #if defined(EIGEN_HIP_DEVICE_COMPILE)
  628|       |//
  629|       |// For cases where the tweak is specific to CUDA, the code should be guarded with
  630|       |//      #if defined(EIGEN_CUDA_ARCH)
  631|       |//
  632|       |#endif
  633|       |
  634|       |/// \internal EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC set to 1 if the architecture
  635|       |/// supports Neon vector intrinsics for fp16.
  636|       |#if EIGEN_ARCH_ARM_OR_ARM64
  637|       |#ifndef EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC
  638|       |// Clang only supports FP16 on aarch64, and not all intrinsics are available
  639|       |// on A32 anyways even in GCC (e.g. vdiv_f16, vsqrt_f16).
  640|       |#if EIGEN_ARCH_ARM64 && defined(__ARM_FEATURE_FP16_VECTOR_ARITHMETIC) && !defined(EIGEN_GPU_COMPILE_PHASE)
  641|       |#define EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC 1
  642|       |#else
  643|       |#define EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC 0
  644|       |#endif
  645|       |#endif
  646|       |#endif
  647|       |
  648|       |/// \internal EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC set to 1 if the architecture
  649|       |/// supports Neon scalar intrinsics for fp16.
  650|       |#if EIGEN_ARCH_ARM_OR_ARM64
  651|       |#ifndef EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC
  652|       |// Clang only supports FP16 on aarch64, and not all intrinsics are available
  653|       |// on A32 anyways, even in GCC (e.g. vceqh_f16).
  654|       |#if EIGEN_ARCH_ARM64 && defined(__ARM_FEATURE_FP16_SCALAR_ARITHMETIC) && !defined(EIGEN_GPU_COMPILE_PHASE)
  655|       |#define EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC 1
  656|       |#endif
  657|       |#endif
  658|       |#endif
  659|       |
  660|       |#if defined(EIGEN_USE_SYCL) && defined(__SYCL_DEVICE_ONLY__)
  661|       |// EIGEN_USE_SYCL is a user-defined macro while __SYCL_DEVICE_ONLY__ is a compiler-defined macro.
  662|       |// In most cases we want to check if both macros are defined which can be done using the define below.
  663|       |#define SYCL_DEVICE_ONLY
  664|       |#endif
  665|       |
  666|       |//------------------------------------------------------------------------------------------
  667|       |// Detect Compiler/Architecture/OS specific features
  668|       |//------------------------------------------------------------------------------------------
  669|       |
  670|       |// Cross compiler wrapper around LLVM's __has_builtin
  671|       |#ifdef __has_builtin
  672|       |#define EIGEN_HAS_BUILTIN(x) __has_builtin(x)
  673|       |#else
  674|       |#define EIGEN_HAS_BUILTIN(x) 0
  675|       |#endif
  676|       |
  677|       |// A Clang feature extension to determine compiler features.
  678|       |// We use it to determine 'cxx_rvalue_references'
  679|       |#ifndef __has_feature
  680|       |#define __has_feature(x) 0
  681|       |#endif
  682|       |
  683|       |// The macro EIGEN_CPLUSPLUS is a replacement for __cplusplus/_MSVC_LANG that
  684|       |// works for both platforms, indicating the C++ standard version number.
  685|       |//
  686|       |// With MSVC, without defining /Zc:__cplusplus, the __cplusplus macro will
  687|       |// report 199711L regardless of the language standard specified via /std.
  688|       |// We need to rely on _MSVC_LANG instead, which is only available after
  689|       |// VS2015.3.
  690|       |#if EIGEN_COMP_MSVC_LANG > 0
  691|       |#define EIGEN_CPLUSPLUS EIGEN_COMP_MSVC_LANG
  692|       |#elif EIGEN_COMP_MSVC >= 1900
  693|       |#define EIGEN_CPLUSPLUS 201103L
  694|       |#elif defined(__cplusplus)
  695|       |#define EIGEN_CPLUSPLUS __cplusplus
  696|       |#else
  697|       |#define EIGEN_CPLUSPLUS 0
  698|       |#endif
  699|       |
  700|       |// The macro EIGEN_COMP_CXXVER defines the c++ version expected by the compiler.
  701|       |// For instance, if compiling with gcc and -std=c++17, then EIGEN_COMP_CXXVER
  702|       |// is defined to 17.
  703|       |#if EIGEN_CPLUSPLUS >= 202002L
  704|       |#define EIGEN_COMP_CXXVER 20
  705|       |#elif EIGEN_CPLUSPLUS >= 201703L
  706|       |#define EIGEN_COMP_CXXVER 17
  707|       |#elif EIGEN_CPLUSPLUS >= 201402L
  708|       |#define EIGEN_COMP_CXXVER 14
  709|       |#elif EIGEN_CPLUSPLUS >= 201103L
  710|       |#define EIGEN_COMP_CXXVER 11
  711|       |#else
  712|       |#define EIGEN_COMP_CXXVER 03
  713|       |#endif
  714|       |
  715|       |// The macros EIGEN_HAS_CXX?? defines a rough estimate of available c++ features
  716|       |// but in practice we should not rely on them but rather on the availability of
  717|       |// individual features as defined later.
  718|       |// This is why there is no EIGEN_HAS_CXX17.
  719|       |#if EIGEN_MAX_CPP_VER < 14 || EIGEN_COMP_CXXVER < 14 || (EIGEN_COMP_MSVC && EIGEN_COMP_MSVC < 1900) || \
  720|       |    (EIGEN_COMP_ICC && EIGEN_COMP_ICC < 1500) || (EIGEN_COMP_NVCC && EIGEN_COMP_NVCC < 80000) ||       \
  721|       |    (EIGEN_COMP_CLANG_STRICT && EIGEN_COMP_CLANG < 390) ||                                             \
  722|       |    (EIGEN_COMP_CLANGAPPLE && EIGEN_COMP_CLANGAPPLE < 9000000) || (EIGEN_COMP_GNUC_STRICT && EIGEN_COMP_GNUC < 510)
  723|       |#error Eigen requires at least c++14 support.
  724|       |#endif
  725|       |
  726|       |// Does the compiler support C99?
  727|       |// Need to include <cmath> to make sure _GLIBCXX_USE_C99 gets defined
  728|       |#include <cmath>
  729|       |#ifndef EIGEN_HAS_C99_MATH
  730|       |#if ((defined(__STDC_VERSION__) && (__STDC_VERSION__ >= 199901)) ||                                          \
  731|       |     (defined(__GNUC__) && defined(_GLIBCXX_USE_C99)) || (defined(_LIBCPP_VERSION) && !defined(_MSC_VER)) || \
  732|       |     (EIGEN_COMP_MSVC) || defined(SYCL_DEVICE_ONLY))
  733|       |#define EIGEN_HAS_C99_MATH 1
  734|       |#else
  735|       |#define EIGEN_HAS_C99_MATH 0
  736|       |#endif
  737|       |#endif
  738|       |
  739|       |// Does the compiler support std::hash?
  740|       |#ifndef EIGEN_HAS_STD_HASH
  741|       |// The std::hash struct is defined in C++11 but is not labelled as a __device__
  742|       |// function and is not constexpr, so cannot be used on device.
  743|       |#if !defined(EIGEN_GPU_COMPILE_PHASE)
  744|       |#define EIGEN_HAS_STD_HASH 1
  745|       |#else
  746|       |#define EIGEN_HAS_STD_HASH 0
  747|       |#endif
  748|       |#endif  // EIGEN_HAS_STD_HASH
  749|       |
  750|       |#ifndef EIGEN_HAS_STD_INVOKE_RESULT
  751|       |#if EIGEN_MAX_CPP_VER >= 17 && EIGEN_COMP_CXXVER >= 17
  752|       |#define EIGEN_HAS_STD_INVOKE_RESULT 1
  753|       |#else
  754|       |#define EIGEN_HAS_STD_INVOKE_RESULT 0
  755|       |#endif
  756|       |#endif
  757|       |
  758|       |#define EIGEN_CONSTEXPR constexpr
  759|       |
  760|       |// NOTE: the required Apple's clang version is very conservative
  761|       |//       and it could be that XCode 9 works just fine.
  762|       |// NOTE: the MSVC version is based on https://en.cppreference.com/w/cpp/compiler_support
  763|       |//       and not tested.
  764|       |// NOTE: Intel C++ Compiler Classic (icc) Version 19.0 and later supports dynamic allocation
  765|       |//       for over-aligned data, but not in a manner that is compatible with Eigen.
  766|       |//       See https://gitlab.com/libeigen/eigen/-/issues/2575
  767|       |#ifndef EIGEN_HAS_CXX17_OVERALIGN
  768|       |#if EIGEN_MAX_CPP_VER >= 17 && EIGEN_COMP_CXXVER >= 17 &&                                                            \
  769|       |    ((EIGEN_COMP_MSVC >= 1912) || (EIGEN_GNUC_STRICT_AT_LEAST(7, 0, 0)) || (EIGEN_CLANG_STRICT_AT_LEAST(5, 0, 0)) || \
  770|       |     (EIGEN_COMP_CLANGAPPLE && EIGEN_COMP_CLANGAPPLE >= 10000000)) &&                                                \
  771|       |    !EIGEN_COMP_ICC
  772|       |#define EIGEN_HAS_CXX17_OVERALIGN 1
  773|       |#else
  774|       |#define EIGEN_HAS_CXX17_OVERALIGN 0
  775|       |#endif
  776|       |#endif
  777|       |
  778|       |#if defined(EIGEN_CUDACC)
  779|       |// While available already with c++11, this is useful mostly starting with c++14 and relaxed constexpr rules
  780|       |#if defined(__NVCC__)
  781|       |// nvcc considers constexpr functions as __host__ __device__ with the option --expt-relaxed-constexpr
  782|       |#ifdef __CUDACC_RELAXED_CONSTEXPR__
  783|       |#define EIGEN_CONSTEXPR_ARE_DEVICE_FUNC
  784|       |#endif
  785|       |#elif defined(__clang__) && defined(__CUDA__) && __has_feature(cxx_relaxed_constexpr)
  786|       |// clang++ always considers constexpr functions as implicitly __host__ __device__
  787|       |#define EIGEN_CONSTEXPR_ARE_DEVICE_FUNC
  788|       |#endif
  789|       |#endif
  790|       |
  791|       |// Does the compiler support the __int128 and __uint128_t extensions for 128-bit
  792|       |// integer arithmetic?
  793|       |//
  794|       |// Clang and GCC define __SIZEOF_INT128__ when these extensions are supported,
  795|       |// but we avoid using them in certain cases:
  796|       |//
  797|       |// * Building using Clang for Windows, where the Clang runtime library has
  798|       |//   128-bit support only on LP64 architectures, but Windows is LLP64.
  799|       |#ifndef EIGEN_HAS_BUILTIN_INT128
  800|       |#if defined(__SIZEOF_INT128__) && !(EIGEN_OS_WIN && EIGEN_COMP_CLANG)
  801|       |#define EIGEN_HAS_BUILTIN_INT128 1
  802|       |#else
  803|       |#define EIGEN_HAS_BUILTIN_INT128 0
  804|       |#endif
  805|       |#endif
  806|       |
  807|       |//------------------------------------------------------------------------------------------
  808|       |// Preprocessor programming helpers
  809|       |//------------------------------------------------------------------------------------------
  810|       |
  811|       |// This macro can be used to prevent from macro expansion, e.g.:
  812|       |//   std::max EIGEN_NOT_A_MACRO(a,b)
  813|       |#define EIGEN_NOT_A_MACRO
  814|       |
  815|       |#define EIGEN_DEBUG_VAR(x) std::cerr << #x << " = " << x << std::endl;
  816|       |
  817|       |// concatenate two tokens
  818|      4|#define EIGEN_CAT2(a, b) a##b
  819|      4|#define EIGEN_CAT(a, b) EIGEN_CAT2(a, b)
  820|       |
  821|       |#define EIGEN_COMMA ,
  822|       |
  823|       |// convert a token to a string
  824|      8|#define EIGEN_MAKESTRING2(a) #a
  825|      8|#define EIGEN_MAKESTRING(a) EIGEN_MAKESTRING2(a)
  826|       |
  827|       |// EIGEN_STRONG_INLINE is a stronger version of the inline, using __forceinline on MSVC,
  828|       |// but it still doesn't use GCC's always_inline. This is useful in (common) situations where MSVC needs forceinline
  829|       |// but GCC is still doing fine with just inline.
  830|       |#ifndef EIGEN_STRONG_INLINE
  831|       |#if (EIGEN_COMP_MSVC || EIGEN_COMP_ICC) && !defined(EIGEN_GPUCC)
  832|       |#define EIGEN_STRONG_INLINE __forceinline
  833|       |#else
  834|       |#define EIGEN_STRONG_INLINE inline
  835|       |#endif
  836|       |#endif
  837|       |
  838|       |// EIGEN_ALWAYS_INLINE is the strongest, it has the effect of making the function inline and adding every possible
  839|       |// attribute to maximize inlining. This should only be used when really necessary: in particular,
  840|       |// it uses __attribute__((always_inline)) on GCC, which most of the time is useless and can severely harm compile times.
  841|       |// FIXME with the always_inline attribute,
  842|       |#if EIGEN_COMP_GNUC && !defined(SYCL_DEVICE_ONLY)
  843|       |#define EIGEN_ALWAYS_INLINE __attribute__((always_inline)) inline
  844|       |#else
  845|       |#define EIGEN_ALWAYS_INLINE EIGEN_STRONG_INLINE
  846|       |#endif
  847|       |
  848|       |#if EIGEN_COMP_GNUC
  849|       |#define EIGEN_DONT_INLINE __attribute__((noinline))
  850|       |#elif EIGEN_COMP_MSVC
  851|       |#define EIGEN_DONT_INLINE __declspec(noinline)
  852|       |#else
  853|       |#define EIGEN_DONT_INLINE
  854|       |#endif
  855|       |
  856|       |#if EIGEN_COMP_GNUC
  857|       |#define EIGEN_PERMISSIVE_EXPR __extension__
  858|       |#else
  859|       |#define EIGEN_PERMISSIVE_EXPR
  860|       |#endif
  861|       |
  862|       |// GPU stuff
  863|       |
  864|       |// Disable some features when compiling with GPU compilers (SYCL/HIPCC)
  865|       |#if defined(SYCL_DEVICE_ONLY) || defined(EIGEN_HIP_DEVICE_COMPILE)
  866|       |// Do not try asserts on device code
  867|       |#ifndef EIGEN_NO_DEBUG
  868|       |#define EIGEN_NO_DEBUG
  869|       |#endif
  870|       |
  871|       |#ifdef EIGEN_INTERNAL_DEBUGGING
  872|       |#undef EIGEN_INTERNAL_DEBUGGING
  873|       |#endif
  874|       |#endif
  875|       |
  876|       |// No exceptions on device.
  877|       |#if defined(SYCL_DEVICE_ONLY) || defined(EIGEN_GPU_COMPILE_PHASE)
  878|       |#ifdef EIGEN_EXCEPTIONS
  879|       |#undef EIGEN_EXCEPTIONS
  880|       |#endif
  881|       |#endif
  882|       |
  883|       |#if defined(SYCL_DEVICE_ONLY)
  884|       |#ifndef EIGEN_DONT_VECTORIZE
  885|       |#define EIGEN_DONT_VECTORIZE
  886|       |#endif
  887|       |#define EIGEN_DEVICE_FUNC __attribute__((flatten)) __attribute__((always_inline))
  888|       |// All functions callable from CUDA/HIP code must be qualified with __device__
  889|       |#elif defined(EIGEN_GPUCC)
  890|       |#define EIGEN_DEVICE_FUNC __host__ __device__
  891|       |#else
  892|       |#define EIGEN_DEVICE_FUNC
  893|       |#endif
  894|       |
  895|       |// this macro allows to get rid of linking errors about multiply defined functions.
  896|       |//  - static is not very good because it prevents definitions from different object files to be merged.
  897|       |//           So static causes the resulting linked executable to be bloated with multiple copies of the same function.
  898|       |//  - inline is not perfect either as it unwantedly hints the compiler toward inlining the function.
  899|       |#define EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_DEVICE_FUNC
  900|       |#define EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_DEVICE_FUNC inline
  901|       |
  902|       |#ifdef NDEBUG
  903|       |#ifndef EIGEN_NO_DEBUG
  904|       |#define EIGEN_NO_DEBUG
  905|       |#endif
  906|       |#endif
  907|       |
  908|       |// eigen_assert can be overridden
  909|       |#ifndef eigen_assert
  910|       |#define eigen_assert(x) eigen_plain_assert(x)
  911|       |#endif
  912|       |
  913|       |#ifdef EIGEN_INTERNAL_DEBUGGING
  914|      7|#define eigen_internal_assert(x) eigen_assert(x)
  915|       |#else
  916|       |#define eigen_internal_assert(x) ((void)0)
  917|       |#endif
  918|       |
  919|       |#if defined(EIGEN_NO_DEBUG) || (defined(EIGEN_GPU_COMPILE_PHASE) && defined(EIGEN_NO_DEBUG_GPU))
  920|       |#define EIGEN_ONLY_USED_FOR_DEBUG(x) EIGEN_UNUSED_VARIABLE(x)
  921|       |#else
  922|       |#define EIGEN_ONLY_USED_FOR_DEBUG(x)
  923|       |#endif
  924|       |
  925|       |#ifndef EIGEN_NO_DEPRECATED_WARNING
  926|       |#if EIGEN_COMP_GNUC
  927|       |#define EIGEN_DEPRECATED __attribute__((deprecated))
  928|       |#elif EIGEN_COMP_MSVC
  929|       |#define EIGEN_DEPRECATED __declspec(deprecated)
  930|       |#else
  931|       |#define EIGEN_DEPRECATED
  932|       |#endif
  933|       |#else
  934|       |#define EIGEN_DEPRECATED
  935|       |#endif
  936|       |
  937|       |#if EIGEN_COMP_GNUC
  938|       |#define EIGEN_UNUSED __attribute__((unused))
  939|       |#else
  940|       |#define EIGEN_UNUSED
  941|       |#endif
  942|       |
  943|       |#if EIGEN_COMP_GNUC
  944|       |#define EIGEN_PRAGMA(tokens) _Pragma(#tokens)
  945|       |#define EIGEN_DIAGNOSTICS(tokens) EIGEN_PRAGMA(GCC diagnostic tokens)
  946|       |#define EIGEN_DIAGNOSTICS_OFF(msc, gcc) EIGEN_DIAGNOSTICS(gcc)
  947|       |#elif EIGEN_COMP_MSVC
  948|       |#define EIGEN_PRAGMA(tokens) __pragma(tokens)
  949|       |#define EIGEN_DIAGNOSTICS(tokens) EIGEN_PRAGMA(warning(tokens))
  950|       |#define EIGEN_DIAGNOSTICS_OFF(msc, gcc) EIGEN_DIAGNOSTICS(msc)
  951|       |#else
  952|       |#define EIGEN_PRAGMA(tokens)
  953|       |#define EIGEN_DIAGNOSTICS(tokens)
  954|       |#define EIGEN_DIAGNOSTICS_OFF(msc, gcc)
  955|       |#endif
  956|       |
  957|       |#define EIGEN_DISABLE_DEPRECATED_WARNING EIGEN_DIAGNOSTICS_OFF(disable : 4996, ignored "-Wdeprecated-declarations")
  958|       |
  959|       |// Suppresses 'unused variable' warnings.
  960|       |namespace Eigen {
  961|       |namespace internal {
  962|       |template <typename T>
  963|     18|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void ignore_unused_variable(const T&) {}
  ------------------
  | _ZN5Eigen8internal22ignore_unused_variableIbEEvRKT_:
  |  963|      2|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void ignore_unused_variable(const T&) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22ignore_unused_variableI14AnnoyingScalarEEvRKT_
  ------------------
  | _ZN5Eigen8internal22ignore_unused_variableIlEEvRKT_:
  |  963|     14|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void ignore_unused_variable(const T&) {}
  ------------------
  | _ZN5Eigen8internal22ignore_unused_variableIPNS0_16GemmParallelInfoIlEEEEvRKT_:
  |  963|      2|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void ignore_unused_variable(const T&) {}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22ignore_unused_variableImEEvRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22ignore_unused_variableIfEEvRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22ignore_unused_variableIDv4_fEEvRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22ignore_unused_variableIDv2_dEEvRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22ignore_unused_variableINS0_16blas_data_mapperI14AnnoyingScalarlLi0ELi0ELi1EEEEEvRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22ignore_unused_variableINS0_11gebp_traitsI14AnnoyingScalarS3_Lb0ELb0ELi1ELi0EEEEEvRKT_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal22ignore_unused_variableIPK14AnnoyingScalarEEvRKT_
  ------------------
  964|       |}  // namespace internal
  965|       |}  // namespace Eigen
  966|     18|#define EIGEN_UNUSED_VARIABLE(var) Eigen::internal::ignore_unused_variable(var);
  967|       |
  968|       |#if !defined(EIGEN_ASM_COMMENT)
  969|       |#if EIGEN_COMP_GNUC && (EIGEN_ARCH_i386_OR_x86_64 || EIGEN_ARCH_ARM_OR_ARM64)
  970|     76|#define EIGEN_ASM_COMMENT(X) __asm__("#" X)
  971|       |#else
  972|       |#define EIGEN_ASM_COMMENT(X)
  973|       |#endif
  974|       |#endif
  975|       |
  976|       |// Acts as a barrier preventing operations involving `X` from crossing. This
  977|       |// occurs, for example, in the fast rounding trick where a magic constant is
  978|       |// added then subtracted, which is otherwise compiled away with -ffast-math.
  979|       |//
  980|       |// See bug 1674
  981|       |#if defined(EIGEN_GPU_COMPILE_PHASE)
  982|       |#define EIGEN_OPTIMIZATION_BARRIER(X)
  983|       |#endif
  984|       |
  985|       |#if !defined(EIGEN_OPTIMIZATION_BARRIER)
  986|       |#if EIGEN_COMP_GNUC
  987|       |   // According to https://gcc.gnu.org/onlinedocs/gcc/Constraints.html:
  988|       |//   X: Any operand whatsoever.
  989|       |//   r: A register operand is allowed provided that it is in a general
  990|       |//      register.
  991|       |//   g: Any register, memory or immediate integer operand is allowed, except
  992|       |//      for registers that are not general registers.
  993|       |//   w: (AArch32/AArch64) Floating point register, Advanced SIMD vector
  994|       |//      register or SVE vector register.
  995|       |//   x: (SSE) Any SSE register.
  996|       |//      (AArch64) Like w, but restricted to registers 0 to 15 inclusive.
  997|       |//   v: (PowerPC) An Altivec vector register.
  998|       |//   wa:(PowerPC) A VSX register.
  999|       |//
 1000|       |// "X" (uppercase) should work for all cases, though this seems to fail for
 1001|       |// some versions of GCC for arm/aarch64 with
 1002|       |//   "error: inconsistent operand constraints in an 'asm'"
 1003|       |// Clang x86_64/arm/aarch64 seems to require "g" to support both scalars and
 1004|       |// vectors, otherwise
 1005|       |//   "error: non-trivial scalar-to-vector conversion, possible invalid
 1006|       |//    constraint for vector type"
 1007|       |//
 1008|       |// GCC for ppc64le generates an internal compiler error with x/X/g.
 1009|       |// GCC for AVX generates an internal compiler error with X.
 1010|       |//
 1011|       |// Tested on icc/gcc/clang for sse, avx, avx2, avx512dq
 1012|       |//           gcc for arm, aarch64,
 1013|       |//           gcc for ppc64le,
 1014|       |// both vectors and scalars.
 1015|       |//
 1016|       |// Note that this is restricted to plain types - this will not work
 1017|       |// directly for std::complex<T>, Eigen::half, Eigen::bfloat16. For these,
 1018|       |// you will need to apply to the underlying POD type.
 1019|       |#if EIGEN_ARCH_PPC && EIGEN_COMP_GNUC_STRICT
 1020|       |   // This seems to be broken on clang. Packet4f is loaded into a single
 1021|       |//   register rather than a vector, zeroing out some entries. Integer
 1022|       |//   types also generate a compile error.
 1023|       |#if EIGEN_OS_MAC
 1024|       |   // General, Altivec for Apple (VSX were added in ISA v2.06):
 1025|       |#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__("" : "+r,v"(X));
 1026|       |#else
 1027|       |   // General, Altivec, VSX otherwise:
 1028|       |#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__("" : "+r,v,wa"(X));
 1029|       |#endif
 1030|       |#elif EIGEN_ARCH_ARM_OR_ARM64
 1031|       |#ifdef __ARM_FP
 1032|       |   // General, VFP or NEON.
 1033|       |// Clang doesn't like "r",
 1034|       |//    error: non-trivial scalar-to-vector conversion, possible invalid
 1035|       |//           constraint for vector typ
 1036|       |#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__("" : "+g,w"(X));
 1037|       |#else
 1038|       |   // Arm without VFP or NEON.
 1039|       |// "w" constraint will not compile.
 1040|       |#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__("" : "+g"(X));
 1041|       |#endif
 1042|       |#elif EIGEN_ARCH_i386_OR_x86_64
 1043|       |   // General, SSE.
 1044|       |#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__("" : "+g,x"(X));
 1045|       |#else
 1046|       |   // Not implemented for other architectures.
 1047|       |#define EIGEN_OPTIMIZATION_BARRIER(X)
 1048|       |#endif
 1049|       |#else
 1050|       |   // Not implemented for other compilers.
 1051|       |#define EIGEN_OPTIMIZATION_BARRIER(X)
 1052|       |#endif
 1053|       |#endif
 1054|       |
 1055|       |#if EIGEN_COMP_MSVC
 1056|       |// NOTE MSVC often gives C4127 warnings with compiletime if statements. See bug 1362.
 1057|       |// This workaround is ugly, but it does the job.
 1058|       |#define EIGEN_CONST_CONDITIONAL(cond) (void)0, cond
 1059|       |#else
 1060|       |#define EIGEN_CONST_CONDITIONAL(cond) cond
 1061|       |#endif
 1062|       |
 1063|       |#ifdef EIGEN_DONT_USE_RESTRICT_KEYWORD
 1064|       |#define EIGEN_RESTRICT
 1065|       |#endif
 1066|       |#ifndef EIGEN_RESTRICT
 1067|       |#define EIGEN_RESTRICT __restrict
 1068|       |#endif
 1069|       |
 1070|       |#ifndef EIGEN_DEFAULT_IO_FORMAT
 1071|       |#ifdef EIGEN_MAKING_DOCS
 1072|       |// format used in Eigen's documentation
 1073|       |// needed to define it here as escaping characters in CMake add_definition's argument seems very problematic.
 1074|       |#define EIGEN_DEFAULT_IO_FORMAT Eigen::IOFormat(3, 0, " ", "\n", "", "")
 1075|       |#else
 1076|       |#define EIGEN_DEFAULT_IO_FORMAT Eigen::IOFormat()
 1077|       |#endif
 1078|       |#endif
 1079|       |
 1080|       |// just an empty macro !
 1081|       |#define EIGEN_EMPTY
 1082|       |
 1083|       |// When compiling CUDA/HIP device code with NVCC or HIPCC
 1084|       |// pull in math functions from the global namespace.
 1085|       |// In host mode, and when device code is compiled with clang,
 1086|       |// use the std versions.
 1087|       |#if (defined(EIGEN_CUDA_ARCH) && defined(__NVCC__)) || defined(EIGEN_HIP_DEVICE_COMPILE)
 1088|       |#define EIGEN_USING_STD(FUNC) using ::FUNC;
 1089|       |#else
 1090|     28|#define EIGEN_USING_STD(FUNC) using std::FUNC;
 1091|       |#endif
 1092|       |
 1093|       |#if EIGEN_COMP_CLANG  // workaround clang bug (see http://forum.kde.org/viewtopic.php?f=74&t=102653)
 1094|       |#define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived)                                           \
 1095|       |  using Base::operator=;                                                                           \
 1096|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const Derived& other) {                 \
 1097|       |    Base::operator=(other);                                                                        \
 1098|       |    return *this;                                                                                  \
 1099|       |  }                                                                                                \
 1100|       |  template <typename OtherDerived>                                                                 \
 1101|      0|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const DenseBase<OtherDerived>& other) { \
 1102|      0|    Base::operator=(other.derived());                                                              \
 1103|      0|    return *this;                                                                                  \
 1104|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEaSINS_9TransposeIKNS_5BlockIKNS1_IS2_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEERS6_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEaSINS_5BlockINS1_IS2_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEERS6_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEaSINS_3MapINS1_IS2_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEERS4_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9BlockImplINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ENS_5DenseEEaSINS_3MapINS1_IS2_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEERS5_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal15BlockImpl_denseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1ELb1EEaSINS_3MapINS2_IS3_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEERS5_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEaSIS3_EERS6_RKNS_9DenseBaseIT_EE
  ------------------
  | Unexecuted instantiation: _ZN5Eigen3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEaSINS_9TransposeIKNS1_IS2_Li1ELin1ELi1ELi1ELin1EEEEEEERS6_RKNS_9DenseBaseIT_EE
  ------------------
 1105|       |#else
 1106|       |#define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived)                           \
 1107|       |  using Base::operator=;                                                           \
 1108|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const Derived& other) { \
 1109|       |    Base::operator=(other);                                                        \
 1110|       |    return *this;                                                                  \
 1111|       |  }
 1112|       |#endif
 1113|       |
 1114|       |/**
 1115|       | * \internal
 1116|       | * \brief Macro to explicitly define the default copy constructor.
 1117|       | * This is necessary, because the implicit definition is deprecated if the copy-assignment is overridden.
 1118|       | */
 1119|       |#define EIGEN_DEFAULT_COPY_CONSTRUCTOR(CLASS) EIGEN_DEVICE_FUNC CLASS(const CLASS&) = default;
 1120|       |
 1121|       |/** \internal
 1122|       | * \brief Macro to manually inherit assignment operators.
 1123|       | * This is necessary, because the implicitly defined assignment operator gets deleted when a custom operator= is
 1124|       | * defined. With C++11 or later this also default-implements the copy-constructor
 1125|       | */
 1126|       |#define EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Derived) \
 1127|       |  EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived)  \
 1128|       |  EIGEN_DEFAULT_COPY_CONSTRUCTOR(Derived)
 1129|       |
 1130|       |/** \internal
 1131|       | * \brief Macro to manually define default constructors and destructors.
 1132|       | * This is necessary when the copy constructor is re-defined.
 1133|       | * For empty helper classes this should usually be protected, to avoid accidentally creating empty objects.
 1134|       | *
 1135|       | * Hiding the default destructor lead to problems in C++03 mode together with boost::multiprecision
 1136|       | */
 1137|       |#define EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(Derived) \
 1138|     19|  EIGEN_DEVICE_FUNC Derived() = default;                        \
  ------------------
  | _ZN5Eigen10MatrixBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEC2Ev:
  | 1138|      3|  EIGEN_DEVICE_FUNC Derived() = default;                        \
  ------------------
  | _ZN5Eigen10MatrixBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEC2Ev:
  | 1138|      6|  EIGEN_DEVICE_FUNC Derived() = default;                        \
  ------------------
  | _ZN5Eigen10MatrixBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEEEC2Ev:
  | 1138|      2|  EIGEN_DEVICE_FUNC Derived() = default;                        \
  ------------------
  | _ZN5Eigen10MatrixBaseINS_7ProductINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEENS2_IS3_Lin1ELi1ELi0ELin1ELi1EEELi0EEEEC2Ev:
  | 1138|      1|  EIGEN_DEVICE_FUNC Derived() = default;                        \
  ------------------
  | _ZN5Eigen10MatrixBaseINS_14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEEEEEC2Ev:
  | 1138|      1|  EIGEN_DEVICE_FUNC Derived() = default;                        \
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13TransposeImplIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS_5DenseEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_13CwiseBinaryOpINS_8internal17scalar_product_opI14AnnoyingScalarS4_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS7_ISA_Lin1ELi1ELb1EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li1EEEEC2Ev
  ------------------
  | _ZN5Eigen10MatrixBaseINS_14CwiseNullaryOpINS_8internal14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS4_Lin1ELin1ELi0ELin1ELin1EEEEEEC2Ev:
  | 1138|      3|  EIGEN_DEVICE_FUNC Derived() = default;                        \
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13TransposeImplINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEENS_5DenseEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13TransposeImplIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEENS_5DenseEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockINS_9TransposeINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEC2Ev
  ------------------
  | _ZN5Eigen10MatrixBaseINS_7ProductINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEES4_Li0EEEEC2Ev:
  | 1138|      1|  EIGEN_DEVICE_FUNC Derived() = default;                        \
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_7ProductINS1_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEES4_Li1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_5BlockIKNS1_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13TransposeImplIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEENS_5DenseEEC2Ev
  ------------------
  | Unexecuted instantiation: _ZN5Eigen10MatrixBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEEC2Ev
  ------------------
  | _ZN5Eigen10MatrixBaseINS_13CwiseBinaryOpINS_8internal13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_EEEC2Ev:
  | 1138|      2|  EIGEN_DEVICE_FUNC Derived() = default;                        \
  ------------------
 1139|       |  EIGEN_DEVICE_FUNC ~Derived() = default;
 1140|       |
 1141|       |/**
 1142|       | * Just a side note. Commenting within defines works only by documenting
 1143|       | * behind the object (via '!<'). Comments cannot be multi-line and thus
 1144|       | * we have these extra long lines. What is confusing doxygen over here is
 1145|       | * that we use '\' and basically have a bunch of typedefs with their
 1146|       | * documentation in a single line.
 1147|       | **/
 1148|       |
 1149|       |#define EIGEN_GENERIC_PUBLIC_INTERFACE(Derived)                                                                        \
 1150|       |  typedef typename Eigen::internal::traits<Derived>::Scalar                                                            \
 1151|       |      Scalar; /*!< \brief Numeric type, e.g. float, double, int or std::complex<float>. */                             \
 1152|       |  typedef typename Eigen::NumTraits<Scalar>::Real                                                                      \
 1153|       |      RealScalar; /*!< \brief The underlying numeric type for composed scalar types. \details In cases where Scalar is \
 1154|       |                     e.g. std::complex<T>, T were corresponding to RealScalar. */                                      \
 1155|       |  typedef typename Base::CoeffReturnType                                                                               \
 1156|       |      CoeffReturnType; /*!< \brief The return type for coefficient access. \details Depending on whether the object    \
 1157|       |                          allows direct coefficient access (e.g. for a MatrixXd), this type is either 'const Scalar&'  \
 1158|       |                          or simply 'Scalar' for objects that do not allow direct coefficient access. */               \
 1159|       |  typedef typename Eigen::internal::ref_selector<Derived>::type Nested;                                                \
 1160|       |  typedef typename Eigen::internal::traits<Derived>::StorageKind StorageKind;                                          \
 1161|       |  typedef typename Eigen::internal::traits<Derived>::StorageIndex StorageIndex;                                        \
 1162|       |  enum CompileTimeTraits {                                                                                             \
 1163|       |    RowsAtCompileTime = Eigen::internal::traits<Derived>::RowsAtCompileTime,                                           \
 1164|       |    ColsAtCompileTime = Eigen::internal::traits<Derived>::ColsAtCompileTime,                                           \
 1165|       |    Flags = Eigen::internal::traits<Derived>::Flags,                                                                   \
 1166|       |    SizeAtCompileTime = Base::SizeAtCompileTime,                                                                       \
 1167|       |    MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,                                                                 \
 1168|       |    IsVectorAtCompileTime = Base::IsVectorAtCompileTime                                                                \
 1169|       |  };                                                                                                                   \
 1170|       |  using Base::derived;                                                                                                 \
 1171|       |  using Base::const_cast_derived;
 1172|       |
 1173|       |// FIXME Maybe the EIGEN_DENSE_PUBLIC_INTERFACE could be removed as importing PacketScalar is rarely needed
 1174|       |#define EIGEN_DENSE_PUBLIC_INTERFACE(Derived) \
 1175|       |  EIGEN_GENERIC_PUBLIC_INTERFACE(Derived)     \
 1176|       |  typedef typename Base::PacketScalar PacketScalar;
 1177|       |
 1178|       |#if EIGEN_HAS_BUILTIN(__builtin_expect) || EIGEN_COMP_GNUC
 1179|       |#define EIGEN_PREDICT_FALSE(x) (__builtin_expect(x, false))
 1180|       |#define EIGEN_PREDICT_TRUE(x) (__builtin_expect(false || (x), true))
 1181|       |#else
 1182|       |#define EIGEN_PREDICT_FALSE(x) (x)
 1183|       |#define EIGEN_PREDICT_TRUE(x) (x)
 1184|       |#endif
 1185|       |
 1186|       |// the expression type of a standard coefficient wise binary operation
 1187|       |#define EIGEN_CWISE_BINARY_RETURN_TYPE(LHS, RHS, OPNAME)                                                       \
 1188|      2|  CwiseBinaryOp<EIGEN_CAT(EIGEN_CAT(internal::scalar_, OPNAME), _op) < typename internal::traits<LHS>::Scalar, \
 1189|      2|                typename internal::traits<RHS>::Scalar>,                                                       \
 1190|      2|      const LHS, const RHS >
 1191|       |
 1192|       |#define EIGEN_MAKE_CWISE_BINARY_OP(METHOD, OPNAME)                                                                \
 1193|       |  template <typename OtherDerived>                                                                                \
 1194|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const EIGEN_CWISE_BINARY_RETURN_TYPE(                                     \
 1195|      2|      Derived, OtherDerived, OPNAME)(METHOD)(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const { \
 1196|      2|    return EIGEN_CWISE_BINARY_RETURN_TYPE(Derived, OtherDerived, OPNAME)(derived(), other.derived());             \
 1197|      2|  }
 1198|       |
 1199|       |#define EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME, TYPEA, TYPEB)     \
 1200|       |  (Eigen::internal::has_ReturnType<Eigen::ScalarBinaryOpTraits< \
 1201|       |       TYPEA, TYPEB, EIGEN_CAT(EIGEN_CAT(Eigen::internal::scalar_, OPNAME), _op) < TYPEA, TYPEB> > > ::value)
 1202|       |
 1203|       |#define EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(EXPR, SCALAR, OPNAME)                                            \
 1204|       |  CwiseBinaryOp<EIGEN_CAT(EIGEN_CAT(internal::scalar_, OPNAME), _op) < typename internal::traits<EXPR>::Scalar, \
 1205|       |                SCALAR>,                                                                                        \
 1206|       |      const EXPR, const typename internal::plain_constant_type<EXPR, SCALAR>::type >
 1207|       |
 1208|       |#define EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(SCALAR, EXPR, OPNAME)           \
 1209|       |  CwiseBinaryOp<EIGEN_CAT(EIGEN_CAT(internal::scalar_, OPNAME), _op) < SCALAR, \
 1210|       |                typename internal::traits<EXPR>::Scalar>,                      \
 1211|       |      const typename internal::plain_constant_type<EXPR, SCALAR>::type, const EXPR >
 1212|       |
 1213|       |#define EIGEN_MAKE_SCALAR_BINARY_OP_ONTHERIGHT(METHOD, OPNAME)                                                       \
 1214|       |  template <typename T>                                                                                              \
 1215|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(                                \
 1216|       |      Derived,                                                                                                       \
 1217|       |      typename internal::promote_scalar_arg<Scalar EIGEN_COMMA T EIGEN_COMMA EIGEN_SCALAR_BINARY_SUPPORTED(          \
 1218|       |          OPNAME, Scalar, T)>::type,                                                                                 \
 1219|       |      OPNAME)(METHOD)(const T& scalar) const {                                                                       \
 1220|       |    typedef typename internal::promote_scalar_arg<Scalar, T, EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME, Scalar, T)>::type \
 1221|       |        PromotedT;                                                                                                   \
 1222|       |    return EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(Derived, PromotedT, OPNAME)(                                       \
 1223|       |        derived(), typename internal::plain_constant_type<Derived, PromotedT>::type(                                 \
 1224|       |                       derived().rows(), derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)));        \
 1225|       |  }
 1226|       |
 1227|       |#define EIGEN_MAKE_SCALAR_BINARY_OP_ONTHELEFT(METHOD, OPNAME)                                                        \
 1228|       |  template <typename T>                                                                                              \
 1229|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE friend const EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(                         \
 1230|       |      typename internal::promote_scalar_arg<Scalar EIGEN_COMMA T EIGEN_COMMA EIGEN_SCALAR_BINARY_SUPPORTED(          \
 1231|       |          OPNAME, T, Scalar)>::type,                                                                                 \
 1232|      0|      Derived, OPNAME)(METHOD)(const T& scalar, const StorageBaseType& matrix) {                                     \
 1233|      0|    typedef typename internal::promote_scalar_arg<Scalar, T, EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME, T, Scalar)>::type \
 1234|      0|        PromotedT;                                                                                                   \
 1235|      0|    return EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(PromotedT, Derived, OPNAME)(                                       \
 1236|      0|        typename internal::plain_constant_type<Derived, PromotedT>::type(                                            \
 1237|      0|            matrix.derived().rows(), matrix.derived().cols(), internal::scalar_constant_op<PromotedT>(scalar)),      \
 1238|      0|        matrix.derived());                                                                                           \
 1239|      0|  }
 1240|       |
 1241|       |#define EIGEN_MAKE_SCALAR_BINARY_OP(METHOD, OPNAME)     \
 1242|       |  EIGEN_MAKE_SCALAR_BINARY_OP_ONTHELEFT(METHOD, OPNAME) \
 1243|       |  EIGEN_MAKE_SCALAR_BINARY_OP_ONTHERIGHT(METHOD, OPNAME)
 1244|       |
 1245|       |#if (defined(_CPPUNWIND) || defined(__EXCEPTIONS)) && !defined(EIGEN_CUDA_ARCH) && !defined(EIGEN_EXCEPTIONS) && \
 1246|       |    !defined(EIGEN_USE_SYCL) && !defined(EIGEN_HIP_DEVICE_COMPILE)
 1247|       |#define EIGEN_EXCEPTIONS
 1248|       |#endif
 1249|       |
 1250|       |#ifdef EIGEN_EXCEPTIONS
 1251|      0|#define EIGEN_THROW_X(X) throw X
 1252|      0|#define EIGEN_THROW throw
 1253|     22|#define EIGEN_TRY try
 1254|       |#define EIGEN_CATCH(X) catch (X)
 1255|       |#else
 1256|       |#if defined(EIGEN_CUDA_ARCH)
 1257|       |#define EIGEN_THROW_X(X) asm("trap;")
 1258|       |#define EIGEN_THROW asm("trap;")
 1259|       |#elif defined(EIGEN_HIP_DEVICE_COMPILE)
 1260|       |#define EIGEN_THROW_X(X) asm("s_trap 0")
 1261|       |#define EIGEN_THROW asm("s_trap 0")
 1262|       |#else
 1263|       |#define EIGEN_THROW_X(X) std::abort()
 1264|       |#define EIGEN_THROW std::abort()
 1265|       |#endif
 1266|       |#define EIGEN_TRY if (true)
 1267|       |#define EIGEN_CATCH(X) else
 1268|       |#endif
 1269|       |
 1270|       |#define EIGEN_NOEXCEPT noexcept
 1271|       |#define EIGEN_NOEXCEPT_IF(x) noexcept(x)
 1272|       |#define EIGEN_NO_THROW noexcept(true)
 1273|       |#define EIGEN_EXCEPTION_SPEC(X) noexcept(false)
 1274|       |
 1275|       |// The all function is used to enable a variadic version of eigen_assert which can take a parameter pack as its input.
 1276|       |namespace Eigen {
 1277|       |namespace internal {
 1278|       |
 1279|      0|EIGEN_DEVICE_FUNC inline bool all() { return true; }
 1280|       |
 1281|       |template <typename T, typename... Ts>
 1282|       |EIGEN_DEVICE_FUNC bool all(T t, Ts... ts) {
 1283|       |  return t && all(ts...);
 1284|       |}
 1285|       |
 1286|       |}  // namespace internal
 1287|       |}  // namespace Eigen
 1288|       |
 1289|       |// provide override and final specifiers if they are available:
 1290|       |#define EIGEN_OVERRIDE override
 1291|       |#define EIGEN_FINAL final
 1292|       |
 1293|       |// Wrapping #pragma unroll in a macro since it is required for SYCL
 1294|       |#if defined(SYCL_DEVICE_ONLY)
 1295|       |#if defined(_MSC_VER)
 1296|       |#define EIGEN_UNROLL_LOOP __pragma(unroll)
 1297|       |#else
 1298|       |#define EIGEN_UNROLL_LOOP _Pragma("unroll")
 1299|       |#endif
 1300|       |#else
 1301|       |#define EIGEN_UNROLL_LOOP
 1302|       |#endif
 1303|       |
 1304|       |// Notice: Use this macro with caution. The code in the if body should still
 1305|       |// compile with C++14.
 1306|       |#if defined(EIGEN_HAS_CXX17_IFCONSTEXPR)
 1307|       |#define EIGEN_IF_CONSTEXPR(X) if constexpr (X)
 1308|       |#else
 1309|      2|#define EIGEN_IF_CONSTEXPR(X) if (X)
 1310|       |#endif
 1311|       |
 1312|       |#endif  // EIGEN_MACROS_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/Memory.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2015 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2008-2009 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |// Copyright (C) 2009 Kenneth Riddile <kfriddile@yahoo.com>
    7|       |// Copyright (C) 2010 Hauke Heibel <hauke.heibel@gmail.com>
    8|       |// Copyright (C) 2010 Thomas Capricelli <orzel@freehackers.org>
    9|       |// Copyright (C) 2013 Pavel Holoborodko <pavel@holoborodko.com>
   10|       |//
   11|       |// This Source Code Form is subject to the terms of the Mozilla
   12|       |// Public License v. 2.0. If a copy of the MPL was not distributed
   13|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   14|       |
   15|       |/*****************************************************************************
   16|       |*** Platform checks for aligned malloc functions                           ***
   17|       |*****************************************************************************/
   18|       |
   19|       |#ifndef EIGEN_MEMORY_H
   20|       |#define EIGEN_MEMORY_H
   21|       |
   22|       |#ifndef EIGEN_MALLOC_ALREADY_ALIGNED
   23|       |
   24|       |// Try to determine automatically if malloc is already aligned.
   25|       |
   26|       |// On 64-bit systems, glibc's malloc returns 16-byte-aligned pointers, see:
   27|       |//   http://www.gnu.org/s/libc/manual/html_node/Aligned-Memory-Blocks.html
   28|       |// This is true at least since glibc 2.8.
   29|       |// This leaves the question how to detect 64-bit. According to this document,
   30|       |//   http://gcc.fyxm.net/summit/2003/Porting%20to%2064%20bit.pdf
   31|       |// page 114, "[The] LP64 model [...] is used by all 64-bit UNIX ports" so it's indeed
   32|       |// quite safe, at least within the context of glibc, to equate 64-bit with LP64.
   33|       |#if defined(__GLIBC__) && ((__GLIBC__ >= 2 && __GLIBC_MINOR__ >= 8) || __GLIBC__ > 2) && defined(__LP64__) && \
   34|       |    !defined(__SANITIZE_ADDRESS__) && (EIGEN_DEFAULT_ALIGN_BYTES == 16)
   35|       |#define EIGEN_GLIBC_MALLOC_ALREADY_ALIGNED 1
   36|       |#else
   37|       |#define EIGEN_GLIBC_MALLOC_ALREADY_ALIGNED 0
   38|       |#endif
   39|       |
   40|       |// FreeBSD 6 seems to have 16-byte aligned malloc
   41|       |//   See http://svn.freebsd.org/viewvc/base/stable/6/lib/libc/stdlib/malloc.c?view=markup
   42|       |// FreeBSD 7 seems to have 16-byte aligned malloc except on ARM and MIPS architectures
   43|       |//   See http://svn.freebsd.org/viewvc/base/stable/7/lib/libc/stdlib/malloc.c?view=markup
   44|       |#if defined(__FreeBSD__) && !(EIGEN_ARCH_ARM || EIGEN_ARCH_MIPS) && (EIGEN_DEFAULT_ALIGN_BYTES == 16)
   45|       |#define EIGEN_FREEBSD_MALLOC_ALREADY_ALIGNED 1
   46|       |#else
   47|       |#define EIGEN_FREEBSD_MALLOC_ALREADY_ALIGNED 0
   48|       |#endif
   49|       |
   50|       |#if (EIGEN_OS_MAC && (EIGEN_DEFAULT_ALIGN_BYTES == 16)) || (EIGEN_OS_WIN64 && (EIGEN_DEFAULT_ALIGN_BYTES == 16)) || \
   51|       |    EIGEN_GLIBC_MALLOC_ALREADY_ALIGNED || EIGEN_FREEBSD_MALLOC_ALREADY_ALIGNED
   52|       |#define EIGEN_MALLOC_ALREADY_ALIGNED 1
   53|       |#else
   54|       |#define EIGEN_MALLOC_ALREADY_ALIGNED 0
   55|       |#endif
   56|       |
   57|       |#endif
   58|       |
   59|       |#ifndef EIGEN_MALLOC_CHECK_THREAD_LOCAL
   60|       |
   61|       |// Check whether we can use the thread_local keyword to allow or disallow
   62|       |// allocating memory with per-thread granularity, by means of the
   63|       |// set_is_malloc_allowed() function.
   64|       |#ifndef EIGEN_AVOID_THREAD_LOCAL
   65|       |
   66|       |#if ((EIGEN_COMP_GNUC) || __has_feature(cxx_thread_local) || EIGEN_COMP_MSVC >= 1900) && \
   67|       |    !defined(EIGEN_GPU_COMPILE_PHASE)
   68|       |#define EIGEN_MALLOC_CHECK_THREAD_LOCAL thread_local
   69|       |#else
   70|       |#define EIGEN_MALLOC_CHECK_THREAD_LOCAL
   71|       |#endif
   72|       |
   73|       |#else  // EIGEN_AVOID_THREAD_LOCAL
   74|       |#define EIGEN_MALLOC_CHECK_THREAD_LOCAL
   75|       |#endif  // EIGEN_AVOID_THREAD_LOCAL
   76|       |
   77|       |#endif
   78|       |
   79|       |// IWYU pragma: private
   80|       |#include "../InternalHeaderCheck.h"
   81|       |
   82|       |namespace Eigen {
   83|       |
   84|       |namespace internal {
   85|       |
   86|       |/*****************************************************************************
   87|       |*** Implementation of portable aligned versions of malloc/free/realloc     ***
   88|       |*****************************************************************************/
   89|       |
   90|       |#ifdef EIGEN_NO_MALLOC
   91|       |EIGEN_DEVICE_FUNC inline void check_that_malloc_is_allowed() {
   92|       |  eigen_assert(false && "heap allocation is forbidden (EIGEN_NO_MALLOC is defined)");
   93|       |}
   94|       |#elif defined EIGEN_RUNTIME_NO_MALLOC
   95|       |EIGEN_DEVICE_FUNC inline bool is_malloc_allowed_impl(bool update, bool new_value = false) {
   96|       |  EIGEN_MALLOC_CHECK_THREAD_LOCAL static bool value = true;
   97|       |  if (update == 1) value = new_value;
   98|       |  return value;
   99|       |}
  100|       |EIGEN_DEVICE_FUNC inline bool is_malloc_allowed() { return is_malloc_allowed_impl(false); }
  101|       |EIGEN_DEVICE_FUNC inline bool set_is_malloc_allowed(bool new_value) { return is_malloc_allowed_impl(true, new_value); }
  102|       |EIGEN_DEVICE_FUNC inline void check_that_malloc_is_allowed() {
  103|       |  eigen_assert(is_malloc_allowed() &&
  104|       |               "heap allocation is forbidden (EIGEN_RUNTIME_NO_MALLOC is defined and g_is_malloc_allowed is false)");
  105|       |}
  106|       |#else
  107|     18|EIGEN_DEVICE_FUNC inline void check_that_malloc_is_allowed() {}
  108|       |#endif
  109|       |
  110|      0|EIGEN_DEVICE_FUNC inline void throw_std_bad_alloc() {
  111|      0|#ifdef EIGEN_EXCEPTIONS
  112|      0|  throw std::bad_alloc();
  113|       |#else
  114|       |  std::size_t huge = static_cast<std::size_t>(-1);
  115|       |#if defined(EIGEN_HIPCC)
  116|       |  //
  117|       |  // calls to "::operator new" are to be treated as opaque function calls (i.e no inlining),
  118|       |  // and as a consequence the code in the #else block triggers the hipcc warning :
  119|       |  // "no overloaded function has restriction specifiers that are compatible with the ambient context"
  120|       |  //
  121|       |  // "throw_std_bad_alloc" has the EIGEN_DEVICE_FUNC attribute, so it seems that hipcc expects
  122|       |  // the same on "operator new"
  123|       |  // Reverting code back to the old version in this #if block for the hipcc compiler
  124|       |  //
  125|       |  new int[huge];
  126|       |#else
  127|       |  void* unused = ::operator new(huge);
  128|       |  EIGEN_UNUSED_VARIABLE(unused);
  129|       |#endif
  130|       |#endif
  131|      0|}
  132|       |
  133|       |/*****************************************************************************
  134|       |*** Implementation of handmade aligned functions                           ***
  135|       |*****************************************************************************/
  136|       |
  137|       |/* ----- Hand made implementations of aligned malloc/free and realloc ----- */
  138|       |
  139|       |/** \internal Like malloc, but the returned pointer is guaranteed to be aligned to `alignment`.
  140|       | * Fast, but wastes `alignment` additional bytes of memory. Does not throw any exception.
  141|       | */
  142|       |EIGEN_DEVICE_FUNC inline void* handmade_aligned_malloc(std::size_t size,
  143|      0|                                                       std::size_t alignment = EIGEN_DEFAULT_ALIGN_BYTES) {
  144|      0|  eigen_assert(alignment >= sizeof(void*) && alignment <= 128 && (alignment & (alignment - 1)) == 0 &&
  145|      0|               "Alignment must be at least sizeof(void*), less than or equal to 128, and a power of 2");
  146|      0|
  147|      0|  check_that_malloc_is_allowed();
  148|      0|  EIGEN_USING_STD(malloc)
  149|      0|  void* original = malloc(size + alignment);
  150|      0|  if (original == nullptr) return nullptr;
  151|      0|  uint8_t offset = static_cast<uint8_t>(alignment - (reinterpret_cast<std::size_t>(original) & (alignment - 1)));
  152|      0|  void* aligned = static_cast<void*>(static_cast<uint8_t*>(original) + offset);
  153|      0|  *(static_cast<uint8_t*>(aligned) - 1) = offset;
  154|      0|  return aligned;
  155|      0|}
  156|       |
  157|       |/** \internal Frees memory allocated with handmade_aligned_malloc */
  158|      0|EIGEN_DEVICE_FUNC inline void handmade_aligned_free(void* ptr) {
  159|      0|  if (ptr != nullptr) {
  160|      0|    uint8_t offset = static_cast<uint8_t>(*(static_cast<uint8_t*>(ptr) - 1));
  161|      0|    void* original = static_cast<void*>(static_cast<uint8_t*>(ptr) - offset);
  162|      0|
  163|      0|    check_that_malloc_is_allowed();
  164|      0|    EIGEN_USING_STD(free)
  165|      0|    free(original);
  166|      0|  }
  167|      0|}
  168|       |
  169|       |/** \internal
  170|       | * \brief Reallocates aligned memory.
  171|       | * Since we know that our handmade version is based on std::malloc
  172|       | * we can use std::realloc to implement efficient reallocation.
  173|       | */
  174|       |EIGEN_DEVICE_FUNC inline void* handmade_aligned_realloc(void* ptr, std::size_t new_size, std::size_t old_size,
  175|      0|                                                        std::size_t alignment = EIGEN_DEFAULT_ALIGN_BYTES) {
  176|      0|  if (ptr == nullptr) return handmade_aligned_malloc(new_size, alignment);
  177|      0|  uint8_t old_offset = *(static_cast<uint8_t*>(ptr) - 1);
  178|      0|  void* old_original = static_cast<uint8_t*>(ptr) - old_offset;
  179|      0|
  180|      0|  check_that_malloc_is_allowed();
  181|      0|  EIGEN_USING_STD(realloc)
  182|      0|  void* original = realloc(old_original, new_size + alignment);
  183|      0|  if (original == nullptr) return nullptr;
  184|      0|  if (original == old_original) return ptr;
  185|      0|  uint8_t offset = static_cast<uint8_t>(alignment - (reinterpret_cast<std::size_t>(original) & (alignment - 1)));
  186|      0|  void* aligned = static_cast<void*>(static_cast<uint8_t*>(original) + offset);
  187|      0|  if (offset != old_offset) {
  188|      0|    const void* src = static_cast<const void*>(static_cast<uint8_t*>(original) + old_offset);
  189|      0|    std::size_t count = (std::min)(new_size, old_size);
  190|      0|    std::memmove(aligned, src, count);
  191|      0|  }
  192|      0|  *(static_cast<uint8_t*>(aligned) - 1) = offset;
  193|      0|  return aligned;
  194|      0|}
  195|       |
  196|       |/** \internal Allocates \a size bytes. The returned pointer is guaranteed to have 16 or 32 bytes alignment depending on
  197|       | * the requirements. On allocation error, the returned pointer is null, and std::bad_alloc is thrown.
  198|       | */
  199|      9|EIGEN_DEVICE_FUNC inline void* aligned_malloc(std::size_t size) {
  200|      9|  if (size == 0) return nullptr;
  201|       |
  202|      9|  void* result;
  203|      9|#if (EIGEN_DEFAULT_ALIGN_BYTES == 0) || EIGEN_MALLOC_ALREADY_ALIGNED
  204|       |
  205|      9|  check_that_malloc_is_allowed();
  206|      9|  EIGEN_USING_STD(malloc)
  207|      9|  result = malloc(size);
  208|       |
  209|      9|#if EIGEN_DEFAULT_ALIGN_BYTES == 16
  210|      9|  eigen_assert((size < 16 || (std::size_t(result) % 16) == 0) &&
  211|      9|               "System's malloc returned an unaligned pointer. Compile with EIGEN_MALLOC_ALREADY_ALIGNED=0 to fallback "
  212|      9|               "to handmade aligned memory allocator.");
  213|      9|#endif
  214|       |#else
  215|       |  result = handmade_aligned_malloc(size);
  216|       |#endif
  217|       |
  218|      9|  if (!result && size) throw_std_bad_alloc();
  219|       |
  220|      9|  return result;
  221|      9|}
  222|       |
  223|       |/** \internal Frees memory allocated with aligned_malloc. */
  224|     22|EIGEN_DEVICE_FUNC inline void aligned_free(void* ptr) {
  225|     22|#if (EIGEN_DEFAULT_ALIGN_BYTES == 0) || EIGEN_MALLOC_ALREADY_ALIGNED
  226|       |
  227|     22|  if (ptr != nullptr) {
  228|      9|    check_that_malloc_is_allowed();
  229|      9|    EIGEN_USING_STD(free)
  230|      9|    free(ptr);
  231|      9|  }
  232|       |
  233|       |#else
  234|       |  handmade_aligned_free(ptr);
  235|       |#endif
  236|     22|}
  237|       |
  238|       |/**
  239|       | * \internal
  240|       | * \brief Reallocates an aligned block of memory.
  241|       | * \throws std::bad_alloc on allocation failure
  242|       | */
  243|      0|EIGEN_DEVICE_FUNC inline void* aligned_realloc(void* ptr, std::size_t new_size, std::size_t old_size) {
  244|      0|  if (ptr == nullptr) return aligned_malloc(new_size);
  245|      0|  if (old_size == new_size) return ptr;
  246|      0|  if (new_size == 0) {
  247|      0|    aligned_free(ptr);
  248|      0|    return nullptr;
  249|      0|  }
  250|      0|
  251|      0|  void* result;
  252|      0|#if (EIGEN_DEFAULT_ALIGN_BYTES == 0) || EIGEN_MALLOC_ALREADY_ALIGNED
  253|      0|  EIGEN_UNUSED_VARIABLE(old_size)
  254|      0|
  255|      0|  check_that_malloc_is_allowed();
  256|      0|  EIGEN_USING_STD(realloc)
  257|      0|  result = realloc(ptr, new_size);
  258|      0|#else
  259|      0|  result = handmade_aligned_realloc(ptr, new_size, old_size);
  260|      0|#endif
  261|      0|
  262|      0|  if (!result && new_size) throw_std_bad_alloc();
  263|      0|
  264|      0|  return result;
  265|      0|}
  266|       |
  267|       |/*****************************************************************************
  268|       |*** Implementation of conditionally aligned functions                      ***
  269|       |*****************************************************************************/
  270|       |
  271|       |/** \internal Allocates \a size bytes. If Align is true, then the returned ptr is 16-byte-aligned.
  272|       | * On allocation error, the returned pointer is null, and a std::bad_alloc is thrown.
  273|       | */
  274|       |template <bool Align>
  275|      9|EIGEN_DEVICE_FUNC inline void* conditional_aligned_malloc(std::size_t size) {
  276|      9|  return aligned_malloc(size);
  277|      9|}
  278|       |
  279|       |template <>
  280|      0|EIGEN_DEVICE_FUNC inline void* conditional_aligned_malloc<false>(std::size_t size) {
  281|      0|  if (size == 0) return nullptr;
  282|      0|
  283|      0|  check_that_malloc_is_allowed();
  284|      0|  EIGEN_USING_STD(malloc)
  285|      0|  void* result = malloc(size);
  286|      0|
  287|      0|  if (!result && size) throw_std_bad_alloc();
  288|      0|  return result;
  289|      0|}
  290|       |
  291|       |/** \internal Frees memory allocated with conditional_aligned_malloc */
  292|       |template <bool Align>
  293|     18|EIGEN_DEVICE_FUNC inline void conditional_aligned_free(void* ptr) {
  294|     18|  aligned_free(ptr);
  295|     18|}
  296|       |
  297|       |template <>
  298|      0|EIGEN_DEVICE_FUNC inline void conditional_aligned_free<false>(void* ptr) {
  299|      0|  if (ptr != nullptr) {
  300|      0|    check_that_malloc_is_allowed();
  301|      0|    EIGEN_USING_STD(free)
  302|      0|    free(ptr);
  303|      0|  }
  304|      0|}
  305|       |
  306|       |template <bool Align>
  307|       |EIGEN_DEVICE_FUNC inline void* conditional_aligned_realloc(void* ptr, std::size_t new_size, std::size_t old_size) {
  308|       |  return aligned_realloc(ptr, new_size, old_size);
  309|       |}
  310|       |
  311|       |template <>
  312|       |EIGEN_DEVICE_FUNC inline void* conditional_aligned_realloc<false>(void* ptr, std::size_t new_size,
  313|      0|                                                                  std::size_t old_size) {
  314|      0|  if (ptr == nullptr) return conditional_aligned_malloc<false>(new_size);
  315|      0|  if (old_size == new_size) return ptr;
  316|      0|  if (new_size == 0) {
  317|      0|    conditional_aligned_free<false>(ptr);
  318|      0|    return nullptr;
  319|      0|  }
  320|      0|
  321|      0|  check_that_malloc_is_allowed();
  322|      0|  EIGEN_USING_STD(realloc)
  323|      0|  return realloc(ptr, new_size);
  324|      0|}
  325|       |
  326|       |/*****************************************************************************
  327|       |*** Construction/destruction of array elements                             ***
  328|       |*****************************************************************************/
  329|       |
  330|       |/** \internal Destructs the elements of an array.
  331|       | * The \a size parameters tells on how many objects to call the destructor of T.
  332|       | */
  333|       |template <typename T>
  334|     26|EIGEN_DEVICE_FUNC inline void destruct_elements_of_array(T* ptr, std::size_t size) {
  335|       |  // always destruct an array starting from the end.
  336|     26|  if (ptr)
  337|  25.1k|    while (size) ptr[--size].~T();
  338|     26|}
  339|       |
  340|       |/** \internal Constructs the elements of an array.
  341|       | * The \a size parameter tells on how many objects to call the constructor of T.
  342|       | */
  343|       |template <typename T>
  344|     13|EIGEN_DEVICE_FUNC inline T* default_construct_elements_of_array(T* ptr, std::size_t size) {
  345|     13|  std::size_t i = 0;
  346|     13|  EIGEN_TRY {
  347|  25.1k|    for (i = 0; i < size; ++i) ::new (ptr + i) T;
  348|     13|  }
  349|     13|  EIGEN_CATCH(...) {
  350|      0|    destruct_elements_of_array(ptr, i);
  351|      0|    EIGEN_THROW;
  352|      0|  }
  353|     13|  return ptr;
  354|     13|}
  355|       |
  356|       |/** \internal Copy-constructs the elements of an array.
  357|       | * The \a size parameter tells on how many objects to copy.
  358|       | */
  359|       |template <typename T>
  360|       |EIGEN_DEVICE_FUNC inline T* copy_construct_elements_of_array(T* ptr, const T* src, std::size_t size) {
  361|       |  std::size_t i = 0;
  362|       |  EIGEN_TRY {
  363|       |    for (i = 0; i < size; ++i) ::new (ptr + i) T(*(src + i));
  364|       |  }
  365|       |  EIGEN_CATCH(...) {
  366|       |    destruct_elements_of_array(ptr, i);
  367|       |    EIGEN_THROW;
  368|       |  }
  369|       |  return ptr;
  370|       |}
  371|       |
  372|       |/** \internal Move-constructs the elements of an array.
  373|       | * The \a size parameter tells on how many objects to move.
  374|       | */
  375|       |template <typename T>
  376|       |EIGEN_DEVICE_FUNC inline T* move_construct_elements_of_array(T* ptr, T* src, std::size_t size) {
  377|       |  std::size_t i = 0;
  378|       |  EIGEN_TRY {
  379|       |    for (i = 0; i < size; ++i) ::new (ptr + i) T(std::move(*(src + i)));
  380|       |  }
  381|       |  EIGEN_CATCH(...) {
  382|       |    destruct_elements_of_array(ptr, i);
  383|       |    EIGEN_THROW;
  384|       |  }
  385|       |  return ptr;
  386|       |}
  387|       |
  388|       |/*****************************************************************************
  389|       |*** Implementation of aligned new/delete-like functions                    ***
  390|       |*****************************************************************************/
  391|       |
  392|       |template <typename T>
  393|     13|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size) {
  394|     13|  constexpr std::size_t max_elements = (std::numeric_limits<std::ptrdiff_t>::max)() / sizeof(T);
  395|     13|  if (size > max_elements) throw_std_bad_alloc();
  396|     13|}
  397|       |
  398|       |/** \internal Allocates \a size objects of type T. The returned pointer is guaranteed to have 16 bytes alignment.
  399|       | * On allocation error, the returned pointer is undefined, but a std::bad_alloc is thrown.
  400|       | * The default constructor of T is called.
  401|       | */
  402|       |template <typename T>
  403|       |EIGEN_DEVICE_FUNC inline T* aligned_new(std::size_t size) {
  404|       |  check_size_for_overflow<T>(size);
  405|       |  T* result = static_cast<T*>(aligned_malloc(sizeof(T) * size));
  406|       |  EIGEN_TRY { return default_construct_elements_of_array(result, size); }
  407|       |  EIGEN_CATCH(...) {
  408|       |    aligned_free(result);
  409|       |    EIGEN_THROW;
  410|       |  }
  411|       |  return result;
  412|       |}
  413|       |
  414|       |template <typename T, bool Align>
  415|       |EIGEN_DEVICE_FUNC inline T* conditional_aligned_new(std::size_t size) {
  416|       |  check_size_for_overflow<T>(size);
  417|       |  T* result = static_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T) * size));
  418|       |  EIGEN_TRY { return default_construct_elements_of_array(result, size); }
  419|       |  EIGEN_CATCH(...) {
  420|       |    conditional_aligned_free<Align>(result);
  421|       |    EIGEN_THROW;
  422|       |  }
  423|       |  return result;
  424|       |}
  425|       |
  426|       |/** \internal Deletes objects constructed with aligned_new
  427|       | * The \a size parameters tells on how many objects to call the destructor of T.
  428|       | */
  429|       |template <typename T>
  430|      4|EIGEN_DEVICE_FUNC inline void aligned_delete(T* ptr, std::size_t size) {
  431|      4|  destruct_elements_of_array<T>(ptr, size);
  432|      4|  aligned_free(ptr);
  433|      4|}
  434|       |
  435|       |/** \internal Deletes objects constructed with conditional_aligned_new
  436|       | * The \a size parameters tells on how many objects to call the destructor of T.
  437|       | */
  438|       |template <typename T, bool Align>
  439|       |EIGEN_DEVICE_FUNC inline void conditional_aligned_delete(T* ptr, std::size_t size) {
  440|       |  destruct_elements_of_array<T>(ptr, size);
  441|       |  conditional_aligned_free<Align>(ptr);
  442|       |}
  443|       |
  444|       |template <typename T, bool Align>
  445|       |EIGEN_DEVICE_FUNC inline T* conditional_aligned_realloc_new(T* pts, std::size_t new_size, std::size_t old_size) {
  446|       |  check_size_for_overflow<T>(new_size);
  447|       |  check_size_for_overflow<T>(old_size);
  448|       |
  449|       |  // If elements need to be explicitly initialized, we cannot simply realloc
  450|       |  // (or memcpy) the memory block - each element needs to be reconstructed.
  451|       |  // Otherwise, objects that contain internal pointers like mpfr or
  452|       |  // AnnoyingScalar can be pointing to the wrong thing.
  453|       |  T* result = static_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T) * new_size));
  454|       |  EIGEN_TRY {
  455|       |    // Move-construct initial elements.
  456|       |    std::size_t copy_size = (std::min)(old_size, new_size);
  457|       |    move_construct_elements_of_array(result, pts, copy_size);
  458|       |
  459|       |    // Default-construct remaining elements.
  460|       |    if (new_size > old_size) {
  461|       |      default_construct_elements_of_array(result + copy_size, new_size - old_size);
  462|       |    }
  463|       |
  464|       |    // Delete old elements.
  465|       |    conditional_aligned_delete<T, Align>(pts, old_size);
  466|       |  }
  467|       |  EIGEN_CATCH(...) {
  468|       |    conditional_aligned_free<Align>(result);
  469|       |    EIGEN_THROW;
  470|       |  }
  471|       |
  472|       |  return result;
  473|       |}
  474|       |
  475|       |template <typename T, bool Align>
  476|      9|EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size) {
  477|      9|  if (size == 0) return nullptr;  // short-cut. Also fixes Bug 884
  478|      9|  check_size_for_overflow<T>(size);
  479|      9|  T* result = static_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T) * size));
  480|      9|  if (NumTraits<T>::RequireInitialization) {
  481|      9|    EIGEN_TRY { default_construct_elements_of_array(result, size); }
  482|      9|    EIGEN_CATCH(...) {
  483|      0|      conditional_aligned_free<Align>(result);
  484|      0|      EIGEN_THROW;
  485|      0|    }
  486|      9|  }
  487|      9|  return result;
  488|      9|}
  489|       |
  490|       |template <typename T, bool Align>
  491|       |EIGEN_DEVICE_FUNC inline T* conditional_aligned_realloc_new_auto(T* pts, std::size_t new_size, std::size_t old_size) {
  492|       |  if (NumTraits<T>::RequireInitialization) {
  493|       |    return conditional_aligned_realloc_new<T, Align>(pts, new_size, old_size);
  494|       |  }
  495|       |
  496|       |  check_size_for_overflow<T>(new_size);
  497|       |  check_size_for_overflow<T>(old_size);
  498|       |  return static_cast<T*>(
  499|       |      conditional_aligned_realloc<Align>(static_cast<void*>(pts), sizeof(T) * new_size, sizeof(T) * old_size));
  500|       |}
  501|       |
  502|       |template <typename T, bool Align>
  503|     18|EIGEN_DEVICE_FUNC inline void conditional_aligned_delete_auto(T* ptr, std::size_t size) {
  504|     18|  if (NumTraits<T>::RequireInitialization) destruct_elements_of_array<T>(ptr, size);
  505|     18|  conditional_aligned_free<Align>(ptr);
  506|     18|}
  507|       |
  508|       |/****************************************************************************/
  509|       |
  510|       |/** \internal Returns the index of the first element of the array that is well aligned with respect to the requested \a
  511|       | * Alignment.
  512|       | *
  513|       | * \tparam Alignment requested alignment in Bytes.
  514|       | * \param array the address of the start of the array
  515|       | * \param size the size of the array
  516|       | *
  517|       | * \note If no element of the array is well aligned or the requested alignment is not a multiple of a scalar,
  518|       | * the size of the array is returned. For example with SSE, the requested alignment is typically 16-bytes. If
  519|       | * packet size for the given scalar type is 1, then everything is considered well-aligned.
  520|       | *
  521|       | * \note Otherwise, if the Alignment is larger that the scalar size, we rely on the assumptions that sizeof(Scalar) is a
  522|       | * power of 2. On the other hand, we do not assume that the array address is a multiple of sizeof(Scalar), as that fails
  523|       | * for example with Scalar=double on certain 32-bit platforms, see bug #79.
  524|       | *
  525|       | * There is also the variant first_aligned(const MatrixBase&) defined in DenseCoeffsBase.h.
  526|       | * \sa first_default_aligned()
  527|       | */
  528|       |template <int Alignment, typename Scalar, typename Index>
  529|       |EIGEN_DEVICE_FUNC inline Index first_aligned(const Scalar* array, Index size) {
  530|       |  const Index ScalarSize = sizeof(Scalar);
  531|       |  const Index AlignmentSize = Alignment / ScalarSize;
  532|       |  const Index AlignmentMask = AlignmentSize - 1;
  533|       |
  534|       |  if (AlignmentSize <= 1) {
  535|       |    // Either the requested alignment if smaller than a scalar, or it exactly match a 1 scalar
  536|       |    // so that all elements of the array have the same alignment.
  537|       |    return 0;
  538|       |  } else if ((std::uintptr_t(array) & (sizeof(Scalar) - 1)) || (Alignment % ScalarSize) != 0) {
  539|       |    // The array is not aligned to the size of a single scalar, or the requested alignment is not a multiple of the
  540|       |    // scalar size. Consequently, no element of the array is well aligned.
  541|       |    return size;
  542|       |  } else {
  543|       |    Index first = (AlignmentSize - (Index((std::uintptr_t(array) / sizeof(Scalar))) & AlignmentMask)) & AlignmentMask;
  544|       |    return (first < size) ? first : size;
  545|       |  }
  546|       |}
  547|       |
  548|       |/** \internal Returns the index of the first element of the array that is well aligned with respect the largest packet
  549|       | * requirement. \sa first_aligned(Scalar*,Index) and first_default_aligned(DenseBase<Derived>) */
  550|       |template <typename Scalar, typename Index>
  551|       |EIGEN_DEVICE_FUNC inline Index first_default_aligned(const Scalar* array, Index size) {
  552|       |  typedef typename packet_traits<Scalar>::type DefaultPacketType;
  553|       |  return first_aligned<unpacket_traits<DefaultPacketType>::alignment>(array, size);
  554|       |}
  555|       |
  556|       |/** \internal Returns the smallest integer multiple of \a base and greater or equal to \a size
  557|       | */
  558|       |template <typename Index>
  559|       |inline Index first_multiple(Index size, Index base) {
  560|       |  return ((size + base - 1) / base) * base;
  561|       |}
  562|       |
  563|       |// std::copy is much slower than memcpy, so let's introduce a smart_copy which
  564|       |// use memcpy on trivial types, i.e., on types that does not require an initialization ctor.
  565|       |template <typename T, bool UseMemcpy>
  566|       |struct smart_copy_helper;
  567|       |
  568|       |template <typename T>
  569|       |EIGEN_DEVICE_FUNC void smart_copy(const T* start, const T* end, T* target) {
  570|       |  smart_copy_helper<T, !NumTraits<T>::RequireInitialization>::run(start, end, target);
  571|       |}
  572|       |
  573|       |template <typename T>
  574|       |struct smart_copy_helper<T, true> {
  575|       |  EIGEN_DEVICE_FUNC static inline void run(const T* start, const T* end, T* target) {
  576|       |    std::intptr_t size = std::intptr_t(end) - std::intptr_t(start);
  577|       |    if (size == 0) return;
  578|       |    eigen_internal_assert(start != 0 && end != 0 && target != 0);
  579|       |    EIGEN_USING_STD(memcpy)
  580|       |    memcpy(target, start, size);
  581|       |  }
  582|       |};
  583|       |
  584|       |template <typename T>
  585|       |struct smart_copy_helper<T, false> {
  586|       |  EIGEN_DEVICE_FUNC static inline void run(const T* start, const T* end, T* target) { std::copy(start, end, target); }
  587|       |};
  588|       |
  589|       |// intelligent memmove. falls back to std::memmove for POD types, uses std::copy otherwise.
  590|       |template <typename T, bool UseMemmove>
  591|       |struct smart_memmove_helper;
  592|       |
  593|       |template <typename T>
  594|       |void smart_memmove(const T* start, const T* end, T* target) {
  595|       |  smart_memmove_helper<T, !NumTraits<T>::RequireInitialization>::run(start, end, target);
  596|       |}
  597|       |
  598|       |template <typename T>
  599|       |struct smart_memmove_helper<T, true> {
  600|       |  static inline void run(const T* start, const T* end, T* target) {
  601|       |    std::intptr_t size = std::intptr_t(end) - std::intptr_t(start);
  602|       |    if (size == 0) return;
  603|       |    eigen_internal_assert(start != 0 && end != 0 && target != 0);
  604|       |    std::memmove(target, start, size);
  605|       |  }
  606|       |};
  607|       |
  608|       |template <typename T>
  609|       |struct smart_memmove_helper<T, false> {
  610|       |  static inline void run(const T* start, const T* end, T* target) {
  611|       |    if (std::uintptr_t(target) < std::uintptr_t(start)) {
  612|       |      std::copy(start, end, target);
  613|       |    } else {
  614|       |      std::ptrdiff_t count = (std::ptrdiff_t(end) - std::ptrdiff_t(start)) / sizeof(T);
  615|       |      std::copy_backward(start, end, target + count);
  616|       |    }
  617|       |  }
  618|       |};
  619|       |
  620|       |template <typename T>
  621|       |EIGEN_DEVICE_FUNC T* smart_move(T* start, T* end, T* target) {
  622|       |  return std::move(start, end, target);
  623|       |}
  624|       |
  625|       |/*****************************************************************************
  626|       |*** Implementation of runtime stack allocation (falling back to malloc)    ***
  627|       |*****************************************************************************/
  628|       |
  629|       |// you can overwrite Eigen's default behavior regarding alloca by defining EIGEN_ALLOCA
  630|       |// to the appropriate stack allocation function
  631|       |#if !defined EIGEN_ALLOCA && !defined EIGEN_GPU_COMPILE_PHASE
  632|       |#if EIGEN_OS_LINUX || EIGEN_OS_MAC || (defined alloca)
  633|       |#define EIGEN_ALLOCA alloca
  634|       |#elif EIGEN_COMP_MSVC
  635|       |#define EIGEN_ALLOCA _alloca
  636|       |#endif
  637|       |#endif
  638|       |
  639|       |// With clang -Oz -mthumb, alloca changes the stack pointer in a way that is
  640|       |// not allowed in Thumb2. -DEIGEN_STACK_ALLOCATION_LIMIT=0 doesn't work because
  641|       |// the compiler still emits bad code because stack allocation checks use "<=".
  642|       |// TODO: Eliminate after https://bugs.llvm.org/show_bug.cgi?id=23772
  643|       |// is fixed.
  644|       |#if defined(__clang__) && defined(__thumb__)
  645|       |#undef EIGEN_ALLOCA
  646|       |#endif
  647|       |
  648|       |// This helper class construct the allocated memory, and takes care of destructing and freeing the handled data
  649|       |// at destruction time. In practice this helper class is mainly useful to avoid memory leak in case of exceptions.
  650|       |template <typename T>
  651|       |class aligned_stack_memory_handler : noncopyable {
  652|       | public:
  653|       |  /* Creates a stack_memory_handler responsible for the buffer \a ptr of size \a size.
  654|       |   * Note that \a ptr can be 0 regardless of the other parameters.
  655|       |   * This constructor takes care of constructing/initializing the elements of the buffer if required by the scalar type
  656|       |   *T (see NumTraits<T>::RequireInitialization). In this case, the buffer elements will also be destructed when this
  657|       |   *handler will be destructed. Finally, if \a dealloc is true, then the pointer \a ptr is freed.
  658|       |   **/
  659|       |  EIGEN_DEVICE_FUNC aligned_stack_memory_handler(T* ptr, std::size_t size, bool dealloc)
  660|      4|      : m_ptr(ptr), m_size(size), m_deallocate(dealloc) {
  661|      4|    if (NumTraits<T>::RequireInitialization && m_ptr) Eigen::internal::default_construct_elements_of_array(m_ptr, size);
  662|      4|  }
  663|      4|  EIGEN_DEVICE_FUNC ~aligned_stack_memory_handler() {
  664|      4|    if (NumTraits<T>::RequireInitialization && m_ptr) Eigen::internal::destruct_elements_of_array<T>(m_ptr, m_size);
  665|      4|    if (m_deallocate) Eigen::internal::aligned_free(m_ptr);
  666|      4|  }
  667|       |
  668|       | protected:
  669|       |  T* m_ptr;
  670|       |  std::size_t m_size;
  671|       |  bool m_deallocate;
  672|       |};
  673|       |
  674|       |#ifdef EIGEN_ALLOCA
  675|       |
  676|       |template <typename Xpr, int NbEvaluations,
  677|       |          bool MapExternalBuffer = nested_eval<Xpr, NbEvaluations>::Evaluate && Xpr::MaxSizeAtCompileTime == Dynamic>
  678|       |struct local_nested_eval_wrapper {
  679|       |  static constexpr bool NeedExternalBuffer = false;
  680|       |  typedef typename Xpr::Scalar Scalar;
  681|       |  typedef typename nested_eval<Xpr, NbEvaluations>::type ObjectType;
  682|       |  ObjectType object;
  683|       |
  684|       |  EIGEN_DEVICE_FUNC local_nested_eval_wrapper(const Xpr& xpr, Scalar* ptr) : object(xpr) {
  685|       |    EIGEN_UNUSED_VARIABLE(ptr);
  686|       |    eigen_internal_assert(ptr == 0);
  687|       |  }
  688|       |};
  689|       |
  690|       |template <typename Xpr, int NbEvaluations>
  691|       |struct local_nested_eval_wrapper<Xpr, NbEvaluations, true> {
  692|       |  static constexpr bool NeedExternalBuffer = true;
  693|       |  typedef typename Xpr::Scalar Scalar;
  694|       |  typedef typename plain_object_eval<Xpr>::type PlainObject;
  695|       |  typedef Map<PlainObject, EIGEN_DEFAULT_ALIGN_BYTES> ObjectType;
  696|       |  ObjectType object;
  697|       |
  698|       |  EIGEN_DEVICE_FUNC local_nested_eval_wrapper(const Xpr& xpr, Scalar* ptr)
  699|       |      : object(ptr == 0 ? reinterpret_cast<Scalar*>(Eigen::internal::aligned_malloc(sizeof(Scalar) * xpr.size())) : ptr,
  700|       |               xpr.rows(), xpr.cols()),
  701|       |        m_deallocate(ptr == 0) {
  702|       |    if (NumTraits<Scalar>::RequireInitialization && object.data())
  703|       |      Eigen::internal::default_construct_elements_of_array(object.data(), object.size());
  704|       |    object = xpr;
  705|       |  }
  706|       |
  707|       |  EIGEN_DEVICE_FUNC ~local_nested_eval_wrapper() {
  708|       |    if (NumTraits<Scalar>::RequireInitialization && object.data())
  709|       |      Eigen::internal::destruct_elements_of_array(object.data(), object.size());
  710|       |    if (m_deallocate) Eigen::internal::aligned_free(object.data());
  711|       |  }
  712|       |
  713|       | private:
  714|       |  bool m_deallocate;
  715|       |};
  716|       |
  717|       |#endif  // EIGEN_ALLOCA
  718|       |
  719|       |template <typename T>
  720|       |class scoped_array : noncopyable {
  721|       |  T* m_ptr;
  722|       |
  723|       | public:
  724|       |  explicit scoped_array(std::ptrdiff_t size) { m_ptr = new T[size]; }
  725|       |  ~scoped_array() { delete[] m_ptr; }
  726|       |  T& operator[](std::ptrdiff_t i) { return m_ptr[i]; }
  727|       |  const T& operator[](std::ptrdiff_t i) const { return m_ptr[i]; }
  728|       |  T*& ptr() { return m_ptr; }
  729|       |  const T* ptr() const { return m_ptr; }
  730|       |  operator const T*() const { return m_ptr; }
  731|       |};
  732|       |
  733|       |template <typename T>
  734|       |void swap(scoped_array<T>& a, scoped_array<T>& b) {
  735|       |  std::swap(a.ptr(), b.ptr());
  736|       |}
  737|       |
  738|       |}  // end namespace internal
  739|       |
  740|       |/** \internal
  741|       | *
  742|       | * The macro ei_declare_aligned_stack_constructed_variable(TYPE,NAME,SIZE,BUFFER) declares, allocates,
  743|       | * and construct an aligned buffer named NAME of SIZE elements of type TYPE on the stack
  744|       | * if the size in bytes is smaller than EIGEN_STACK_ALLOCATION_LIMIT, and if stack allocation is supported by the
  745|       | * platform (currently, this is Linux, OSX and Visual Studio only). Otherwise the memory is allocated on the heap. The
  746|       | * allocated buffer is automatically deleted when exiting the scope of this declaration. If BUFFER is non null, then the
  747|       | * declared variable is simply an alias for BUFFER, and no allocation/deletion occurs. Here is an example: \code
  748|       | * {
  749|       | *   ei_declare_aligned_stack_constructed_variable(float,data,size,0);
  750|       | *   // use data[0] to data[size-1]
  751|       | * }
  752|       | * \endcode
  753|       | * The underlying stack allocation function can controlled with the EIGEN_ALLOCA preprocessor token.
  754|       | *
  755|       | * The macro ei_declare_local_nested_eval(XPR_T,XPR,N,NAME) is analogue to
  756|       | * \code
  757|       | *   typename internal::nested_eval<XPRT_T,N>::type NAME(XPR);
  758|       | * \endcode
  759|       | * with the advantage of using aligned stack allocation even if the maximal size of XPR at compile time is unknown.
  760|       | * This is accomplished through alloca if this later is supported and if the required number of bytes
  761|       | * is below EIGEN_STACK_ALLOCATION_LIMIT.
  762|       | */
  763|       |#ifdef EIGEN_ALLOCA
  764|       |
  765|       |#if EIGEN_DEFAULT_ALIGN_BYTES > 0
  766|       |// We always manually re-align the result of EIGEN_ALLOCA.
  767|       |// If alloca is already aligned, the compiler should be smart enough to optimize away the re-alignment.
  768|       |
  769|       |#if ((EIGEN_COMP_GNUC || EIGEN_COMP_CLANG) && !EIGEN_COMP_NVHPC)
  770|      4|#define EIGEN_ALIGNED_ALLOCA(SIZE) __builtin_alloca_with_align(SIZE, CHAR_BIT* EIGEN_DEFAULT_ALIGN_BYTES)
  771|       |#else
  772|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void* eigen_aligned_alloca_helper(void* ptr) {
  773|       |  constexpr std::uintptr_t mask = EIGEN_DEFAULT_ALIGN_BYTES - 1;
  774|       |  std::uintptr_t ptr_int = std::uintptr_t(ptr);
  775|       |  std::uintptr_t aligned_ptr_int = (ptr_int + mask) & ~mask;
  776|       |  std::uintptr_t offset = aligned_ptr_int - ptr_int;
  777|       |  return static_cast<void*>(static_cast<uint8_t*>(ptr) + offset);
  778|       |}
  779|       |#define EIGEN_ALIGNED_ALLOCA(SIZE) eigen_aligned_alloca_helper(EIGEN_ALLOCA(SIZE + EIGEN_DEFAULT_ALIGN_BYTES - 1))
  780|       |#endif
  781|       |
  782|       |#else
  783|       |#define EIGEN_ALIGNED_ALLOCA(SIZE) EIGEN_ALLOCA(SIZE)
  784|       |#endif
  785|       |
  786|       |#define ei_declare_aligned_stack_constructed_variable(TYPE, NAME, SIZE, BUFFER)                                     \
  787|      4|  Eigen::internal::check_size_for_overflow<TYPE>(SIZE);                                                             \
  788|      4|  TYPE* NAME = (BUFFER) != 0 ? (BUFFER)                                                                             \
  789|      4|                             : reinterpret_cast<TYPE*>((sizeof(TYPE) * SIZE <= EIGEN_STACK_ALLOCATION_LIMIT)        \
  790|      4|                                                           ? EIGEN_ALIGNED_ALLOCA(sizeof(TYPE) * SIZE)              \
  791|      4|                                                           : Eigen::internal::aligned_malloc(sizeof(TYPE) * SIZE)); \
  792|      4|  Eigen::internal::aligned_stack_memory_handler<TYPE> EIGEN_CAT(NAME, _stack_memory_destructor)(                    \
  793|      4|      (BUFFER) == 0 ? NAME : 0, SIZE, sizeof(TYPE) * SIZE > EIGEN_STACK_ALLOCATION_LIMIT)
  794|       |
  795|       |#define ei_declare_local_nested_eval(XPR_T, XPR, N, NAME)                                        \
  796|       |  Eigen::internal::local_nested_eval_wrapper<XPR_T, N> EIGEN_CAT(NAME, _wrapper)(                \
  797|       |      XPR, reinterpret_cast<typename XPR_T::Scalar*>(                                            \
  798|       |               ((Eigen::internal::local_nested_eval_wrapper<XPR_T, N>::NeedExternalBuffer) &&    \
  799|       |                ((sizeof(typename XPR_T::Scalar) * XPR.size()) <= EIGEN_STACK_ALLOCATION_LIMIT)) \
  800|       |                   ? EIGEN_ALIGNED_ALLOCA(sizeof(typename XPR_T::Scalar) * XPR.size())           \
  801|       |                   : 0));                                                                        \
  802|       |  typename Eigen::internal::local_nested_eval_wrapper<XPR_T, N>::ObjectType NAME(EIGEN_CAT(NAME, _wrapper).object)
  803|       |
  804|       |#else
  805|       |
  806|       |#define ei_declare_aligned_stack_constructed_variable(TYPE, NAME, SIZE, BUFFER)                                        \
  807|       |  Eigen::internal::check_size_for_overflow<TYPE>(SIZE);                                                                \
  808|       |  TYPE* NAME = (BUFFER) != 0 ? BUFFER : reinterpret_cast<TYPE*>(Eigen::internal::aligned_malloc(sizeof(TYPE) * SIZE)); \
  809|       |  Eigen::internal::aligned_stack_memory_handler<TYPE> EIGEN_CAT(NAME, _stack_memory_destructor)(                       \
  810|       |      (BUFFER) == 0 ? NAME : 0, SIZE, true)
  811|       |
  812|       |#define ei_declare_local_nested_eval(XPR_T, XPR, N, NAME) \
  813|       |  typename Eigen::internal::nested_eval<XPR_T, N>::type NAME(XPR)
  814|       |
  815|       |#endif
  816|       |
  817|       |/*****************************************************************************
  818|       |*** Implementation of EIGEN_MAKE_ALIGNED_OPERATOR_NEW [_IF]                ***
  819|       |*****************************************************************************/
  820|       |
  821|       |#if EIGEN_HAS_CXX17_OVERALIGN
  822|       |
  823|       |// C++17 -> no need to bother about alignment anymore :)
  824|       |
  825|       |#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign)
  826|       |#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
  827|       |#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW
  828|       |#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF_VECTORIZABLE_FIXED_SIZE(Scalar, Size)
  829|       |
  830|       |#else
  831|       |
  832|       |// HIP does not support new/delete on device.
  833|       |#if EIGEN_MAX_ALIGN_BYTES != 0 && !defined(EIGEN_HIP_DEVICE_COMPILE)
  834|       |#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign)                                    \
  835|       |  EIGEN_DEVICE_FUNC void* operator new(std::size_t size, const std::nothrow_t&) EIGEN_NO_THROW { \
  836|       |    EIGEN_TRY { return Eigen::internal::conditional_aligned_malloc<NeedsToAlign>(size); }        \
  837|       |    EIGEN_CATCH(...) { return 0; }                                                               \
  838|       |  }
  839|       |#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)                                                             \
  840|       |  EIGEN_DEVICE_FUNC void* operator new(std::size_t size) {                                                           \
  841|       |    return Eigen::internal::conditional_aligned_malloc<NeedsToAlign>(size);                                          \
  842|       |  }                                                                                                                  \
  843|       |  EIGEN_DEVICE_FUNC void* operator new[](std::size_t size) {                                                         \
  844|       |    return Eigen::internal::conditional_aligned_malloc<NeedsToAlign>(size);                                          \
  845|       |  }                                                                                                                  \
  846|       |  EIGEN_DEVICE_FUNC void operator delete(void* ptr) EIGEN_NO_THROW {                                                 \
  847|       |    Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr);                                                    \
  848|       |  }                                                                                                                  \
  849|       |  EIGEN_DEVICE_FUNC void operator delete[](void* ptr) EIGEN_NO_THROW {                                               \
  850|       |    Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr);                                                    \
  851|       |  }                                                                                                                  \
  852|       |  EIGEN_DEVICE_FUNC void operator delete(void* ptr, std::size_t /* sz */) EIGEN_NO_THROW {                           \
  853|       |    Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr);                                                    \
  854|       |  }                                                                                                                  \
  855|       |  EIGEN_DEVICE_FUNC void operator delete[](void* ptr, std::size_t /* sz */) EIGEN_NO_THROW {                         \
  856|       |    Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr);                                                    \
  857|       |  }                                                                                                                  \
  858|       |  /* in-place new and delete. since (at least afaik) there is no actual   */                                         \
  859|       |  /* memory allocated we can safely let the default implementation handle */                                         \
  860|       |  /* this particular case. */                                                                                        \
  861|       |  EIGEN_DEVICE_FUNC static void* operator new(std::size_t size, void* ptr) { return ::operator new(size, ptr); }     \
  862|       |  EIGEN_DEVICE_FUNC static void* operator new[](std::size_t size, void* ptr) { return ::operator new[](size, ptr); } \
  863|       |  EIGEN_DEVICE_FUNC void operator delete(void* memory, void* ptr) EIGEN_NO_THROW {                                   \
  864|       |    return ::operator delete(memory, ptr);                                                                           \
  865|       |  }                                                                                                                  \
  866|       |  EIGEN_DEVICE_FUNC void operator delete[](void* memory, void* ptr) EIGEN_NO_THROW {                                 \
  867|       |    return ::operator delete[](memory, ptr);                                                                         \
  868|       |  }                                                                                                                  \
  869|       |  /* nothrow-new (returns zero instead of std::bad_alloc) */                                                         \
  870|       |  EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign)                                                              \
  871|       |  EIGEN_DEVICE_FUNC void operator delete(void* ptr, const std::nothrow_t&) EIGEN_NO_THROW {                          \
  872|       |    Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr);                                                    \
  873|       |  }                                                                                                                  \
  874|       |  typedef void eigen_aligned_operator_new_marker_type;
  875|       |#else
  876|       |#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
  877|       |#endif
  878|       |
  879|       |#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(true)
  880|       |#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF_VECTORIZABLE_FIXED_SIZE(Scalar, Size)                                 \
  881|       |  EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(                                                                            \
  882|       |      bool(((Size) != Eigen::Dynamic) &&                                                                         \
  883|       |           (((EIGEN_MAX_ALIGN_BYTES >= 16) && ((sizeof(Scalar) * (Size)) % (EIGEN_MAX_ALIGN_BYTES) == 0)) ||     \
  884|       |            ((EIGEN_MAX_ALIGN_BYTES >= 32) && ((sizeof(Scalar) * (Size)) % (EIGEN_MAX_ALIGN_BYTES / 2) == 0)) || \
  885|       |            ((EIGEN_MAX_ALIGN_BYTES >= 64) && ((sizeof(Scalar) * (Size)) % (EIGEN_MAX_ALIGN_BYTES / 4) == 0)))))
  886|       |
  887|       |#endif
  888|       |
  889|       |/****************************************************************************/
  890|       |
  891|       |/** \class aligned_allocator
  892|       | * \ingroup Core_Module
  893|       | *
  894|       | * \brief STL compatible allocator to use with types requiring a non-standard alignment.
  895|       | *
  896|       | * The memory is aligned as for dynamically aligned matrix/array types such as MatrixXd.
  897|       | * By default, it will thus provide at least 16 bytes alignment and more in following cases:
  898|       | *  - 32 bytes alignment if AVX is enabled.
  899|       | *  - 64 bytes alignment if AVX512 is enabled.
  900|       | *
  901|       | * This can be controlled using the \c EIGEN_MAX_ALIGN_BYTES macro as documented
  902|       | * \link TopicPreprocessorDirectivesPerformance there \endlink.
  903|       | *
  904|       | * Example:
  905|       | * \code
  906|       | * // Matrix4f requires 16 bytes alignment:
  907|       | * std::map< int, Matrix4f, std::less<int>,
  908|       | *           aligned_allocator<std::pair<const int, Matrix4f> > > my_map_mat4;
  909|       | * // Vector3f does not require 16 bytes alignment, no need to use Eigen's allocator:
  910|       | * std::map< int, Vector3f > my_map_vec3;
  911|       | * \endcode
  912|       | *
  913|       | * \sa \blank \ref TopicStlContainers.
  914|       | */
  915|       |template <class T>
  916|       |class aligned_allocator {
  917|       | public:
  918|       |  typedef std::size_t size_type;
  919|       |  typedef std::ptrdiff_t difference_type;
  920|       |  typedef T* pointer;
  921|       |  typedef const T* const_pointer;
  922|       |  typedef T& reference;
  923|       |  typedef const T& const_reference;
  924|       |  typedef T value_type;
  925|       |
  926|       |  template <class U>
  927|       |  struct rebind {
  928|       |    typedef aligned_allocator<U> other;
  929|       |  };
  930|       |
  931|       |  aligned_allocator() = default;
  932|       |
  933|       |  aligned_allocator(const aligned_allocator&) = default;
  934|       |
  935|       |  template <class U>
  936|       |  aligned_allocator(const aligned_allocator<U>&) {}
  937|       |
  938|       |  template <class U>
  939|       |  constexpr bool operator==(const aligned_allocator<U>&) const noexcept {
  940|       |    return true;
  941|       |  }
  942|       |  template <class U>
  943|       |  constexpr bool operator!=(const aligned_allocator<U>&) const noexcept {
  944|       |    return false;
  945|       |  }
  946|       |
  947|       |#if EIGEN_COMP_GNUC_STRICT && EIGEN_GNUC_STRICT_AT_LEAST(7, 0, 0)
  948|       |  // In gcc std::allocator::max_size() is bugged making gcc triggers a warning:
  949|       |  // eigen/Eigen/src/Core/util/Memory.h:189:12: warning: argument 1 value '18446744073709551612' exceeds maximum object
  950|       |  // size 9223372036854775807 See https://gcc.gnu.org/bugzilla/show_bug.cgi?id=87544
  951|       |  size_type max_size() const { return (std::numeric_limits<std::ptrdiff_t>::max)() / sizeof(T); }
  952|       |#endif
  953|       |
  954|       |  pointer allocate(size_type num, const void* /*hint*/ = 0) {
  955|       |    internal::check_size_for_overflow<T>(num);
  956|       |    return static_cast<pointer>(internal::aligned_malloc(num * sizeof(T)));
  957|       |  }
  958|       |
  959|       |  void deallocate(pointer p, size_type /*num*/) { internal::aligned_free(p); }
  960|       |};
  961|       |
  962|       |//---------- Cache sizes ----------
  963|       |
  964|       |#if !defined(EIGEN_NO_CPUID)
  965|       |#if EIGEN_COMP_GNUC && EIGEN_ARCH_i386_OR_x86_64
  966|       |#if defined(__PIC__) && EIGEN_ARCH_i386
  967|       |// Case for x86 with PIC
  968|       |#define EIGEN_CPUID(abcd, func, id)                                                  \
  969|       |  __asm__ __volatile__("xchgl %%ebx, %k1;cpuid; xchgl %%ebx,%k1"                     \
  970|       |                       : "=a"(abcd[0]), "=&r"(abcd[1]), "=c"(abcd[2]), "=d"(abcd[3]) \
  971|       |                       : "a"(func), "c"(id));
  972|       |#elif defined(__PIC__) && EIGEN_ARCH_x86_64
  973|       |// Case for x64 with PIC. In theory this is only a problem with recent gcc and with medium or large code model, not with
  974|       |// the default small code model. However, we cannot detect which code model is used, and the xchg overhead is negligible
  975|       |// anyway.
  976|       |#define EIGEN_CPUID(abcd, func, id)                                                  \
  977|      6|  __asm__ __volatile__("xchg{q}\t{%%}rbx, %q1; cpuid; xchg{q}\t{%%}rbx, %q1"         \
  978|      6|                       : "=a"(abcd[0]), "=&r"(abcd[1]), "=c"(abcd[2]), "=d"(abcd[3]) \
  979|      6|                       : "0"(func), "2"(id));
  980|       |#else
  981|       |// Case for x86_64 or x86 w/o PIC
  982|       |#define EIGEN_CPUID(abcd, func, id) \
  983|       |  __asm__ __volatile__("cpuid" : "=a"(abcd[0]), "=b"(abcd[1]), "=c"(abcd[2]), "=d"(abcd[3]) : "0"(func), "2"(id));
  984|       |#endif
  985|       |#elif EIGEN_COMP_MSVC
  986|       |#if EIGEN_ARCH_i386_OR_x86_64
  987|       |#define EIGEN_CPUID(abcd, func, id) __cpuidex((int*)abcd, func, id)
  988|       |#endif
  989|       |#endif
  990|       |#endif
  991|       |
  992|       |namespace internal {
  993|       |
  994|       |#ifdef EIGEN_CPUID
  995|       |
  996|      1|inline bool cpuid_is_vendor(int abcd[4], const int vendor[3]) {
  997|      1|  return abcd[1] == vendor[0] && abcd[3] == vendor[1] && abcd[2] == vendor[2];
  998|      1|}
  999|       |
 1000|      1|inline void queryCacheSizes_intel_direct(int& l1, int& l2, int& l3) {
 1001|      1|  int abcd[4];
 1002|      1|  l1 = l2 = l3 = 0;
 1003|      1|  int cache_id = 0;
 1004|      1|  int cache_type = 0;
 1005|      5|  do {
 1006|      5|    abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
 1007|      5|    EIGEN_CPUID(abcd, 0x4, cache_id);
 1008|      5|    cache_type = (abcd[0] & 0x0F) >> 0;
 1009|      5|    if (cache_type == 1 || cache_type == 3)  // data or unified cache
 1010|      3|    {
 1011|      3|      int cache_level = (abcd[0] & 0xE0) >> 5;        // A[7:5]
 1012|      3|      int ways = (abcd[1] & 0xFFC00000) >> 22;        // B[31:22]
 1013|      3|      int partitions = (abcd[1] & 0x003FF000) >> 12;  // B[21:12]
 1014|      3|      int line_size = (abcd[1] & 0x00000FFF) >> 0;    // B[11:0]
 1015|      3|      int sets = (abcd[2]);                           // C[31:0]
 1016|       |
 1017|      3|      int cache_size = (ways + 1) * (partitions + 1) * (line_size + 1) * (sets + 1);
 1018|       |
 1019|      3|      switch (cache_level) {
 1020|      1|        case 1:
 1021|      1|          l1 = cache_size;
 1022|      1|          break;
 1023|      1|        case 2:
 1024|      1|          l2 = cache_size;
 1025|      1|          break;
 1026|      1|        case 3:
 1027|      1|          l3 = cache_size;
 1028|      1|          break;
 1029|      0|        default:
 1030|      0|          break;
 1031|      3|      }
 1032|      3|    }
 1033|      5|    cache_id++;
 1034|      5|  } while (cache_type > 0 && cache_id < 16);
 1035|      1|}
 1036|       |
 1037|      0|inline void queryCacheSizes_intel_codes(int& l1, int& l2, int& l3) {
 1038|      0|  int abcd[4];
 1039|      0|  abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
 1040|      0|  l1 = l2 = l3 = 0;
 1041|      0|  EIGEN_CPUID(abcd, 0x00000002, 0);
 1042|      0|  unsigned char* bytes = reinterpret_cast<unsigned char*>(abcd) + 2;
 1043|      0|  bool check_for_p2_core2 = false;
 1044|      0|  for (int i = 0; i < 14; ++i) {
 1045|      0|    switch (bytes[i]) {
 1046|      0|      case 0x0A:
 1047|      0|        l1 = 8;
 1048|      0|        break;  // 0Ah   data L1 cache, 8 KB, 2 ways, 32 byte lines
 1049|      0|      case 0x0C:
 1050|      0|        l1 = 16;
 1051|      0|        break;  // 0Ch   data L1 cache, 16 KB, 4 ways, 32 byte lines
 1052|      0|      case 0x0E:
 1053|      0|        l1 = 24;
 1054|      0|        break;  // 0Eh   data L1 cache, 24 KB, 6 ways, 64 byte lines
 1055|      0|      case 0x10:
 1056|      0|        l1 = 16;
 1057|      0|        break;  // 10h   data L1 cache, 16 KB, 4 ways, 32 byte lines (IA-64)
 1058|      0|      case 0x15:
 1059|      0|        l1 = 16;
 1060|      0|        break;  // 15h   code L1 cache, 16 KB, 4 ways, 32 byte lines (IA-64)
 1061|      0|      case 0x2C:
 1062|      0|        l1 = 32;
 1063|      0|        break;  // 2Ch   data L1 cache, 32 KB, 8 ways, 64 byte lines
 1064|      0|      case 0x30:
 1065|      0|        l1 = 32;
 1066|      0|        break;  // 30h   code L1 cache, 32 KB, 8 ways, 64 byte lines
 1067|      0|      case 0x60:
 1068|      0|        l1 = 16;
 1069|      0|        break;  // 60h   data L1 cache, 16 KB, 8 ways, 64 byte lines, sectored
 1070|      0|      case 0x66:
 1071|      0|        l1 = 8;
 1072|      0|        break;  // 66h   data L1 cache, 8 KB, 4 ways, 64 byte lines, sectored
 1073|      0|      case 0x67:
 1074|      0|        l1 = 16;
 1075|      0|        break;  // 67h   data L1 cache, 16 KB, 4 ways, 64 byte lines, sectored
 1076|      0|      case 0x68:
 1077|      0|        l1 = 32;
 1078|      0|        break;  // 68h   data L1 cache, 32 KB, 4 ways, 64 byte lines, sectored
 1079|      0|      case 0x1A:
 1080|      0|        l2 = 96;
 1081|      0|        break;  // code and data L2 cache, 96 KB, 6 ways, 64 byte lines (IA-64)
 1082|      0|      case 0x22:
 1083|      0|        l3 = 512;
 1084|      0|        break;  // code and data L3 cache, 512 KB, 4 ways (!), 64 byte lines, dual-sectored
 1085|      0|      case 0x23:
 1086|      0|        l3 = 1024;
 1087|      0|        break;  // code and data L3 cache, 1024 KB, 8 ways, 64 byte lines, dual-sectored
 1088|      0|      case 0x25:
 1089|      0|        l3 = 2048;
 1090|      0|        break;  // code and data L3 cache, 2048 KB, 8 ways, 64 byte lines, dual-sectored
 1091|      0|      case 0x29:
 1092|      0|        l3 = 4096;
 1093|      0|        break;  // code and data L3 cache, 4096 KB, 8 ways, 64 byte lines, dual-sectored
 1094|      0|      case 0x39:
 1095|      0|        l2 = 128;
 1096|      0|        break;  // code and data L2 cache, 128 KB, 4 ways, 64 byte lines, sectored
 1097|      0|      case 0x3A:
 1098|      0|        l2 = 192;
 1099|      0|        break;  // code and data L2 cache, 192 KB, 6 ways, 64 byte lines, sectored
 1100|      0|      case 0x3B:
 1101|      0|        l2 = 128;
 1102|      0|        break;  // code and data L2 cache, 128 KB, 2 ways, 64 byte lines, sectored
 1103|      0|      case 0x3C:
 1104|      0|        l2 = 256;
 1105|      0|        break;  // code and data L2 cache, 256 KB, 4 ways, 64 byte lines, sectored
 1106|      0|      case 0x3D:
 1107|      0|        l2 = 384;
 1108|      0|        break;  // code and data L2 cache, 384 KB, 6 ways, 64 byte lines, sectored
 1109|      0|      case 0x3E:
 1110|      0|        l2 = 512;
 1111|      0|        break;  // code and data L2 cache, 512 KB, 4 ways, 64 byte lines, sectored
 1112|      0|      case 0x40:
 1113|      0|        l2 = 0;
 1114|      0|        break;  // no integrated L2 cache (P6 core) or L3 cache (P4 core)
 1115|      0|      case 0x41:
 1116|      0|        l2 = 128;
 1117|      0|        break;  // code and data L2 cache, 128 KB, 4 ways, 32 byte lines
 1118|      0|      case 0x42:
 1119|      0|        l2 = 256;
 1120|      0|        break;  // code and data L2 cache, 256 KB, 4 ways, 32 byte lines
 1121|      0|      case 0x43:
 1122|      0|        l2 = 512;
 1123|      0|        break;  // code and data L2 cache, 512 KB, 4 ways, 32 byte lines
 1124|      0|      case 0x44:
 1125|      0|        l2 = 1024;
 1126|      0|        break;  // code and data L2 cache, 1024 KB, 4 ways, 32 byte lines
 1127|      0|      case 0x45:
 1128|      0|        l2 = 2048;
 1129|      0|        break;  // code and data L2 cache, 2048 KB, 4 ways, 32 byte lines
 1130|      0|      case 0x46:
 1131|      0|        l3 = 4096;
 1132|      0|        break;  // code and data L3 cache, 4096 KB, 4 ways, 64 byte lines
 1133|      0|      case 0x47:
 1134|      0|        l3 = 8192;
 1135|      0|        break;  // code and data L3 cache, 8192 KB, 8 ways, 64 byte lines
 1136|      0|      case 0x48:
 1137|      0|        l2 = 3072;
 1138|      0|        break;  // code and data L2 cache, 3072 KB, 12 ways, 64 byte lines
 1139|      0|      case 0x49:
 1140|      0|        if (l2 != 0)
 1141|      0|          l3 = 4096;
 1142|      0|        else {
 1143|      0|          check_for_p2_core2 = true;
 1144|      0|          l3 = l2 = 4096;
 1145|      0|        }
 1146|      0|        break;  // code and data L3 cache, 4096 KB, 16 ways, 64 byte lines (P4) or L2 for core2
 1147|      0|      case 0x4A:
 1148|      0|        l3 = 6144;
 1149|      0|        break;  // code and data L3 cache, 6144 KB, 12 ways, 64 byte lines
 1150|      0|      case 0x4B:
 1151|      0|        l3 = 8192;
 1152|      0|        break;  // code and data L3 cache, 8192 KB, 16 ways, 64 byte lines
 1153|      0|      case 0x4C:
 1154|      0|        l3 = 12288;
 1155|      0|        break;  // code and data L3 cache, 12288 KB, 12 ways, 64 byte lines
 1156|      0|      case 0x4D:
 1157|      0|        l3 = 16384;
 1158|      0|        break;  // code and data L3 cache, 16384 KB, 16 ways, 64 byte lines
 1159|      0|      case 0x4E:
 1160|      0|        l2 = 6144;
 1161|      0|        break;  // code and data L2 cache, 6144 KB, 24 ways, 64 byte lines
 1162|      0|      case 0x78:
 1163|      0|        l2 = 1024;
 1164|      0|        break;  // code and data L2 cache, 1024 KB, 4 ways, 64 byte lines
 1165|      0|      case 0x79:
 1166|      0|        l2 = 128;
 1167|      0|        break;  // code and data L2 cache, 128 KB, 8 ways, 64 byte lines, dual-sectored
 1168|      0|      case 0x7A:
 1169|      0|        l2 = 256;
 1170|      0|        break;  // code and data L2 cache, 256 KB, 8 ways, 64 byte lines, dual-sectored
 1171|      0|      case 0x7B:
 1172|      0|        l2 = 512;
 1173|      0|        break;  // code and data L2 cache, 512 KB, 8 ways, 64 byte lines, dual-sectored
 1174|      0|      case 0x7C:
 1175|      0|        l2 = 1024;
 1176|      0|        break;  // code and data L2 cache, 1024 KB, 8 ways, 64 byte lines, dual-sectored
 1177|      0|      case 0x7D:
 1178|      0|        l2 = 2048;
 1179|      0|        break;  // code and data L2 cache, 2048 KB, 8 ways, 64 byte lines
 1180|      0|      case 0x7E:
 1181|      0|        l2 = 256;
 1182|      0|        break;  // code and data L2 cache, 256 KB, 8 ways, 128 byte lines, sect. (IA-64)
 1183|      0|      case 0x7F:
 1184|      0|        l2 = 512;
 1185|      0|        break;  // code and data L2 cache, 512 KB, 2 ways, 64 byte lines
 1186|      0|      case 0x80:
 1187|      0|        l2 = 512;
 1188|      0|        break;  // code and data L2 cache, 512 KB, 8 ways, 64 byte lines
 1189|      0|      case 0x81:
 1190|      0|        l2 = 128;
 1191|      0|        break;  // code and data L2 cache, 128 KB, 8 ways, 32 byte lines
 1192|      0|      case 0x82:
 1193|      0|        l2 = 256;
 1194|      0|        break;  // code and data L2 cache, 256 KB, 8 ways, 32 byte lines
 1195|      0|      case 0x83:
 1196|      0|        l2 = 512;
 1197|      0|        break;  // code and data L2 cache, 512 KB, 8 ways, 32 byte lines
 1198|      0|      case 0x84:
 1199|      0|        l2 = 1024;
 1200|      0|        break;  // code and data L2 cache, 1024 KB, 8 ways, 32 byte lines
 1201|      0|      case 0x85:
 1202|      0|        l2 = 2048;
 1203|      0|        break;  // code and data L2 cache, 2048 KB, 8 ways, 32 byte lines
 1204|      0|      case 0x86:
 1205|      0|        l2 = 512;
 1206|      0|        break;  // code and data L2 cache, 512 KB, 4 ways, 64 byte lines
 1207|      0|      case 0x87:
 1208|      0|        l2 = 1024;
 1209|      0|        break;  // code and data L2 cache, 1024 KB, 8 ways, 64 byte lines
 1210|      0|      case 0x88:
 1211|      0|        l3 = 2048;
 1212|      0|        break;  // code and data L3 cache, 2048 KB, 4 ways, 64 byte lines (IA-64)
 1213|      0|      case 0x89:
 1214|      0|        l3 = 4096;
 1215|      0|        break;  // code and data L3 cache, 4096 KB, 4 ways, 64 byte lines (IA-64)
 1216|      0|      case 0x8A:
 1217|      0|        l3 = 8192;
 1218|      0|        break;  // code and data L3 cache, 8192 KB, 4 ways, 64 byte lines (IA-64)
 1219|      0|      case 0x8D:
 1220|      0|        l3 = 3072;
 1221|      0|        break;  // code and data L3 cache, 3072 KB, 12 ways, 128 byte lines (IA-64)
 1222|       |
 1223|      0|      default:
 1224|      0|        break;
 1225|      0|    }
 1226|      0|  }
 1227|      0|  if (check_for_p2_core2 && l2 == l3) l3 = 0;
 1228|      0|  l1 *= 1024;
 1229|      0|  l2 *= 1024;
 1230|      0|  l3 *= 1024;
 1231|      0|}
 1232|       |
 1233|      1|inline void queryCacheSizes_intel(int& l1, int& l2, int& l3, int max_std_funcs) {
 1234|      1|  if (max_std_funcs >= 4)
 1235|      1|    queryCacheSizes_intel_direct(l1, l2, l3);
 1236|      0|  else if (max_std_funcs >= 2)
 1237|      0|    queryCacheSizes_intel_codes(l1, l2, l3);
 1238|      0|  else
 1239|      0|    l1 = l2 = l3 = 0;
 1240|      1|}
 1241|       |
 1242|      0|inline void queryCacheSizes_amd(int& l1, int& l2, int& l3) {
 1243|      0|  int abcd[4];
 1244|      0|  abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
 1245|       |
 1246|       |  // First query the max supported function.
 1247|      0|  EIGEN_CPUID(abcd, 0x80000000, 0);
 1248|      0|  if (static_cast<numext::uint32_t>(abcd[0]) >= static_cast<numext::uint32_t>(0x80000006)) {
 1249|      0|    EIGEN_CPUID(abcd, 0x80000005, 0);
 1250|      0|    l1 = (abcd[2] >> 24) * 1024;  // C[31:24] = L1 size in KB
 1251|      0|    abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
 1252|      0|    EIGEN_CPUID(abcd, 0x80000006, 0);
 1253|      0|    l2 = (abcd[2] >> 16) * 1024;                      // C[31;16] = l2 cache size in KB
 1254|      0|    l3 = ((abcd[3] & 0xFFFC000) >> 18) * 512 * 1024;  // D[31;18] = l3 cache size in 512KB
 1255|      0|  } else {
 1256|      0|    l1 = l2 = l3 = 0;
 1257|      0|  }
 1258|      0|}
 1259|       |#endif
 1260|       |
 1261|       |/** \internal
 1262|       | * Queries and returns the cache sizes in Bytes of the L1, L2, and L3 data caches respectively */
 1263|      1|inline void queryCacheSizes(int& l1, int& l2, int& l3) {
 1264|      1|#ifdef EIGEN_CPUID
 1265|      1|  int abcd[4];
 1266|      1|  const int GenuineIntel[] = {0x756e6547, 0x49656e69, 0x6c65746e};
 1267|      1|  const int AuthenticAMD[] = {0x68747541, 0x69746e65, 0x444d4163};
 1268|      1|  const int AMDisbetter_[] = {0x69444d41, 0x74656273, 0x21726574};  // "AMDisbetter!"
 1269|       |
 1270|       |  // identify the CPU vendor
 1271|      1|  EIGEN_CPUID(abcd, 0x0, 0);
 1272|      1|  int max_std_funcs = abcd[0];
 1273|      1|  if (cpuid_is_vendor(abcd, GenuineIntel))
 1274|      1|    queryCacheSizes_intel(l1, l2, l3, max_std_funcs);
 1275|      0|  else if (cpuid_is_vendor(abcd, AuthenticAMD) || cpuid_is_vendor(abcd, AMDisbetter_))
 1276|      0|    queryCacheSizes_amd(l1, l2, l3);
 1277|      0|  else
 1278|       |    // by default let's use Intel's API
 1279|      0|    queryCacheSizes_intel(l1, l2, l3, max_std_funcs);
 1280|       |
 1281|       |    // here is the list of other vendors:
 1282|       |    //   ||cpuid_is_vendor(abcd,"VIA VIA VIA ")
 1283|       |    //   ||cpuid_is_vendor(abcd,"CyrixInstead")
 1284|       |    //   ||cpuid_is_vendor(abcd,"CentaurHauls")
 1285|       |    //   ||cpuid_is_vendor(abcd,"GenuineTMx86")
 1286|       |    //   ||cpuid_is_vendor(abcd,"TransmetaCPU")
 1287|       |    //   ||cpuid_is_vendor(abcd,"RiseRiseRise")
 1288|       |    //   ||cpuid_is_vendor(abcd,"Geode by NSC")
 1289|       |    //   ||cpuid_is_vendor(abcd,"SiS SiS SiS ")
 1290|       |    //   ||cpuid_is_vendor(abcd,"UMC UMC UMC ")
 1291|       |    //   ||cpuid_is_vendor(abcd,"NexGenDriven")
 1292|       |#else
 1293|       |  l1 = l2 = l3 = -1;
 1294|       |#endif
 1295|      1|}
 1296|       |
 1297|       |/** \internal
 1298|       | * \returns the size in Bytes of the L1 data cache */
 1299|      0|inline int queryL1CacheSize() {
 1300|      0|  int l1(-1), l2, l3;
 1301|      0|  queryCacheSizes(l1, l2, l3);
 1302|      0|  return l1;
 1303|      0|}
 1304|       |
 1305|       |/** \internal
 1306|       | * \returns the size in Bytes of the L2 or L3 cache if this later is present */
 1307|      0|inline int queryTopLevelCacheSize() {
 1308|      0|  int l1, l2(-1), l3(-1);
 1309|      0|  queryCacheSizes(l1, l2, l3);
 1310|      0|  return (std::max)(l2, l3);
 1311|      0|}
 1312|       |
 1313|       |/** \internal
 1314|       | * This wraps C++20's std::construct_at, using placement new instead if it is not available.
 1315|       | */
 1316|       |
 1317|       |#if EIGEN_COMP_CXXVER >= 20
 1318|       |using std::construct_at;
 1319|       |#else
 1320|       |template <class T, class... Args>
 1321|      0|EIGEN_DEVICE_FUNC T* construct_at(T* p, Args&&... args) {
 1322|      0|  return ::new (const_cast<void*>(static_cast<const volatile void*>(p))) T(std::forward<Args>(args)...);
 1323|      0|}
 1324|       |#endif
 1325|       |
 1326|       |/** \internal
 1327|       | * This wraps C++17's std::destroy_at.  If it's not available it calls the destructor.
 1328|       | * The wrapper is not a full replacement for C++20's std::destroy_at as it cannot
 1329|       | * be applied to std::array.
 1330|       | */
 1331|       |#if EIGEN_COMP_CXXVER >= 17
 1332|       |using std::destroy_at;
 1333|       |#else
 1334|       |template <class T>
 1335|       |EIGEN_DEVICE_FUNC void destroy_at(T* p) {
 1336|       |  p->~T();
 1337|       |}
 1338|       |#endif
 1339|       |
 1340|       |}  // end namespace internal
 1341|       |
 1342|       |}  // end namespace Eigen
 1343|       |
 1344|       |#endif  // EIGEN_MEMORY_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/Meta.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2015 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_META_H
   12|       |#define EIGEN_META_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "../InternalHeaderCheck.h"
   16|       |
   17|       |#if defined(EIGEN_GPU_COMPILE_PHASE)
   18|       |
   19|       |#include <cfloat>
   20|       |
   21|       |#if defined(EIGEN_CUDA_ARCH)
   22|       |#include <math_constants.h>
   23|       |#endif
   24|       |
   25|       |#if defined(EIGEN_HIP_DEVICE_COMPILE)
   26|       |#include "Eigen/src/Core/arch/HIP/hcc/math_constants.h"
   27|       |#endif
   28|       |
   29|       |#endif
   30|       |
   31|       |// Define portable (u)int{32,64} types
   32|       |#include <cstdint>
   33|       |
   34|       |namespace Eigen {
   35|       |namespace numext {
   36|       |typedef std::uint8_t uint8_t;
   37|       |typedef std::int8_t int8_t;
   38|       |typedef std::uint16_t uint16_t;
   39|       |typedef std::int16_t int16_t;
   40|       |typedef std::uint32_t uint32_t;
   41|       |typedef std::int32_t int32_t;
   42|       |typedef std::uint64_t uint64_t;
   43|       |typedef std::int64_t int64_t;
   44|       |
   45|       |template <size_t Size>
   46|       |struct get_integer_by_size {
   47|       |  typedef void signed_type;
   48|       |  typedef void unsigned_type;
   49|       |};
   50|       |template <>
   51|       |struct get_integer_by_size<1> {
   52|       |  typedef int8_t signed_type;
   53|       |  typedef uint8_t unsigned_type;
   54|       |};
   55|       |template <>
   56|       |struct get_integer_by_size<2> {
   57|       |  typedef int16_t signed_type;
   58|       |  typedef uint16_t unsigned_type;
   59|       |};
   60|       |template <>
   61|       |struct get_integer_by_size<4> {
   62|       |  typedef int32_t signed_type;
   63|       |  typedef uint32_t unsigned_type;
   64|       |};
   65|       |template <>
   66|       |struct get_integer_by_size<8> {
   67|       |  typedef int64_t signed_type;
   68|       |  typedef uint64_t unsigned_type;
   69|       |};
   70|       |}  // namespace numext
   71|       |}  // namespace Eigen
   72|       |
   73|       |namespace Eigen {
   74|       |
   75|       |typedef EIGEN_DEFAULT_DENSE_INDEX_TYPE DenseIndex;
   76|       |
   77|       |/**
   78|       | * \brief The Index type as used for the API.
   79|       | * \details To change this, \c \#define the preprocessor symbol \c EIGEN_DEFAULT_DENSE_INDEX_TYPE.
   80|       | * \sa \blank \ref TopicPreprocessorDirectives, StorageIndex.
   81|       | */
   82|       |
   83|       |typedef EIGEN_DEFAULT_DENSE_INDEX_TYPE Index;
   84|       |
   85|       |namespace internal {
   86|       |
   87|       |/** \internal
   88|       | * \file Meta.h
   89|       | * This file contains generic metaprogramming classes which are not specifically related to Eigen.
   90|       | * \note In case you wonder, yes we're aware that Boost already provides all these features,
   91|       | * we however don't want to add a dependency to Boost.
   92|       | */
   93|       |
   94|       |struct true_type {
   95|       |  enum { value = 1 };
   96|       |};
   97|       |struct false_type {
   98|       |  enum { value = 0 };
   99|       |};
  100|       |
  101|       |template <bool Condition>
  102|       |struct bool_constant;
  103|       |
  104|       |template <>
  105|       |struct bool_constant<true> : true_type {};
  106|       |
  107|       |template <>
  108|       |struct bool_constant<false> : false_type {};
  109|       |
  110|       |// Third-party libraries rely on these.
  111|       |using std::conditional;
  112|       |using std::remove_const;
  113|       |using std::remove_pointer;
  114|       |using std::remove_reference;
  115|       |
  116|       |template <typename T>
  117|       |struct remove_all {
  118|       |  typedef T type;
  119|       |};
  120|       |template <typename T>
  121|       |struct remove_all<const T> {
  122|       |  typedef typename remove_all<T>::type type;
  123|       |};
  124|       |template <typename T>
  125|       |struct remove_all<T const&> {
  126|       |  typedef typename remove_all<T>::type type;
  127|       |};
  128|       |template <typename T>
  129|       |struct remove_all<T&> {
  130|       |  typedef typename remove_all<T>::type type;
  131|       |};
  132|       |template <typename T>
  133|       |struct remove_all<T const*> {
  134|       |  typedef typename remove_all<T>::type type;
  135|       |};
  136|       |template <typename T>
  137|       |struct remove_all<T*> {
  138|       |  typedef typename remove_all<T>::type type;
  139|       |};
  140|       |
  141|       |template <typename T>
  142|       |using remove_all_t = typename remove_all<T>::type;
  143|       |
  144|       |template <typename T>
  145|       |struct is_arithmetic {
  146|       |  enum { value = false };
  147|       |};
  148|       |template <>
  149|       |struct is_arithmetic<float> {
  150|       |  enum { value = true };
  151|       |};
  152|       |template <>
  153|       |struct is_arithmetic<double> {
  154|       |  enum { value = true };
  155|       |};
  156|       |// GPU devices treat `long double` as `double`.
  157|       |#ifndef EIGEN_GPU_COMPILE_PHASE
  158|       |template <>
  159|       |struct is_arithmetic<long double> {
  160|       |  enum { value = true };
  161|       |};
  162|       |#endif
  163|       |template <>
  164|       |struct is_arithmetic<bool> {
  165|       |  enum { value = true };
  166|       |};
  167|       |template <>
  168|       |struct is_arithmetic<char> {
  169|       |  enum { value = true };
  170|       |};
  171|       |template <>
  172|       |struct is_arithmetic<signed char> {
  173|       |  enum { value = true };
  174|       |};
  175|       |template <>
  176|       |struct is_arithmetic<unsigned char> {
  177|       |  enum { value = true };
  178|       |};
  179|       |template <>
  180|       |struct is_arithmetic<signed short> {
  181|       |  enum { value = true };
  182|       |};
  183|       |template <>
  184|       |struct is_arithmetic<unsigned short> {
  185|       |  enum { value = true };
  186|       |};
  187|       |template <>
  188|       |struct is_arithmetic<signed int> {
  189|       |  enum { value = true };
  190|       |};
  191|       |template <>
  192|       |struct is_arithmetic<unsigned int> {
  193|       |  enum { value = true };
  194|       |};
  195|       |template <>
  196|       |struct is_arithmetic<signed long> {
  197|       |  enum { value = true };
  198|       |};
  199|       |template <>
  200|       |struct is_arithmetic<unsigned long> {
  201|       |  enum { value = true };
  202|       |};
  203|       |
  204|       |template <typename T, typename U>
  205|       |struct is_same {
  206|       |  enum { value = 0 };
  207|       |};
  208|       |template <typename T>
  209|       |struct is_same<T, T> {
  210|       |  enum { value = 1 };
  211|       |};
  212|       |
  213|       |template <class T>
  214|       |struct is_void : is_same<void, std::remove_const_t<T>> {};
  215|       |
  216|       |/** \internal
  217|       | * Implementation of std::void_t for SFINAE.
  218|       | *
  219|       | * Pre C++17:
  220|       | * Custom implementation.
  221|       | *
  222|       | * Post C++17: Uses std::void_t
  223|       | */
  224|       |#if EIGEN_COMP_CXXVER >= 17
  225|       |using std::void_t;
  226|       |#else
  227|       |template <typename...>
  228|       |using void_t = void;
  229|       |#endif
  230|       |
  231|       |template <>
  232|       |struct is_arithmetic<signed long long> {
  233|       |  enum { value = true };
  234|       |};
  235|       |template <>
  236|       |struct is_arithmetic<unsigned long long> {
  237|       |  enum { value = true };
  238|       |};
  239|       |using std::is_integral;
  240|       |
  241|       |using std::make_unsigned;
  242|       |
  243|       |template <typename T>
  244|       |struct is_const {
  245|       |  enum { value = 0 };
  246|       |};
  247|       |template <typename T>
  248|       |struct is_const<T const> {
  249|       |  enum { value = 1 };
  250|       |};
  251|       |
  252|       |template <typename T>
  253|       |struct add_const_on_value_type {
  254|       |  typedef const T type;
  255|       |};
  256|       |template <typename T>
  257|       |struct add_const_on_value_type<T&> {
  258|       |  typedef T const& type;
  259|       |};
  260|       |template <typename T>
  261|       |struct add_const_on_value_type<T*> {
  262|       |  typedef T const* type;
  263|       |};
  264|       |template <typename T>
  265|       |struct add_const_on_value_type<T* const> {
  266|       |  typedef T const* const type;
  267|       |};
  268|       |template <typename T>
  269|       |struct add_const_on_value_type<T const* const> {
  270|       |  typedef T const* const type;
  271|       |};
  272|       |
  273|       |template <typename T>
  274|       |using add_const_on_value_type_t = typename add_const_on_value_type<T>::type;
  275|       |
  276|       |using std::is_convertible;
  277|       |
  278|       |/** \internal
  279|       | * A base class do disable default copy ctor and copy assignment operator.
  280|       | */
  281|       |class noncopyable {
  282|       |  EIGEN_DEVICE_FUNC noncopyable(const noncopyable&);
  283|       |  EIGEN_DEVICE_FUNC const noncopyable& operator=(const noncopyable&);
  284|       |
  285|       | protected:
  286|      4|  EIGEN_DEVICE_FUNC noncopyable() {}
  287|      4|  EIGEN_DEVICE_FUNC ~noncopyable() {}
  288|       |};
  289|       |
  290|       |/** \internal
  291|       | * Provides access to the number of elements in the object of as a compile-time constant expression.
  292|       | * It "returns" Eigen::Dynamic if the size cannot be resolved at compile-time (default).
  293|       | *
  294|       | * Similar to std::tuple_size, but more general.
  295|       | *
  296|       | * It currently supports:
  297|       | *  - any types T defining T::SizeAtCompileTime
  298|       | *  - plain C arrays as T[N]
  299|       | *  - std::array (c++11)
  300|       | *  - some internal types such as SingleRange and AllRange
  301|       | *
  302|       | * The second template parameter eases SFINAE-based specializations.
  303|       | */
  304|       |template <typename T, typename EnableIf = void>
  305|       |struct array_size {
  306|       |  static constexpr Index value = Dynamic;
  307|       |};
  308|       |
  309|       |template <typename T>
  310|       |struct array_size<T, std::enable_if_t<((T::SizeAtCompileTime & 0) == 0)>> {
  311|       |  static constexpr Index value = T::SizeAtCompileTime;
  312|       |};
  313|       |
  314|       |template <typename T, int N>
  315|       |struct array_size<const T (&)[N]> {
  316|       |  static constexpr Index value = N;
  317|       |};
  318|       |template <typename T, int N>
  319|       |struct array_size<T (&)[N]> {
  320|       |  static constexpr Index value = N;
  321|       |};
  322|       |
  323|       |template <typename T, std::size_t N>
  324|       |struct array_size<const std::array<T, N>> {
  325|       |  static constexpr Index value = N;
  326|       |};
  327|       |template <typename T, std::size_t N>
  328|       |struct array_size<std::array<T, N>> {
  329|       |  static constexpr Index value = N;
  330|       |};
  331|       |
  332|       |/** \internal
  333|       | * Analogue of the std::ssize free function.
  334|       | * It returns the signed size of the container or view \a x of type \c T
  335|       | *
  336|       | * It currently supports:
  337|       | *  - any types T defining a member T::size() const
  338|       | *  - plain C arrays as T[N]
  339|       | *
  340|       | * For C++20, this function just forwards to `std::ssize`, or any ADL discoverable `ssize` function.
  341|       | */
  342|       |#if EIGEN_COMP_CXXVER < 20 || EIGEN_GNUC_STRICT_LESS_THAN(10, 0, 0)
  343|       |template <typename T>
  344|       |EIGEN_CONSTEXPR auto index_list_size(const T& x) {
  345|       |  using R = std::common_type_t<std::ptrdiff_t, std::make_signed_t<decltype(x.size())>>;
  346|       |  return static_cast<R>(x.size());
  347|       |}
  348|       |
  349|       |template <typename T, std::ptrdiff_t N>
  350|       |EIGEN_CONSTEXPR std::ptrdiff_t index_list_size(const T (&)[N]) {
  351|       |  return N;
  352|       |}
  353|       |#else
  354|       |template <typename T>
  355|       |EIGEN_CONSTEXPR auto index_list_size(T&& x) {
  356|       |  using std::ssize;
  357|       |  return ssize(std::forward<T>(x));
  358|       |}
  359|       |#endif  // EIGEN_COMP_CXXVER
  360|       |
  361|       |/** \internal
  362|       | * Convenient struct to get the result type of a nullary, unary, binary, or
  363|       | * ternary functor.
  364|       | *
  365|       | * Pre C++17:
  366|       | * This uses std::result_of. However, note the `type` member removes
  367|       | * const and converts references/pointers to their corresponding value type.
  368|       | *
  369|       | * Post C++17: Uses std::invoke_result
  370|       | */
  371|       |#if EIGEN_HAS_STD_INVOKE_RESULT
  372|       |template <typename T>
  373|       |struct result_of;
  374|       |
  375|       |template <typename F, typename... ArgTypes>
  376|       |struct result_of<F(ArgTypes...)> {
  377|       |  typedef typename std::invoke_result<F, ArgTypes...>::type type1;
  378|       |  typedef remove_all_t<type1> type;
  379|       |};
  380|       |
  381|       |template <typename F, typename... ArgTypes>
  382|       |struct invoke_result {
  383|       |  typedef typename std::invoke_result<F, ArgTypes...>::type type1;
  384|       |  typedef remove_all_t<type1> type;
  385|       |};
  386|       |#else
  387|       |template <typename T>
  388|       |struct result_of {
  389|       |  typedef typename std::result_of<T>::type type1;
  390|       |  typedef remove_all_t<type1> type;
  391|       |};
  392|       |
  393|       |template <typename F, typename... ArgTypes>
  394|       |struct invoke_result {
  395|       |  typedef typename result_of<F(ArgTypes...)>::type type1;
  396|       |  typedef remove_all_t<type1> type;
  397|       |};
  398|       |#endif
  399|       |
  400|       |// Reduces a sequence of bools to true if all are true, false otherwise.
  401|       |template <bool... values>
  402|       |using reduce_all =
  403|       |    std::is_same<std::integer_sequence<bool, values..., true>, std::integer_sequence<bool, true, values...>>;
  404|       |
  405|       |// Reduces a sequence of bools to true if any are true, false if all false.
  406|       |template <bool... values>
  407|       |using reduce_any = std::integral_constant<bool, !std::is_same<std::integer_sequence<bool, values..., false>,
  408|       |                                                              std::integer_sequence<bool, false, values...>>::value>;
  409|       |
  410|       |struct meta_yes {
  411|       |  char a[1];
  412|       |};
  413|       |struct meta_no {
  414|       |  char a[2];
  415|       |};
  416|       |
  417|       |// Check whether T::ReturnType does exist
  418|       |template <typename T>
  419|       |struct has_ReturnType {
  420|       |  template <typename C>
  421|       |  static meta_yes testFunctor(C const*, typename C::ReturnType const* = 0);
  422|       |  template <typename C>
  423|       |  static meta_no testFunctor(...);
  424|       |
  425|       |  enum { value = sizeof(testFunctor<T>(static_cast<T*>(0))) == sizeof(meta_yes) };
  426|       |};
  427|       |
  428|       |template <typename T>
  429|       |const T* return_ptr();
  430|       |
  431|       |template <typename T, typename IndexType = Index>
  432|       |struct has_nullary_operator {
  433|       |  template <typename C>
  434|       |  static meta_yes testFunctor(C const*, std::enable_if_t<(sizeof(return_ptr<C>()->operator()()) > 0)>* = 0);
  435|       |  static meta_no testFunctor(...);
  436|       |
  437|       |  enum { value = sizeof(testFunctor(static_cast<T*>(0))) == sizeof(meta_yes) };
  438|       |};
  439|       |
  440|       |template <typename T, typename IndexType = Index>
  441|       |struct has_unary_operator {
  442|       |  template <typename C>
  443|       |  static meta_yes testFunctor(C const*, std::enable_if_t<(sizeof(return_ptr<C>()->operator()(IndexType(0))) > 0)>* = 0);
  444|       |  static meta_no testFunctor(...);
  445|       |
  446|       |  enum { value = sizeof(testFunctor(static_cast<T*>(0))) == sizeof(meta_yes) };
  447|       |};
  448|       |
  449|       |template <typename T, typename IndexType = Index>
  450|       |struct has_binary_operator {
  451|       |  template <typename C>
  452|       |  static meta_yes testFunctor(
  453|       |      C const*, std::enable_if_t<(sizeof(return_ptr<C>()->operator()(IndexType(0), IndexType(0))) > 0)>* = 0);
  454|       |  static meta_no testFunctor(...);
  455|       |
  456|       |  enum { value = sizeof(testFunctor(static_cast<T*>(0))) == sizeof(meta_yes) };
  457|       |};
  458|       |
  459|       |/** \internal In short, it computes int(sqrt(\a Y)) with \a Y an integer.
  460|       | * Usage example: \code meta_sqrt<1023>::ret \endcode
  461|       | */
  462|       |template <int Y, int InfX = 0, int SupX = ((Y == 1) ? 1 : Y / 2),
  463|       |          bool Done = ((SupX - InfX) <= 1 || ((SupX * SupX <= Y) && ((SupX + 1) * (SupX + 1) > Y)))>
  464|       |class meta_sqrt {
  465|       |  enum {
  466|       |    MidX = (InfX + SupX) / 2,
  467|       |    TakeInf = MidX * MidX > Y ? 1 : 0,
  468|       |    NewInf = int(TakeInf) ? InfX : int(MidX),
  469|       |    NewSup = int(TakeInf) ? int(MidX) : SupX
  470|       |  };
  471|       |
  472|       | public:
  473|       |  enum { ret = meta_sqrt<Y, NewInf, NewSup>::ret };
  474|       |};
  475|       |
  476|       |template <int Y, int InfX, int SupX>
  477|       |class meta_sqrt<Y, InfX, SupX, true> {
  478|       | public:
  479|       |  enum { ret = (SupX * SupX <= Y) ? SupX : InfX };
  480|       |};
  481|       |
  482|       |/** \internal Computes the least common multiple of two positive integer A and B
  483|       | * at compile-time.
  484|       | */
  485|       |template <int A, int B, int K = 1, bool Done = ((A * K) % B) == 0, bool Big = (A >= B)>
  486|       |struct meta_least_common_multiple {
  487|       |  enum { ret = meta_least_common_multiple<A, B, K + 1>::ret };
  488|       |};
  489|       |template <int A, int B, int K, bool Done>
  490|       |struct meta_least_common_multiple<A, B, K, Done, false> {
  491|       |  enum { ret = meta_least_common_multiple<B, A, K>::ret };
  492|       |};
  493|       |template <int A, int B, int K>
  494|       |struct meta_least_common_multiple<A, B, K, true, true> {
  495|       |  enum { ret = A * K };
  496|       |};
  497|       |
  498|       |/** \internal determines whether the product of two numeric types is allowed and what the return type is */
  499|       |template <typename T, typename U>
  500|       |struct scalar_product_traits {
  501|       |  enum { Defined = 0 };
  502|       |};
  503|       |
  504|       |// FIXME quick workaround around current limitation of result_of
  505|       |// template<typename Scalar, typename ArgType0, typename ArgType1>
  506|       |// struct result_of<scalar_product_op<Scalar>(ArgType0,ArgType1)> {
  507|       |// typedef typename scalar_product_traits<remove_all_t<ArgType0>, remove_all_t<ArgType1>>::ReturnType type;
  508|       |// };
  509|       |
  510|       |/** \internal Obtains a POD type suitable to use as storage for an object of a size
  511|       | * of at most Len bytes, aligned as specified by \c Align.
  512|       | */
  513|       |template <unsigned Len, unsigned Align>
  514|       |struct aligned_storage {
  515|       |  struct type {
  516|       |    EIGEN_ALIGN_TO_BOUNDARY(Align) unsigned char data[Len];
  517|       |  };
  518|       |};
  519|       |
  520|       |}  // end namespace internal
  521|       |
  522|       |template <typename T>
  523|       |struct NumTraits;
  524|       |
  525|       |namespace numext {
  526|       |
  527|       |#if defined(EIGEN_GPU_COMPILE_PHASE)
  528|       |template <typename T>
  529|       |EIGEN_DEVICE_FUNC void swap(T& a, T& b) {
  530|       |  T tmp = b;
  531|       |  b = a;
  532|       |  a = tmp;
  533|       |}
  534|       |#else
  535|       |template <typename T>
  536|       |EIGEN_STRONG_INLINE void swap(T& a, T& b) {
  537|       |  std::swap(a, b);
  538|       |}
  539|       |#endif
  540|       |
  541|       |using std::numeric_limits;
  542|       |
  543|       |// Handle integer comparisons of different signedness.
  544|       |template <typename X, typename Y, bool XIsInteger = NumTraits<X>::IsInteger, bool XIsSigned = NumTraits<X>::IsSigned,
  545|       |          bool YIsInteger = NumTraits<Y>::IsInteger, bool YIsSigned = NumTraits<Y>::IsSigned>
  546|       |struct equal_strict_impl {
  547|      0|  static EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool run(const X& x, const Y& y) { return x == y; }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implI14AnnoyingScalarS2_Lb0ELb1ELb0ELb1EE3runERKS2_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implIssLb1ELb1ELb1ELb1EE3runERKsS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implIttLb1ELb0ELb1ELb0EE3runERKtS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implIiiLb1ELb1ELb1ELb1EE3runERKiS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implIjjLb1ELb0ELb1ELb0EE3runERKjS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implIllLb1ELb1ELb1ELb1EE3runERKlS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implImmLb1ELb0ELb1ELb0EE3runERKmS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implIxxLb1ELb1ELb1ELb1EE3runERKxS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implIyyLb1ELb0ELb1ELb0EE3runERKyS4_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implINS_4halfES2_Lb0ELb1ELb0ELb1EE3runERKS2_S5_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext17equal_strict_implINS_8bfloat16ES2_Lb0ELb1ELb0ELb1EE3runERKS2_S5_
  ------------------
  548|       |};
  549|       |template <typename X, typename Y>
  550|       |struct equal_strict_impl<X, Y, true, false, true, true> {
  551|       |  // X is an unsigned integer
  552|       |  // Y is a signed integer
  553|       |  // if Y is non-negative, it may be represented exactly as its unsigned counterpart.
  554|       |  using UnsignedY = typename internal::make_unsigned<Y>::type;
  555|       |  static EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool run(const X& x, const Y& y) {
  556|       |    return y < Y(0) ? false : (x == static_cast<UnsignedY>(y));
  557|       |  }
  558|       |};
  559|       |template <typename X, typename Y>
  560|       |struct equal_strict_impl<X, Y, true, true, true, false> {
  561|       |  // X is a signed integer
  562|       |  // Y is an unsigned integer
  563|       |  static EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool run(const X& x, const Y& y) {
  564|       |    return equal_strict_impl<Y, X>::run(y, x);
  565|       |  }
  566|       |};
  567|       |
  568|       |// The aim of the following functions is to bypass -Wfloat-equal warnings
  569|       |// when we really want a strict equality comparison on floating points.
  570|       |template <typename X, typename Y>
  571|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool equal_strict(const X& x, const Y& y) {
  572|      0|  return equal_strict_impl<X, Y>::run(x, y);
  573|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictI14AnnoyingScalarS2_EEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictIssEEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictIttEEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictIiiEEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictIjjEEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictIllEEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictImmEEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictIxxEEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictIyyEEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictINS_4halfES2_EEbRKT_RKT0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen6numext12equal_strictINS_8bfloat16ES2_EEbRKT_RKT0_
  ------------------
  574|       |
  575|       |#if !defined(EIGEN_GPU_COMPILE_PHASE) || (!defined(EIGEN_CUDA_ARCH) && defined(EIGEN_CONSTEXPR_ARE_DEVICE_FUNC))
  576|       |template <>
  577|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool equal_strict(const float& x, const float& y) {
  578|      0|  return std::equal_to<float>()(x, y);
  579|      0|}
  580|       |
  581|       |template <>
  582|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool equal_strict(const double& x, const double& y) {
  583|      0|  return std::equal_to<double>()(x, y);
  584|      0|}
  585|       |#endif
  586|       |
  587|       |/**
  588|       | * \internal Performs an exact comparison of x to zero, e.g. to decide whether a term can be ignored.
  589|       | * Use this to to bypass -Wfloat-equal warnings when exact zero is what needs to be tested.
  590|       | */
  591|       |template <typename X>
  592|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool is_exactly_zero(const X& x) {
  593|      0|  return equal_strict(x, typename NumTraits<X>::Literal{0});
  594|      0|}
  595|       |
  596|       |/**
  597|       | * \internal Performs an exact comparison of x to one, e.g. to decide whether a factor needs to be multiplied.
  598|       | * Use this to to bypass -Wfloat-equal warnings when exact one is what needs to be tested.
  599|       | */
  600|       |template <typename X>
  601|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool is_exactly_one(const X& x) {
  602|      0|  return equal_strict(x, typename NumTraits<X>::Literal{1});
  603|      0|}
  604|       |
  605|       |template <typename X, typename Y>
  606|       |EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool not_equal_strict(const X& x, const Y& y) {
  607|       |  return !equal_strict_impl<X, Y>::run(x, y);
  608|       |}
  609|       |
  610|       |#if !defined(EIGEN_GPU_COMPILE_PHASE) || (!defined(EIGEN_CUDA_ARCH) && defined(EIGEN_CONSTEXPR_ARE_DEVICE_FUNC))
  611|       |template <>
  612|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool not_equal_strict(const float& x, const float& y) {
  613|      0|  return std::not_equal_to<float>()(x, y);
  614|      0|}
  615|       |
  616|       |template <>
  617|      0|EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool not_equal_strict(const double& x, const double& y) {
  618|      0|  return std::not_equal_to<double>()(x, y);
  619|      0|}
  620|       |#endif
  621|       |
  622|       |}  // end namespace numext
  623|       |
  624|       |namespace internal {
  625|       |
  626|       |template <typename Scalar>
  627|       |struct is_identically_zero_impl {
  628|       |  static inline bool run(const Scalar& s) { return numext::is_exactly_zero(s); }
  629|       |};
  630|       |
  631|       |template <typename Scalar>
  632|       |EIGEN_STRONG_INLINE bool is_identically_zero(const Scalar& s) {
  633|       |  return is_identically_zero_impl<Scalar>::run(s);
  634|       |}
  635|       |
  636|       |/// \internal Returns true if its argument is of integer or enum type.
  637|       |/// FIXME this has the same purpose as `is_valid_index_type` in XprHelper.h
  638|       |template <typename A>
  639|       |constexpr bool is_int_or_enum_v = std::is_enum<A>::value || std::is_integral<A>::value;
  640|       |
  641|       |template <typename A, typename B>
  642|      0|inline constexpr void plain_enum_asserts(A, B) {
  643|      0|  static_assert(is_int_or_enum_v<A>, "Argument a must be an integer or enum");
  644|      0|  static_assert(is_int_or_enum_v<B>, "Argument b must be an integer or enum");
  645|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsIiNS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsIiNS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsIiNS0_9evaluatorINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsIiNS0_9evaluatorINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsIiNS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsIiiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEUt_ES7_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt_ES7_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_6traitsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt0_ES7_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ES9_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_6traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_INS4_IS5_Lin1ELi1ELi0ELin1ELi1EEEEUt0_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEENS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELi0EEEEUt_ESB_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_6traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_IS6_EUt0_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEES6_Li0EEEEUt_ESA_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS5_EEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEES9_EEEUt_ESC_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEEUt_ESB_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_ENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EE17CompileTimeTraitsEiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEEEUt_ESC_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEUt_ESA_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_EiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_EiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EE17CompileTimeTraitsENS2_IKNS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EE17CompileTimeTraitsEEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li1EEEEUt_ES9_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EE17CompileTimeTraitsES5_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ENS0_17product_evaluatorINS_7ProductIS6_S6_Li1EEELi8ENS_10DenseShapeESD_S5_S5_EUt0_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EE17CompileTimeTraitsEiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_ESA_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEUt_ESD_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ESA_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS5_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS5_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS8_ISB_Lin1ELi1ELb1EEEEEEUt_ESK_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_15unary_evaluatorINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEENS0_10IndexBasedES6_EUt_ENS0_9evaluatorINS4_IS8_Lin1ELi1ELb1EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS5_Lin1ELin1ELi0ELin1ELin1EEEEEEUt_ESB_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ES9_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_6traitsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt0_ENS2_INS_5BlockIKS5_Lin1ELi1ELb1EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEKNS_5BlockIKS6_Lin1ELi1ELb1EEELi0EEEEUt_ESD_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_ES9_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_6traitsINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_ENS2_IS6_EUt0_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEES7_Li0EEEEUt_ESD_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEEUt_ESC_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_EiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EE17CompileTimeTraitsENS2_IKNS2_IS6_Lin1ELi1ELb1EEELin1ELi1ELb1EE17CompileTimeTraitsEEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_13AlignmentTypeENS0_13packet_traitsI14AnnoyingScalarEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_ESB_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_14CwiseNullaryOpINS0_18scalar_constant_opI14AnnoyingScalarEEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEEUt_ESC_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISB_Li1ENS_6StrideILi0ELi0EEEEEEEEUt_ESM_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_ENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEE17CompileTimeTraitsEiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_ENS2_INS_5BlockINS4_IS5_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsIiNS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_14CwiseNullaryOpINS0_18scalar_constant_opI14AnnoyingScalarEEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEEUt_ENS2_INS_3MapIS8_Li1ENS_6StrideILi0ELi0EEEEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ENS0_16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opIS5_S5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKNS4_IS5_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISH_Li1ENS_6StrideILi0ELi0EEEEEEENS0_10IndexBasedESR_S5_S5_EUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EE17CompileTimeTraitsEiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ENS2_INS_3MapINS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEUt_ESC_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_EiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EE17CompileTimeTraitsENS2_IS6_Lin1ELi1ELb1EE17CompileTimeTraitsEEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEUt_ESB_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ESA_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEUt_ESB_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockINS_9TransposeINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1EEEEUt_ESC_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEUt_ENS0_15unary_evaluatorINS_9TransposeIKNS_5BlockIKNS4_IS5_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEENS0_10IndexBasedES5_EUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEE17CompileTimeTraitsEiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsIimEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_ENS2_INS_15PlainObjectBaseIS6_EEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_ENS0_16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opIS5_S5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKS6_EEKNS_3MapIS6_Li1ENS_6StrideILi0ELi0EEEEEEENS0_10IndexBasedESQ_S5_S5_EUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_ENS2_INS_3MapIS6_Li1ENS_6StrideILi0ELi0EEEEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_ES9_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_IS6_EUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEES6_Li1EEEEUt_ESA_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ENS0_17product_evaluatorINS_7ProductINSB_IS6_S6_Li0EEES6_Li1EEELi8ENS_10DenseShapeESE_S5_S5_EUt0_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_6traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_INS_5BlockIKS6_Lin1ELi1ELb1EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEKNS_5BlockIKS6_Lin1ELi1ELb1EEELi0EEEEUt_ESE_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_6traitsINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEEEUt_ENS2_IS7_EUt0_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_7ProductIKNS_5BlockIKNS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEES7_Li0EEEEUt_ESE_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EE17CompileTimeTraitsENS2_IKNS2_IKS6_Lin1ELi1ELb1EEELin1ELi1ELb1EE17CompileTimeTraitsEEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_5BlockIKNS3_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEUt_ESE_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEUt_ES7_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEEEUt_EiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_5BlockIKNS2_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EE17CompileTimeTraitsENS2_IKS6_Lin1ELi1ELb1EE17CompileTimeTraitsEEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEEUt_ENS2_INS_5BlockIKNS_7ProductINS4_IS5_Lin1ELin1ELi0ELin1ELin1EEESC_Li0EEELi1ELin1ELb0EEEEUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EE17CompileTimeTraitsEiEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_9DenseBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEEUt_ESA_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEUt_ENS0_15unary_evaluatorINS_9TransposeIKNS4_IS5_Li1ELin1ELi1ELi1ELin1EEEEENS0_10IndexBasedES5_EUt_EEEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ES9_EEvT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal18plain_enum_assertsINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_E17CompileTimeTraitsESA_EEvT_T0_
  ------------------
  646|       |
  647|       |/// \internal Gets the minimum of two values which may be integers or enums
  648|       |template <typename A, typename B>
  649|      0|inline constexpr int plain_enum_min(A a, B b) {
  650|      0|  plain_enum_asserts(a, b);
  651|      0|  return ((int)a <= (int)b) ? (int)a : (int)b;
  652|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minIiiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_6traitsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt0_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_6traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_INS4_IS5_Lin1ELi1ELi0ELin1ELi1EEEEUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_6traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_IS6_EUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_ENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_EiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_EiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EE17CompileTimeTraitsENS2_IKNS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EE17CompileTimeTraitsES5_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ENS0_17product_evaluatorINS_7ProductIS6_S6_Li1EEELi8ENS_10DenseShapeESD_S5_S5_EUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_15unary_evaluatorINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEENS0_10IndexBasedES6_EUt_ENS0_9evaluatorINS4_IS8_Lin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_6traitsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt0_ENS2_INS_5BlockIKS5_Lin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_6traitsINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_ENS2_IS6_EUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_EiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EE17CompileTimeTraitsENS2_IKNS2_IS6_Lin1ELi1ELb1EEELin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_13AlignmentTypeENS0_13packet_traitsI14AnnoyingScalarEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_ENS2_INS_14CwiseNullaryOpINS0_14scalar_zero_opIS5_EES6_EEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_ENS2_INS_5BlockINS4_IS5_Lin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_14CwiseNullaryOpINS0_18scalar_constant_opI14AnnoyingScalarEEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEEUt_ENS2_INS_3MapIS8_Li1ENS_6StrideILi0ELi0EEEEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ENS0_16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opIS5_S5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKNS4_IS5_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISH_Li1ENS_6StrideILi0ELi0EEEEEEENS0_10IndexBasedESR_S5_S5_EUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ENS2_INS_3MapINS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_EiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EE17CompileTimeTraitsENS2_IS6_Lin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEUt_ENS0_15unary_evaluatorINS_9TransposeIKNS_5BlockIKNS4_IS5_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEENS0_10IndexBasedES5_EUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minIimEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_ENS2_INS_15PlainObjectBaseIS6_EEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_ENS0_16binary_evaluatorINS_13CwiseBinaryOpINS0_17scalar_product_opIS5_S5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKS6_EEKNS_3MapIS6_Li1ENS_6StrideILi0ELi0EEEEEEENS0_10IndexBasedESQ_S5_S5_EUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_ENS2_INS_3MapIS6_Li1ENS_6StrideILi0ELi0EEEEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_IS6_EUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ENS0_17product_evaluatorINS_7ProductINSB_IS6_S6_Li0EEES6_Li1EEELi8ENS_10DenseShapeESE_S5_S5_EUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_6traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_INS_5BlockIKS6_Lin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_6traitsINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEEEUt_ENS2_IS7_EUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EE17CompileTimeTraitsENS2_IKNS2_IKS6_Lin1ELi1ELb1EEELin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEEEUt_EiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_5BlockIKNS2_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EE17CompileTimeTraitsENS2_IKS6_Lin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEEUt_ENS2_INS_5BlockIKNS_7ProductINS4_IS5_Lin1ELin1ELi0ELin1ELin1EEESC_Li0EEELi1ELin1ELb0EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEUt_ENS0_15unary_evaluatorINS_9TransposeIKNS4_IS5_Li1ELin1ELi1ELi1ELin1EEEEENS0_10IndexBasedES5_EUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS0_9evaluatorINS_15PlainObjectBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_minINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_E17CompileTimeTraitsESA_EEiT_T0_
  ------------------
  653|       |
  654|       |/// \internal Gets the maximum of two values which may be integers or enums
  655|       |template <typename A, typename B>
  656|      0|inline constexpr int plain_enum_max(A a, B b) {
  657|      0|  plain_enum_asserts(a, b);
  658|      0|  return ((int)a >= (int)b) ? (int)a : (int)b;
  659|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxIiNS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxIiNS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxIiNS0_9evaluatorINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxIiNS0_9evaluatorINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxIiNS0_9evaluatorINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxIiiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEUt_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEENS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELi0EEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEES6_Li0EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS5_EEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEES9_EEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li1EEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEUt_ESD_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS5_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS5_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS8_ISB_Lin1ELi1ELb1EEEEEEUt_ESK_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS5_Lin1ELin1ELi0ELin1ELin1EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEKNS_5BlockIKS6_Lin1ELi1ELb1EEELi0EEEEUt_ESD_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_7ProductIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEES7_Li0EEEEUt_ESD_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_14CwiseNullaryOpINS0_18scalar_constant_opI14AnnoyingScalarEEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISB_Li1ENS_6StrideILi0ELi0EEEEEEEEUt_ESM_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxIiNS0_9evaluatorINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockINS_9TransposeINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1EEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEES6_Li1EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEKNS_5BlockIKS6_Lin1ELi1ELb1EEELi0EEEEUt_ESE_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_7ProductIKNS_5BlockIKNS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEES7_Li0EEEEUt_ESE_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_5BlockIKNS3_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEUt_ESE_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEUt_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal14plain_enum_maxINS_9DenseBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEEUt_ESA_EEiT_T0_
  ------------------
  660|       |
  661|       |/**
  662|       | * \internal
  663|       | *  `min_size_prefer_dynamic` gives the min between compile-time sizes. 0 has absolute priority, followed by 1,
  664|       | *  followed by Dynamic, followed by other finite values. The reason for giving Dynamic the priority over
  665|       | *  finite values is that min(3, Dynamic) should be Dynamic, since that could be anything between 0 and 3.
  666|       | */
  667|       |template <typename A, typename B>
  668|       |inline constexpr int min_size_prefer_dynamic(A a, B b) {
  669|       |  plain_enum_asserts(a, b);
  670|       |  if ((int)a == 0 || (int)b == 0) return 0;
  671|       |  if ((int)a == 1 || (int)b == 1) return 1;
  672|       |  if ((int)a == Dynamic || (int)b == Dynamic) return Dynamic;
  673|       |  return plain_enum_min(a, b);
  674|       |}
  675|       |
  676|       |/**
  677|       | * \internal
  678|       | *  min_size_prefer_fixed is a variant of `min_size_prefer_dynamic` comparing MaxSizes. The difference is that finite
  679|       | * values now have priority over Dynamic, so that min(3, Dynamic) gives 3. Indeed, whatever the actual value is (between
  680|       | * 0 and 3), it is not more than 3.
  681|       | */
  682|       |template <typename A, typename B>
  683|      0|inline constexpr int min_size_prefer_fixed(A a, B b) {
  684|      0|  plain_enum_asserts(a, b);
  685|      0|  if ((int)a == 0 || (int)b == 0) return 0;
  686|      0|  if ((int)a == 1 || (int)b == 1) return 1;
  687|      0|  if ((int)a == Dynamic && (int)b == Dynamic) return Dynamic;
  688|      0|  if ((int)a == Dynamic) return (int)b;
  689|      0|  if ((int)b == Dynamic) return (int)a;
  690|      0|  return plain_enum_min(a, b);
  691|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedIiiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS0_6traitsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt0_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS0_6traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_INS4_IS5_Lin1ELi1ELi0ELin1ELi1EEEEUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS0_6traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_IS6_EUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EE17CompileTimeTraitsENS2_IKNS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EE17CompileTimeTraitsES5_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS0_6traitsINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt0_ENS2_INS_5BlockIKS5_Lin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS0_6traitsINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_ENS2_IS6_EUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EE17CompileTimeTraitsENS2_IKNS2_IS6_Lin1ELi1ELb1EEELin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_5BlockIKNS2_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EE17CompileTimeTraitsENS2_IS6_Lin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_IS6_EUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS0_6traitsINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ENS2_INS_5BlockIKS6_Lin1ELi1ELb1EEEEUt_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS0_6traitsINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEEEUt_ENS2_IS7_EUt0_EEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EE17CompileTimeTraitsENS2_IKNS2_IKS6_Lin1ELi1ELb1EEELin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_5BlockIKNS2_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EE17CompileTimeTraitsENS2_IKS6_Lin1ELi1ELb1EE17CompileTimeTraitsEEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EE17CompileTimeTraitsEiEEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal21min_size_prefer_fixedINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS4_EEKNS_6MatrixIS4_Lin1ELi1ELi0ELin1ELi1EEES8_E17CompileTimeTraitsESA_EEiT_T0_
  ------------------
  692|       |
  693|       |/// \internal see `min_size_prefer_fixed`. No need for a separate variant for MaxSizes here.
  694|       |template <typename A, typename B>
  695|      0|inline constexpr int max_size_prefer_dynamic(A a, B b) {
  696|      0|  plain_enum_asserts(a, b);
  697|      0|  if ((int)a == Dynamic || (int)b == Dynamic) return Dynamic;
  698|      0|  return plain_enum_max(a, b);
  699|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEEUt_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEUt_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEENS4_IS5_Lin1ELi1ELi0ELin1ELi1EEELi0EEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEES6_Li0EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_13CwiseBinaryOpINS0_13scalar_sum_opI14AnnoyingScalarS5_EEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEES9_EEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELin1ELi1ELb1EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li1EEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_9TransposeIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEUt_ESD_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS5_EEKNS_9TransposeIKNS_5BlockIKNS_6MatrixIS5_Lin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEKNS8_ISB_Lin1ELi1ELb1EEEEEEUt_ESK_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_14CwiseNullaryOpINS0_14scalar_zero_opI14AnnoyingScalarEENS_6MatrixIS5_Lin1ELin1ELi0ELin1ELin1EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEKNS_5BlockIKS6_Lin1ELi1ELb1EEELi0EEEEUt_ESD_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEUt_ES9_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_7ProductIKNS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEES7_Li0EEEEUt_ESD_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEELin1ELi1ELb1EEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi1ENS_6StrideILi0ELi0EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_14CwiseNullaryOpINS0_18scalar_constant_opI14AnnoyingScalarEEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_13CwiseBinaryOpINS0_17scalar_product_opI14AnnoyingScalarS5_EEKNS_14CwiseNullaryOpINS0_18scalar_constant_opIS5_EEKNS_6MatrixIS5_Lin1ELi1ELi0ELin1ELi1EEEEEKNS_3MapISB_Li1ENS_6StrideILi0ELi0EEEEEEEEUt_ESM_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockIKNS3_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_3MapINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEUt_ESB_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockINS_9TransposeINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEELin1ELi1ELb1EEEEUt_ESC_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEES6_Li1EEEEUt_ESA_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_7ProductINS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES6_Li0EEEKNS_5BlockIKS6_Lin1ELi1ELb1EEELi0EEEEUt_ESE_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_7ProductIKNS_5BlockIKNS3_INS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEES7_Li0EEEEUt_ESE_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_5BlockIKNS3_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES7_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEEUt_ESE_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEUt_ES7_EEiT_T0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal23max_size_prefer_dynamicINS_9DenseBaseINS_9TransposeIKNS_6MatrixI14AnnoyingScalarLi1ELin1ELi1ELi1ELin1EEEEEEUt_ESA_EEiT_T0_
  ------------------
  700|       |
  701|       |template <typename A, typename B>
  702|       |inline constexpr bool enum_eq_not_dynamic(A a, B b) {
  703|       |  plain_enum_asserts(a, b);
  704|       |  if ((int)a == Dynamic || (int)b == Dynamic) return false;
  705|       |  return (int)a == (int)b;
  706|       |}
  707|       |
  708|       |template <typename A, typename B>
  709|       |inline constexpr bool enum_lt_not_dynamic(A a, B b) {
  710|       |  plain_enum_asserts(a, b);
  711|       |  if ((int)a == Dynamic || (int)b == Dynamic) return false;
  712|       |  return (int)a < (int)b;
  713|       |}
  714|       |
  715|       |template <typename A, typename B>
  716|       |inline constexpr bool enum_le_not_dynamic(A a, B b) {
  717|       |  plain_enum_asserts(a, b);
  718|       |  if ((int)a == Dynamic || (int)b == Dynamic) return false;
  719|       |  return (int)a <= (int)b;
  720|       |}
  721|       |
  722|       |template <typename A, typename B>
  723|       |inline constexpr bool enum_gt_not_dynamic(A a, B b) {
  724|       |  plain_enum_asserts(a, b);
  725|       |  if ((int)a == Dynamic || (int)b == Dynamic) return false;
  726|       |  return (int)a > (int)b;
  727|       |}
  728|       |
  729|       |template <typename A, typename B>
  730|       |inline constexpr bool enum_ge_not_dynamic(A a, B b) {
  731|       |  plain_enum_asserts(a, b);
  732|       |  if ((int)a == Dynamic || (int)b == Dynamic) return false;
  733|       |  return (int)a >= (int)b;
  734|       |}
  735|       |
  736|       |/// \internal Calculate logical XOR at compile time
  737|      0|inline constexpr bool logical_xor(bool a, bool b) { return a != b; }
  738|       |
  739|       |/// \internal Calculate logical IMPLIES at compile time
  740|     28|inline constexpr bool check_implication(bool a, bool b) { return !a || b; }
  741|       |
  742|       |/// \internal Provide fallback for std::is_constant_evaluated for pre-C++20.
  743|       |#if EIGEN_COMP_CXXVER >= 20
  744|       |using std::is_constant_evaluated;
  745|       |#else
  746|      0|constexpr bool is_constant_evaluated() { return false; }
  747|       |#endif
  748|       |
  749|       |}  // end namespace internal
  750|       |
  751|       |}  // end namespace Eigen
  752|       |
  753|       |#endif  // EIGEN_META_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/ReshapedHelper.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2017 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_RESHAPED_HELPER_H
   11|       |#define EIGEN_RESHAPED_HELPER_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |enum AutoSize_t { AutoSize };
   19|       |const int AutoOrder = 2;
   20|       |
   21|       |namespace internal {
   22|       |
   23|       |template <typename SizeType, typename OtherSize, int TotalSize>
   24|       |struct get_compiletime_reshape_size {
   25|       |  enum { value = get_fixed_value<SizeType>::value };
   26|       |};
   27|       |
   28|       |template <typename SizeType>
   29|       |Index get_runtime_reshape_size(SizeType size, Index /*other*/, Index /*total*/) {
   30|       |  return internal::get_runtime_value(size);
   31|       |}
   32|       |
   33|       |template <typename OtherSize, int TotalSize>
   34|       |struct get_compiletime_reshape_size<AutoSize_t, OtherSize, TotalSize> {
   35|       |  enum {
   36|       |    other_size = get_fixed_value<OtherSize>::value,
   37|       |    value = (TotalSize == Dynamic || other_size == Dynamic) ? Dynamic : TotalSize / other_size
   38|       |  };
   39|       |};
   40|       |
   41|      0|inline Index get_runtime_reshape_size(AutoSize_t /*size*/, Index other, Index total) { return total / other; }
   42|       |
   43|      0|constexpr inline int get_compiletime_reshape_order(int flags, int order) {
   44|      0|  return order == AutoOrder ? flags & RowMajorBit : order;
   45|      0|}
   46|       |
   47|       |}  // namespace internal
   48|       |
   49|       |}  // end namespace Eigen
   50|       |
   51|       |#endif  // EIGEN_RESHAPED_HELPER_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/Serializer.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2021 The Eigen Team
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_SERIALIZER_H
   11|       |#define EIGEN_SERIALIZER_H
   12|       |
   13|       |#include <type_traits>
   14|       |
   15|       |// The Serializer class encodes data into a memory buffer so it can be later
   16|       |// reconstructed. This is mainly used to send objects back-and-forth between
   17|       |// the CPU and GPU.
   18|       |
   19|       |namespace Eigen {
   20|       |
   21|       |/**
   22|       | * Serializes an object to a memory buffer.
   23|       | *
   24|       | * Useful for transferring data (e.g. back-and-forth to a device).
   25|       | */
   26|       |template <typename T, typename EnableIf = void>
   27|       |class Serializer;
   28|       |
   29|       |// Specialization for POD types.
   30|       |template <typename T>
   31|       |class Serializer<T, typename std::enable_if_t<std::is_trivial<T>::value && std::is_standard_layout<T>::value>> {
   32|       | public:
   33|       |  /**
   34|       |   * Determines the required size of the serialization buffer for a value.
   35|       |   *
   36|       |   * \param value the value to serialize.
   37|       |   * \return the required size.
   38|       |   */
   39|       |  EIGEN_DEVICE_FUNC size_t size(const T& value) const { return sizeof(value); }
   40|       |
   41|       |  /**
   42|       |   * Serializes a value to a byte buffer.
   43|       |   * \param dest the destination buffer; if this is nullptr, does nothing.
   44|       |   * \param end the end of the destination buffer.
   45|       |   * \param value the value to serialize.
   46|       |   * \return the next memory address past the end of the serialized data.
   47|       |   */
   48|       |  EIGEN_DEVICE_FUNC uint8_t* serialize(uint8_t* dest, uint8_t* end, const T& value) {
   49|       |    if (EIGEN_PREDICT_FALSE(dest == nullptr)) return nullptr;
   50|       |    if (EIGEN_PREDICT_FALSE(dest + sizeof(value) > end)) return nullptr;
   51|       |    EIGEN_USING_STD(memcpy)
   52|       |    memcpy(dest, &value, sizeof(value));
   53|       |    return dest + sizeof(value);
   54|       |  }
   55|       |
   56|       |  /**
   57|       |   * Deserializes a value from a byte buffer.
   58|       |   * \param src the source buffer; if this is nullptr, does nothing.
   59|       |   * \param end the end of the source buffer.
   60|       |   * \param value the value to populate.
   61|       |   * \return the next unprocessed memory address; nullptr if parsing errors are detected.
   62|       |   */
   63|       |  EIGEN_DEVICE_FUNC const uint8_t* deserialize(const uint8_t* src, const uint8_t* end, T& value) const {
   64|       |    if (EIGEN_PREDICT_FALSE(src == nullptr)) return nullptr;
   65|       |    if (EIGEN_PREDICT_FALSE(src + sizeof(value) > end)) return nullptr;
   66|       |    EIGEN_USING_STD(memcpy)
   67|       |    memcpy(&value, src, sizeof(value));
   68|       |    return src + sizeof(value);
   69|       |  }
   70|       |};
   71|       |
   72|       |// Specialization for DenseBase.
   73|       |// Serializes [rows, cols, data...].
   74|       |template <typename Derived>
   75|       |class Serializer<DenseBase<Derived>, void> {
   76|       | public:
   77|       |  typedef typename Derived::Scalar Scalar;
   78|       |
   79|       |  struct Header {
   80|       |    typename Derived::Index rows;
   81|       |    typename Derived::Index cols;
   82|       |  };
   83|       |
   84|       |  EIGEN_DEVICE_FUNC size_t size(const Derived& value) const { return sizeof(Header) + sizeof(Scalar) * value.size(); }
   85|       |
   86|       |  EIGEN_DEVICE_FUNC uint8_t* serialize(uint8_t* dest, uint8_t* end, const Derived& value) {
   87|       |    if (EIGEN_PREDICT_FALSE(dest == nullptr)) return nullptr;
   88|       |    if (EIGEN_PREDICT_FALSE(dest + size(value) > end)) return nullptr;
   89|       |    const size_t header_bytes = sizeof(Header);
   90|       |    const size_t data_bytes = sizeof(Scalar) * value.size();
   91|       |    Header header = {value.rows(), value.cols()};
   92|       |    EIGEN_USING_STD(memcpy)
   93|       |    memcpy(dest, &header, header_bytes);
   94|       |    dest += header_bytes;
   95|       |    memcpy(dest, value.data(), data_bytes);
   96|       |    return dest + data_bytes;
   97|       |  }
   98|       |
   99|       |  EIGEN_DEVICE_FUNC const uint8_t* deserialize(const uint8_t* src, const uint8_t* end, Derived& value) const {
  100|       |    if (EIGEN_PREDICT_FALSE(src == nullptr)) return nullptr;
  101|       |    if (EIGEN_PREDICT_FALSE(src + sizeof(Header) > end)) return nullptr;
  102|       |    const size_t header_bytes = sizeof(Header);
  103|       |    Header header;
  104|       |    EIGEN_USING_STD(memcpy)
  105|       |    memcpy(&header, src, header_bytes);
  106|       |    src += header_bytes;
  107|       |    const size_t data_bytes = sizeof(Scalar) * header.rows * header.cols;
  108|       |    if (EIGEN_PREDICT_FALSE(src + data_bytes > end)) return nullptr;
  109|       |    value.resize(header.rows, header.cols);
  110|       |    memcpy(value.data(), src, data_bytes);
  111|       |    return src + data_bytes;
  112|       |  }
  113|       |};
  114|       |
  115|       |template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  116|       |class Serializer<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>
  117|       |    : public Serializer<DenseBase<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>> {};
  118|       |
  119|       |template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  120|       |class Serializer<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>
  121|       |    : public Serializer<DenseBase<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>>> {};
  122|       |
  123|       |namespace internal {
  124|       |
  125|       |// Recursive serialization implementation helper.
  126|       |template <size_t N, typename... Types>
  127|       |struct serialize_impl;
  128|       |
  129|       |template <size_t N, typename T1, typename... Ts>
  130|       |struct serialize_impl<N, T1, Ts...> {
  131|       |  using Serializer = Eigen::Serializer<typename std::decay<T1>::type>;
  132|       |
  133|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE size_t serialize_size(const T1& value, const Ts&... args) {
  134|       |    Serializer serializer;
  135|       |    size_t size = serializer.size(value);
  136|       |    return size + serialize_impl<N - 1, Ts...>::serialize_size(args...);
  137|       |  }
  138|       |
  139|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE uint8_t* serialize(uint8_t* dest, uint8_t* end, const T1& value,
  140|       |                                                                  const Ts&... args) {
  141|       |    Serializer serializer;
  142|       |    dest = serializer.serialize(dest, end, value);
  143|       |    return serialize_impl<N - 1, Ts...>::serialize(dest, end, args...);
  144|       |  }
  145|       |
  146|       |  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const uint8_t* deserialize(const uint8_t* src, const uint8_t* end,
  147|       |                                                                          T1& value, Ts&... args) {
  148|       |    Serializer serializer;
  149|       |    src = serializer.deserialize(src, end, value);
  150|       |    return serialize_impl<N - 1, Ts...>::deserialize(src, end, args...);
  151|       |  }
  152|       |};
  153|       |
  154|       |// Base case.
  155|       |template <>
  156|       |struct serialize_impl<0> {
  157|      0|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE size_t serialize_size() { return 0; }
  158|       |
  159|      0|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE uint8_t* serialize(uint8_t* dest, uint8_t* /*end*/) { return dest; }
  160|       |
  161|      0|  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const uint8_t* deserialize(const uint8_t* src, const uint8_t* /*end*/) {
  162|      0|    return src;
  163|      0|  }
  164|       |};
  165|       |
  166|       |}  // namespace internal
  167|       |
  168|       |/**
  169|       | * Determine the buffer size required to serialize a set of values.
  170|       | *
  171|       | * \param args ... arguments to serialize in sequence.
  172|       | * \return the total size of the required buffer.
  173|       | */
  174|       |template <typename... Args>
  175|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE size_t serialize_size(const Args&... args) {
  176|       |  return internal::serialize_impl<sizeof...(args), Args...>::serialize_size(args...);
  177|       |}
  178|       |
  179|       |/**
  180|       | * Serialize a set of values to the byte buffer.
  181|       | *
  182|       | * \param dest output byte buffer; if this is nullptr, does nothing.
  183|       | * \param end the end of the output byte buffer.
  184|       | * \param args ... arguments to serialize in sequence.
  185|       | * \return the next address after all serialized values.
  186|       | */
  187|       |template <typename... Args>
  188|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE uint8_t* serialize(uint8_t* dest, uint8_t* end, const Args&... args) {
  189|       |  return internal::serialize_impl<sizeof...(args), Args...>::serialize(dest, end, args...);
  190|       |}
  191|       |
  192|       |/**
  193|       | * Deserialize a set of values from the byte buffer.
  194|       | *
  195|       | * \param src input byte buffer; if this is nullptr, does nothing.
  196|       | * \param end the end of input byte buffer.
  197|       | * \param args ... arguments to deserialize in sequence.
  198|       | * \return the next address after all parsed values; nullptr if parsing errors are detected.
  199|       | */
  200|       |template <typename... Args>
  201|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const uint8_t* deserialize(const uint8_t* src, const uint8_t* end,
  202|       |                                                                 Args&... args) {
  203|       |  return internal::serialize_impl<sizeof...(args), Args...>::deserialize(src, end, args...);
  204|       |}
  205|       |
  206|       |}  // namespace Eigen
  207|       |
  208|       |#endif  // EIGEN_SERIALIZER_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/StaticAssert.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_STATIC_ASSERT_H
   12|       |#define EIGEN_STATIC_ASSERT_H
   13|       |
   14|       |/* Some notes on Eigen's static assertion mechanism:
   15|       | *
   16|       | *  - in EIGEN_STATIC_ASSERT(CONDITION,MSG) the parameter CONDITION must be a compile time boolean
   17|       | *    expression, and MSG an enum listed in struct internal::static_assertion<true>
   18|       | *
   19|       | *  - currently EIGEN_STATIC_ASSERT can only be used in function scope
   20|       | *
   21|       | */
   22|       |
   23|       |#ifndef EIGEN_STATIC_ASSERT
   24|       |#ifndef EIGEN_NO_STATIC_ASSERT
   25|       |
   26|     66|#define EIGEN_STATIC_ASSERT(X, MSG) static_assert(X, #MSG);
   27|       |
   28|       |#else  // EIGEN_NO_STATIC_ASSERT
   29|       |
   30|       |#define EIGEN_STATIC_ASSERT(CONDITION, MSG)
   31|       |
   32|       |#endif  // EIGEN_NO_STATIC_ASSERT
   33|       |#endif  // EIGEN_STATIC_ASSERT
   34|       |
   35|       |// static assertion failing if the type \a TYPE is not a vector type
   36|       |#define EIGEN_STATIC_ASSERT_VECTOR_ONLY(TYPE) \
   37|      2|  EIGEN_STATIC_ASSERT(TYPE::IsVectorAtCompileTime, YOU_TRIED_CALLING_A_VECTOR_METHOD_ON_A_MATRIX)
   38|       |
   39|       |// static assertion failing if the type \a TYPE is not fixed-size
   40|       |#define EIGEN_STATIC_ASSERT_FIXED_SIZE(TYPE)                     \
   41|       |  EIGEN_STATIC_ASSERT(TYPE::SizeAtCompileTime != Eigen::Dynamic, \
   42|       |                      YOU_CALLED_A_FIXED_SIZE_METHOD_ON_A_DYNAMIC_SIZE_MATRIX_OR_VECTOR)
   43|       |
   44|       |// static assertion failing if the type \a TYPE is not dynamic-size
   45|       |#define EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(TYPE)                   \
   46|       |  EIGEN_STATIC_ASSERT(TYPE::SizeAtCompileTime == Eigen::Dynamic, \
   47|       |                      YOU_CALLED_A_DYNAMIC_SIZE_METHOD_ON_A_FIXED_SIZE_MATRIX_OR_VECTOR)
   48|       |
   49|       |// static assertion failing if the type \a TYPE is not a vector type of the given size
   50|       |#define EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(TYPE, SIZE)                         \
   51|       |  EIGEN_STATIC_ASSERT(TYPE::IsVectorAtCompileTime&& TYPE::SizeAtCompileTime == SIZE, \
   52|       |                      THIS_METHOD_IS_ONLY_FOR_VECTORS_OF_A_SPECIFIC_SIZE)
   53|       |
   54|       |// static assertion failing if the type \a TYPE is not a vector type of the given size
   55|       |#define EIGEN_STATIC_ASSERT_MATRIX_SPECIFIC_SIZE(TYPE, ROWS, COLS)                        \
   56|       |  EIGEN_STATIC_ASSERT(TYPE::RowsAtCompileTime == ROWS && TYPE::ColsAtCompileTime == COLS, \
   57|       |                      THIS_METHOD_IS_ONLY_FOR_MATRICES_OF_A_SPECIFIC_SIZE)
   58|       |
   59|       |// static assertion failing if the two vector expression types are not compatible (same fixed-size or dynamic size)
   60|       |#define EIGEN_STATIC_ASSERT_SAME_VECTOR_SIZE(TYPE0, TYPE1)                                                   \
   61|       |  EIGEN_STATIC_ASSERT(                                                                                       \
   62|       |      (int(TYPE0::SizeAtCompileTime) == Eigen::Dynamic || int(TYPE1::SizeAtCompileTime) == Eigen::Dynamic || \
   63|       |       int(TYPE0::SizeAtCompileTime) == int(TYPE1::SizeAtCompileTime)),                                      \
   64|       |      YOU_MIXED_VECTORS_OF_DIFFERENT_SIZES)
   65|       |
   66|       |#define EIGEN_PREDICATE_SAME_MATRIX_SIZE(TYPE0, TYPE1)                                                     \
   67|       |  ((int(Eigen::internal::size_of_xpr_at_compile_time<TYPE0>::ret) == 0 &&                                  \
   68|       |    int(Eigen::internal::size_of_xpr_at_compile_time<TYPE1>::ret) == 0) ||                                 \
   69|       |   ((int(TYPE0::RowsAtCompileTime) == Eigen::Dynamic || int(TYPE1::RowsAtCompileTime) == Eigen::Dynamic || \
   70|       |     int(TYPE0::RowsAtCompileTime) == int(TYPE1::RowsAtCompileTime)) &&                                    \
   71|       |    (int(TYPE0::ColsAtCompileTime) == Eigen::Dynamic || int(TYPE1::ColsAtCompileTime) == Eigen::Dynamic || \
   72|       |     int(TYPE0::ColsAtCompileTime) == int(TYPE1::ColsAtCompileTime))))
   73|       |
   74|       |#define EIGEN_STATIC_ASSERT_NON_INTEGER(TYPE) \
   75|       |  EIGEN_STATIC_ASSERT(!Eigen::NumTraits<TYPE>::IsInteger, THIS_FUNCTION_IS_NOT_FOR_INTEGER_NUMERIC_TYPES)
   76|       |
   77|       |// static assertion failing if it is guaranteed at compile-time that the two matrix expression types have different
   78|       |// sizes
   79|       |#define EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(TYPE0, TYPE1) \
   80|      4|  EIGEN_STATIC_ASSERT(EIGEN_PREDICATE_SAME_MATRIX_SIZE(TYPE0, TYPE1), YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES)
   81|       |
   82|       |#define EIGEN_STATIC_ASSERT_SIZE_1x1(TYPE)                                                             \
   83|       |  EIGEN_STATIC_ASSERT((TYPE::RowsAtCompileTime == 1 || TYPE::RowsAtCompileTime == Eigen::Dynamic) &&   \
   84|       |                          (TYPE::ColsAtCompileTime == 1 || TYPE::ColsAtCompileTime == Eigen::Dynamic), \
   85|       |                      THIS_METHOD_IS_ONLY_FOR_1x1_EXPRESSIONS)
   86|       |
   87|       |#define EIGEN_STATIC_ASSERT_LVALUE(Derived) \
   88|      4|  EIGEN_STATIC_ASSERT(Eigen::internal::is_lvalue<Derived>::value, THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY)
   89|       |
   90|       |#define EIGEN_STATIC_ASSERT_ARRAYXPR(Derived)                                                                          \
   91|       |  EIGEN_STATIC_ASSERT((Eigen::internal::is_same<typename Eigen::internal::traits<Derived>::XprKind, ArrayXpr>::value), \
   92|       |                      THIS_METHOD_IS_ONLY_FOR_ARRAYS_NOT_MATRICES)
   93|       |
   94|       |#define EIGEN_STATIC_ASSERT_SAME_XPR_KIND(Derived1, Derived2)                                                 \
   95|       |  EIGEN_STATIC_ASSERT((Eigen::internal::is_same<typename Eigen::internal::traits<Derived1>::XprKind,          \
   96|       |                                                typename Eigen::internal::traits<Derived2>::XprKind>::value), \
   97|       |                      YOU_CANNOT_MIX_ARRAYS_AND_MATRICES)
   98|       |
   99|       |// Check that a cost value is positive, and that is stay within a reasonable range
  100|       |// TODO this check could be enabled for internal debugging only
  101|       |#define EIGEN_INTERNAL_CHECK_COST_VALUE(C)                    \
  102|     16|  EIGEN_STATIC_ASSERT((C) >= 0 && (C) <= HugeCost * HugeCost, \
  103|     16|                      EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT__INVALID_COST_VALUE);
  104|       |
  105|       |#endif  // EIGEN_STATIC_ASSERT_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/SymbolicIndex.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2017 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_SYMBOLIC_INDEX_H
   11|       |#define EIGEN_SYMBOLIC_INDEX_H
   12|       |
   13|       |// IWYU pragma: private
   14|       |#include "../InternalHeaderCheck.h"
   15|       |
   16|       |namespace Eigen {
   17|       |
   18|       |/** \namespace Eigen::symbolic
   19|       | * \ingroup Core_Module
   20|       | *
   21|       | * This namespace defines a set of classes and functions to build and evaluate symbolic expressions of scalar type
   22|       | * Index. Here is a simple example:
   23|       | *
   24|       | * \code
   25|       | * // First step, defines symbols:
   26|       | * struct x_tag {};  static const symbolic::SymbolExpr<x_tag> x;
   27|       | * struct y_tag {};  static const symbolic::SymbolExpr<y_tag> y;
   28|       | * struct z_tag {};  static const symbolic::SymbolExpr<z_tag> z;
   29|       | *
   30|       | * // Defines an expression:
   31|       | * auto expr = (x+3)/y+z;
   32|       | *
   33|       | * // And evaluate it: (c++14)
   34|       | * std::cout << expr.eval(x=6,y=3,z=-13) << "\n";
   35|       | *
   36|       | * \endcode
   37|       | *
   38|       | * It is currently only used internally to define and manipulate the
   39|       | * Eigen::placeholders::last and Eigen::placeholders::lastp1 symbols in
   40|       | * Eigen::seq and Eigen::seqN.
   41|       | *
   42|       | */
   43|       |namespace symbolic {
   44|       |
   45|       |template <typename Tag>
   46|       |class Symbol;
   47|       |template <typename Tag, typename Type>
   48|       |class SymbolValue;
   49|       |template <typename Arg0>
   50|       |class NegateExpr;
   51|       |template <typename Arg1, typename Arg2>
   52|       |class AddExpr;
   53|       |template <typename Arg1, typename Arg2>
   54|       |class ProductExpr;
   55|       |template <typename Arg1, typename Arg2>
   56|       |class QuotientExpr;
   57|       |template <typename IndexType = Index>
   58|       |class ValueExpr;
   59|       |
   60|       |/** \class BaseExpr
   61|       | * \ingroup Core_Module
   62|       | * Common base class of any symbolic expressions
   63|       | */
   64|       |template <typename Derived_>
   65|       |class BaseExpr {
   66|       | public:
   67|       |  using Derived = Derived_;
   68|      0|  constexpr const Derived& derived() const { return *static_cast<const Derived*>(this); }
   69|       |
   70|       |  /** Evaluate the expression given the \a values of the symbols.
   71|       |   *
   72|       |   * \param values defines the values of the symbols, as constructed by SymbolExpr::operator= operator.
   73|       |   *
   74|       |   */
   75|       |  template <typename... Tags, typename... Types>
   76|       |  constexpr Index eval(const SymbolValue<Tags, Types>&... values) const {
   77|       |    return derived().eval_impl(values...);
   78|       |  }
   79|       |
   80|       |  /** Evaluate the expression at compile time given the \a values of the symbols.
   81|       |   *
   82|       |   * If a value is not known at compile-time, returns Eigen::Undefined.
   83|       |   *
   84|       |   */
   85|       |  template <typename... Tags, typename... Types>
   86|       |  static constexpr Index eval_at_compile_time(const SymbolValue<Tags, Types>&...) {
   87|       |    return Derived::eval_at_compile_time_impl(SymbolValue<Tags, Types>{}...);
   88|       |  }
   89|       |
   90|       |  constexpr NegateExpr<Derived> operator-() const { return NegateExpr<Derived>(derived()); }
   91|       |
   92|       |  constexpr AddExpr<Derived, ValueExpr<>> operator+(Index b) const {
   93|       |    return AddExpr<Derived, ValueExpr<>>(derived(), b);
   94|       |  }
   95|       |  constexpr AddExpr<Derived, ValueExpr<>> operator-(Index a) const {
   96|       |    return AddExpr<Derived, ValueExpr<>>(derived(), -a);
   97|       |  }
   98|       |  constexpr ProductExpr<Derived, ValueExpr<>> operator*(Index a) const {
   99|       |    return ProductExpr<Derived, ValueExpr<>>(derived(), a);
  100|       |  }
  101|       |  constexpr QuotientExpr<Derived, ValueExpr<>> operator/(Index a) const {
  102|       |    return QuotientExpr<Derived, ValueExpr<>>(derived(), a);
  103|       |  }
  104|       |
  105|       |  friend constexpr AddExpr<Derived, ValueExpr<>> operator+(Index a, const BaseExpr& b) {
  106|       |    return AddExpr<Derived, ValueExpr<>>(b.derived(), a);
  107|       |  }
  108|       |  friend constexpr AddExpr<NegateExpr<Derived>, ValueExpr<>> operator-(Index a, const BaseExpr& b) {
  109|       |    return AddExpr<NegateExpr<Derived>, ValueExpr<>>(-b.derived(), a);
  110|       |  }
  111|       |  friend constexpr ProductExpr<ValueExpr<>, Derived> operator*(Index a, const BaseExpr& b) {
  112|       |    return ProductExpr<ValueExpr<>, Derived>(a, b.derived());
  113|       |  }
  114|       |  friend constexpr QuotientExpr<ValueExpr<>, Derived> operator/(Index a, const BaseExpr& b) {
  115|       |    return QuotientExpr<ValueExpr<>, Derived>(a, b.derived());
  116|       |  }
  117|       |
  118|       |  template <int N>
  119|      0|  constexpr AddExpr<Derived, ValueExpr<internal::FixedInt<N>>> operator+(internal::FixedInt<N>) const {
  120|      0|    return AddExpr<Derived, ValueExpr<internal::FixedInt<N>>>(derived(), ValueExpr<internal::FixedInt<N>>());
  121|      0|  }
  122|       |  template <int N>
  123|       |  constexpr AddExpr<Derived, ValueExpr<internal::FixedInt<-N>>> operator-(internal::FixedInt<N>) const {
  124|       |    return AddExpr<Derived, ValueExpr<internal::FixedInt<-N>>>(derived(), ValueExpr<internal::FixedInt<-N>>());
  125|       |  }
  126|       |  template <int N>
  127|       |  constexpr ProductExpr<Derived, ValueExpr<internal::FixedInt<N>>> operator*(internal::FixedInt<N>) const {
  128|       |    return ProductExpr<Derived, ValueExpr<internal::FixedInt<N>>>(derived(), ValueExpr<internal::FixedInt<N>>());
  129|       |  }
  130|       |  template <int N>
  131|       |  constexpr QuotientExpr<Derived, ValueExpr<internal::FixedInt<N>>> operator/(internal::FixedInt<N>) const {
  132|       |    return QuotientExpr<Derived, ValueExpr<internal::FixedInt<N>>>(derived(), ValueExpr<internal::FixedInt<N>>());
  133|       |  }
  134|       |
  135|       |  template <int N>
  136|       |  friend constexpr AddExpr<Derived, ValueExpr<internal::FixedInt<N>>> operator+(internal::FixedInt<N>,
  137|       |                                                                                const BaseExpr& b) {
  138|       |    return AddExpr<Derived, ValueExpr<internal::FixedInt<N>>>(b.derived(), ValueExpr<internal::FixedInt<N>>());
  139|       |  }
  140|       |  template <int N>
  141|       |  friend constexpr AddExpr<NegateExpr<Derived>, ValueExpr<internal::FixedInt<N>>> operator-(internal::FixedInt<N>,
  142|       |                                                                                            const BaseExpr& b) {
  143|       |    return AddExpr<NegateExpr<Derived>, ValueExpr<internal::FixedInt<N>>>(-b.derived(),
  144|       |                                                                          ValueExpr<internal::FixedInt<N>>());
  145|       |  }
  146|       |  template <int N>
  147|       |  friend constexpr ProductExpr<ValueExpr<internal::FixedInt<N>>, Derived> operator*(internal::FixedInt<N>,
  148|       |                                                                                    const BaseExpr& b) {
  149|       |    return ProductExpr<ValueExpr<internal::FixedInt<N>>, Derived>(ValueExpr<internal::FixedInt<N>>(), b.derived());
  150|       |  }
  151|       |  template <int N>
  152|       |  friend constexpr QuotientExpr<ValueExpr<internal::FixedInt<N>>, Derived> operator/(internal::FixedInt<N>,
  153|       |                                                                                     const BaseExpr& b) {
  154|       |    return QuotientExpr<ValueExpr<internal::FixedInt<N>>, Derived>(ValueExpr<internal::FixedInt<N>>(), b.derived());
  155|       |  }
  156|       |
  157|       |  template <typename OtherDerived>
  158|       |  constexpr AddExpr<Derived, OtherDerived> operator+(const BaseExpr<OtherDerived>& b) const {
  159|       |    return AddExpr<Derived, OtherDerived>(derived(), b.derived());
  160|       |  }
  161|       |
  162|       |  template <typename OtherDerived>
  163|       |  constexpr AddExpr<Derived, NegateExpr<OtherDerived>> operator-(const BaseExpr<OtherDerived>& b) const {
  164|       |    return AddExpr<Derived, NegateExpr<OtherDerived>>(derived(), -b.derived());
  165|       |  }
  166|       |
  167|       |  template <typename OtherDerived>
  168|       |  constexpr ProductExpr<Derived, OtherDerived> operator*(const BaseExpr<OtherDerived>& b) const {
  169|       |    return ProductExpr<Derived, OtherDerived>(derived(), b.derived());
  170|       |  }
  171|       |
  172|       |  template <typename OtherDerived>
  173|       |  constexpr QuotientExpr<Derived, OtherDerived> operator/(const BaseExpr<OtherDerived>& b) const {
  174|       |    return QuotientExpr<Derived, OtherDerived>(derived(), b.derived());
  175|       |  }
  176|       |};
  177|       |
  178|       |template <typename T>
  179|       |struct is_symbolic {
  180|       |  // BaseExpr has no conversion ctor, so we only have to check whether T can be statically cast to its base class
  181|       |  // BaseExpr<T>.
  182|       |  enum { value = internal::is_convertible<T, BaseExpr<T>>::value };
  183|       |};
  184|       |
  185|       |// A simple wrapper around an integral value to provide the eval method.
  186|       |// We could also use a free-function symbolic_eval...
  187|       |template <typename IndexType>
  188|       |class ValueExpr : BaseExpr<ValueExpr<IndexType>> {
  189|       | public:
  190|       |  constexpr ValueExpr() = default;
  191|       |  constexpr ValueExpr(IndexType val) : value_(val) {}
  192|       |  template <typename... Tags, typename... Types>
  193|       |  constexpr IndexType eval_impl(const SymbolValue<Tags, Types>&...) const {
  194|       |    return value_;
  195|       |  }
  196|       |  template <typename... Tags, typename... Types>
  197|       |  static constexpr IndexType eval_at_compile_time_impl(const SymbolValue<Tags, Types>&...) {
  198|       |    return IndexType(Undefined);
  199|       |  }
  200|       |
  201|       | protected:
  202|       |  IndexType value_;
  203|       |};
  204|       |
  205|       |// Specialization for compile-time value,
  206|       |// It is similar to ValueExpr(N) but this version helps the compiler to generate better code.
  207|       |template <int N>
  208|       |class ValueExpr<internal::FixedInt<N>> : public BaseExpr<ValueExpr<internal::FixedInt<N>>> {
  209|       | public:
  210|       |  constexpr ValueExpr() = default;
  211|       |  constexpr ValueExpr(internal::FixedInt<N>) {}
  212|       |  template <typename... Tags, typename... Types>
  213|       |  constexpr Index eval_impl(const SymbolValue<Tags, Types>&...) const {
  214|       |    return Index(N);
  215|       |  }
  216|       |  template <typename... Tags, typename... Types>
  217|       |  static constexpr Index eval_at_compile_time_impl(const SymbolValue<Tags, Types>&...) {
  218|       |    return Index(N);
  219|       |  }
  220|       |};
  221|       |
  222|       |/** Represents the actual value of a symbol identified by its tag
  223|       | *
  224|       | * It is the return type of SymbolValue::operator=, and most of the time this is only way it is used.
  225|       | */
  226|       |template <typename Tag, typename Type>
  227|       |class SymbolValue : public BaseExpr<SymbolValue<Tag, Type>> {};
  228|       |
  229|       |template <typename Tag>
  230|       |class SymbolValue<Tag, Index> : public BaseExpr<SymbolValue<Tag, Index>> {
  231|       | public:
  232|       |  constexpr SymbolValue() = default;
  233|       |
  234|       |  /** Default constructor from the value \a val */
  235|       |  constexpr SymbolValue(Index val) : value_(val) {}
  236|       |
  237|       |  /** \returns the stored value of the symbol */
  238|       |  constexpr Index value() const { return value_; }
  239|       |
  240|       |  /** \returns the stored value of the symbol at compile time, or Undefined if not known. */
  241|       |  static constexpr Index value_at_compile_time() { return Index(Undefined); }
  242|       |
  243|       |  template <typename... Tags, typename... Types>
  244|       |  constexpr Index eval_impl(const SymbolValue<Tags, Types>&...) const {
  245|       |    return value();
  246|       |  }
  247|       |
  248|       |  template <typename... Tags, typename... Types>
  249|       |  static constexpr Index eval_at_compile_time_impl(const SymbolValue<Tags, Types>&...) {
  250|       |    return value_at_compile_time();
  251|       |  }
  252|       |
  253|       | protected:
  254|       |  Index value_;
  255|       |};
  256|       |
  257|       |template <typename Tag, int N>
  258|       |class SymbolValue<Tag, internal::FixedInt<N>> : public BaseExpr<SymbolValue<Tag, internal::FixedInt<N>>> {
  259|       | public:
  260|       |  constexpr SymbolValue() = default;
  261|       |
  262|       |  /** Default constructor from the value \a val */
  263|       |  constexpr SymbolValue(internal::FixedInt<N>) {}
  264|       |
  265|       |  /** \returns the stored value of the symbol */
  266|       |  constexpr Index value() const { return static_cast<Index>(N); }
  267|       |
  268|       |  /** \returns the stored value of the symbol at compile time, or Undefined if not known. */
  269|       |  static constexpr Index value_at_compile_time() { return static_cast<Index>(N); }
  270|       |
  271|       |  template <typename... Tags, typename... Types>
  272|       |  constexpr Index eval_impl(const SymbolValue<Tags, Types>&...) const {
  273|       |    return value();
  274|       |  }
  275|       |
  276|       |  template <typename... Tags, typename... Types>
  277|       |  static constexpr Index eval_at_compile_time_impl(const SymbolValue<Tags, Types>&...) {
  278|       |    return value_at_compile_time();
  279|       |  }
  280|       |};
  281|       |
  282|       |// Find and return a symbol value based on the tag.
  283|       |template <typename Tag, typename... Types>
  284|       |struct EvalSymbolValueHelper;
  285|       |
  286|       |// Empty base case, symbol not found.
  287|       |template <typename Tag>
  288|       |struct EvalSymbolValueHelper<Tag> {
  289|       |  static constexpr Index eval_impl() {
  290|       |    eigen_assert(false && "Symbol not found.");
  291|       |    return Index(Undefined);
  292|       |  }
  293|       |  static constexpr Index eval_at_compile_time_impl() { return Index(Undefined); }
  294|       |};
  295|       |
  296|       |// We found a symbol value matching the provided Tag!
  297|       |template <typename Tag, typename Type, typename... OtherTypes>
  298|       |struct EvalSymbolValueHelper<Tag, SymbolValue<Tag, Type>, OtherTypes...> {
  299|       |  static constexpr Index eval_impl(const SymbolValue<Tag, Type>& symbol, const OtherTypes&...) {
  300|       |    return symbol.value();
  301|       |  }
  302|       |  static constexpr Index eval_at_compile_time_impl(const SymbolValue<Tag, Type>& symbol, const OtherTypes&...) {
  303|       |    return symbol.value_at_compile_time();
  304|       |  }
  305|       |};
  306|       |
  307|       |// No symbol value in first value, recursive search starting with next.
  308|       |template <typename Tag, typename T1, typename... OtherTypes>
  309|       |struct EvalSymbolValueHelper<Tag, T1, OtherTypes...> {
  310|       |  static constexpr Index eval_impl(const T1&, const OtherTypes&... values) {
  311|       |    return EvalSymbolValueHelper<Tag, OtherTypes...>::eval_impl(values...);
  312|       |  }
  313|       |  static constexpr Index eval_at_compile_time_impl(const T1&, const OtherTypes&...) {
  314|       |    return EvalSymbolValueHelper<Tag, OtherTypes...>::eval_at_compile_time_impl(OtherTypes{}...);
  315|       |  }
  316|       |};
  317|       |
  318|       |/** Expression of a symbol uniquely identified by the template parameter type \c tag */
  319|       |template <typename tag>
  320|       |class SymbolExpr : public BaseExpr<SymbolExpr<tag>> {
  321|       | public:
  322|       |  /** Alias to the template parameter \c tag */
  323|       |  typedef tag Tag;
  324|       |
  325|       |  constexpr SymbolExpr() = default;
  326|       |
  327|       |  /** Associate the value \a val to the given symbol \c *this, uniquely identified by its \c Tag.
  328|       |   *
  329|       |   * The returned object should be passed to ExprBase::eval() to evaluate a given expression with this specified
  330|       |   * runtime-time value.
  331|       |   */
  332|      0|  constexpr SymbolValue<Tag, Index> operator=(Index val) const { return SymbolValue<Tag, Index>(val); }
  333|       |
  334|       |  template <int N>
  335|       |  constexpr SymbolValue<Tag, internal::FixedInt<N>> operator=(internal::FixedInt<N>) const {
  336|       |    return SymbolValue<Tag, internal::FixedInt<N>>{internal::FixedInt<N>{}};
  337|       |  }
  338|       |
  339|       |  template <typename... Tags, typename... Types>
  340|       |  constexpr Index eval_impl(const SymbolValue<Tags, Types>&... values) const {
  341|       |    return EvalSymbolValueHelper<Tag, SymbolValue<Tags, Types>...>::eval_impl(values...);
  342|       |  }
  343|       |
  344|       |  template <typename... Tags, typename... Types>
  345|       |  static constexpr Index eval_at_compile_time_impl(const SymbolValue<Tags, Types>&...) {
  346|       |    return EvalSymbolValueHelper<Tag, SymbolValue<Tags, Types>...>::eval_at_compile_time_impl(
  347|       |        SymbolValue<Tags, Types>{}...);
  348|       |  }
  349|       |};
  350|       |
  351|       |template <typename Arg0>
  352|       |class NegateExpr : public BaseExpr<NegateExpr<Arg0>> {
  353|       | public:
  354|       |  constexpr NegateExpr() = default;
  355|       |  constexpr NegateExpr(const Arg0& arg0) : m_arg0(arg0) {}
  356|       |
  357|       |  template <typename... Tags, typename... Types>
  358|       |  constexpr Index eval_impl(const SymbolValue<Tags, Types>&... values) const {
  359|       |    return -m_arg0.eval_impl(values...);
  360|       |  }
  361|       |
  362|       |  template <typename... Tags, typename... Types>
  363|       |  static constexpr Index eval_at_compile_time_impl(const SymbolValue<Tags, Types>&...) {
  364|       |    constexpr Index v = Arg0::eval_at_compile_time_impl(SymbolValue<Tags, Types>{}...);
  365|       |    return (v == Undefined) ? Undefined : -v;
  366|       |  }
  367|       |
  368|       | protected:
  369|       |  Arg0 m_arg0;
  370|       |};
  371|       |
  372|       |template <typename Arg0, typename Arg1>
  373|       |class AddExpr : public BaseExpr<AddExpr<Arg0, Arg1>> {
  374|       | public:
  375|       |  constexpr AddExpr() = default;
  376|       |  constexpr AddExpr(const Arg0& arg0, const Arg1& arg1) : m_arg0(arg0), m_arg1(arg1) {}
  377|       |
  378|       |  template <typename... Tags, typename... Types>
  379|       |  constexpr Index eval_impl(const SymbolValue<Tags, Types>&... values) const {
  380|       |    return m_arg0.eval_impl(values...) + m_arg1.eval_impl(values...);
  381|       |  }
  382|       |
  383|       |  template <typename... Tags, typename... Types>
  384|       |  static constexpr Index eval_at_compile_time_impl(const SymbolValue<Tags, Types>&...) {
  385|       |    constexpr Index v0 = Arg0::eval_at_compile_time_impl(SymbolValue<Tags, Types>{}...);
  386|       |    constexpr Index v1 = Arg1::eval_at_compile_time_impl(SymbolValue<Tags, Types>{}...);
  387|       |    return (v0 == Undefined || v1 == Undefined) ? Undefined : v0 + v1;
  388|       |  }
  389|       |
  390|       | protected:
  391|       |  Arg0 m_arg0;
  392|       |  Arg1 m_arg1;
  393|       |};
  394|       |
  395|       |template <typename Arg0, typename Arg1>
  396|       |class ProductExpr : public BaseExpr<ProductExpr<Arg0, Arg1>> {
  397|       | public:
  398|       |  constexpr ProductExpr() = default;
  399|       |  constexpr ProductExpr(const Arg0& arg0, const Arg1& arg1) : m_arg0(arg0), m_arg1(arg1) {}
  400|       |
  401|       |  template <typename... Tags, typename... Types>
  402|       |  constexpr Index eval_impl(const SymbolValue<Tags, Types>&... values) const {
  403|       |    return m_arg0.eval_impl(values...) * m_arg1.eval_impl(values...);
  404|       |  }
  405|       |
  406|       |  template <typename... Tags, typename... Types>
  407|       |  static constexpr Index eval_at_compile_time_impl(const SymbolValue<Tags, Types>&...) {
  408|       |    constexpr Index v0 = Arg0::eval_at_compile_time_impl(SymbolValue<Tags, Types>{}...);
  409|       |    constexpr Index v1 = Arg1::eval_at_compile_time_impl(SymbolValue<Tags, Types>{}...);
  410|       |    return (v0 == Undefined || v1 == Undefined) ? Undefined : v0 * v1;
  411|       |  }
  412|       |
  413|       | protected:
  414|       |  Arg0 m_arg0;
  415|       |  Arg1 m_arg1;
  416|       |};
  417|       |
  418|       |template <typename Arg0, typename Arg1>
  419|       |class QuotientExpr : public BaseExpr<QuotientExpr<Arg0, Arg1>> {
  420|       | public:
  421|       |  constexpr QuotientExpr() = default;
  422|       |  constexpr QuotientExpr(const Arg0& arg0, const Arg1& arg1) : m_arg0(arg0), m_arg1(arg1) {}
  423|       |
  424|       |  template <typename... Tags, typename... Types>
  425|       |  constexpr Index eval_impl(const SymbolValue<Tags, Types>&... values) const {
  426|       |    return m_arg0.eval_impl(values...) / m_arg1.eval_impl(values...);
  427|       |  }
  428|       |
  429|       |  template <typename... Tags, typename... Types>
  430|       |  static constexpr Index eval_at_compile_time_impl(const SymbolValue<Tags, Types>&...) {
  431|       |    constexpr Index v0 = Arg0::eval_at_compile_time_impl(SymbolValue<Tags, Types>{}...);
  432|       |    constexpr Index v1 = Arg1::eval_at_compile_time_impl(SymbolValue<Tags, Types>{}...);
  433|       |    return (v0 == Undefined || v1 == Undefined) ? Undefined : v0 / v1;
  434|       |  }
  435|       |
  436|       | protected:
  437|       |  Arg0 m_arg0;
  438|       |  Arg1 m_arg1;
  439|       |};
  440|       |
  441|       |}  // end namespace symbolic
  442|       |
  443|       |}  // end namespace Eigen
  444|       |
  445|       |#endif  // EIGEN_SYMBOLIC_INDEX_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/Core/util/XprHelper.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_XPRHELPER_H
   12|       |#define EIGEN_XPRHELPER_H
   13|       |
   14|       |// IWYU pragma: private
   15|       |#include "../InternalHeaderCheck.h"
   16|       |
   17|       |namespace Eigen {
   18|       |
   19|       |namespace internal {
   20|       |
   21|       |// useful for unsigned / signed integer comparisons when idx is intended to be non-negative
   22|       |template <typename IndexType>
   23|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename make_unsigned<IndexType>::type returnUnsignedIndexValue(
   24|       |    const IndexType& idx) {
   25|       |  EIGEN_STATIC_ASSERT((NumTraits<IndexType>::IsInteger), THIS FUNCTION IS FOR INTEGER TYPES)
   26|       |  eigen_internal_assert(idx >= 0 && "Index value is negative and target type is unsigned");
   27|       |  using UnsignedType = typename make_unsigned<IndexType>::type;
   28|       |  return static_cast<UnsignedType>(idx);
   29|       |}
   30|       |
   31|       |template <typename IndexDest, typename IndexSrc, bool IndexDestIsInteger = NumTraits<IndexDest>::IsInteger,
   32|       |          bool IndexDestIsSigned = NumTraits<IndexDest>::IsSigned,
   33|       |          bool IndexSrcIsInteger = NumTraits<IndexSrc>::IsInteger,
   34|       |          bool IndexSrcIsSigned = NumTraits<IndexSrc>::IsSigned>
   35|       |struct convert_index_impl {
   36|       |  static inline EIGEN_DEVICE_FUNC IndexDest run(const IndexSrc& idx) {
   37|       |    eigen_internal_assert(idx <= NumTraits<IndexDest>::highest() && "Index value is too big for target type");
   38|       |    return static_cast<IndexDest>(idx);
   39|       |  }
   40|       |};
   41|       |template <typename IndexDest, typename IndexSrc>
   42|       |struct convert_index_impl<IndexDest, IndexSrc, true, true, true, false> {
   43|       |  // IndexDest is a signed integer
   44|       |  // IndexSrc is an unsigned integer
   45|       |  static inline EIGEN_DEVICE_FUNC IndexDest run(const IndexSrc& idx) {
   46|       |    eigen_internal_assert(idx <= returnUnsignedIndexValue(NumTraits<IndexDest>::highest()) &&
   47|       |                          "Index value is too big for target type");
   48|       |    return static_cast<IndexDest>(idx);
   49|       |  }
   50|       |};
   51|       |template <typename IndexDest, typename IndexSrc>
   52|       |struct convert_index_impl<IndexDest, IndexSrc, true, false, true, true> {
   53|       |  // IndexDest is an unsigned integer
   54|       |  // IndexSrc is a signed integer
   55|       |  static inline EIGEN_DEVICE_FUNC IndexDest run(const IndexSrc& idx) {
   56|       |    eigen_internal_assert(returnUnsignedIndexValue(idx) <= NumTraits<IndexDest>::highest() &&
   57|       |                          "Index value is too big for target type");
   58|       |    return static_cast<IndexDest>(idx);
   59|       |  }
   60|       |};
   61|       |
   62|       |template <typename IndexDest, typename IndexSrc>
   63|       |EIGEN_DEVICE_FUNC inline IndexDest convert_index(const IndexSrc& idx) {
   64|       |  return convert_index_impl<IndexDest, IndexSrc>::run(idx);
   65|       |}
   66|       |
   67|       |// true if T can be considered as an integral index (i.e., and integral type or enum)
   68|       |template <typename T>
   69|       |struct is_valid_index_type {
   70|       |  enum { value = internal::is_integral<T>::value || std::is_enum<T>::value };
   71|       |};
   72|       |
   73|       |// true if both types are not valid index types
   74|       |template <typename RowIndices, typename ColIndices>
   75|       |struct valid_indexed_view_overload {
   76|       |  enum {
   77|       |    value = !(internal::is_valid_index_type<RowIndices>::value && internal::is_valid_index_type<ColIndices>::value)
   78|       |  };
   79|       |};
   80|       |
   81|       |// promote_scalar_arg is an helper used in operation between an expression and a scalar, like:
   82|       |//    expression * scalar
   83|       |// Its role is to determine how the type T of the scalar operand should be promoted given the scalar type ExprScalar of
   84|       |// the given expression. The IsSupported template parameter must be provided by the caller as:
   85|       |// internal::has_ReturnType<ScalarBinaryOpTraits<ExprScalar,T,op> >::value using the proper order for ExprScalar and T.
   86|       |// Then the logic is as follows:
   87|       |//  - if the operation is natively supported as defined by IsSupported, then the scalar type is not promoted, and T is
   88|       |//  returned.
   89|       |//  - otherwise, NumTraits<ExprScalar>::Literal is returned if T is implicitly convertible to
   90|       |//  NumTraits<ExprScalar>::Literal AND that this does not imply a float to integer conversion.
   91|       |//  - otherwise, ExprScalar is returned if T is implicitly convertible to ExprScalar AND that this does not imply a
   92|       |//  float to integer conversion.
   93|       |//  - In all other cases, the promoted type is not defined, and the respective operation is thus invalid and not
   94|       |//  available (SFINAE).
   95|       |template <typename ExprScalar, typename T, bool IsSupported>
   96|       |struct promote_scalar_arg;
   97|       |
   98|       |template <typename S, typename T>
   99|       |struct promote_scalar_arg<S, T, true> {
  100|       |  typedef T type;
  101|       |};
  102|       |
  103|       |// Recursively check safe conversion to PromotedType, and then ExprScalar if they are different.
  104|       |template <typename ExprScalar, typename T, typename PromotedType,
  105|       |          bool ConvertibleToLiteral = internal::is_convertible<T, PromotedType>::value,
  106|       |          bool IsSafe = NumTraits<T>::IsInteger || !NumTraits<PromotedType>::IsInteger>
  107|       |struct promote_scalar_arg_unsupported;
  108|       |
  109|       |// Start recursion with NumTraits<ExprScalar>::Literal
  110|       |template <typename S, typename T>
  111|       |struct promote_scalar_arg<S, T, false> : promote_scalar_arg_unsupported<S, T, typename NumTraits<S>::Literal> {};
  112|       |
  113|       |// We found a match!
  114|       |template <typename S, typename T, typename PromotedType>
  115|       |struct promote_scalar_arg_unsupported<S, T, PromotedType, true, true> {
  116|       |  typedef PromotedType type;
  117|       |};
  118|       |
  119|       |// No match, but no real-to-integer issues, and ExprScalar and current PromotedType are different,
  120|       |// so let's try to promote to ExprScalar
  121|       |template <typename ExprScalar, typename T, typename PromotedType>
  122|       |struct promote_scalar_arg_unsupported<ExprScalar, T, PromotedType, false, true>
  123|       |    : promote_scalar_arg_unsupported<ExprScalar, T, ExprScalar> {};
  124|       |
  125|       |// Unsafe real-to-integer, let's stop.
  126|       |template <typename S, typename T, typename PromotedType, bool ConvertibleToLiteral>
  127|       |struct promote_scalar_arg_unsupported<S, T, PromotedType, ConvertibleToLiteral, false> {};
  128|       |
  129|       |// T is not even convertible to ExprScalar, let's stop.
  130|       |template <typename S, typename T>
  131|       |struct promote_scalar_arg_unsupported<S, T, S, false, true> {};
  132|       |
  133|       |// classes inheriting no_assignment_operator don't generate a default operator=.
  134|       |class no_assignment_operator {
  135|       | private:
  136|       |  no_assignment_operator& operator=(const no_assignment_operator&);
  137|       |
  138|       | protected:
  139|       |  EIGEN_DEFAULT_COPY_CONSTRUCTOR(no_assignment_operator)
  140|       |  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(no_assignment_operator)
  141|       |};
  142|       |
  143|       |/** \internal return the index type with the largest number of bits */
  144|       |template <typename I1, typename I2>
  145|       |struct promote_index_type {
  146|       |  typedef std::conditional_t<(sizeof(I1) < sizeof(I2)), I2, I1> type;
  147|       |};
  148|       |
  149|       |/** \internal If the template parameter Value is Dynamic, this class is just a wrapper around a T variable that
  150|       | * can be accessed using value() and setValue().
  151|       | * Otherwise, this class is an empty structure and value() just returns the template parameter Value.
  152|       | */
  153|       |template <typename T, int Value>
  154|       |class variable_if_dynamic {
  155|       | public:
  156|       |  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(variable_if_dynamic)
  157|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T v) {
  158|      1|    EIGEN_ONLY_USED_FOR_DEBUG(v);
  159|      1|    eigen_assert(v == T(Value));
  160|      1|  }
  ------------------
  | _ZN5Eigen8internal19variable_if_dynamicIlLi1EEC2El:
  |  157|      1|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T v) {
  |  158|      1|    EIGEN_ONLY_USED_FOR_DEBUG(v);
  |  159|      1|    eigen_assert(v == T(Value));
  |  160|      1|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19variable_if_dynamicIlLi0EEC2El
  ------------------
  161|      1|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR T value() { return T(Value); }
  ------------------
  | _ZN5Eigen8internal19variable_if_dynamicIlLi1EE5valueEv:
  |  161|      1|  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR T value() { return T(Value); }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen8internal19variable_if_dynamicIlLi0EE5valueEv
  ------------------
  162|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR operator T() const { return T(Value); }
  163|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T v) const {
  164|       |    EIGEN_ONLY_USED_FOR_DEBUG(v);
  165|       |    eigen_assert(v == T(Value));
  166|       |  }
  167|       |};
  168|       |
  169|       |template <typename T>
  170|       |class variable_if_dynamic<T, Dynamic> {
  171|       |  T m_value;
  172|       |
  173|       | public:
  174|      8|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T value = 0) EIGEN_NO_THROW : m_value(value) {}
  175|      8|  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T value() const { return m_value; }
  176|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE operator T() const { return m_value; }
  177|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T value) { m_value = value; }
  178|       |};
  179|       |
  180|       |/** \internal like variable_if_dynamic but for DynamicIndex
  181|       | */
  182|       |template <typename T, int Value>
  183|       |class variable_if_dynamicindex {
  184|       | public:
  185|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamicindex(T v) {
  186|       |    EIGEN_ONLY_USED_FOR_DEBUG(v);
  187|       |    eigen_assert(v == T(Value));
  188|       |  }
  189|       |  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR T value() { return T(Value); }
  190|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T) {}
  191|       |};
  192|       |
  193|       |template <typename T>
  194|       |class variable_if_dynamicindex<T, DynamicIndex> {
  195|       |  T m_value;
  196|       |  EIGEN_DEVICE_FUNC variable_if_dynamicindex() { eigen_assert(false); }
  197|       |
  198|       | public:
  199|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamicindex(T value) : m_value(value) {}
  200|       |  EIGEN_DEVICE_FUNC T EIGEN_STRONG_INLINE value() const { return m_value; }
  201|       |  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T value) { m_value = value; }
  202|       |};
  203|       |
  204|       |template <typename T>
  205|       |struct functor_traits {
  206|       |  enum { Cost = 10, PacketAccess = false, IsRepeatable = false };
  207|       |};
  208|       |
  209|       |// estimates the cost of lazily evaluating a generic functor by unwinding the expression
  210|       |template <typename Xpr>
  211|       |struct nested_functor_cost {
  212|       |  static constexpr Index Cost = static_cast<Index>(functor_traits<Xpr>::Cost);
  213|       |};
  214|       |
  215|       |template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  216|       |struct nested_functor_cost<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols>> {
  217|       |  static constexpr Index Cost = 1;
  218|       |};
  219|       |
  220|       |template <typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
  221|       |struct nested_functor_cost<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols>> {
  222|       |  static constexpr Index Cost = 1;
  223|       |};
  224|       |
  225|       |// TODO: assign a cost to the stride type?
  226|       |template <typename PlainObjectType, int MapOptions, typename StrideType>
  227|       |struct nested_functor_cost<Map<PlainObjectType, MapOptions, StrideType>> : nested_functor_cost<PlainObjectType> {};
  228|       |
  229|       |template <typename Func, typename Xpr>
  230|       |struct nested_functor_cost<CwiseUnaryOp<Func, Xpr>> {
  231|       |  using XprCleaned = remove_all_t<Xpr>;
  232|       |  using FuncCleaned = remove_all_t<Func>;
  233|       |  static constexpr Index Cost = nested_functor_cost<FuncCleaned>::Cost + nested_functor_cost<XprCleaned>::Cost;
  234|       |};
  235|       |
  236|       |template <typename Func, typename Xpr>
  237|       |struct nested_functor_cost<CwiseNullaryOp<Func, Xpr>> {
  238|       |  using XprCleaned = remove_all_t<Xpr>;
  239|       |  using FuncCleaned = remove_all_t<Func>;
  240|       |  static constexpr Index Cost = nested_functor_cost<FuncCleaned>::Cost + nested_functor_cost<XprCleaned>::Cost;
  241|       |};
  242|       |
  243|       |template <typename Func, typename LhsXpr, typename RhsXpr>
  244|       |struct nested_functor_cost<CwiseBinaryOp<Func, LhsXpr, RhsXpr>> {
  245|       |  using LhsXprCleaned = remove_all_t<LhsXpr>;
  246|       |  using RhsXprCleaned = remove_all_t<RhsXpr>;
  247|       |  using FuncCleaned = remove_all_t<Func>;
  248|       |  static constexpr Index Cost = nested_functor_cost<FuncCleaned>::Cost + nested_functor_cost<LhsXprCleaned>::Cost +
  249|       |                                nested_functor_cost<RhsXprCleaned>::Cost;
  250|       |};
  251|       |
  252|       |template <typename Func, typename LhsXpr, typename MidXpr, typename RhsXpr>
  253|       |struct nested_functor_cost<CwiseTernaryOp<Func, LhsXpr, MidXpr, RhsXpr>> {
  254|       |  using LhsXprCleaned = remove_all_t<LhsXpr>;
  255|       |  using MidXprCleaned = remove_all_t<MidXpr>;
  256|       |  using RhsXprCleaned = remove_all_t<RhsXpr>;
  257|       |  using FuncCleaned = remove_all_t<Func>;
  258|       |  static constexpr Index Cost = nested_functor_cost<FuncCleaned>::Cost + nested_functor_cost<LhsXprCleaned>::Cost +
  259|       |                                nested_functor_cost<MidXprCleaned>::Cost + nested_functor_cost<RhsXprCleaned>::Cost;
  260|       |};
  261|       |
  262|       |template <typename Xpr>
  263|       |struct functor_cost {
  264|       |  static constexpr Index Cost = plain_enum_max(nested_functor_cost<Xpr>::Cost, 1);
  265|       |};
  266|       |
  267|       |template <typename T>
  268|       |struct packet_traits;
  269|       |
  270|       |template <typename T>
  271|       |struct unpacket_traits;
  272|       |
  273|       |template <int Size, typename PacketType,
  274|       |          bool Stop = Size == Dynamic || (Size % unpacket_traits<PacketType>::size) == 0 ||
  275|       |                      is_same<PacketType, typename unpacket_traits<PacketType>::half>::value>
  276|       |struct find_best_packet_helper;
  277|       |
  278|       |template <int Size, typename PacketType>
  279|       |struct find_best_packet_helper<Size, PacketType, true> {
  280|       |  typedef PacketType type;
  281|       |};
  282|       |
  283|       |template <int Size, typename PacketType>
  284|       |struct find_best_packet_helper<Size, PacketType, false> {
  285|       |  typedef typename find_best_packet_helper<Size, typename unpacket_traits<PacketType>::half>::type type;
  286|       |};
  287|       |
  288|       |template <typename T, int Size>
  289|       |struct find_best_packet {
  290|       |  typedef typename find_best_packet_helper<Size, typename packet_traits<T>::type>::type type;
  291|       |};
  292|       |
  293|       |template <int Size, typename PacketType,
  294|       |          bool Stop = (Size == unpacket_traits<PacketType>::size) ||
  295|       |                      is_same<PacketType, typename unpacket_traits<PacketType>::half>::value>
  296|       |struct find_packet_by_size_helper;
  297|       |template <int Size, typename PacketType>
  298|       |struct find_packet_by_size_helper<Size, PacketType, true> {
  299|       |  using type = PacketType;
  300|       |};
  301|       |template <int Size, typename PacketType>
  302|       |struct find_packet_by_size_helper<Size, PacketType, false> {
  303|       |  using type = typename find_packet_by_size_helper<Size, typename unpacket_traits<PacketType>::half>::type;
  304|       |};
  305|       |
  306|       |template <typename T, int Size>
  307|       |struct find_packet_by_size {
  308|       |  using type = typename find_packet_by_size_helper<Size, typename packet_traits<T>::type>::type;
  309|       |  static constexpr bool value = (Size == unpacket_traits<type>::size);
  310|       |};
  311|       |template <typename T>
  312|       |struct find_packet_by_size<T, 1> {
  313|       |  using type = typename unpacket_traits<T>::type;
  314|       |  static constexpr bool value = (unpacket_traits<type>::size == 1);
  315|       |};
  316|       |
  317|       |#if EIGEN_MAX_STATIC_ALIGN_BYTES > 0
  318|      0|constexpr inline int compute_default_alignment_helper(int ArrayBytes, int AlignmentBytes) {
  319|      0|  if ((ArrayBytes % AlignmentBytes) == 0) {
  320|      0|    return AlignmentBytes;
  321|      0|  } else if (EIGEN_MIN_ALIGN_BYTES < AlignmentBytes) {
  322|      0|    return compute_default_alignment_helper(ArrayBytes, AlignmentBytes / 2);
  323|      0|  } else {
  324|      0|    return 0;
  325|      0|  }
  326|      0|}
  327|       |#else
  328|       |// If static alignment is disabled, no need to bother.
  329|       |// This also avoids a division by zero
  330|       |constexpr inline int compute_default_alignment_helper(int ArrayBytes, int AlignmentBytes) {
  331|       |  EIGEN_UNUSED_VARIABLE(ArrayBytes);
  332|       |  EIGEN_UNUSED_VARIABLE(AlignmentBytes);
  333|       |  return 0;
  334|       |}
  335|       |#endif
  336|       |
  337|       |template <typename T, int Size>
  338|       |struct compute_default_alignment {
  339|       |  enum { value = compute_default_alignment_helper(Size * sizeof(T), EIGEN_MAX_STATIC_ALIGN_BYTES) };
  340|       |};
  341|       |
  342|       |template <typename T>
  343|       |struct compute_default_alignment<T, Dynamic> {
  344|       |  enum { value = EIGEN_MAX_ALIGN_BYTES };
  345|       |};
  346|       |
  347|       |template <typename Scalar_, int Rows_, int Cols_,
  348|       |          int Options_ = AutoAlign | ((Rows_ == 1 && Cols_ != 1)   ? RowMajor
  349|       |                                      : (Cols_ == 1 && Rows_ != 1) ? ColMajor
  350|       |                                                                   : EIGEN_DEFAULT_MATRIX_STORAGE_ORDER_OPTION),
  351|       |          int MaxRows_ = Rows_, int MaxCols_ = Cols_>
  352|       |class make_proper_matrix_type {
  353|       |  enum {
  354|       |    IsColVector = Cols_ == 1 && Rows_ != 1,
  355|       |    IsRowVector = Rows_ == 1 && Cols_ != 1,
  356|       |    Options = IsColVector   ? (Options_ | ColMajor) & ~RowMajor
  357|       |              : IsRowVector ? (Options_ | RowMajor) & ~ColMajor
  358|       |                            : Options_
  359|       |  };
  360|       |
  361|       | public:
  362|       |  typedef Matrix<Scalar_, Rows_, Cols_, Options, MaxRows_, MaxCols_> type;
  363|       |};
  364|       |
  365|      0|constexpr inline unsigned compute_matrix_flags(int Options) {
  366|      0|  unsigned row_major_bit = Options & RowMajor ? RowMajorBit : 0;
  367|      0|  // FIXME currently we still have to handle DirectAccessBit at the expression level to handle DenseCoeffsBase<>
  368|      0|  // and then propagate this information to the evaluator's flags.
  369|      0|  // However, I (Gael) think that DirectAccessBit should only matter at the evaluation stage.
  370|      0|  return DirectAccessBit | LvalueBit | NestByRefBit | row_major_bit;
  371|      0|}
  372|       |
  373|      0|constexpr inline int size_at_compile_time(int rows, int cols) {
  374|      0|  if (rows == 0 || cols == 0) return 0;
  375|      0|  if (rows == Dynamic || cols == Dynamic) return Dynamic;
  376|      0|  return rows * cols;
  377|      0|}
  378|       |
  379|       |template <typename XprType>
  380|       |struct size_of_xpr_at_compile_time {
  381|       |  enum { ret = size_at_compile_time(traits<XprType>::RowsAtCompileTime, traits<XprType>::ColsAtCompileTime) };
  382|       |};
  383|       |
  384|       |/* plain_matrix_type : the difference from eval is that plain_matrix_type is always a plain matrix type,
  385|       | * whereas eval is a const reference in the case of a matrix
  386|       | */
  387|       |
  388|       |template <typename T, typename StorageKind = typename traits<T>::StorageKind>
  389|       |struct plain_matrix_type;
  390|       |template <typename T, typename BaseClassType, int Flags>
  391|       |struct plain_matrix_type_dense;
  392|       |template <typename T>
  393|       |struct plain_matrix_type<T, Dense> {
  394|       |  typedef typename plain_matrix_type_dense<T, typename traits<T>::XprKind, traits<T>::Flags>::type type;
  395|       |};
  396|       |template <typename T>
  397|       |struct plain_matrix_type<T, DiagonalShape> {
  398|       |  typedef typename T::PlainObject type;
  399|       |};
  400|       |
  401|       |template <typename T>
  402|       |struct plain_matrix_type<T, SkewSymmetricShape> {
  403|       |  typedef typename T::PlainObject type;
  404|       |};
  405|       |
  406|       |template <typename T, int Flags>
  407|       |struct plain_matrix_type_dense<T, MatrixXpr, Flags> {
  408|       |  typedef Matrix<typename traits<T>::Scalar, traits<T>::RowsAtCompileTime, traits<T>::ColsAtCompileTime,
  409|       |                 AutoAlign | (Flags & RowMajorBit ? RowMajor : ColMajor), traits<T>::MaxRowsAtCompileTime,
  410|       |                 traits<T>::MaxColsAtCompileTime>
  411|       |      type;
  412|       |};
  413|       |
  414|       |template <typename T, int Flags>
  415|       |struct plain_matrix_type_dense<T, ArrayXpr, Flags> {
  416|       |  typedef Array<typename traits<T>::Scalar, traits<T>::RowsAtCompileTime, traits<T>::ColsAtCompileTime,
  417|       |                AutoAlign | (Flags & RowMajorBit ? RowMajor : ColMajor), traits<T>::MaxRowsAtCompileTime,
  418|       |                traits<T>::MaxColsAtCompileTime>
  419|       |      type;
  420|       |};
  421|       |
  422|       |/* eval : the return type of eval(). For matrices, this is just a const reference
  423|       | * in order to avoid a useless copy
  424|       | */
  425|       |
  426|       |template <typename T, typename StorageKind = typename traits<T>::StorageKind>
  427|       |struct eval;
  428|       |
  429|       |template <typename T>
  430|       |struct eval<T, Dense> {
  431|       |  typedef typename plain_matrix_type<T>::type type;
  432|       |  //   typedef typename T::PlainObject type;
  433|       |  //   typedef T::Matrix<typename traits<T>::Scalar,
  434|       |  //                 traits<T>::RowsAtCompileTime,
  435|       |  //                 traits<T>::ColsAtCompileTime,
  436|       |  //                 AutoAlign | (traits<T>::Flags&RowMajorBit ? RowMajor : ColMajor),
  437|       |  //                 traits<T>::MaxRowsAtCompileTime,
  438|       |  //                 traits<T>::MaxColsAtCompileTime
  439|       |  //           > type;
  440|       |};
  441|       |
  442|       |template <typename T>
  443|       |struct eval<T, DiagonalShape> {
  444|       |  typedef typename plain_matrix_type<T>::type type;
  445|       |};
  446|       |
  447|       |template <typename T>
  448|       |struct eval<T, SkewSymmetricShape> {
  449|       |  typedef typename plain_matrix_type<T>::type type;
  450|       |};
  451|       |
  452|       |// for matrices, no need to evaluate, just use a const reference to avoid a useless copy
  453|       |template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
  454|       |struct eval<Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>, Dense> {
  455|       |  typedef const Matrix<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>& type;
  456|       |};
  457|       |
  458|       |template <typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_>
  459|       |struct eval<Array<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>, Dense> {
  460|       |  typedef const Array<Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_>& type;
  461|       |};
  462|       |
  463|       |/* similar to plain_matrix_type, but using the evaluator's Flags */
  464|       |template <typename T, typename StorageKind = typename traits<T>::StorageKind>
  465|       |struct plain_object_eval;
  466|       |
  467|       |template <typename T>
  468|       |struct plain_object_eval<T, Dense> {
  469|       |  typedef typename plain_matrix_type_dense<T, typename traits<T>::XprKind, evaluator<T>::Flags>::type type;
  470|       |};
  471|       |
  472|       |/* plain_matrix_type_column_major : same as plain_matrix_type but guaranteed to be column-major
  473|       | */
  474|       |template <typename T>
  475|       |struct plain_matrix_type_column_major {
  476|       |  enum {
  477|       |    Rows = traits<T>::RowsAtCompileTime,
  478|       |    Cols = traits<T>::ColsAtCompileTime,
  479|       |    MaxRows = traits<T>::MaxRowsAtCompileTime,
  480|       |    MaxCols = traits<T>::MaxColsAtCompileTime
  481|       |  };
  482|       |  typedef Matrix<typename traits<T>::Scalar, Rows, Cols, (MaxRows == 1 && MaxCols != 1) ? RowMajor : ColMajor, MaxRows,
  483|       |                 MaxCols>
  484|       |      type;
  485|       |};
  486|       |
  487|       |/* plain_matrix_type_row_major : same as plain_matrix_type but guaranteed to be row-major
  488|       | */
  489|       |template <typename T>
  490|       |struct plain_matrix_type_row_major {
  491|       |  enum {
  492|       |    Rows = traits<T>::RowsAtCompileTime,
  493|       |    Cols = traits<T>::ColsAtCompileTime,
  494|       |    MaxRows = traits<T>::MaxRowsAtCompileTime,
  495|       |    MaxCols = traits<T>::MaxColsAtCompileTime
  496|       |  };
  497|       |  typedef Matrix<typename traits<T>::Scalar, Rows, Cols, (MaxCols == 1 && MaxRows != 1) ? ColMajor : RowMajor, MaxRows,
  498|       |                 MaxCols>
  499|       |      type;
  500|       |};
  501|       |
  502|       |/** \internal The reference selector for template expressions. The idea is that we don't
  503|       | * need to use references for expressions since they are light weight proxy
  504|       | * objects which should generate no copying overhead. */
  505|       |template <typename T>
  506|       |struct ref_selector {
  507|       |  typedef std::conditional_t<bool(traits<T>::Flags& NestByRefBit), T const&, const T> type;
  508|       |
  509|       |  typedef std::conditional_t<bool(traits<T>::Flags& NestByRefBit), T&, T> non_const_type;
  510|       |};
  511|       |
  512|       |/** \internal Adds the const qualifier on the value-type of T2 if and only if T1 is a const type */
  513|       |template <typename T1, typename T2>
  514|       |struct transfer_constness {
  515|       |  typedef std::conditional_t<bool(internal::is_const<T1>::value), add_const_on_value_type_t<T2>, T2> type;
  516|       |};
  517|       |
  518|       |// However, we still need a mechanism to detect whether an expression which is evaluated multiple time
  519|       |// has to be evaluated into a temporary.
  520|       |// That's the purpose of this new nested_eval helper:
  521|       |/** \internal Determines how a given expression should be nested when evaluated multiple times.
  522|       | * For example, when you do a * (b+c), Eigen will determine how the expression b+c should be
  523|       | * evaluated into the bigger product expression. The choice is between nesting the expression b+c as-is, or
  524|       | * evaluating that expression b+c into a temporary variable d, and nest d so that the resulting expression is
  525|       | * a*d. Evaluating can be beneficial for example if every coefficient access in the resulting expression causes
  526|       | * many coefficient accesses in the nested expressions -- as is the case with matrix product for example.
  527|       | *
  528|       | * \tparam T the type of the expression being nested.
  529|       | * \tparam n the number of coefficient accesses in the nested expression for each coefficient access in the bigger
  530|       | * expression. \tparam PlainObject the type of the temporary if needed.
  531|       | */
  532|       |template <typename T, int n, typename PlainObject = typename plain_object_eval<T>::type>
  533|       |struct nested_eval {
  534|       |  enum {
  535|       |    ScalarReadCost = NumTraits<typename traits<T>::Scalar>::ReadCost,
  536|       |    CoeffReadCost =
  537|       |        evaluator<T>::CoeffReadCost,  // NOTE What if an evaluator evaluate itself into a temporary?
  538|       |                                      //      Then CoeffReadCost will be small (e.g., 1) but we still have to evaluate,
  539|       |                                      //      especially if n>1. This situation is already taken care by the
  540|       |                                      //      EvalBeforeNestingBit flag, which is turned ON for all evaluator creating a
  541|       |                                      //      temporary. This flag is then propagated by the parent evaluators. Another
  542|       |                                      //      solution could be to count the number of temps?
  543|       |    NAsInteger = n == Dynamic ? HugeCost : n,
  544|       |    CostEval = (NAsInteger + 1) * ScalarReadCost + CoeffReadCost,
  545|       |    CostNoEval = int(NAsInteger) * int(CoeffReadCost),
  546|       |    Evaluate = (int(evaluator<T>::Flags) & EvalBeforeNestingBit) || (int(CostEval) < int(CostNoEval))
  547|       |  };
  548|       |
  549|       |  typedef std::conditional_t<Evaluate, PlainObject, typename ref_selector<T>::type> type;
  550|       |};
  551|       |
  552|       |template <typename T>
  553|       |EIGEN_DEVICE_FUNC inline T* const_cast_ptr(const T* ptr) {
  554|       |  return const_cast<T*>(ptr);
  555|       |}
  556|       |
  557|       |template <typename Derived, typename XprKind = typename traits<Derived>::XprKind>
  558|       |struct dense_xpr_base {
  559|       |  /* dense_xpr_base should only ever be used on dense expressions, thus falling either into the MatrixXpr or into the
  560|       |   * ArrayXpr cases */
  561|       |};
  562|       |
  563|       |template <typename Derived>
  564|       |struct dense_xpr_base<Derived, MatrixXpr> {
  565|       |  typedef MatrixBase<Derived> type;
  566|       |};
  567|       |
  568|       |template <typename Derived>
  569|       |struct dense_xpr_base<Derived, ArrayXpr> {
  570|       |  typedef ArrayBase<Derived> type;
  571|       |};
  572|       |
  573|       |template <typename Derived, typename XprKind = typename traits<Derived>::XprKind,
  574|       |          typename StorageKind = typename traits<Derived>::StorageKind>
  575|       |struct generic_xpr_base;
  576|       |
  577|       |template <typename Derived, typename XprKind>
  578|       |struct generic_xpr_base<Derived, XprKind, Dense> {
  579|       |  typedef typename dense_xpr_base<Derived, XprKind>::type type;
  580|       |};
  581|       |
  582|       |template <typename XprType, typename CastType>
  583|       |struct cast_return_type {
  584|       |  typedef typename XprType::Scalar CurrentScalarType;
  585|       |  typedef remove_all_t<CastType> CastType_;
  586|       |  typedef typename CastType_::Scalar NewScalarType;
  587|       |  typedef std::conditional_t<is_same<CurrentScalarType, NewScalarType>::value, const XprType&, CastType> type;
  588|       |};
  589|       |
  590|       |template <typename A, typename B>
  591|       |struct promote_storage_type;
  592|       |
  593|       |template <typename A>
  594|       |struct promote_storage_type<A, A> {
  595|       |  typedef A ret;
  596|       |};
  597|       |template <typename A>
  598|       |struct promote_storage_type<A, const A> {
  599|       |  typedef A ret;
  600|       |};
  601|       |template <typename A>
  602|       |struct promote_storage_type<const A, A> {
  603|       |  typedef A ret;
  604|       |};
  605|       |
  606|       |/** \internal Specify the "storage kind" of applying a coefficient-wise
  607|       | * binary operations between two expressions of kinds A and B respectively.
  608|       | * The template parameter Functor permits to specialize the resulting storage kind wrt to
  609|       | * the functor.
  610|       | * The default rules are as follows:
  611|       | * \code
  612|       | * A      op A      -> A
  613|       | * A      op dense  -> dense
  614|       | * dense  op B      -> dense
  615|       | * sparse op dense  -> sparse
  616|       | * dense  op sparse -> sparse
  617|       | * \endcode
  618|       | */
  619|       |template <typename A, typename B, typename Functor>
  620|       |struct cwise_promote_storage_type;
  621|       |
  622|       |template <typename A, typename Functor>
  623|       |struct cwise_promote_storage_type<A, A, Functor> {
  624|       |  typedef A ret;
  625|       |};
  626|       |template <typename Functor>
  627|       |struct cwise_promote_storage_type<Dense, Dense, Functor> {
  628|       |  typedef Dense ret;
  629|       |};
  630|       |template <typename A, typename Functor>
  631|       |struct cwise_promote_storage_type<A, Dense, Functor> {
  632|       |  typedef Dense ret;
  633|       |};
  634|       |template <typename B, typename Functor>
  635|       |struct cwise_promote_storage_type<Dense, B, Functor> {
  636|       |  typedef Dense ret;
  637|       |};
  638|       |template <typename Functor>
  639|       |struct cwise_promote_storage_type<Sparse, Dense, Functor> {
  640|       |  typedef Sparse ret;
  641|       |};
  642|       |template <typename Functor>
  643|       |struct cwise_promote_storage_type<Dense, Sparse, Functor> {
  644|       |  typedef Sparse ret;
  645|       |};
  646|       |
  647|       |template <typename LhsKind, typename RhsKind, int LhsOrder, int RhsOrder>
  648|       |struct cwise_promote_storage_order {
  649|       |  enum { value = LhsOrder };
  650|       |};
  651|       |
  652|       |template <typename LhsKind, int LhsOrder, int RhsOrder>
  653|       |struct cwise_promote_storage_order<LhsKind, Sparse, LhsOrder, RhsOrder> {
  654|       |  enum { value = RhsOrder };
  655|       |};
  656|       |template <typename RhsKind, int LhsOrder, int RhsOrder>
  657|       |struct cwise_promote_storage_order<Sparse, RhsKind, LhsOrder, RhsOrder> {
  658|       |  enum { value = LhsOrder };
  659|       |};
  660|       |template <int Order>
  661|       |struct cwise_promote_storage_order<Sparse, Sparse, Order, Order> {
  662|       |  enum { value = Order };
  663|       |};
  664|       |
  665|       |/** \internal Specify the "storage kind" of multiplying an expression of kind A with kind B.
  666|       | * The template parameter ProductTag permits to specialize the resulting storage kind wrt to
  667|       | * some compile-time properties of the product: GemmProduct, GemvProduct, OuterProduct, InnerProduct.
  668|       | * The default rules are as follows:
  669|       | * \code
  670|       | *  K * K            -> K
  671|       | *  dense * K        -> dense
  672|       | *  K * dense        -> dense
  673|       | *  diag * K         -> K
  674|       | *  K * diag         -> K
  675|       | *  Perm * K         -> K
  676|       | * K * Perm          -> K
  677|       | * \endcode
  678|       | */
  679|       |template <typename A, typename B, int ProductTag>
  680|       |struct product_promote_storage_type;
  681|       |
  682|       |template <typename A, int ProductTag>
  683|       |struct product_promote_storage_type<A, A, ProductTag> {
  684|       |  typedef A ret;
  685|       |};
  686|       |template <int ProductTag>
  687|       |struct product_promote_storage_type<Dense, Dense, ProductTag> {
  688|       |  typedef Dense ret;
  689|       |};
  690|       |template <typename A, int ProductTag>
  691|       |struct product_promote_storage_type<A, Dense, ProductTag> {
  692|       |  typedef Dense ret;
  693|       |};
  694|       |template <typename B, int ProductTag>
  695|       |struct product_promote_storage_type<Dense, B, ProductTag> {
  696|       |  typedef Dense ret;
  697|       |};
  698|       |
  699|       |template <typename A, int ProductTag>
  700|       |struct product_promote_storage_type<A, DiagonalShape, ProductTag> {
  701|       |  typedef A ret;
  702|       |};
  703|       |template <typename B, int ProductTag>
  704|       |struct product_promote_storage_type<DiagonalShape, B, ProductTag> {
  705|       |  typedef B ret;
  706|       |};
  707|       |template <int ProductTag>
  708|       |struct product_promote_storage_type<Dense, DiagonalShape, ProductTag> {
  709|       |  typedef Dense ret;
  710|       |};
  711|       |template <int ProductTag>
  712|       |struct product_promote_storage_type<DiagonalShape, Dense, ProductTag> {
  713|       |  typedef Dense ret;
  714|       |};
  715|       |
  716|       |template <typename A, int ProductTag>
  717|       |struct product_promote_storage_type<A, SkewSymmetricShape, ProductTag> {
  718|       |  typedef A ret;
  719|       |};
  720|       |template <typename B, int ProductTag>
  721|       |struct product_promote_storage_type<SkewSymmetricShape, B, ProductTag> {
  722|       |  typedef B ret;
  723|       |};
  724|       |template <int ProductTag>
  725|       |struct product_promote_storage_type<Dense, SkewSymmetricShape, ProductTag> {
  726|       |  typedef Dense ret;
  727|       |};
  728|       |template <int ProductTag>
  729|       |struct product_promote_storage_type<SkewSymmetricShape, Dense, ProductTag> {
  730|       |  typedef Dense ret;
  731|       |};
  732|       |template <int ProductTag>
  733|       |struct product_promote_storage_type<SkewSymmetricShape, SkewSymmetricShape, ProductTag> {
  734|       |  typedef Dense ret;
  735|       |};
  736|       |
  737|       |template <typename A, int ProductTag>
  738|       |struct product_promote_storage_type<A, PermutationStorage, ProductTag> {
  739|       |  typedef A ret;
  740|       |};
  741|       |template <typename B, int ProductTag>
  742|       |struct product_promote_storage_type<PermutationStorage, B, ProductTag> {
  743|       |  typedef B ret;
  744|       |};
  745|       |template <int ProductTag>
  746|       |struct product_promote_storage_type<Dense, PermutationStorage, ProductTag> {
  747|       |  typedef Dense ret;
  748|       |};
  749|       |template <int ProductTag>
  750|       |struct product_promote_storage_type<PermutationStorage, Dense, ProductTag> {
  751|       |  typedef Dense ret;
  752|       |};
  753|       |
  754|       |/** \internal gives the plain matrix or array type to store a row/column/diagonal of a matrix type.
  755|       | * \tparam Scalar optional parameter allowing to pass a different scalar type than the one of the MatrixType.
  756|       | */
  757|       |template <typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
  758|       |struct plain_row_type {
  759|       |  typedef Matrix<Scalar, 1, ExpressionType::ColsAtCompileTime,
  760|       |                 int(ExpressionType::PlainObject::Options) | int(RowMajor), 1, ExpressionType::MaxColsAtCompileTime>
  761|       |      MatrixRowType;
  762|       |  typedef Array<Scalar, 1, ExpressionType::ColsAtCompileTime, int(ExpressionType::PlainObject::Options) | int(RowMajor),
  763|       |                1, ExpressionType::MaxColsAtCompileTime>
  764|       |      ArrayRowType;
  765|       |
  766|       |  typedef std::conditional_t<is_same<typename traits<ExpressionType>::XprKind, MatrixXpr>::value, MatrixRowType,
  767|       |                             ArrayRowType>
  768|       |      type;
  769|       |};
  770|       |
  771|       |template <typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
  772|       |struct plain_col_type {
  773|       |  typedef Matrix<Scalar, ExpressionType::RowsAtCompileTime, 1, ExpressionType::PlainObject::Options & ~RowMajor,
  774|       |                 ExpressionType::MaxRowsAtCompileTime, 1>
  775|       |      MatrixColType;
  776|       |  typedef Array<Scalar, ExpressionType::RowsAtCompileTime, 1, ExpressionType::PlainObject::Options & ~RowMajor,
  777|       |                ExpressionType::MaxRowsAtCompileTime, 1>
  778|       |      ArrayColType;
  779|       |
  780|       |  typedef std::conditional_t<is_same<typename traits<ExpressionType>::XprKind, MatrixXpr>::value, MatrixColType,
  781|       |                             ArrayColType>
  782|       |      type;
  783|       |};
  784|       |
  785|       |template <typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
  786|       |struct plain_diag_type {
  787|       |  enum {
  788|       |    diag_size = internal::min_size_prefer_dynamic(ExpressionType::RowsAtCompileTime, ExpressionType::ColsAtCompileTime),
  789|       |    max_diag_size = min_size_prefer_fixed(ExpressionType::MaxRowsAtCompileTime, ExpressionType::MaxColsAtCompileTime)
  790|       |  };
  791|       |  typedef Matrix<Scalar, diag_size, 1, ExpressionType::PlainObject::Options & ~RowMajor, max_diag_size, 1>
  792|       |      MatrixDiagType;
  793|       |  typedef Array<Scalar, diag_size, 1, ExpressionType::PlainObject::Options & ~RowMajor, max_diag_size, 1> ArrayDiagType;
  794|       |
  795|       |  typedef std::conditional_t<is_same<typename traits<ExpressionType>::XprKind, MatrixXpr>::value, MatrixDiagType,
  796|       |                             ArrayDiagType>
  797|       |      type;
  798|       |};
  799|       |
  800|       |template <typename Expr, typename Scalar = typename Expr::Scalar>
  801|       |struct plain_constant_type {
  802|       |  enum { Options = (traits<Expr>::Flags & RowMajorBit) ? RowMajor : 0 };
  803|       |
  804|       |  typedef Array<Scalar, traits<Expr>::RowsAtCompileTime, traits<Expr>::ColsAtCompileTime, Options,
  805|       |                traits<Expr>::MaxRowsAtCompileTime, traits<Expr>::MaxColsAtCompileTime>
  806|       |      array_type;
  807|       |
  808|       |  typedef Matrix<Scalar, traits<Expr>::RowsAtCompileTime, traits<Expr>::ColsAtCompileTime, Options,
  809|       |                 traits<Expr>::MaxRowsAtCompileTime, traits<Expr>::MaxColsAtCompileTime>
  810|       |      matrix_type;
  811|       |
  812|       |  typedef CwiseNullaryOp<
  813|       |      scalar_constant_op<Scalar>,
  814|       |      const std::conditional_t<is_same<typename traits<Expr>::XprKind, MatrixXpr>::value, matrix_type, array_type>>
  815|       |      type;
  816|       |};
  817|       |
  818|       |template <typename ExpressionType>
  819|       |struct is_lvalue {
  820|       |  enum { value = (!bool(is_const<ExpressionType>::value)) && bool(traits<ExpressionType>::Flags & LvalueBit) };
  821|       |};
  822|       |
  823|       |template <typename T>
  824|       |struct is_diagonal {
  825|       |  enum { ret = false };
  826|       |};
  827|       |
  828|       |template <typename T>
  829|       |struct is_diagonal<DiagonalBase<T>> {
  830|       |  enum { ret = true };
  831|       |};
  832|       |
  833|       |template <typename T>
  834|       |struct is_diagonal<DiagonalWrapper<T>> {
  835|       |  enum { ret = true };
  836|       |};
  837|       |
  838|       |template <typename T, int S>
  839|       |struct is_diagonal<DiagonalMatrix<T, S>> {
  840|       |  enum { ret = true };
  841|       |};
  842|       |
  843|       |template <typename T>
  844|       |struct is_identity {
  845|       |  enum { value = false };
  846|       |};
  847|       |
  848|       |template <typename T>
  849|       |struct is_identity<CwiseNullaryOp<internal::scalar_identity_op<typename T::Scalar>, T>> {
  850|       |  enum { value = true };
  851|       |};
  852|       |
  853|       |template <typename S1, typename S2>
  854|       |struct glue_shapes;
  855|       |template <>
  856|       |struct glue_shapes<DenseShape, TriangularShape> {
  857|       |  typedef TriangularShape type;
  858|       |};
  859|       |
  860|       |template <typename T1, typename T2>
  861|       |struct possibly_same_dense {
  862|       |  enum {
  863|       |    value = has_direct_access<T1>::ret && has_direct_access<T2>::ret &&
  864|       |            is_same<typename T1::Scalar, typename T2::Scalar>::value
  865|       |  };
  866|       |};
  867|       |
  868|       |template <typename T1, typename T2>
  869|       |EIGEN_DEVICE_FUNC bool is_same_dense(const T1& mat1, const T2& mat2,
  870|       |                                     std::enable_if_t<possibly_same_dense<T1, T2>::value>* = 0) {
  871|       |  return (mat1.data() == mat2.data()) && (mat1.innerStride() == mat2.innerStride()) &&
  872|       |         (mat1.outerStride() == mat2.outerStride());
  873|       |}
  874|       |
  875|       |template <typename T1, typename T2>
  876|       |EIGEN_DEVICE_FUNC bool is_same_dense(const T1&, const T2&, std::enable_if_t<!possibly_same_dense<T1, T2>::value>* = 0) {
  877|       |  return false;
  878|       |}
  879|       |
  880|       |// Internal helper defining the cost of a scalar division for the type T.
  881|       |// The default heuristic can be specialized for each scalar type and architecture.
  882|       |template <typename T, bool Vectorized = false, typename EnableIf = void>
  883|       |struct scalar_div_cost {
  884|       |  enum { value = 8 * NumTraits<T>::MulCost };
  885|       |};
  886|       |
  887|       |template <typename T, bool Vectorized>
  888|       |struct scalar_div_cost<std::complex<T>, Vectorized> {
  889|       |  enum { value = 2 * scalar_div_cost<T>::value + 6 * NumTraits<T>::MulCost + 3 * NumTraits<T>::AddCost };
  890|       |};
  891|       |
  892|       |template <bool Vectorized>
  893|       |struct scalar_div_cost<signed long, Vectorized, std::conditional_t<sizeof(long) == 8, void, false_type>> {
  894|       |  enum { value = 24 };
  895|       |};
  896|       |template <bool Vectorized>
  897|       |struct scalar_div_cost<unsigned long, Vectorized, std::conditional_t<sizeof(long) == 8, void, false_type>> {
  898|       |  enum { value = 21 };
  899|       |};
  900|       |
  901|       |#ifdef EIGEN_DEBUG_ASSIGN
  902|       |std::string demangle_traversal(int t) {
  903|       |  if (t == DefaultTraversal) return "DefaultTraversal";
  904|       |  if (t == LinearTraversal) return "LinearTraversal";
  905|       |  if (t == InnerVectorizedTraversal) return "InnerVectorizedTraversal";
  906|       |  if (t == LinearVectorizedTraversal) return "LinearVectorizedTraversal";
  907|       |  if (t == SliceVectorizedTraversal) return "SliceVectorizedTraversal";
  908|       |  return "?";
  909|       |}
  910|       |std::string demangle_unrolling(int t) {
  911|       |  if (t == NoUnrolling) return "NoUnrolling";
  912|       |  if (t == InnerUnrolling) return "InnerUnrolling";
  913|       |  if (t == CompleteUnrolling) return "CompleteUnrolling";
  914|       |  return "?";
  915|       |}
  916|       |std::string demangle_flags(int f) {
  917|       |  std::string res;
  918|       |  if (f & RowMajorBit) res += " | RowMajor";
  919|       |  if (f & PacketAccessBit) res += " | Packet";
  920|       |  if (f & LinearAccessBit) res += " | Linear";
  921|       |  if (f & LvalueBit) res += " | Lvalue";
  922|       |  if (f & DirectAccessBit) res += " | Direct";
  923|       |  if (f & NestByRefBit) res += " | NestByRef";
  924|       |  if (f & NoPreferredStorageOrderBit) res += " | NoPreferredStorageOrderBit";
  925|       |
  926|       |  return res;
  927|       |}
  928|       |#endif
  929|       |
  930|       |template <typename XprType>
  931|       |struct is_block_xpr : std::false_type {};
  932|       |
  933|       |template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
  934|       |struct is_block_xpr<Block<XprType, BlockRows, BlockCols, InnerPanel>> : std::true_type {};
  935|       |
  936|       |template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
  937|       |struct is_block_xpr<const Block<XprType, BlockRows, BlockCols, InnerPanel>> : std::true_type {};
  938|       |
  939|       |// Helper utility for constructing non-recursive block expressions.
  940|       |template <typename XprType>
  941|       |struct block_xpr_helper {
  942|       |  using BaseType = XprType;
  943|       |
  944|       |  // For regular block expressions, simply forward along the InnerPanel argument,
  945|       |  // which is set when calling row/column expressions.
  946|       |  static constexpr bool is_inner_panel(bool inner_panel) { return inner_panel; }
  947|       |
  948|       |  // Only enable non-const base function if XprType is not const (otherwise we get a duplicate definition).
  949|       |  template <typename T = XprType, typename EnableIf = std::enable_if_t<!std::is_const<T>::value>>
  950|       |  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BaseType& base(XprType& xpr) {
  951|       |    return xpr;
  952|       |  }
  953|       |  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE const BaseType& base(const XprType& xpr) { return xpr; }
  954|       |  static constexpr EIGEN_ALWAYS_INLINE Index row(const XprType& /*xpr*/, Index r) { return r; }
  955|       |  static constexpr EIGEN_ALWAYS_INLINE Index col(const XprType& /*xpr*/, Index c) { return c; }
  956|       |};
  957|       |
  958|       |template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
  959|       |struct block_xpr_helper<Block<XprType, BlockRows, BlockCols, InnerPanel>> {
  960|       |  using BlockXprType = Block<XprType, BlockRows, BlockCols, InnerPanel>;
  961|       |  // Recursive helper in case of explicit block-of-block expression.
  962|       |  using NestedXprHelper = block_xpr_helper<XprType>;
  963|       |  using BaseType = typename NestedXprHelper::BaseType;
  964|       |
  965|       |  // For block-of-block expressions, we need to combine the InnerPannel trait
  966|       |  // with that of the block subexpression.
  967|       |  static constexpr bool is_inner_panel(bool inner_panel) { return InnerPanel && inner_panel; }
  968|       |
  969|       |  // Only enable non-const base function if XprType is not const (otherwise we get a duplicates definition).
  970|       |  template <typename T = XprType, typename EnableIf = std::enable_if_t<!std::is_const<T>::value>>
  971|       |  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BaseType& base(BlockXprType& xpr) {
  972|       |    return NestedXprHelper::base(xpr.nestedExpression());
  973|       |  }
  974|       |  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE const BaseType& base(const BlockXprType& xpr) {
  975|       |    return NestedXprHelper::base(xpr.nestedExpression());
  976|       |  }
  977|       |  static constexpr EIGEN_ALWAYS_INLINE Index row(const BlockXprType& xpr, Index r) {
  978|       |    return xpr.startRow() + NestedXprHelper::row(xpr.nestedExpression(), r);
  979|       |  }
  980|       |  static constexpr EIGEN_ALWAYS_INLINE Index col(const BlockXprType& xpr, Index c) {
  981|       |    return xpr.startCol() + NestedXprHelper::col(xpr.nestedExpression(), c);
  982|       |  }
  983|       |};
  984|       |
  985|       |template <typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
  986|       |struct block_xpr_helper<const Block<XprType, BlockRows, BlockCols, InnerPanel>>
  987|       |    : block_xpr_helper<Block<XprType, BlockRows, BlockCols, InnerPanel>> {};
  988|       |
  989|       |template <typename XprType>
  990|       |struct is_matrix_base_xpr : std::is_base_of<MatrixBase<remove_all_t<XprType>>, remove_all_t<XprType>> {};
  991|       |
  992|       |template <typename XprType>
  993|       |struct is_permutation_base_xpr : std::is_base_of<PermutationBase<remove_all_t<XprType>>, remove_all_t<XprType>> {};
  994|       |
  995|       |}  // end namespace internal
  996|       |
  997|       |/** \class ScalarBinaryOpTraits
  998|       |  * \ingroup Core_Module
  999|       |  *
 1000|       |  * \brief Determines whether the given binary operation of two numeric types is allowed and what the scalar return type
 1001|       |  is.
 1002|       |  *
 1003|       |  * This class permits to control the scalar return type of any binary operation performed on two different scalar types
 1004|       |  through (partial) template specializations.
 1005|       |  *
 1006|       |  * For instance, let \c U1, \c U2 and \c U3 be three user defined scalar types for which most operations between
 1007|       |  instances of \c U1 and \c U2 returns an \c U3.
 1008|       |  * You can let %Eigen knows that by defining:
 1009|       |    \code
 1010|       |    template<typename BinaryOp>
 1011|       |    struct ScalarBinaryOpTraits<U1,U2,BinaryOp> { typedef U3 ReturnType;  };
 1012|       |    template<typename BinaryOp>
 1013|       |    struct ScalarBinaryOpTraits<U2,U1,BinaryOp> { typedef U3 ReturnType;  };
 1014|       |    \endcode
 1015|       |  * You can then explicitly disable some particular operations to get more explicit error messages:
 1016|       |    \code
 1017|       |    template<>
 1018|       |    struct ScalarBinaryOpTraits<U1,U2,internal::scalar_max_op<U1,U2> > {};
 1019|       |    \endcode
 1020|       |  * Or customize the return type for individual operation:
 1021|       |    \code
 1022|       |    template<>
 1023|       |    struct ScalarBinaryOpTraits<U1,U2,internal::scalar_sum_op<U1,U2> > { typedef U1 ReturnType; };
 1024|       |    \endcode
 1025|       |  *
 1026|       |  * By default, the following generic combinations are supported:
 1027|       |  <table class="manual">
 1028|       |  <tr><th>ScalarA</th><th>ScalarB</th><th>BinaryOp</th><th>ReturnType</th><th>Note</th></tr>
 1029|       |  <tr            ><td>\c T </td><td>\c T </td><td>\c * </td><td>\c T </td><td></td></tr>
 1030|       |  <tr class="alt"><td>\c NumTraits<T>::Real </td><td>\c T </td><td>\c * </td><td>\c T </td><td>Only if \c
 1031|       |  NumTraits<T>::IsComplex </td></tr> <tr            ><td>\c T </td><td>\c NumTraits<T>::Real </td><td>\c * </td><td>\c T
 1032|       |  </td><td>Only if \c NumTraits<T>::IsComplex </td></tr>
 1033|       |  </table>
 1034|       |  *
 1035|       |  * \sa CwiseBinaryOp
 1036|       |  */
 1037|       |template <typename ScalarA, typename ScalarB, typename BinaryOp = internal::scalar_product_op<ScalarA, ScalarB>>
 1038|       |struct ScalarBinaryOpTraits
 1039|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
 1040|       |    // for backward compatibility, use the hints given by the (deprecated) internal::scalar_product_traits class.
 1041|       |    : internal::scalar_product_traits<ScalarA, ScalarB>
 1042|       |#endif  // EIGEN_PARSED_BY_DOXYGEN
 1043|       |{
 1044|       |};
 1045|       |
 1046|       |template <typename T, typename BinaryOp>
 1047|       |struct ScalarBinaryOpTraits<T, T, BinaryOp> {
 1048|       |  typedef T ReturnType;
 1049|       |};
 1050|       |
 1051|       |template <typename T, typename BinaryOp>
 1052|       |struct ScalarBinaryOpTraits<T, typename NumTraits<std::enable_if_t<NumTraits<T>::IsComplex, T>>::Real, BinaryOp> {
 1053|       |  typedef T ReturnType;
 1054|       |};
 1055|       |template <typename T, typename BinaryOp>
 1056|       |struct ScalarBinaryOpTraits<typename NumTraits<std::enable_if_t<NumTraits<T>::IsComplex, T>>::Real, T, BinaryOp> {
 1057|       |  typedef T ReturnType;
 1058|       |};
 1059|       |
 1060|       |// For Matrix * Permutation
 1061|       |template <typename T, typename BinaryOp>
 1062|       |struct ScalarBinaryOpTraits<T, void, BinaryOp> {
 1063|       |  typedef T ReturnType;
 1064|       |};
 1065|       |
 1066|       |// For Permutation * Matrix
 1067|       |template <typename T, typename BinaryOp>
 1068|       |struct ScalarBinaryOpTraits<void, T, BinaryOp> {
 1069|       |  typedef T ReturnType;
 1070|       |};
 1071|       |
 1072|       |// for Permutation*Permutation
 1073|       |template <typename BinaryOp>
 1074|       |struct ScalarBinaryOpTraits<void, void, BinaryOp> {
 1075|       |  typedef void ReturnType;
 1076|       |};
 1077|       |
 1078|       |// We require Lhs and Rhs to have "compatible" scalar types.
 1079|       |// It is tempting to always allow mixing different types but remember that this is often impossible in the vectorized
 1080|       |// paths. So allowing mixing different types gives very unexpected errors when enabling vectorization, when the user
 1081|       |// tries to add together a float matrix and a double matrix.
 1082|       |#define EIGEN_CHECK_BINARY_COMPATIBILIY(BINOP, LHS, RHS)                               \
 1083|      4|  EIGEN_STATIC_ASSERT(                                                                 \
 1084|      4|      (Eigen::internal::has_ReturnType<ScalarBinaryOpTraits<LHS, RHS, BINOP>>::value), \
 1085|      4|      YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY)
 1086|       |
 1087|       |}  // end namespace Eigen
 1088|       |
 1089|       |#endif  // EIGEN_XPRHELPER_H

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/plugins/BlockMethods.inc:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
   12|       |
   13|       |/// \internal expression type of a column */
   14|       |typedef Block<Derived, internal::traits<Derived>::RowsAtCompileTime, 1, !IsRowMajor> ColXpr;
   15|       |typedef const Block<const Derived, internal::traits<Derived>::RowsAtCompileTime, 1, !IsRowMajor> ConstColXpr;
   16|       |/// \internal expression type of a row */
   17|       |typedef Block<Derived, 1, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> RowXpr;
   18|       |typedef const Block<const Derived, 1, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> ConstRowXpr;
   19|       |/// \internal expression type of a block of whole columns */
   20|       |typedef Block<Derived, internal::traits<Derived>::RowsAtCompileTime, Dynamic, !IsRowMajor> ColsBlockXpr;
   21|       |typedef const Block<const Derived, internal::traits<Derived>::RowsAtCompileTime, Dynamic, !IsRowMajor>
   22|       |    ConstColsBlockXpr;
   23|       |/// \internal expression type of a block of whole rows */
   24|       |typedef Block<Derived, Dynamic, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> RowsBlockXpr;
   25|       |typedef const Block<const Derived, Dynamic, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> ConstRowsBlockXpr;
   26|       |/// \internal expression type of a block of whole columns */
   27|       |template <int N>
   28|       |struct NColsBlockXpr {
   29|       |  typedef Block<Derived, internal::traits<Derived>::RowsAtCompileTime, N, !IsRowMajor> Type;
   30|       |};
   31|       |template <int N>
   32|       |struct ConstNColsBlockXpr {
   33|       |  typedef const Block<const Derived, internal::traits<Derived>::RowsAtCompileTime, N, !IsRowMajor> Type;
   34|       |};
   35|       |/// \internal expression type of a block of whole rows */
   36|       |template <int N>
   37|       |struct NRowsBlockXpr {
   38|       |  typedef Block<Derived, N, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> Type;
   39|       |};
   40|       |template <int N>
   41|       |struct ConstNRowsBlockXpr {
   42|       |  typedef const Block<const Derived, N, internal::traits<Derived>::ColsAtCompileTime, IsRowMajor> Type;
   43|       |};
   44|       |/// \internal expression of a block */
   45|       |typedef Block<Derived> BlockXpr;
   46|       |typedef const Block<const Derived> ConstBlockXpr;
   47|       |/// \internal expression of a block of fixed sizes */
   48|       |template <int Rows, int Cols>
   49|       |struct FixedBlockXpr {
   50|       |  typedef Block<Derived, Rows, Cols> Type;
   51|       |};
   52|       |template <int Rows, int Cols>
   53|       |struct ConstFixedBlockXpr {
   54|       |  typedef Block<const Derived, Rows, Cols> Type;
   55|       |};
   56|       |
   57|       |typedef VectorBlock<Derived> SegmentReturnType;
   58|       |typedef const VectorBlock<const Derived> ConstSegmentReturnType;
   59|       |template <int Size>
   60|       |struct FixedSegmentReturnType {
   61|       |  typedef VectorBlock<Derived, Size> Type;
   62|       |};
   63|       |template <int Size>
   64|       |struct ConstFixedSegmentReturnType {
   65|       |  typedef const VectorBlock<const Derived, Size> Type;
   66|       |};
   67|       |
   68|       |/// \internal inner-vector
   69|       |typedef Block<Derived, IsRowMajor ? 1 : Dynamic, IsRowMajor ? Dynamic : 1, true> InnerVectorReturnType;
   70|       |typedef Block<const Derived, IsRowMajor ? 1 : Dynamic, IsRowMajor ? Dynamic : 1, true> ConstInnerVectorReturnType;
   71|       |
   72|       |/// \internal set of inner-vectors
   73|       |typedef Block<Derived, Dynamic, Dynamic, true> InnerVectorsReturnType;
   74|       |typedef Block<const Derived, Dynamic, Dynamic, true> ConstInnerVectorsReturnType;
   75|       |
   76|       |#endif  // not EIGEN_PARSED_BY_DOXYGEN
   77|       |
   78|       |/// \returns an expression of a block in \c *this with either dynamic or fixed sizes.
   79|       |///
   80|       |/// \param  startRow  the first row in the block
   81|       |/// \param  startCol  the first column in the block
   82|       |/// \param  blockRows number of rows in the block, specified at either run-time or compile-time
   83|       |/// \param  blockCols number of columns in the block, specified at either run-time or compile-time
   84|       |/// \tparam NRowsType the type of the value handling the number of rows in the block, typically Index.
   85|       |/// \tparam NColsType the type of the value handling the number of columns in the block, typically Index.
   86|       |///
   87|       |/// Example using runtime (aka dynamic) sizes: \include MatrixBase_block_int_int_int_int.cpp
   88|       |/// Output: \verbinclude MatrixBase_block_int_int_int_int.out
   89|       |///
   90|       |/// \newin{3.4}:
   91|       |///
   92|       |/// The number of rows \a blockRows and columns \a blockCols can also be specified at compile-time by passing
   93|       |/// Eigen::fix<N>, or Eigen::fix<N>(n) as arguments. In the later case, \c n plays the role of a runtime fallback value
   94|       |/// in case \c N equals Eigen::Dynamic. Here is an example with a fixed number of rows \c NRows and dynamic number of
   95|       |/// columns \c cols: \code mat.block(i,j,fix<NRows>,cols) \endcode
   96|       |///
   97|       |/// This function thus fully covers the features offered by the following overloads block<NRows,NCols>(Index, Index),
   98|       |/// and block<NRows,NCols>(Index, Index, Index, Index) that are thus obsolete. Indeed, this generic version avoids
   99|       |/// redundancy, it preserves the argument order, and prevents the need to rely on the template keyword in templated
  100|       |/// code.
  101|       |///
  102|       |/// but with less redundancy and more consistency as it does not modify the argument order
  103|       |/// and seamlessly enable hybrid fixed/dynamic sizes.
  104|       |///
  105|       |/// \note Even in the case that the returned expression has dynamic size, in the case
  106|       |/// when it is applied to a fixed-size matrix, it inherits a fixed maximal size,
  107|       |/// which means that evaluating it does not cause a dynamic memory allocation.
  108|       |///
  109|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  110|       |///
  111|       |/// \sa class Block, fix, fix<N>(int)
  112|       |///
  113|       |template <typename NRowsType, typename NColsType>
  114|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  115|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  116|       |    typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  117|       |                           internal::get_fixed_value<NColsType>::value>::Type
  118|       |#else
  119|       |    typename FixedBlockXpr<..., ...>::Type
  120|       |#endif
  121|       |    block(Index startRow, Index startCol, NRowsType blockRows, NColsType blockCols) {
  122|       |  return
  123|       |      typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  124|       |                             internal::get_fixed_value<NColsType>::value>::Type(derived(), startRow, startCol,
  125|       |                                                                                internal::get_runtime_value(blockRows),
  126|       |                                                                                internal::get_runtime_value(blockCols));
  127|       |}
  128|       |
  129|       |/// This is the const version of block(Index,Index,NRowsType,NColsType)
  130|       |template <typename NRowsType, typename NColsType>
  131|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  132|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  133|       |    const typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  134|       |                                      internal::get_fixed_value<NColsType>::value>::Type
  135|       |#else
  136|       |    const typename ConstFixedBlockXpr<..., ...>::Type
  137|       |#endif
  138|       |    block(Index startRow, Index startCol, NRowsType blockRows, NColsType blockCols) const {
  139|       |  return typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  140|       |                                     internal::get_fixed_value<NColsType>::value>::Type(derived(), startRow, startCol,
  141|       |                                                                                        internal::get_runtime_value(
  142|       |                                                                                            blockRows),
  143|       |                                                                                        internal::get_runtime_value(
  144|       |                                                                                            blockCols));
  145|       |}
  146|       |
  147|       |/// \returns a expression of a top-right corner of \c *this with either dynamic or fixed sizes.
  148|       |///
  149|       |/// \param cRows the number of rows in the corner
  150|       |/// \param cCols the number of columns in the corner
  151|       |/// \tparam NRowsType the type of the value handling the number of rows in the block, typically Index.
  152|       |/// \tparam NColsType the type of the value handling the number of columns in the block, typically Index.
  153|       |///
  154|       |/// Example with dynamic sizes: \include MatrixBase_topRightCorner_int_int.cpp
  155|       |/// Output: \verbinclude MatrixBase_topRightCorner_int_int.out
  156|       |///
  157|       |/// The number of rows \a blockRows and columns \a blockCols can also be specified at compile-time by passing
  158|       |/// Eigen::fix<N>, or Eigen::fix<N>(n) as arguments. See \link block(Index,Index,NRowsType,NColsType) block() \endlink
  159|       |/// for the details.
  160|       |///
  161|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  162|       |///
  163|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  164|       |///
  165|       |template <typename NRowsType, typename NColsType>
  166|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  167|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  168|       |    typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  169|       |                           internal::get_fixed_value<NColsType>::value>::Type
  170|       |#else
  171|       |    typename FixedBlockXpr<..., ...>::Type
  172|       |#endif
  173|       |    topRightCorner(NRowsType cRows, NColsType cCols) {
  174|       |  return typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  175|       |                                internal::get_fixed_value<NColsType>::value>::Type(derived(), 0,
  176|       |                                                                                   cols() - internal::get_runtime_value(
  177|       |                                                                                                cCols),
  178|       |                                                                                   internal::get_runtime_value(cRows),
  179|       |                                                                                   internal::get_runtime_value(cCols));
  180|       |}
  181|       |
  182|       |/// This is the const version of topRightCorner(NRowsType, NColsType).
  183|       |template <typename NRowsType, typename NColsType>
  184|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  185|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  186|       |    const typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  187|       |                                      internal::get_fixed_value<NColsType>::value>::Type
  188|       |#else
  189|       |    const typename ConstFixedBlockXpr<..., ...>::Type
  190|       |#endif
  191|       |    topRightCorner(NRowsType cRows, NColsType cCols) const {
  192|       |  return
  193|       |      typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  194|       |                                  internal::get_fixed_value<NColsType>::value>::Type(derived(), 0,
  195|       |                                                                                     cols() -
  196|       |                                                                                         internal::get_runtime_value(
  197|       |                                                                                             cCols),
  198|       |                                                                                     internal::get_runtime_value(cRows),
  199|       |                                                                                     internal::get_runtime_value(
  200|       |                                                                                         cCols));
  201|       |}
  202|       |
  203|       |/// \returns an expression of a fixed-size top-right corner of \c *this.
  204|       |///
  205|       |/// \tparam CRows the number of rows in the corner
  206|       |/// \tparam CCols the number of columns in the corner
  207|       |///
  208|       |/// Example: \include MatrixBase_template_int_int_topRightCorner.cpp
  209|       |/// Output: \verbinclude MatrixBase_template_int_int_topRightCorner.out
  210|       |///
  211|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  212|       |///
  213|       |/// \sa class Block, block<int,int>(Index,Index)
  214|       |///
  215|       |template <int CRows, int CCols>
  216|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedBlockXpr<CRows, CCols>::Type topRightCorner() {
  217|       |  return typename FixedBlockXpr<CRows, CCols>::Type(derived(), 0, cols() - CCols);
  218|       |}
  219|       |
  220|       |/// This is the const version of topRightCorner<int, int>().
  221|       |template <int CRows, int CCols>
  222|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<CRows, CCols>::Type topRightCorner() const {
  223|       |  return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), 0, cols() - CCols);
  224|       |}
  225|       |
  226|       |/// \returns an expression of a top-right corner of \c *this.
  227|       |///
  228|       |/// \tparam CRows number of rows in corner as specified at compile-time
  229|       |/// \tparam CCols number of columns in corner as specified at compile-time
  230|       |/// \param  cRows number of rows in corner as specified at run-time
  231|       |/// \param  cCols number of columns in corner as specified at run-time
  232|       |///
  233|       |/// This function is mainly useful for corners where the number of rows is specified at compile-time
  234|       |/// and the number of columns is specified at run-time, or vice versa. The compile-time and run-time
  235|       |/// information should not contradict. In other words, \a cRows should equal \a CRows unless
  236|       |/// \a CRows is \a Dynamic, and the same for the number of columns.
  237|       |///
  238|       |/// Example: \include MatrixBase_template_int_int_topRightCorner_int_int.cpp
  239|       |/// Output: \verbinclude MatrixBase_template_int_int_topRightCorner_int_int.out
  240|       |///
  241|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  242|       |///
  243|       |/// \sa class Block
  244|       |///
  245|       |template <int CRows, int CCols>
  246|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedBlockXpr<CRows, CCols>::Type topRightCorner(Index cRows,
  247|       |                                                                                                Index cCols) {
  248|       |  return typename FixedBlockXpr<CRows, CCols>::Type(derived(), 0, cols() - cCols, cRows, cCols);
  249|       |}
  250|       |
  251|       |/// This is the const version of topRightCorner<int, int>(Index, Index).
  252|       |template <int CRows, int CCols>
  253|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<CRows, CCols>::Type topRightCorner(
  254|       |    Index cRows, Index cCols) const {
  255|       |  return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), 0, cols() - cCols, cRows, cCols);
  256|       |}
  257|       |
  258|       |/// \returns an expression of a top-left corner of \c *this  with either dynamic or fixed sizes.
  259|       |///
  260|       |/// \param cRows the number of rows in the corner
  261|       |/// \param cCols the number of columns in the corner
  262|       |/// \tparam NRowsType the type of the value handling the number of rows in the block, typically Index.
  263|       |/// \tparam NColsType the type of the value handling the number of columns in the block, typically Index.
  264|       |///
  265|       |/// Example: \include MatrixBase_topLeftCorner_int_int.cpp
  266|       |/// Output: \verbinclude MatrixBase_topLeftCorner_int_int.out
  267|       |///
  268|       |/// The number of rows \a blockRows and columns \a blockCols can also be specified at compile-time by passing
  269|       |/// Eigen::fix<N>, or Eigen::fix<N>(n) as arguments. See \link block(Index,Index,NRowsType,NColsType) block() \endlink
  270|       |/// for the details.
  271|       |///
  272|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  273|       |///
  274|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  275|       |///
  276|       |template <typename NRowsType, typename NColsType>
  277|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  278|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  279|       |    typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  280|       |                           internal::get_fixed_value<NColsType>::value>::Type
  281|       |#else
  282|       |    typename FixedBlockXpr<..., ...>::Type
  283|       |#endif
  284|       |    topLeftCorner(NRowsType cRows, NColsType cCols) {
  285|       |  return typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  286|       |                                internal::get_fixed_value<NColsType>::value>::Type(derived(), 0, 0,
  287|       |                                                                                   internal::get_runtime_value(cRows),
  288|       |                                                                                   internal::get_runtime_value(cCols));
  289|       |}
  290|       |
  291|       |/// This is the const version of topLeftCorner(Index, Index).
  292|       |template <typename NRowsType, typename NColsType>
  293|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  294|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  295|       |    const typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  296|       |                                      internal::get_fixed_value<NColsType>::value>::Type
  297|       |#else
  298|       |    const typename ConstFixedBlockXpr<..., ...>::Type
  299|       |#endif
  300|       |    topLeftCorner(NRowsType cRows, NColsType cCols) const {
  301|       |  return
  302|       |      typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  303|       |                                  internal::get_fixed_value<NColsType>::value>::Type(derived(), 0, 0,
  304|       |                                                                                     internal::get_runtime_value(cRows),
  305|       |                                                                                     internal::get_runtime_value(
  306|       |                                                                                         cCols));
  307|       |}
  308|       |
  309|       |/// \returns an expression of a fixed-size top-left corner of \c *this.
  310|       |///
  311|       |/// The template parameters CRows and CCols are the number of rows and columns in the corner.
  312|       |///
  313|       |/// Example: \include MatrixBase_template_int_int_topLeftCorner.cpp
  314|       |/// Output: \verbinclude MatrixBase_template_int_int_topLeftCorner.out
  315|       |///
  316|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  317|       |///
  318|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  319|       |///
  320|       |template <int CRows, int CCols>
  321|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedBlockXpr<CRows, CCols>::Type topLeftCorner() {
  322|       |  return typename FixedBlockXpr<CRows, CCols>::Type(derived(), 0, 0);
  323|       |}
  324|       |
  325|       |/// This is the const version of topLeftCorner<int, int>().
  326|       |template <int CRows, int CCols>
  327|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<CRows, CCols>::Type topLeftCorner() const {
  328|       |  return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), 0, 0);
  329|       |}
  330|       |
  331|       |/// \returns an expression of a top-left corner of \c *this.
  332|       |///
  333|       |/// \tparam CRows number of rows in corner as specified at compile-time
  334|       |/// \tparam CCols number of columns in corner as specified at compile-time
  335|       |/// \param  cRows number of rows in corner as specified at run-time
  336|       |/// \param  cCols number of columns in corner as specified at run-time
  337|       |///
  338|       |/// This function is mainly useful for corners where the number of rows is specified at compile-time
  339|       |/// and the number of columns is specified at run-time, or vice versa. The compile-time and run-time
  340|       |/// information should not contradict. In other words, \a cRows should equal \a CRows unless
  341|       |/// \a CRows is \a Dynamic, and the same for the number of columns.
  342|       |///
  343|       |/// Example: \include MatrixBase_template_int_int_topLeftCorner_int_int.cpp
  344|       |/// Output: \verbinclude MatrixBase_template_int_int_topLeftCorner_int_int.out
  345|       |///
  346|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  347|       |///
  348|       |/// \sa class Block
  349|       |///
  350|       |template <int CRows, int CCols>
  351|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedBlockXpr<CRows, CCols>::Type topLeftCorner(Index cRows,
  352|       |                                                                                               Index cCols) {
  353|       |  return typename FixedBlockXpr<CRows, CCols>::Type(derived(), 0, 0, cRows, cCols);
  354|       |}
  355|       |
  356|       |/// This is the const version of topLeftCorner<int, int>(Index, Index).
  357|       |template <int CRows, int CCols>
  358|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<CRows, CCols>::Type topLeftCorner(
  359|       |    Index cRows, Index cCols) const {
  360|       |  return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), 0, 0, cRows, cCols);
  361|       |}
  362|       |
  363|       |/// \returns an expression of a bottom-right corner of \c *this  with either dynamic or fixed sizes.
  364|       |///
  365|       |/// \param cRows the number of rows in the corner
  366|       |/// \param cCols the number of columns in the corner
  367|       |/// \tparam NRowsType the type of the value handling the number of rows in the block, typically Index.
  368|       |/// \tparam NColsType the type of the value handling the number of columns in the block, typically Index.
  369|       |///
  370|       |/// Example: \include MatrixBase_bottomRightCorner_int_int.cpp
  371|       |/// Output: \verbinclude MatrixBase_bottomRightCorner_int_int.out
  372|       |///
  373|       |/// The number of rows \a blockRows and columns \a blockCols can also be specified at compile-time by passing
  374|       |/// Eigen::fix<N>, or Eigen::fix<N>(n) as arguments. See \link block(Index,Index,NRowsType,NColsType) block() \endlink
  375|       |/// for the details.
  376|       |///
  377|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  378|       |///
  379|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  380|       |///
  381|       |template <typename NRowsType, typename NColsType>
  382|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  383|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  384|       |    typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  385|       |                           internal::get_fixed_value<NColsType>::value>::Type
  386|       |#else
  387|       |    typename FixedBlockXpr<..., ...>::Type
  388|       |#endif
  389|       |    bottomRightCorner(NRowsType cRows, NColsType cCols) {
  390|       |  return
  391|       |      typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value, internal::get_fixed_value<NColsType>::value>::
  392|       |          Type(derived(), rows() - internal::get_runtime_value(cRows), cols() - internal::get_runtime_value(cCols),
  393|       |               internal::get_runtime_value(cRows), internal::get_runtime_value(cCols));
  394|       |}
  395|       |
  396|       |/// This is the const version of bottomRightCorner(NRowsType, NColsType).
  397|       |template <typename NRowsType, typename NColsType>
  398|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  399|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  400|       |    const typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  401|       |                                      internal::get_fixed_value<NColsType>::value>::Type
  402|       |#else
  403|       |    const typename ConstFixedBlockXpr<..., ...>::Type
  404|       |#endif
  405|       |    bottomRightCorner(NRowsType cRows, NColsType cCols) const {
  406|       |  return typename ConstFixedBlockXpr<
  407|       |      internal::get_fixed_value<NRowsType>::value,
  408|       |      internal::get_fixed_value<NColsType>::value>::Type(derived(), rows() - internal::get_runtime_value(cRows),
  409|       |                                                         cols() - internal::get_runtime_value(cCols),
  410|       |                                                         internal::get_runtime_value(cRows),
  411|       |                                                         internal::get_runtime_value(cCols));
  412|       |}
  413|       |
  414|       |/// \returns an expression of a fixed-size bottom-right corner of \c *this.
  415|       |///
  416|       |/// The template parameters CRows and CCols are the number of rows and columns in the corner.
  417|       |///
  418|       |/// Example: \include MatrixBase_template_int_int_bottomRightCorner.cpp
  419|       |/// Output: \verbinclude MatrixBase_template_int_int_bottomRightCorner.out
  420|       |///
  421|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  422|       |///
  423|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  424|       |///
  425|       |template <int CRows, int CCols>
  426|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedBlockXpr<CRows, CCols>::Type bottomRightCorner() {
  427|       |  return typename FixedBlockXpr<CRows, CCols>::Type(derived(), rows() - CRows, cols() - CCols);
  428|       |}
  429|       |
  430|       |/// This is the const version of bottomRightCorner<int, int>().
  431|       |template <int CRows, int CCols>
  432|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<CRows, CCols>::Type bottomRightCorner() const {
  433|       |  return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), rows() - CRows, cols() - CCols);
  434|       |}
  435|       |
  436|       |/// \returns an expression of a bottom-right corner of \c *this.
  437|       |///
  438|       |/// \tparam CRows number of rows in corner as specified at compile-time
  439|       |/// \tparam CCols number of columns in corner as specified at compile-time
  440|       |/// \param  cRows number of rows in corner as specified at run-time
  441|       |/// \param  cCols number of columns in corner as specified at run-time
  442|       |///
  443|       |/// This function is mainly useful for corners where the number of rows is specified at compile-time
  444|       |/// and the number of columns is specified at run-time, or vice versa. The compile-time and run-time
  445|       |/// information should not contradict. In other words, \a cRows should equal \a CRows unless
  446|       |/// \a CRows is \a Dynamic, and the same for the number of columns.
  447|       |///
  448|       |/// Example: \include MatrixBase_template_int_int_bottomRightCorner_int_int.cpp
  449|       |/// Output: \verbinclude MatrixBase_template_int_int_bottomRightCorner_int_int.out
  450|       |///
  451|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  452|       |///
  453|       |/// \sa class Block
  454|       |///
  455|       |template <int CRows, int CCols>
  456|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedBlockXpr<CRows, CCols>::Type bottomRightCorner(Index cRows,
  457|       |                                                                                                   Index cCols) {
  458|       |  return typename FixedBlockXpr<CRows, CCols>::Type(derived(), rows() - cRows, cols() - cCols, cRows, cCols);
  459|       |}
  460|       |
  461|       |/// This is the const version of bottomRightCorner<int, int>(Index, Index).
  462|       |template <int CRows, int CCols>
  463|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<CRows, CCols>::Type bottomRightCorner(
  464|       |    Index cRows, Index cCols) const {
  465|       |  return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), rows() - cRows, cols() - cCols, cRows, cCols);
  466|       |}
  467|       |
  468|       |/// \returns an expression of a bottom-left corner of \c *this  with either dynamic or fixed sizes.
  469|       |///
  470|       |/// \param cRows the number of rows in the corner
  471|       |/// \param cCols the number of columns in the corner
  472|       |/// \tparam NRowsType the type of the value handling the number of rows in the block, typically Index.
  473|       |/// \tparam NColsType the type of the value handling the number of columns in the block, typically Index.
  474|       |///
  475|       |/// Example: \include MatrixBase_bottomLeftCorner_int_int.cpp
  476|       |/// Output: \verbinclude MatrixBase_bottomLeftCorner_int_int.out
  477|       |///
  478|       |/// The number of rows \a blockRows and columns \a blockCols can also be specified at compile-time by passing
  479|       |/// Eigen::fix<N>, or Eigen::fix<N>(n) as arguments. See \link block(Index,Index,NRowsType,NColsType) block() \endlink
  480|       |/// for the details.
  481|       |///
  482|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  483|       |///
  484|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  485|       |///
  486|       |template <typename NRowsType, typename NColsType>
  487|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  488|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  489|       |    typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  490|       |                           internal::get_fixed_value<NColsType>::value>::Type
  491|       |#else
  492|       |    typename FixedBlockXpr<..., ...>::Type
  493|       |#endif
  494|       |    bottomLeftCorner(NRowsType cRows, NColsType cCols) {
  495|       |  return
  496|       |      typename FixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  497|       |                             internal::get_fixed_value<NColsType>::value>::Type(derived(),
  498|       |                                                                                rows() -
  499|       |                                                                                    internal::get_runtime_value(cRows),
  500|       |                                                                                0, internal::get_runtime_value(cRows),
  501|       |                                                                                internal::get_runtime_value(cCols));
  502|       |}
  503|       |
  504|       |/// This is the const version of bottomLeftCorner(NRowsType, NColsType).
  505|       |template <typename NRowsType, typename NColsType>
  506|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  507|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  508|       |    typename ConstFixedBlockXpr<internal::get_fixed_value<NRowsType>::value,
  509|       |                                internal::get_fixed_value<NColsType>::value>::Type
  510|       |#else
  511|       |    typename ConstFixedBlockXpr<..., ...>::Type
  512|       |#endif
  513|       |    bottomLeftCorner(NRowsType cRows, NColsType cCols) const {
  514|       |  return typename ConstFixedBlockXpr<
  515|       |      internal::get_fixed_value<NRowsType>::value,
  516|       |      internal::get_fixed_value<NColsType>::value>::Type(derived(), rows() - internal::get_runtime_value(cRows), 0,
  517|       |                                                         internal::get_runtime_value(cRows),
  518|       |                                                         internal::get_runtime_value(cCols));
  519|       |}
  520|       |
  521|       |/// \returns an expression of a fixed-size bottom-left corner of \c *this.
  522|       |///
  523|       |/// The template parameters CRows and CCols are the number of rows and columns in the corner.
  524|       |///
  525|       |/// Example: \include MatrixBase_template_int_int_bottomLeftCorner.cpp
  526|       |/// Output: \verbinclude MatrixBase_template_int_int_bottomLeftCorner.out
  527|       |///
  528|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  529|       |///
  530|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  531|       |///
  532|       |template <int CRows, int CCols>
  533|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedBlockXpr<CRows, CCols>::Type bottomLeftCorner() {
  534|       |  return typename FixedBlockXpr<CRows, CCols>::Type(derived(), rows() - CRows, 0);
  535|       |}
  536|       |
  537|       |/// This is the const version of bottomLeftCorner<int, int>().
  538|       |template <int CRows, int CCols>
  539|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<CRows, CCols>::Type bottomLeftCorner() const {
  540|       |  return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), rows() - CRows, 0);
  541|       |}
  542|       |
  543|       |/// \returns an expression of a bottom-left corner of \c *this.
  544|       |///
  545|       |/// \tparam CRows number of rows in corner as specified at compile-time
  546|       |/// \tparam CCols number of columns in corner as specified at compile-time
  547|       |/// \param  cRows number of rows in corner as specified at run-time
  548|       |/// \param  cCols number of columns in corner as specified at run-time
  549|       |///
  550|       |/// This function is mainly useful for corners where the number of rows is specified at compile-time
  551|       |/// and the number of columns is specified at run-time, or vice versa. The compile-time and run-time
  552|       |/// information should not contradict. In other words, \a cRows should equal \a CRows unless
  553|       |/// \a CRows is \a Dynamic, and the same for the number of columns.
  554|       |///
  555|       |/// Example: \include MatrixBase_template_int_int_bottomLeftCorner_int_int.cpp
  556|       |/// Output: \verbinclude MatrixBase_template_int_int_bottomLeftCorner_int_int.out
  557|       |///
  558|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
  559|       |///
  560|       |/// \sa class Block
  561|       |///
  562|       |template <int CRows, int CCols>
  563|       |EIGEN_STRONG_INLINE typename FixedBlockXpr<CRows, CCols>::Type bottomLeftCorner(Index cRows, Index cCols) {
  564|       |  return typename FixedBlockXpr<CRows, CCols>::Type(derived(), rows() - cRows, 0, cRows, cCols);
  565|       |}
  566|       |
  567|       |/// This is the const version of bottomLeftCorner<int, int>(Index, Index).
  568|       |template <int CRows, int CCols>
  569|       |EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<CRows, CCols>::Type bottomLeftCorner(Index cRows,
  570|       |                                                                                           Index cCols) const {
  571|       |  return typename ConstFixedBlockXpr<CRows, CCols>::Type(derived(), rows() - cRows, 0, cRows, cCols);
  572|       |}
  573|       |
  574|       |/// \returns a block consisting of the top rows of \c *this.
  575|       |///
  576|       |/// \param n the number of rows in the block
  577|       |/// \tparam NRowsType the type of the value handling the number of rows in the block, typically Index.
  578|       |///
  579|       |/// Example: \include MatrixBase_topRows_int.cpp
  580|       |/// Output: \verbinclude MatrixBase_topRows_int.out
  581|       |///
  582|       |/// The number of rows \a n can also be specified at compile-time by passing Eigen::fix<N>,
  583|       |/// or Eigen::fix<N>(n) as arguments.
  584|       |/// See \link block(Index,Index,NRowsType,NColsType) block() \endlink for the details.
  585|       |///
  586|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(row - major)
  587|       |///
  588|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  589|       |///
  590|       |template <typename NRowsType>
  591|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  592|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  593|       |    typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type
  594|       |#else
  595|       |    typename NRowsBlockXpr<...>::Type
  596|       |#endif
  597|       |    topRows(NRowsType n) {
  598|       |  return typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
  599|       |      derived(), 0, 0, internal::get_runtime_value(n), cols());
  600|       |}
  601|       |
  602|       |/// This is the const version of topRows(NRowsType).
  603|       |template <typename NRowsType>
  604|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  605|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  606|       |    const typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type
  607|       |#else
  608|       |    const typename ConstNRowsBlockXpr<...>::Type
  609|       |#endif
  610|       |    topRows(NRowsType n) const {
  611|       |  return typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
  612|       |      derived(), 0, 0, internal::get_runtime_value(n), cols());
  613|       |}
  614|       |
  615|       |/// \returns a block consisting of the top rows of \c *this.
  616|       |///
  617|       |/// \tparam N the number of rows in the block as specified at compile-time
  618|       |/// \param n the number of rows in the block as specified at run-time
  619|       |///
  620|       |/// The compile-time and run-time information should not contradict. In other words,
  621|       |/// \a n should equal \a N unless \a N is \a Dynamic.
  622|       |///
  623|       |/// Example: \include MatrixBase_template_int_topRows.cpp
  624|       |/// Output: \verbinclude MatrixBase_template_int_topRows.out
  625|       |///
  626|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(row - major)
  627|       |///
  628|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  629|       |///
  630|       |template <int N>
  631|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NRowsBlockXpr<N>::Type topRows(Index n = N) {
  632|       |  return typename NRowsBlockXpr<N>::Type(derived(), 0, 0, n, cols());
  633|       |}
  634|       |
  635|       |/// This is the const version of topRows<int>().
  636|       |template <int N>
  637|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename ConstNRowsBlockXpr<N>::Type topRows(Index n = N) const {
  638|       |  return typename ConstNRowsBlockXpr<N>::Type(derived(), 0, 0, n, cols());
  639|       |}
  640|       |
  641|       |/// \returns a block consisting of the bottom rows of \c *this.
  642|       |///
  643|       |/// \param n the number of rows in the block
  644|       |/// \tparam NRowsType the type of the value handling the number of rows in the block, typically Index.
  645|       |///
  646|       |/// Example: \include MatrixBase_bottomRows_int.cpp
  647|       |/// Output: \verbinclude MatrixBase_bottomRows_int.out
  648|       |///
  649|       |/// The number of rows \a n can also be specified at compile-time by passing Eigen::fix<N>,
  650|       |/// or Eigen::fix<N>(n) as arguments.
  651|       |/// See \link block(Index,Index,NRowsType,NColsType) block() \endlink for the details.
  652|       |///
  653|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(row - major)
  654|       |///
  655|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  656|       |///
  657|       |template <typename NRowsType>
  658|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  659|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  660|       |    typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type
  661|       |#else
  662|       |    typename NRowsBlockXpr<...>::Type
  663|       |#endif
  664|       |    bottomRows(NRowsType n) {
  665|       |  return typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
  666|       |      derived(), rows() - internal::get_runtime_value(n), 0, internal::get_runtime_value(n), cols());
  667|       |}
  668|       |
  669|       |/// This is the const version of bottomRows(NRowsType).
  670|       |template <typename NRowsType>
  671|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  672|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  673|       |    const typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type
  674|       |#else
  675|       |    const typename ConstNRowsBlockXpr<...>::Type
  676|       |#endif
  677|       |    bottomRows(NRowsType n) const {
  678|       |  return typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
  679|       |      derived(), rows() - internal::get_runtime_value(n), 0, internal::get_runtime_value(n), cols());
  680|       |}
  681|       |
  682|       |/// \returns a block consisting of the bottom rows of \c *this.
  683|       |///
  684|       |/// \tparam N the number of rows in the block as specified at compile-time
  685|       |/// \param n the number of rows in the block as specified at run-time
  686|       |///
  687|       |/// The compile-time and run-time information should not contradict. In other words,
  688|       |/// \a n should equal \a N unless \a N is \a Dynamic.
  689|       |///
  690|       |/// Example: \include MatrixBase_template_int_bottomRows.cpp
  691|       |/// Output: \verbinclude MatrixBase_template_int_bottomRows.out
  692|       |///
  693|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(row - major)
  694|       |///
  695|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  696|       |///
  697|       |template <int N>
  698|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NRowsBlockXpr<N>::Type bottomRows(Index n = N) {
  699|       |  return typename NRowsBlockXpr<N>::Type(derived(), rows() - n, 0, n, cols());
  700|       |}
  701|       |
  702|       |/// This is the const version of bottomRows<int>().
  703|       |template <int N>
  704|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename ConstNRowsBlockXpr<N>::Type bottomRows(Index n = N) const {
  705|       |  return typename ConstNRowsBlockXpr<N>::Type(derived(), rows() - n, 0, n, cols());
  706|       |}
  707|       |
  708|       |/// \returns a block consisting of a range of rows of \c *this.
  709|       |///
  710|       |/// \param startRow the index of the first row in the block
  711|       |/// \param n the number of rows in the block
  712|       |/// \tparam NRowsType the type of the value handling the number of rows in the block, typically Index.
  713|       |///
  714|       |/// Example: \include DenseBase_middleRows_int.cpp
  715|       |/// Output: \verbinclude DenseBase_middleRows_int.out
  716|       |///
  717|       |/// The number of rows \a n can also be specified at compile-time by passing Eigen::fix<N>,
  718|       |/// or Eigen::fix<N>(n) as arguments.
  719|       |/// See \link block(Index,Index,NRowsType,NColsType) block() \endlink for the details.
  720|       |///
  721|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(row - major)
  722|       |///
  723|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  724|       |///
  725|       |template <typename NRowsType>
  726|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  727|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  728|       |    typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type
  729|       |#else
  730|       |    typename NRowsBlockXpr<...>::Type
  731|       |#endif
  732|       |    middleRows(Index startRow, NRowsType n) {
  733|       |  return typename NRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
  734|       |      derived(), startRow, 0, internal::get_runtime_value(n), cols());
  735|       |}
  736|       |
  737|       |/// This is the const version of middleRows(Index,NRowsType).
  738|       |template <typename NRowsType>
  739|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  740|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  741|       |    const typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type
  742|       |#else
  743|       |    const typename ConstNRowsBlockXpr<...>::Type
  744|       |#endif
  745|       |    middleRows(Index startRow, NRowsType n) const {
  746|       |  return typename ConstNRowsBlockXpr<internal::get_fixed_value<NRowsType>::value>::Type(
  747|       |      derived(), startRow, 0, internal::get_runtime_value(n), cols());
  748|       |}
  749|       |
  750|       |/// \returns a block consisting of a range of rows of \c *this.
  751|       |///
  752|       |/// \tparam N the number of rows in the block as specified at compile-time
  753|       |/// \param startRow the index of the first row in the block
  754|       |/// \param n the number of rows in the block as specified at run-time
  755|       |///
  756|       |/// The compile-time and run-time information should not contradict. In other words,
  757|       |/// \a n should equal \a N unless \a N is \a Dynamic.
  758|       |///
  759|       |/// Example: \include DenseBase_template_int_middleRows.cpp
  760|       |/// Output: \verbinclude DenseBase_template_int_middleRows.out
  761|       |///
  762|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(row - major)
  763|       |///
  764|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  765|       |///
  766|       |template <int N>
  767|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NRowsBlockXpr<N>::Type middleRows(Index startRow, Index n = N) {
  768|       |  return typename NRowsBlockXpr<N>::Type(derived(), startRow, 0, n, cols());
  769|       |}
  770|       |
  771|       |/// This is the const version of middleRows<int>().
  772|       |template <int N>
  773|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename ConstNRowsBlockXpr<N>::Type middleRows(Index startRow,
  774|       |                                                                                      Index n = N) const {
  775|       |  return typename ConstNRowsBlockXpr<N>::Type(derived(), startRow, 0, n, cols());
  776|       |}
  777|       |
  778|       |/// \returns a block consisting of the left columns of \c *this.
  779|       |///
  780|       |/// \param n the number of columns in the block
  781|       |/// \tparam NColsType the type of the value handling the number of columns in the block, typically Index.
  782|       |///
  783|       |/// Example: \include MatrixBase_leftCols_int.cpp
  784|       |/// Output: \verbinclude MatrixBase_leftCols_int.out
  785|       |///
  786|       |/// The number of columns \a n can also be specified at compile-time by passing Eigen::fix<N>,
  787|       |/// or Eigen::fix<N>(n) as arguments.
  788|       |/// See \link block(Index,Index,NRowsType,NColsType) block() \endlink for the details.
  789|       |///
  790|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(column - major)
  791|       |///
  792|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  793|       |///
  794|       |template <typename NColsType>
  795|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  796|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  797|       |    typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type
  798|       |#else
  799|       |    typename NColsBlockXpr<...>::Type
  800|       |#endif
  801|       |    leftCols(NColsType n) {
  802|       |  return typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(derived(), 0, 0, rows(),
  803|       |                                                                                   internal::get_runtime_value(n));
  804|       |}
  805|       |
  806|       |/// This is the const version of leftCols(NColsType).
  807|       |template <typename NColsType>
  808|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  809|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  810|       |    const typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type
  811|       |#else
  812|       |    const typename ConstNColsBlockXpr<...>::Type
  813|       |#endif
  814|       |    leftCols(NColsType n) const {
  815|       |  return typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(derived(), 0, 0, rows(),
  816|       |                                                                                        internal::get_runtime_value(n));
  817|       |}
  818|       |
  819|       |/// \returns a block consisting of the left columns of \c *this.
  820|       |///
  821|       |/// \tparam N the number of columns in the block as specified at compile-time
  822|       |/// \param n the number of columns in the block as specified at run-time
  823|       |///
  824|       |/// The compile-time and run-time information should not contradict. In other words,
  825|       |/// \a n should equal \a N unless \a N is \a Dynamic.
  826|       |///
  827|       |/// Example: \include MatrixBase_template_int_leftCols.cpp
  828|       |/// Output: \verbinclude MatrixBase_template_int_leftCols.out
  829|       |///
  830|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(column - major)
  831|       |///
  832|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  833|       |///
  834|       |template <int N>
  835|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NColsBlockXpr<N>::Type leftCols(Index n = N) {
  836|       |  return typename NColsBlockXpr<N>::Type(derived(), 0, 0, rows(), n);
  837|       |}
  838|       |
  839|       |/// This is the const version of leftCols<int>().
  840|       |template <int N>
  841|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename ConstNColsBlockXpr<N>::Type leftCols(Index n = N) const {
  842|       |  return typename ConstNColsBlockXpr<N>::Type(derived(), 0, 0, rows(), n);
  843|       |}
  844|       |
  845|       |/// \returns a block consisting of the right columns of \c *this.
  846|       |///
  847|       |/// \param n the number of columns in the block
  848|       |/// \tparam NColsType the type of the value handling the number of columns in the block, typically Index.
  849|       |///
  850|       |/// Example: \include MatrixBase_rightCols_int.cpp
  851|       |/// Output: \verbinclude MatrixBase_rightCols_int.out
  852|       |///
  853|       |/// The number of columns \a n can also be specified at compile-time by passing Eigen::fix<N>,
  854|       |/// or Eigen::fix<N>(n) as arguments.
  855|       |/// See \link block(Index,Index,NRowsType,NColsType) block() \endlink for the details.
  856|       |///
  857|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(column - major)
  858|       |///
  859|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  860|       |///
  861|       |template <typename NColsType>
  862|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  863|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  864|       |    typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type
  865|       |#else
  866|       |    typename NColsBlockXpr<...>::Type
  867|       |#endif
  868|       |    rightCols(NColsType n) {
  869|       |  return typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
  870|       |      derived(), 0, cols() - internal::get_runtime_value(n), rows(), internal::get_runtime_value(n));
  871|       |}
  872|       |
  873|       |/// This is the const version of rightCols(NColsType).
  874|       |template <typename NColsType>
  875|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  876|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  877|       |    const typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type
  878|       |#else
  879|       |    const typename ConstNColsBlockXpr<...>::Type
  880|       |#endif
  881|       |    rightCols(NColsType n) const {
  882|       |  return typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
  883|       |      derived(), 0, cols() - internal::get_runtime_value(n), rows(), internal::get_runtime_value(n));
  884|       |}
  885|       |
  886|       |/// \returns a block consisting of the right columns of \c *this.
  887|       |///
  888|       |/// \tparam N the number of columns in the block as specified at compile-time
  889|       |/// \param n the number of columns in the block as specified at run-time
  890|       |///
  891|       |/// The compile-time and run-time information should not contradict. In other words,
  892|       |/// \a n should equal \a N unless \a N is \a Dynamic.
  893|       |///
  894|       |/// Example: \include MatrixBase_template_int_rightCols.cpp
  895|       |/// Output: \verbinclude MatrixBase_template_int_rightCols.out
  896|       |///
  897|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(column - major)
  898|       |///
  899|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  900|       |///
  901|       |template <int N>
  902|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NColsBlockXpr<N>::Type rightCols(Index n = N) {
  903|       |  return typename NColsBlockXpr<N>::Type(derived(), 0, cols() - n, rows(), n);
  904|       |}
  905|       |
  906|       |/// This is the const version of rightCols<int>().
  907|       |template <int N>
  908|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename ConstNColsBlockXpr<N>::Type rightCols(Index n = N) const {
  909|       |  return typename ConstNColsBlockXpr<N>::Type(derived(), 0, cols() - n, rows(), n);
  910|       |}
  911|       |
  912|       |/// \returns a block consisting of a range of columns of \c *this.
  913|       |///
  914|       |/// \param startCol the index of the first column in the block
  915|       |/// \param numCols the number of columns in the block
  916|       |/// \tparam NColsType the type of the value handling the number of columns in the block, typically Index.
  917|       |///
  918|       |/// Example: \include DenseBase_middleCols_int.cpp
  919|       |/// Output: \verbinclude DenseBase_middleCols_int.out
  920|       |///
  921|       |/// The number of columns \a n can also be specified at compile-time by passing Eigen::fix<N>,
  922|       |/// or Eigen::fix<N>(n) as arguments.
  923|       |/// See \link block(Index,Index,NRowsType,NColsType) block() \endlink for the details.
  924|       |///
  925|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(column - major)
  926|       |///
  927|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  928|       |///
  929|       |template <typename NColsType>
  930|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  931|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  932|       |    typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type
  933|       |#else
  934|       |    typename NColsBlockXpr<...>::Type
  935|       |#endif
  936|       |    middleCols(Index startCol, NColsType numCols) {
  937|       |  return typename NColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
  938|       |      derived(), 0, startCol, rows(), internal::get_runtime_value(numCols));
  939|       |}
  940|       |
  941|       |/// This is the const version of middleCols(Index,NColsType).
  942|       |template <typename NColsType>
  943|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  944|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
  945|       |    const typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type
  946|       |#else
  947|       |    const typename ConstNColsBlockXpr<...>::Type
  948|       |#endif
  949|       |    middleCols(Index startCol, NColsType numCols) const {
  950|       |  return typename ConstNColsBlockXpr<internal::get_fixed_value<NColsType>::value>::Type(
  951|       |      derived(), 0, startCol, rows(), internal::get_runtime_value(numCols));
  952|       |}
  953|       |
  954|       |/// \returns a block consisting of a range of columns of \c *this.
  955|       |///
  956|       |/// \tparam N the number of columns in the block as specified at compile-time
  957|       |/// \param startCol the index of the first column in the block
  958|       |/// \param n the number of columns in the block as specified at run-time
  959|       |///
  960|       |/// The compile-time and run-time information should not contradict. In other words,
  961|       |/// \a n should equal \a N unless \a N is \a Dynamic.
  962|       |///
  963|       |/// Example: \include DenseBase_template_int_middleCols.cpp
  964|       |/// Output: \verbinclude DenseBase_template_int_middleCols.out
  965|       |///
  966|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(column - major)
  967|       |///
  968|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
  969|       |///
  970|       |template <int N>
  971|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NColsBlockXpr<N>::Type middleCols(Index startCol, Index n = N) {
  972|       |  return typename NColsBlockXpr<N>::Type(derived(), 0, startCol, rows(), n);
  973|       |}
  974|       |
  975|       |/// This is the const version of middleCols<int>().
  976|       |template <int N>
  977|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename ConstNColsBlockXpr<N>::Type middleCols(Index startCol,
  978|       |                                                                                      Index n = N) const {
  979|       |  return typename ConstNColsBlockXpr<N>::Type(derived(), 0, startCol, rows(), n);
  980|       |}
  981|       |
  982|       |/// \returns a fixed-size expression of a block of \c *this.
  983|       |///
  984|       |/// The template parameters \a NRows and \a NCols are the number of
  985|       |/// rows and columns in the block.
  986|       |///
  987|       |/// \param startRow the first row in the block
  988|       |/// \param startCol the first column in the block
  989|       |///
  990|       |/// Example: \include MatrixBase_block_int_int.cpp
  991|       |/// Output: \verbinclude MatrixBase_block_int_int.out
  992|       |///
  993|       |/// \note The usage of of this overload is discouraged from %Eigen 3.4, better used the generic
  994|       |/// block(Index,Index,NRowsType,NColsType), here is the one-to-one equivalence:
  995|       |/// \code
  996|       |/// mat.template block<NRows,NCols>(i,j)  <-->  mat.block(i,j,fix<NRows>,fix<NCols>)
  997|       |/// \endcode
  998|       |///
  999|       |/// \note since block is a templated member, the keyword template has to be used
 1000|       |/// if the matrix type is also a template parameter: \code m.template block<3,3>(1,1); \endcode
 1001|       |///
 1002|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
 1003|       |///
 1004|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
 1005|       |///
 1006|       |template <int NRows, int NCols>
 1007|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedBlockXpr<NRows, NCols>::Type block(Index startRow, Index startCol) {
 1008|       |  return typename FixedBlockXpr<NRows, NCols>::Type(derived(), startRow, startCol);
 1009|       |}
 1010|       |
 1011|       |/// This is the const version of block<>(Index, Index). */
 1012|       |template <int NRows, int NCols>
 1013|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<NRows, NCols>::Type block(
 1014|       |    Index startRow, Index startCol) const {
 1015|       |  return typename ConstFixedBlockXpr<NRows, NCols>::Type(derived(), startRow, startCol);
 1016|       |}
 1017|       |
 1018|       |/// \returns an expression of a block of \c *this.
 1019|       |///
 1020|       |/// \tparam NRows number of rows in block as specified at compile-time
 1021|       |/// \tparam NCols number of columns in block as specified at compile-time
 1022|       |/// \param  startRow  the first row in the block
 1023|       |/// \param  startCol  the first column in the block
 1024|       |/// \param  blockRows number of rows in block as specified at run-time
 1025|       |/// \param  blockCols number of columns in block as specified at run-time
 1026|       |///
 1027|       |/// This function is mainly useful for blocks where the number of rows is specified at compile-time
 1028|       |/// and the number of columns is specified at run-time, or vice versa. The compile-time and run-time
 1029|       |/// information should not contradict. In other words, \a blockRows should equal \a NRows unless
 1030|       |/// \a NRows is \a Dynamic, and the same for the number of columns.
 1031|       |///
 1032|       |/// Example: \include MatrixBase_template_int_int_block_int_int_int_int.cpp
 1033|       |/// Output: \verbinclude MatrixBase_template_int_int_block_int_int_int_int.out
 1034|       |///
 1035|       |/// \note The usage of of this overload is discouraged from %Eigen 3.4, better used the generic
 1036|       |/// block(Index,Index,NRowsType,NColsType), here is the one-to-one complete equivalence:
 1037|       |/// \code
 1038|       |/// mat.template block<NRows,NCols>(i,j,rows,cols)     <-->  mat.block(i,j,fix<NRows>(rows),fix<NCols>(cols))
 1039|       |/// \endcode
 1040|       |/// If we known that, e.g., NRows==Dynamic and NCols!=Dynamic, then the equivalence becomes:
 1041|       |/// \code
 1042|       |/// mat.template block<Dynamic,NCols>(i,j,rows,NCols)  <-->  mat.block(i,j,rows,fix<NCols>)
 1043|       |/// \endcode
 1044|       |///
 1045|       |EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL
 1046|       |///
 1047|       |/// \sa block(Index,Index,NRowsType,NColsType), class Block
 1048|       |///
 1049|       |template <int NRows, int NCols>
 1050|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedBlockXpr<NRows, NCols>::Type block(Index startRow, Index startCol,
 1051|       |                                                                                       Index blockRows,
 1052|       |                                                                                       Index blockCols) {
 1053|       |  return typename FixedBlockXpr<NRows, NCols>::Type(derived(), startRow, startCol, blockRows, blockCols);
 1054|       |}
 1055|       |
 1056|       |/// This is the const version of block<>(Index, Index, Index, Index).
 1057|       |template <int NRows, int NCols>
 1058|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const typename ConstFixedBlockXpr<NRows, NCols>::Type block(
 1059|       |    Index startRow, Index startCol, Index blockRows, Index blockCols) const {
 1060|       |  return typename ConstFixedBlockXpr<NRows, NCols>::Type(derived(), startRow, startCol, blockRows, blockCols);
 1061|       |}
 1062|       |
 1063|       |/// \returns an expression of the \a i-th column of \c *this. Note that the numbering starts at 0.
 1064|       |///
 1065|       |/// Example: \include MatrixBase_col.cpp
 1066|       |/// Output: \verbinclude MatrixBase_col.out
 1067|       |///
 1068|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(column - major)
 1069|       |/**
 1070|       | * \sa row(), class Block */
 1071|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ColXpr col(Index i) { return ColXpr(derived(), i); }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE3colEl
  ------------------
  | Unexecuted instantiation: _ZN5Eigen9DenseBaseINS_9TransposeINS_5BlockINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEEEE3colEl
  ------------------
 1072|       |
 1073|       |/// This is the const version of col().
 1074|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ConstColXpr col(Index i) const { return ConstColXpr(derived(), i); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE3colEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELin1ELi1ELb1EEEE3colEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELi1ELi0ELin1ELi1EEEE3colEl
  ------------------
 1075|       |
 1076|       |/// \returns an expression of the \a i-th row of \c *this. Note that the numbering starts at 0.
 1077|       |///
 1078|       |/// Example: \include MatrixBase_row.cpp
 1079|       |/// Output: \verbinclude MatrixBase_row.out
 1080|       |///
 1081|       |EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(row - major)
 1082|       |/**
 1083|       | * \sa col(), class Block */
 1084|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE RowXpr row(Index i) { return RowXpr(derived(), i); }
 1085|       |
 1086|       |/// This is the const version of row(). */
 1087|      0|EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ConstRowXpr row(Index i) const { return ConstRowXpr(derived(), i); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEEE3rowEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE3rowEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE3rowEl
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEE3rowEl
  ------------------
 1088|       |
 1089|       |/// \returns an expression of a segment (i.e. a vector block) in \c *this with either dynamic or fixed sizes.
 1090|       |///
 1091|       |/// \only_for_vectors
 1092|       |///
 1093|       |/// \param start the first coefficient in the segment
 1094|       |/// \param n the number of coefficients in the segment
 1095|       |/// \tparam NType the type of the value handling the number of coefficients in the segment, typically Index.
 1096|       |///
 1097|       |/// Example: \include MatrixBase_segment_int_int.cpp
 1098|       |/// Output: \verbinclude MatrixBase_segment_int_int.out
 1099|       |///
 1100|       |/// The number of coefficients \a n can also be specified at compile-time by passing Eigen::fix<N>,
 1101|       |/// or Eigen::fix<N>(n) as arguments.
 1102|       |/// See \link block(Index,Index,NRowsType,NColsType) block() \endlink for the details.
 1103|       |///
 1104|       |/// \note Even in the case that the returned expression has dynamic size, in the case
 1105|       |/// when it is applied to a fixed-size vector, it inherits a fixed maximal size,
 1106|       |/// which means that evaluating it does not cause a dynamic memory allocation.
 1107|       |///
 1108|       |/// \sa block(Index,Index,NRowsType,NColsType), fix<N>, fix<N>(int), class Block
 1109|       |///
 1110|       |template <typename NType>
 1111|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 1112|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
 1113|       |    typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type
 1114|       |#else
 1115|       |    typename FixedSegmentReturnType<...>::Type
 1116|       |#endif
 1117|       |    segment(Index start, NType n) {
 1118|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1119|       |  return typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(derived(), start,
 1120|       |                                                                                        internal::get_runtime_value(n));
 1121|       |}
 1122|       |
 1123|       |/// This is the const version of segment(Index,NType).
 1124|       |template <typename NType>
 1125|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 1126|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
 1127|       |    const typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type
 1128|       |#else
 1129|       |    const typename ConstFixedSegmentReturnType<...>::Type
 1130|       |#endif
 1131|       |    segment(Index start, NType n) const {
 1132|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1133|       |  return typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
 1134|       |      derived(), start, internal::get_runtime_value(n));
 1135|       |}
 1136|       |
 1137|       |/// \returns an expression of the first coefficients of \c *this with either dynamic or fixed sizes.
 1138|       |///
 1139|       |/// \only_for_vectors
 1140|       |///
 1141|       |/// \param n the number of coefficients in the segment
 1142|       |/// \tparam NType the type of the value handling the number of coefficients in the segment, typically Index.
 1143|       |///
 1144|       |/// Example: \include MatrixBase_start_int.cpp
 1145|       |/// Output: \verbinclude MatrixBase_start_int.out
 1146|       |///
 1147|       |/// The number of coefficients \a n can also be specified at compile-time by passing Eigen::fix<N>,
 1148|       |/// or Eigen::fix<N>(n) as arguments.
 1149|       |/// See \link block(Index,Index,NRowsType,NColsType) block() \endlink for the details.
 1150|       |///
 1151|       |/// \note Even in the case that the returned expression has dynamic size, in the case
 1152|       |/// when it is applied to a fixed-size vector, it inherits a fixed maximal size,
 1153|       |/// which means that evaluating it does not cause a dynamic memory allocation.
 1154|       |///
 1155|       |/// \sa class Block, block(Index,Index)
 1156|       |///
 1157|       |template <typename NType>
 1158|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 1159|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
 1160|       |    typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type
 1161|       |#else
 1162|       |    typename FixedSegmentReturnType<...>::Type
 1163|       |#endif
 1164|       |    head(NType n) {
 1165|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1166|       |  return typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(derived(), 0,
 1167|       |                                                                                        internal::get_runtime_value(n));
 1168|       |}
 1169|       |
 1170|       |/// This is the const version of head(NType).
 1171|       |template <typename NType>
 1172|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 1173|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
 1174|       |    const typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type
 1175|       |#else
 1176|       |    const typename ConstFixedSegmentReturnType<...>::Type
 1177|       |#endif
 1178|       |    head(NType n) const {
 1179|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1180|       |  return typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
 1181|       |      derived(), 0, internal::get_runtime_value(n));
 1182|       |}
 1183|       |
 1184|       |/// \returns an expression of a last coefficients of \c *this with either dynamic or fixed sizes.
 1185|       |///
 1186|       |/// \only_for_vectors
 1187|       |///
 1188|       |/// \param n the number of coefficients in the segment
 1189|       |/// \tparam NType the type of the value handling the number of coefficients in the segment, typically Index.
 1190|       |///
 1191|       |/// Example: \include MatrixBase_end_int.cpp
 1192|       |/// Output: \verbinclude MatrixBase_end_int.out
 1193|       |///
 1194|       |/// The number of coefficients \a n can also be specified at compile-time by passing Eigen::fix<N>,
 1195|       |/// or Eigen::fix<N>(n) as arguments.
 1196|       |/// See \link block(Index,Index,NRowsType,NColsType) block() \endlink for the details.
 1197|       |///
 1198|       |/// \note Even in the case that the returned expression has dynamic size, in the case
 1199|       |/// when it is applied to a fixed-size vector, it inherits a fixed maximal size,
 1200|       |/// which means that evaluating it does not cause a dynamic memory allocation.
 1201|       |///
 1202|       |/// \sa class Block, block(Index,Index)
 1203|       |///
 1204|       |template <typename NType>
 1205|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 1206|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
 1207|       |    typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type
 1208|       |#else
 1209|       |    typename FixedSegmentReturnType<...>::Type
 1210|       |#endif
 1211|       |    tail(NType n) {
 1212|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1213|       |  return typename FixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
 1214|       |      derived(), this->size() - internal::get_runtime_value(n), internal::get_runtime_value(n));
 1215|       |}
 1216|       |
 1217|       |/// This is the const version of tail(Index).
 1218|       |template <typename NType>
 1219|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 1220|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
 1221|       |    const typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type
 1222|       |#else
 1223|       |    const typename ConstFixedSegmentReturnType<...>::Type
 1224|       |#endif
 1225|       |    tail(NType n) const {
 1226|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1227|       |  return typename ConstFixedSegmentReturnType<internal::get_fixed_value<NType>::value>::Type(
 1228|       |      derived(), this->size() - internal::get_runtime_value(n), internal::get_runtime_value(n));
 1229|       |}
 1230|       |
 1231|       |/// \returns a fixed-size expression of a segment (i.e. a vector block) in \c *this
 1232|       |///
 1233|       |/// \only_for_vectors
 1234|       |///
 1235|       |/// \tparam N the number of coefficients in the segment as specified at compile-time
 1236|       |/// \param start the index of the first element in the segment
 1237|       |/// \param n the number of coefficients in the segment as specified at compile-time
 1238|       |///
 1239|       |/// The compile-time and run-time information should not contradict. In other words,
 1240|       |/// \a n should equal \a N unless \a N is \a Dynamic.
 1241|       |///
 1242|       |/// Example: \include MatrixBase_template_int_segment.cpp
 1243|       |/// Output: \verbinclude MatrixBase_template_int_segment.out
 1244|       |///
 1245|       |/// \sa segment(Index,NType), class Block
 1246|       |///
 1247|       |template <int N>
 1248|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedSegmentReturnType<N>::Type segment(Index start, Index n = N) {
 1249|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1250|       |  return typename FixedSegmentReturnType<N>::Type(derived(), start, n);
 1251|       |}
 1252|       |
 1253|       |/// This is the const version of segment<int>(Index).
 1254|       |template <int N>
 1255|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename ConstFixedSegmentReturnType<N>::Type segment(Index start,
 1256|       |                                                                                            Index n = N) const {
 1257|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1258|       |  return typename ConstFixedSegmentReturnType<N>::Type(derived(), start, n);
 1259|       |}
 1260|       |
 1261|       |/// \returns a fixed-size expression of the first coefficients of \c *this.
 1262|       |///
 1263|       |/// \only_for_vectors
 1264|       |///
 1265|       |/// \tparam N the number of coefficients in the segment as specified at compile-time
 1266|       |/// \param  n the number of coefficients in the segment as specified at run-time
 1267|       |///
 1268|       |/// The compile-time and run-time information should not contradict. In other words,
 1269|       |/// \a n should equal \a N unless \a N is \a Dynamic.
 1270|       |///
 1271|       |/// Example: \include MatrixBase_template_int_start.cpp
 1272|       |/// Output: \verbinclude MatrixBase_template_int_start.out
 1273|       |///
 1274|       |/// \sa head(NType), class Block
 1275|       |///
 1276|       |template <int N>
 1277|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedSegmentReturnType<N>::Type head(Index n = N) {
 1278|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1279|       |  return typename FixedSegmentReturnType<N>::Type(derived(), 0, n);
 1280|       |}
 1281|       |
 1282|       |/// This is the const version of head<int>().
 1283|       |template <int N>
 1284|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename ConstFixedSegmentReturnType<N>::Type head(Index n = N) const {
 1285|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1286|       |  return typename ConstFixedSegmentReturnType<N>::Type(derived(), 0, n);
 1287|       |}
 1288|       |
 1289|       |/// \returns a fixed-size expression of the last coefficients of \c *this.
 1290|       |///
 1291|       |/// \only_for_vectors
 1292|       |///
 1293|       |/// \tparam N the number of coefficients in the segment as specified at compile-time
 1294|       |/// \param  n the number of coefficients in the segment as specified at run-time
 1295|       |///
 1296|       |/// The compile-time and run-time information should not contradict. In other words,
 1297|       |/// \a n should equal \a N unless \a N is \a Dynamic.
 1298|       |///
 1299|       |/// Example: \include MatrixBase_template_int_end.cpp
 1300|       |/// Output: \verbinclude MatrixBase_template_int_end.out
 1301|       |///
 1302|       |/// \sa tail(NType), class Block
 1303|       |///
 1304|       |template <int N>
 1305|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename FixedSegmentReturnType<N>::Type tail(Index n = N) {
 1306|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1307|       |  return typename FixedSegmentReturnType<N>::Type(derived(), size() - n, n);
 1308|       |}
 1309|       |
 1310|       |/// This is the const version of tail<int>.
 1311|       |template <int N>
 1312|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename ConstFixedSegmentReturnType<N>::Type tail(Index n = N) const {
 1313|       |  EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
 1314|       |  return typename ConstFixedSegmentReturnType<N>::Type(derived(), size() - n, n);
 1315|       |}
 1316|       |
 1317|       |/// \returns the \a outer -th column (resp. row) of the matrix \c *this if \c *this
 1318|       |/// is col-major (resp. row-major).
 1319|       |///
 1320|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE InnerVectorReturnType innerVector(Index outer) {
 1321|       |  return InnerVectorReturnType(derived(), outer);
 1322|       |}
 1323|       |
 1324|       |/// \returns the \a outer -th column (resp. row) of the matrix \c *this if \c *this
 1325|       |/// is col-major (resp. row-major). Read-only.
 1326|       |///
 1327|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const ConstInnerVectorReturnType innerVector(Index outer) const {
 1328|       |  return ConstInnerVectorReturnType(derived(), outer);
 1329|       |}
 1330|       |
 1331|       |/// \returns the \a outer -th column (resp. row) of the matrix \c *this if \c *this
 1332|       |/// is col-major (resp. row-major).
 1333|       |///
 1334|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE InnerVectorsReturnType innerVectors(Index outerStart, Index outerSize) {
 1335|       |  return Block<Derived, Dynamic, Dynamic, true>(derived(), IsRowMajor ? outerStart : 0, IsRowMajor ? 0 : outerStart,
 1336|       |                                                IsRowMajor ? outerSize : rows(), IsRowMajor ? cols() : outerSize);
 1337|       |}
 1338|       |
 1339|       |/// \returns the \a outer -th column (resp. row) of the matrix \c *this if \c *this
 1340|       |/// is col-major (resp. row-major). Read-only.
 1341|       |///
 1342|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const ConstInnerVectorsReturnType innerVectors(Index outerStart,
 1343|       |                                                                                     Index outerSize) const {
 1344|       |  return Block<const Derived, Dynamic, Dynamic, true>(derived(), IsRowMajor ? outerStart : 0,
 1345|       |                                                      IsRowMajor ? 0 : outerStart, IsRowMajor ? outerSize : rows(),
 1346|       |                                                      IsRowMajor ? cols() : outerSize);
 1347|       |}
 1348|       |
 1349|       |/** \returns the i-th subvector (column or vector) according to the \c Direction
 1350|       | * \sa subVectors()
 1351|       | */
 1352|       |template <DirectionType Direction>
 1353|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE std::conditional_t<Direction == Vertical, ColXpr, RowXpr> subVector(Index i) {
 1354|       |  return std::conditional_t<Direction == Vertical, ColXpr, RowXpr>(derived(), i);
 1355|       |}
 1356|       |
 1357|       |/** This is the const version of subVector(Index) */
 1358|       |template <DirectionType Direction>
 1359|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE std::conditional_t<Direction == Vertical, ConstColXpr, ConstRowXpr> subVector(
 1360|       |    Index i) const {
 1361|       |  return std::conditional_t<Direction == Vertical, ConstColXpr, ConstRowXpr>(derived(), i);
 1362|       |}
 1363|       |
 1364|       |/** \returns the number of subvectors (rows or columns) in the direction \c Direction
 1365|       | * \sa subVector(Index)
 1366|       | */
 1367|       |template <DirectionType Direction>
 1368|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index subVectors() const {
 1369|       |  return (Direction == Vertical) ? cols() : rows();
 1370|       |}

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/plugins/CommonCwiseUnaryOps.inc:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2009 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |// This file is a base class plugin containing common coefficient wise functions.
   12|       |
   13|       |#ifndef EIGEN_PARSED_BY_DOXYGEN
   14|       |
   15|       |/** \internal the return type of conjugate() */
   16|       |typedef std::conditional_t<NumTraits<Scalar>::IsComplex,
   17|       |                           const CwiseUnaryOp<internal::scalar_conjugate_op<Scalar>, const Derived>, const Derived&>
   18|       |    ConjugateReturnType;
   19|       |/** \internal the return type of real() const */
   20|       |typedef std::conditional_t<NumTraits<Scalar>::IsComplex,
   21|       |                           const CwiseUnaryOp<internal::scalar_real_op<Scalar>, const Derived>, const Derived&>
   22|       |    RealReturnType;
   23|       |/** \internal the return type of real() */
   24|       |typedef std::conditional_t<NumTraits<Scalar>::IsComplex, CwiseUnaryView<internal::scalar_real_ref_op<Scalar>, Derived>,
   25|       |                           Derived&>
   26|       |    NonConstRealReturnType;
   27|       |/** \internal the return type of imag() const */
   28|       |typedef CwiseUnaryOp<internal::scalar_imag_op<Scalar>, const Derived> ImagReturnType;
   29|       |/** \internal the return type of imag() */
   30|       |typedef CwiseUnaryView<internal::scalar_imag_ref_op<Scalar>, Derived> NonConstImagReturnType;
   31|       |
   32|       |typedef CwiseUnaryOp<internal::scalar_opposite_op<Scalar>, const Derived> NegativeReturnType;
   33|       |
   34|       |#endif  // not EIGEN_PARSED_BY_DOXYGEN
   35|       |
   36|       |/// \returns an expression of the opposite of \c *this
   37|       |///
   38|       |EIGEN_DOC_UNARY_ADDONS(operator-, opposite)
   39|       |///
   40|       |EIGEN_DEVICE_FUNC inline const NegativeReturnType operator-() const { return NegativeReturnType(derived()); }
   41|       |
   42|       |template <class NewType>
   43|       |struct CastXpr {
   44|       |  typedef typename internal::cast_return_type<
   45|       |      Derived, const CwiseUnaryOp<internal::core_cast_op<Scalar, NewType>, const Derived> >::type Type;
   46|       |};
   47|       |
   48|       |/// \returns an expression of \c *this with the \a Scalar type casted to
   49|       |/// \a NewScalar.
   50|       |///
   51|       |/// The template parameter \a NewScalar is the type we are casting the scalars to.
   52|       |///
   53|       |EIGEN_DOC_UNARY_ADDONS(cast, conversion function)
   54|       |///
   55|       |/// \sa class CwiseUnaryOp
   56|       |///
   57|       |template <typename NewType>
   58|       |EIGEN_DEVICE_FUNC typename CastXpr<NewType>::Type cast() const {
   59|       |  return typename CastXpr<NewType>::Type(derived());
   60|       |}
   61|       |
   62|       |/// \returns an expression of the complex conjugate of \c *this.
   63|       |///
   64|       |EIGEN_DOC_UNARY_ADDONS(conjugate, complex conjugate)
   65|       |///
   66|       |/// \sa <a href="group__CoeffwiseMathFunctions.html#cwisetable_conj">Math functions</a>, MatrixBase::adjoint()
   67|      0|EIGEN_DEVICE_FUNC inline ConjugateReturnType conjugate() const { return ConjugateReturnType(derived()); }
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_5BlockIKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEEE9conjugateEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_5BlockIKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEEE9conjugateEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_5BlockIKNS1_IKNS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE9conjugateEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_5BlockIKNS1_IKNS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES5_Li0EEELi1ELin1ELb0EEELi1ELin1ELb1EEEE9conjugateEv
  ------------------
   68|       |
   69|       |/// \returns an expression of the complex conjugate of \c *this if Cond==true, returns derived() otherwise.
   70|       |///
   71|       |EIGEN_DOC_UNARY_ADDONS(conjugate, complex conjugate)
   72|       |///
   73|       |/// \sa conjugate()
   74|       |template <bool Cond>
   75|      0|EIGEN_DEVICE_FUNC inline std::conditional_t<Cond, ConjugateReturnType, const Derived&> conjugateIf() const {
   76|      0|  typedef std::conditional_t<Cond, ConjugateReturnType, const Derived&> ReturnType;
   77|      0|  return ReturnType(derived());
   78|      0|}
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEEE11conjugateIfILb0EEENSt11conditionalIXT_ERKS3_S8_E4typeEv
  ------------------
  | Unexecuted instantiation: _ZNK5Eigen9DenseBaseINS_7ProductINS_6MatrixI14AnnoyingScalarLin1ELin1ELi0ELin1ELin1EEES4_Li0EEEE11conjugateIfILb0EEENSt11conditionalIXT_ERKS5_SA_E4typeEv
  ------------------
   79|       |
   80|       |/// \returns a read-only expression of the real part of \c *this.
   81|       |///
   82|       |EIGEN_DOC_UNARY_ADDONS(real, real part function)
   83|       |///
   84|       |/// \sa imag()
   85|       |EIGEN_DEVICE_FUNC inline RealReturnType real() const { return RealReturnType(derived()); }
   86|       |
   87|       |/// \returns an read-only expression of the imaginary part of \c *this.
   88|       |///
   89|       |EIGEN_DOC_UNARY_ADDONS(imag, imaginary part function)
   90|       |///
   91|       |/// \sa real()
   92|       |EIGEN_DEVICE_FUNC inline const ImagReturnType imag() const { return ImagReturnType(derived()); }
   93|       |
   94|       |/// \brief Apply a unary operator coefficient-wise
   95|       |/// \param[in]  func  Functor implementing the unary operator
   96|       |/// \tparam  CustomUnaryOp Type of \a func
   97|       |/// \returns An expression of a custom coefficient-wise unary operator \a func of *this
   98|       |///
   99|       |/// The function \c ptr_fun() from the C++ standard library can be used to make functors out of normal functions.
  100|       |///
  101|       |/// Example:
  102|       |/// \include class_CwiseUnaryOp_ptrfun.cpp
  103|       |/// Output: \verbinclude class_CwiseUnaryOp_ptrfun.out
  104|       |///
  105|       |/// Genuine functors allow for more possibilities, for instance it may contain a state.
  106|       |///
  107|       |/// Example:
  108|       |/// \include class_CwiseUnaryOp.cpp
  109|       |/// Output: \verbinclude class_CwiseUnaryOp.out
  110|       |///
  111|       |EIGEN_DOC_UNARY_ADDONS(unaryExpr, unary function)
  112|       |///
  113|       |/// \sa unaryViewExpr, binaryExpr, class CwiseUnaryOp
  114|       |///
  115|       |template <typename CustomUnaryOp>
  116|       |EIGEN_DEVICE_FUNC inline const CwiseUnaryOp<CustomUnaryOp, const Derived> unaryExpr(
  117|       |    const CustomUnaryOp& func = CustomUnaryOp()) const {
  118|       |  return CwiseUnaryOp<CustomUnaryOp, const Derived>(derived(), func);
  119|       |}
  120|       |
  121|       |/// \returns a const expression of a custom coefficient-wise unary operator \a func of *this
  122|       |///
  123|       |/// The template parameter \a CustomUnaryOp is the type of the functor
  124|       |/// of the custom unary operator.
  125|       |///
  126|       |/// Example:
  127|       |/// \include class_CwiseUnaryOp.cpp
  128|       |/// Output: \verbinclude class_CwiseUnaryOp.out
  129|       |///
  130|       |EIGEN_DOC_UNARY_ADDONS(unaryViewExpr, unary function)
  131|       |///
  132|       |/// \sa unaryExpr, binaryExpr class CwiseUnaryOp
  133|       |///
  134|       |template <typename CustomViewOp>
  135|       |EIGEN_DEVICE_FUNC inline const CwiseUnaryView<CustomViewOp, const Derived> unaryViewExpr(
  136|       |    const CustomViewOp& func = CustomViewOp()) const {
  137|       |  return CwiseUnaryView<CustomViewOp, const Derived>(derived(), func);
  138|       |}
  139|       |
  140|       |/// \returns a non-const expression of a custom coefficient-wise unary view \a func of *this
  141|       |///
  142|       |/// The template parameter \a CustomUnaryOp is the type of the functor
  143|       |/// of the custom unary operator.
  144|       |///
  145|       |EIGEN_DOC_UNARY_ADDONS(unaryViewExpr, unary function)
  146|       |///
  147|       |/// \sa unaryExpr, binaryExpr class CwiseUnaryOp
  148|       |///
  149|       |template <typename CustomViewOp>
  150|       |EIGEN_DEVICE_FUNC inline CwiseUnaryView<CustomViewOp, Derived> unaryViewExpr(
  151|       |    const CustomViewOp& func = CustomViewOp()) {
  152|       |  return CwiseUnaryView<CustomViewOp, Derived>(derived(), func);
  153|       |}
  154|       |
  155|       |/// \returns a non const expression of the real part of \c *this.
  156|       |///
  157|       |EIGEN_DOC_UNARY_ADDONS(real, real part function)
  158|       |///
  159|       |/// \sa imag()
  160|       |EIGEN_DEVICE_FUNC inline NonConstRealReturnType real() { return NonConstRealReturnType(derived()); }
  161|       |
  162|       |/// \returns a non const expression of the imaginary part of \c *this.
  163|       |///
  164|       |EIGEN_DOC_UNARY_ADDONS(imag, imaginary part function)
  165|       |///
  166|       |/// \sa real()
  167|       |EIGEN_DEVICE_FUNC inline NonConstImagReturnType imag() { return NonConstImagReturnType(derived()); }

/home/kidus/Desktop/GNNs/eigen/eigen/Eigen/src/plugins/MatrixCwiseBinaryOps.inc:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2008-2009 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |// This file is a base class plugin containing matrix specifics coefficient wise functions.
   12|       |
   13|       |/** \returns an expression of the Schur product (coefficient wise product) of *this and \a other
   14|       | *
   15|       | * Example: \include MatrixBase_cwiseProduct.cpp
   16|       | * Output: \verbinclude MatrixBase_cwiseProduct.out
   17|       | *
   18|       | * \sa class CwiseBinaryOp, cwiseAbs2
   19|       | */
   20|       |template <typename OtherDerived>
   21|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const EIGEN_CWISE_BINARY_RETURN_TYPE(Derived, OtherDerived, product)
   22|      0|    cwiseProduct(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
   23|      0|  return EIGEN_CWISE_BINARY_RETURN_TYPE(Derived, OtherDerived, product)(derived(), other.derived());
   24|      0|}
   25|       |
   26|       |template <typename OtherDerived>
   27|       |using CwiseBinaryEqualReturnType =
   28|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ>, const Derived, const OtherDerived>;
   29|       |template <typename OtherDerived>
   30|       |using CwiseBinaryNotEqualReturnType =
   31|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_NEQ>, const Derived, const OtherDerived>;
   32|       |template <typename OtherDerived>
   33|       |using CwiseBinaryLessReturnType =
   34|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LT>, const Derived, const OtherDerived>;
   35|       |template <typename OtherDerived>
   36|       |using CwiseBinaryGreaterReturnType =
   37|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_GT>, const Derived, const OtherDerived>;
   38|       |template <typename OtherDerived>
   39|       |using CwiseBinaryLessOrEqualReturnType =
   40|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LE>, const Derived, const OtherDerived>;
   41|       |template <typename OtherDerived>
   42|       |using CwiseBinaryGreaterOrEqualReturnType =
   43|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_GE>, const Derived, const OtherDerived>;
   44|       |
   45|       |/** \returns an expression of the coefficient-wise == operator of *this and \a other
   46|       | *
   47|       | * \warning this performs an exact comparison, which is generally a bad idea with floating-point types.
   48|       | * In order to check for equality between two vectors or matrices with floating-point coefficients, it is
   49|       | * generally a far better idea to use a fuzzy comparison as provided by isApprox() and
   50|       | * isMuchSmallerThan().
   51|       | *
   52|       | * Example: \include MatrixBase_cwiseEqual.cpp
   53|       | * Output: \verbinclude MatrixBase_cwiseEqual.out
   54|       | *
   55|       | * \sa cwiseNotEqual(), isApprox(), isMuchSmallerThan()
   56|       | */
   57|       |template <typename OtherDerived>
   58|       |EIGEN_DEVICE_FUNC inline const CwiseBinaryEqualReturnType<OtherDerived> cwiseEqual(
   59|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
   60|       |  return CwiseBinaryEqualReturnType<OtherDerived>(derived(), other.derived());
   61|       |}
   62|       |
   63|       |/** \returns an expression of the coefficient-wise != operator of *this and \a other
   64|       | *
   65|       | * \warning this performs an exact comparison, which is generally a bad idea with floating-point types.
   66|       | * In order to check for equality between two vectors or matrices with floating-point coefficients, it is
   67|       | * generally a far better idea to use a fuzzy comparison as provided by isApprox() and
   68|       | * isMuchSmallerThan().
   69|       | *
   70|       | * Example: \include MatrixBase_cwiseNotEqual.cpp
   71|       | * Output: \verbinclude MatrixBase_cwiseNotEqual.out
   72|       | *
   73|       | * \sa cwiseEqual(), isApprox(), isMuchSmallerThan()
   74|       | */
   75|       |template <typename OtherDerived>
   76|       |EIGEN_DEVICE_FUNC inline const CwiseBinaryNotEqualReturnType<OtherDerived> cwiseNotEqual(
   77|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
   78|       |  return CwiseBinaryNotEqualReturnType<OtherDerived>(derived(), other.derived());
   79|       |}
   80|       |
   81|       |/** \returns an expression of the coefficient-wise < operator of *this and \a other */
   82|       |template <typename OtherDerived>
   83|       |EIGEN_DEVICE_FUNC inline const CwiseBinaryLessReturnType<OtherDerived> cwiseLess(
   84|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
   85|       |  return CwiseBinaryLessReturnType<OtherDerived>(derived(), other.derived());
   86|       |}
   87|       |
   88|       |/** \returns an expression of the coefficient-wise > operator of *this and \a other */
   89|       |template <typename OtherDerived>
   90|       |EIGEN_DEVICE_FUNC inline const CwiseBinaryGreaterReturnType<OtherDerived> cwiseGreater(
   91|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
   92|       |  return CwiseBinaryGreaterReturnType<OtherDerived>(derived(), other.derived());
   93|       |}
   94|       |
   95|       |/** \returns an expression of the coefficient-wise <= operator of *this and \a other */
   96|       |template <typename OtherDerived>
   97|       |EIGEN_DEVICE_FUNC inline const CwiseBinaryLessOrEqualReturnType<OtherDerived> cwiseLessOrEqual(
   98|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
   99|       |  return CwiseBinaryLessOrEqualReturnType<OtherDerived>(derived(), other.derived());
  100|       |}
  101|       |
  102|       |/** \returns an expression of the coefficient-wise >= operator of *this and \a other */
  103|       |template <typename OtherDerived>
  104|       |EIGEN_DEVICE_FUNC inline const CwiseBinaryGreaterOrEqualReturnType<OtherDerived> cwiseGreaterOrEqual(
  105|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  106|       |  return CwiseBinaryGreaterOrEqualReturnType<OtherDerived>(derived(), other.derived());
  107|       |}
  108|       |
  109|       |/** \returns an expression of the coefficient-wise min of *this and \a other
  110|       | *
  111|       | * Example: \include MatrixBase_cwiseMin.cpp
  112|       | * Output: \verbinclude MatrixBase_cwiseMin.out
  113|       | *
  114|       | * \sa class CwiseBinaryOp, max()
  115|       | */
  116|       |template <int NaNPropagation = PropagateFast, typename OtherDerived>
  117|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const
  118|       |    CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>
  119|       |    cwiseMin(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  120|       |  return CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>(
  121|       |      derived(), other.derived());
  122|       |}
  123|       |
  124|       |/** \returns an expression of the coefficient-wise min of *this and scalar \a other
  125|       | *
  126|       | * \sa class CwiseBinaryOp, min()
  127|       | */
  128|       |template <int NaNPropagation = PropagateFast>
  129|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const
  130|       |    CwiseBinaryOp<internal::scalar_min_op<Scalar, Scalar, NaNPropagation>, const Derived, const ConstantReturnType>
  131|       |    cwiseMin(const Scalar& other) const {
  132|       |  return cwiseMin<NaNPropagation>(Derived::Constant(rows(), cols(), other));
  133|       |}
  134|       |
  135|       |/** \returns an expression of the coefficient-wise max of *this and \a other
  136|       | *
  137|       | * Example: \include MatrixBase_cwiseMax.cpp
  138|       | * Output: \verbinclude MatrixBase_cwiseMax.out
  139|       | *
  140|       | * \sa class CwiseBinaryOp, min()
  141|       | */
  142|       |template <int NaNPropagation = PropagateFast, typename OtherDerived>
  143|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const
  144|       |    CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>
  145|       |    cwiseMax(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  146|       |  return CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>, const Derived, const OtherDerived>(
  147|       |      derived(), other.derived());
  148|       |}
  149|       |
  150|       |/** \returns an expression of the coefficient-wise max of *this and scalar \a other
  151|       | *
  152|       | * \sa class CwiseBinaryOp, min()
  153|       | */
  154|       |template <int NaNPropagation = PropagateFast>
  155|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const
  156|       |    CwiseBinaryOp<internal::scalar_max_op<Scalar, Scalar, NaNPropagation>, const Derived, const ConstantReturnType>
  157|       |    cwiseMax(const Scalar& other) const {
  158|       |  return cwiseMax<NaNPropagation>(Derived::Constant(rows(), cols(), other));
  159|       |}
  160|       |
  161|       |/** \returns an expression of the coefficient-wise quotient of *this and \a other
  162|       | *
  163|       | * Example: \include MatrixBase_cwiseQuotient.cpp
  164|       | * Output: \verbinclude MatrixBase_cwiseQuotient.out
  165|       | *
  166|       | * \sa class CwiseBinaryOp, cwiseProduct(), cwiseInverse()
  167|       | */
  168|       |template <typename OtherDerived>
  169|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const
  170|       |    CwiseBinaryOp<internal::scalar_quotient_op<Scalar>, const Derived, const OtherDerived>
  171|       |    cwiseQuotient(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  172|       |  return CwiseBinaryOp<internal::scalar_quotient_op<Scalar>, const Derived, const OtherDerived>(derived(),
  173|       |                                                                                                other.derived());
  174|       |}
  175|       |
  176|       |using CwiseScalarEqualReturnType =
  177|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ>, const Derived, const ConstantReturnType>;
  178|       |using CwiseScalarNotEqualReturnType =
  179|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_NEQ>, const Derived, const ConstantReturnType>;
  180|       |using CwiseScalarLessReturnType =
  181|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LT>, const Derived, const ConstantReturnType>;
  182|       |using CwiseScalarGreaterReturnType =
  183|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_GT>, const Derived, const ConstantReturnType>;
  184|       |using CwiseScalarLessOrEqualReturnType =
  185|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LE>, const Derived, const ConstantReturnType>;
  186|       |using CwiseScalarGreaterOrEqualReturnType =
  187|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_GE>, const Derived, const ConstantReturnType>;
  188|       |
  189|       |/** \returns an expression of the coefficient-wise == operator of \c *this and a scalar \a s
  190|       | *
  191|       | * \warning this performs an exact comparison, which is generally a bad idea with floating-point types.
  192|       | * In order to check for equality between two vectors or matrices with floating-point coefficients, it is
  193|       | * generally a far better idea to use a fuzzy comparison as provided by isApprox() and
  194|       | * isMuchSmallerThan().
  195|       | *
  196|       | * \sa cwiseEqual(const MatrixBase<OtherDerived> &) const
  197|       | */
  198|       |EIGEN_DEVICE_FUNC inline const CwiseScalarEqualReturnType cwiseEqual(const Scalar& s) const {
  199|       |  return CwiseScalarEqualReturnType(derived(), Derived::Constant(rows(), cols(), s));
  200|       |}
  201|       |
  202|       |/** \returns an expression of the coefficient-wise == operator of \c *this and a scalar \a s
  203|       | *
  204|       | * \warning this performs an exact comparison, which is generally a bad idea with floating-point types.
  205|       | * In order to check for equality between two vectors or matrices with floating-point coefficients, it is
  206|       | * generally a far better idea to use a fuzzy comparison as provided by isApprox() and
  207|       | * isMuchSmallerThan().
  208|       | *
  209|       | * \sa cwiseEqual(const MatrixBase<OtherDerived> &) const
  210|       | */
  211|       |EIGEN_DEVICE_FUNC inline const CwiseScalarNotEqualReturnType cwiseNotEqual(const Scalar& s) const {
  212|       |  return CwiseScalarNotEqualReturnType(derived(), Derived::Constant(rows(), cols(), s));
  213|       |}
  214|       |
  215|       |/** \returns an expression of the coefficient-wise < operator of \c *this and a scalar \a s */
  216|       |EIGEN_DEVICE_FUNC inline const CwiseScalarLessReturnType cwiseLess(const Scalar& s) const {
  217|       |  return CwiseScalarLessReturnType(derived(), Derived::Constant(rows(), cols(), s));
  218|       |}
  219|       |
  220|       |/** \returns an expression of the coefficient-wise > operator of \c *this and a scalar \a s */
  221|       |EIGEN_DEVICE_FUNC inline const CwiseScalarGreaterReturnType cwiseGreater(const Scalar& s) const {
  222|       |  return CwiseScalarGreaterReturnType(derived(), Derived::Constant(rows(), cols(), s));
  223|       |}
  224|       |
  225|       |/** \returns an expression of the coefficient-wise <= operator of \c *this and a scalar \a s */
  226|       |EIGEN_DEVICE_FUNC inline const CwiseScalarLessOrEqualReturnType cwiseLessOrEqual(const Scalar& s) const {
  227|       |  return CwiseScalarLessOrEqualReturnType(derived(), Derived::Constant(rows(), cols(), s));
  228|       |}
  229|       |
  230|       |/** \returns an expression of the coefficient-wise >= operator of \c *this and a scalar \a s */
  231|       |EIGEN_DEVICE_FUNC inline const CwiseScalarGreaterOrEqualReturnType cwiseGreaterOrEqual(const Scalar& s) const {
  232|       |  return CwiseScalarGreaterOrEqualReturnType(derived(), Derived::Constant(rows(), cols(), s));
  233|       |}
  234|       |
  235|       |template <typename OtherDerived>
  236|       |using CwiseBinaryTypedEqualReturnType =
  237|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ, true>, const Derived, const OtherDerived>;
  238|       |template <typename OtherDerived>
  239|       |using CwiseBinaryTypedNotEqualReturnType =
  240|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_NEQ, true>, const Derived, const OtherDerived>;
  241|       |template <typename OtherDerived>
  242|       |using CwiseBinaryTypedLessReturnType =
  243|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LT, true>, const Derived, const OtherDerived>;
  244|       |template <typename OtherDerived>
  245|       |using CwiseBinaryTypedGreaterReturnType =
  246|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_GT, true>, const Derived, const OtherDerived>;
  247|       |template <typename OtherDerived>
  248|       |using CwiseBinaryTypedLessOrEqualReturnType =
  249|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LE, true>, const Derived, const OtherDerived>;
  250|       |template <typename OtherDerived>
  251|       |using CwiseBinaryTypedGreaterOrEqualReturnType =
  252|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_GE, true>, const Derived, const OtherDerived>;
  253|       |
  254|       |template <typename OtherDerived>
  255|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseBinaryTypedEqualReturnType<OtherDerived> cwiseTypedEqual(
  256|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  257|       |  return CwiseBinaryTypedEqualReturnType<OtherDerived>(derived(), other.derived());
  258|       |}
  259|       |
  260|       |template <typename OtherDerived>
  261|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseBinaryTypedNotEqualReturnType<OtherDerived> cwiseTypedNotEqual(
  262|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  263|       |  return CwiseBinaryTypedNotEqualReturnType<OtherDerived>(derived(), other.derived());
  264|       |}
  265|       |
  266|       |template <typename OtherDerived>
  267|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseBinaryTypedLessReturnType<OtherDerived> cwiseTypedLess(
  268|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  269|       |  return CwiseBinaryTypedLessReturnType<OtherDerived>(derived(), other.derived());
  270|       |}
  271|       |
  272|       |template <typename OtherDerived>
  273|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseBinaryTypedGreaterReturnType<OtherDerived> cwiseTypedGreater(
  274|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  275|       |  return CwiseBinaryTypedGreaterReturnType<OtherDerived>(derived(), other.derived());
  276|       |}
  277|       |
  278|       |template <typename OtherDerived>
  279|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseBinaryTypedLessOrEqualReturnType<OtherDerived> cwiseTypedLessOrEqual(
  280|       |    const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  281|       |  return CwiseBinaryTypedLessOrEqualReturnType<OtherDerived>(derived(), other.derived());
  282|       |}
  283|       |
  284|       |template <typename OtherDerived>
  285|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseBinaryTypedGreaterOrEqualReturnType<OtherDerived>
  286|       |cwiseTypedGreaterOrEqual(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived>& other) const {
  287|       |  return CwiseBinaryTypedGreaterOrEqualReturnType<OtherDerived>(derived(), other.derived());
  288|       |}
  289|       |
  290|       |using CwiseScalarTypedEqualReturnType = CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_EQ, true>,
  291|       |                                                      const Derived, const ConstantReturnType>;
  292|       |using CwiseScalarTypedNotEqualReturnType =
  293|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_NEQ, true>, const Derived,
  294|       |                  const ConstantReturnType>;
  295|       |using CwiseScalarTypedLessReturnType = CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LT, true>,
  296|       |                                                     const Derived, const ConstantReturnType>;
  297|       |using CwiseScalarTypedGreaterReturnType = CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_GT, true>,
  298|       |                                                        const Derived, const ConstantReturnType>;
  299|       |using CwiseScalarTypedLessOrEqualReturnType =
  300|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_LE, true>, const Derived,
  301|       |                  const ConstantReturnType>;
  302|       |using CwiseScalarTypedGreaterOrEqualReturnType =
  303|       |    CwiseBinaryOp<internal::scalar_cmp_op<Scalar, Scalar, internal::cmp_GE, true>, const Derived,
  304|       |                  const ConstantReturnType>;
  305|       |
  306|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseScalarTypedEqualReturnType cwiseTypedEqual(const Scalar& s) const {
  307|       |  return CwiseScalarTypedEqualReturnType(derived(), ConstantReturnType(rows(), cols(), s));
  308|       |}
  309|       |
  310|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseScalarTypedNotEqualReturnType
  311|       |cwiseTypedNotEqual(const Scalar& s) const {
  312|       |  return CwiseScalarTypedNotEqualReturnType(derived(), ConstantReturnType(rows(), cols(), s));
  313|       |}
  314|       |
  315|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseScalarTypedLessReturnType cwiseTypedLess(const Scalar& s) const {
  316|       |  return CwiseScalarTypedLessReturnType(derived(), ConstantReturnType(rows(), cols(), s));
  317|       |}
  318|       |
  319|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseScalarTypedGreaterReturnType cwiseTypedGreater(const Scalar& s) const {
  320|       |  return CwiseScalarTypedGreaterReturnType(derived(), ConstantReturnType(rows(), cols(), s));
  321|       |}
  322|       |
  323|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseScalarTypedLessOrEqualReturnType
  324|       |cwiseTypedLessOrEqual(const Scalar& s) const {
  325|       |  return CwiseScalarTypedLessOrEqualReturnType(derived(), ConstantReturnType(rows(), cols(), s));
  326|       |}
  327|       |
  328|       |EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseScalarTypedGreaterOrEqualReturnType
  329|       |cwiseTypedGreaterOrEqual(const Scalar& s) const {
  330|       |  return CwiseScalarTypedGreaterOrEqualReturnType(derived(), ConstantReturnType(rows(), cols(), s));
  331|       |}

/home/kidus/Desktop/GNNs/eigen/eigen/test/AnnoyingScalar.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2011-2018 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |#ifndef EIGEN_TEST_ANNOYING_SCALAR_H
   11|       |#define EIGEN_TEST_ANNOYING_SCALAR_H
   12|       |
   13|       |#include <ostream>
   14|       |
   15|       |#if EIGEN_COMP_GNUC
   16|       |#pragma GCC diagnostic ignored "-Wshadow"
   17|       |#endif
   18|       |
   19|       |#ifndef EIGEN_TEST_ANNOYING_SCALAR_DONT_THROW
   20|       |struct my_exception {
   21|      3|  my_exception() {}
   22|      6|  ~my_exception() {}
   23|       |};
   24|       |#endif
   25|       |
   26|       |// An AnnoyingScalar is a pseudo scalar type that:
   27|       |// - can randomly through an exception in operator +
   28|       |// - randomly allocate on the heap or initialize a reference to itself making it non trivially copyable, nor movable,
   29|       |// nor relocatable.
   30|       |
   31|       |class AnnoyingScalar {
   32|       | public:
   33|  30.1k|  AnnoyingScalar() {
   34|  30.1k|    init();
   35|  30.1k|    *v = 0;
   36|  30.1k|  }
   37|      0|  AnnoyingScalar(long double _v) {
   38|      0|    init();
   39|      0|    *v = static_cast<float>(_v);
   40|      0|  }
   41|      0|  AnnoyingScalar(double _v) {
   42|      0|    init();
   43|      0|    *v = static_cast<float>(_v);
   44|      0|  }
   45|    534|  AnnoyingScalar(float _v) {
   46|    534|    init();
   47|    534|    *v = _v;
   48|    534|  }
   49|  7.57k|  AnnoyingScalar(int _v) {
   50|  7.57k|    init();
   51|  7.57k|    *v = static_cast<float>(_v);
   52|  7.57k|  }
   53|      0|  AnnoyingScalar(long _v) {
   54|      0|    init();
   55|      0|    *v = static_cast<float>(_v);
   56|      0|  }
   57|      0|  AnnoyingScalar(long long _v) {
   58|      0|    init();
   59|      0|    *v = static_cast<float>(_v);
   60|      0|  }
   61|  5.21k|  AnnoyingScalar(const AnnoyingScalar& other) {
   62|  5.21k|    init();
   63|  5.21k|    *v = *(other.v);
   64|  5.21k|  }
   65|  43.5k|  ~AnnoyingScalar() {
   66|  43.5k|    if (v != &data) delete v;
   67|  43.5k|    instances--;
   68|  43.5k|  }
   69|       |
   70|  43.5k|  void init() {
   71|  43.5k|    if (internal::random<bool>())
   72|  21.9k|      v = new float;
   73|  21.5k|    else
   74|  21.5k|      v = &data;
   75|  43.5k|    instances++;
   76|  43.5k|  }
   77|       |
   78|    300|  AnnoyingScalar operator+(const AnnoyingScalar& other) const {
   79|    300|#ifndef EIGEN_TEST_ANNOYING_SCALAR_DONT_THROW
   80|    300|    countdown--;
   81|    300|    if (countdown <= 0 && !dont_throw) throw my_exception();
   82|    297|#endif
   83|    297|    return AnnoyingScalar(*v + *other.v);
   84|    300|  }
   85|       |
   86|      0|  AnnoyingScalar operator-() const { return AnnoyingScalar(-*v); }
   87|       |
   88|      0|  AnnoyingScalar operator-(const AnnoyingScalar& other) const { return AnnoyingScalar(*v - *other.v); }
   89|       |
   90|    237|  AnnoyingScalar operator*(const AnnoyingScalar& other) const { return AnnoyingScalar((*v) * (*other.v)); }
   91|       |
   92|      0|  AnnoyingScalar operator/(const AnnoyingScalar& other) const { return AnnoyingScalar((*v) / (*other.v)); }
   93|       |
   94|      0|  AnnoyingScalar& operator+=(const AnnoyingScalar& other) {
   95|      0|    *v += *other.v;
   96|      0|    return *this;
   97|      0|  }
   98|      0|  AnnoyingScalar& operator-=(const AnnoyingScalar& other) {
   99|      0|    *v -= *other.v;
  100|      0|    return *this;
  101|      0|  }
  102|      0|  AnnoyingScalar& operator*=(const AnnoyingScalar& other) {
  103|      0|    *v *= *other.v;
  104|      0|    return *this;
  105|      0|  }
  106|      0|  AnnoyingScalar& operator/=(const AnnoyingScalar& other) {
  107|      0|    *v /= *other.v;
  108|      0|    return *this;
  109|      0|  }
  110|  30.9k|  AnnoyingScalar& operator=(const AnnoyingScalar& other) {
  111|  30.9k|    *v = *other.v;
  112|  30.9k|    return *this;
  113|  30.9k|  }
  114|       |
  115|      0|  bool operator==(const AnnoyingScalar& other) const { return numext::equal_strict(*v, *other.v); }
  116|      0|  bool operator!=(const AnnoyingScalar& other) const { return numext::not_equal_strict(*v, *other.v); }
  117|      0|  bool operator<=(const AnnoyingScalar& other) const { return *v <= *other.v; }
  118|      0|  bool operator<(const AnnoyingScalar& other) const { return *v < *other.v; }
  119|      0|  bool operator>=(const AnnoyingScalar& other) const { return *v >= *other.v; }
  120|      0|  bool operator>(const AnnoyingScalar& other) const { return *v > *other.v; }
  121|       |
  122|       |  float* v;
  123|       |  float data;
  124|       |  static int instances;
  125|       |#ifndef EIGEN_TEST_ANNOYING_SCALAR_DONT_THROW
  126|       |  static int countdown;
  127|       |  static bool dont_throw;
  128|       |#endif
  129|       |};
  130|       |
  131|      0|AnnoyingScalar real(const AnnoyingScalar& x) { return x; }
  132|      0|AnnoyingScalar imag(const AnnoyingScalar&) { return 0; }
  133|      0|AnnoyingScalar conj(const AnnoyingScalar& x) { return x; }
  134|      0|AnnoyingScalar sqrt(const AnnoyingScalar& x) { return std::sqrt(*x.v); }
  135|      0|AnnoyingScalar abs(const AnnoyingScalar& x) { return std::abs(*x.v); }
  136|      0|AnnoyingScalar cos(const AnnoyingScalar& x) { return std::cos(*x.v); }
  137|      0|AnnoyingScalar sin(const AnnoyingScalar& x) { return std::sin(*x.v); }
  138|      0|AnnoyingScalar acos(const AnnoyingScalar& x) { return std::acos(*x.v); }
  139|      0|AnnoyingScalar atan2(const AnnoyingScalar& y, const AnnoyingScalar& x) { return std::atan2(*y.v, *x.v); }
  140|       |
  141|      0|std::ostream& operator<<(std::ostream& stream, const AnnoyingScalar& x) {
  142|      0|  stream << (*(x.v));
  143|      0|  return stream;
  144|      0|}
  145|       |
  146|       |int AnnoyingScalar::instances = 0;
  147|       |
  148|       |#ifndef EIGEN_TEST_ANNOYING_SCALAR_DONT_THROW
  149|       |int AnnoyingScalar::countdown = 0;
  150|       |bool AnnoyingScalar::dont_throw = false;
  151|       |#endif
  152|       |
  153|       |namespace Eigen {
  154|       |template <>
  155|       |struct NumTraits<AnnoyingScalar> : NumTraits<float> {
  156|       |  enum {
  157|       |    RequireInitialization = 1,
  158|       |  };
  159|       |  typedef AnnoyingScalar Real;
  160|       |  typedef AnnoyingScalar Nested;
  161|       |  typedef AnnoyingScalar Literal;
  162|       |  typedef AnnoyingScalar NonInteger;
  163|       |};
  164|       |
  165|       |template <>
  166|      0|inline AnnoyingScalar test_precision<AnnoyingScalar>() {
  167|      0|  return test_precision<float>();
  168|      0|}
  169|       |
  170|       |namespace numext {
  171|       |template <>
  172|      0|EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isfinite)(const AnnoyingScalar& x) {
  173|      0|  return (numext::isfinite)(*x.v);
  174|      0|}
  175|       |}  // namespace numext
  176|       |
  177|       |namespace internal {
  178|       |template <>
  179|      0|EIGEN_STRONG_INLINE double cast(const AnnoyingScalar& x) {
  180|      0|  return double(*x.v);
  181|      0|}
  182|       |template <>
  183|      0|EIGEN_STRONG_INLINE float cast(const AnnoyingScalar& x) {
  184|      0|  return *x.v;
  185|      0|}
  186|       |
  187|       |}  // namespace internal
  188|       |}  // namespace Eigen
  189|       |
  190|      0|AnnoyingScalar get_test_precision(const AnnoyingScalar&) { return Eigen::test_precision<AnnoyingScalar>(); }
  191|       |
  192|      0|AnnoyingScalar test_relative_error(const AnnoyingScalar& a, const AnnoyingScalar& b) {
  193|      0|  return test_relative_error(*a.v, *b.v);
  194|      0|}
  195|       |
  196|      0|inline bool test_isApprox(const AnnoyingScalar& a, const AnnoyingScalar& b) {
  197|      0|  return internal::isApprox(*a.v, *b.v, test_precision<float>());
  198|      0|}
  199|       |
  200|      0|inline bool test_isMuchSmallerThan(const AnnoyingScalar& a, const AnnoyingScalar& b) {
  201|      0|  return test_isMuchSmallerThan(*a.v, *b.v);
  202|      0|}
  203|       |
  204|       |#endif  // EIGEN_TEST_ANNOYING_SCALAR_H

/home/kidus/Desktop/GNNs/eigen/eigen/test/exceptions.cpp:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2011 Gael Guennebaud <gael.guennebaud@inria.fr>
    5|       |//
    6|       |// This Source Code Form is subject to the terms of the Mozilla
    7|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    8|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
    9|       |
   10|       |// Various sanity tests with exceptions and non trivially copyable scalar type.
   11|       |//  - no memory leak when a custom scalar type trow an exceptions
   12|       |//  - todo: complete the list of tests!
   13|       |
   14|      8|#define EIGEN_STACK_ALLOCATION_LIMIT 100000000
   15|       |
   16|       |#include "main.h"
   17|       |#include "AnnoyingScalar.h"
   18|       |
   19|       |#define CHECK_MEMLEAK(OP)                                                                                             \
   20|      3|  {                                                                                                                   \
   21|      3|    AnnoyingScalar::countdown = 100;                                                                                  \
   22|      3|    int before = AnnoyingScalar::instances;                                                                           \
   23|      3|    bool exception_thrown = false;                                                                                    \
   24|      3|    try {                                                                                                             \
   25|      3|      OP;                                                                                                             \
   26|      3|    } catch (my_exception) {                                                                                          \
   27|      3|      exception_thrown = true;                                                                                        \
   28|      3|      VERIFY(AnnoyingScalar::instances == before && "memory leak detected in " && EIGEN_MAKESTRING(OP));              \
   29|      3|    }                                                                                                                 \
   30|      3|    VERIFY((AnnoyingScalar::dont_throw) || (exception_thrown && " no exception thrown in " && EIGEN_MAKESTRING(OP))); \
   31|      3|  }
   32|       |
   33|      1|EIGEN_DECLARE_TEST(exceptions) {
   34|      1|  typedef Eigen::Matrix<AnnoyingScalar, Dynamic, 1> VectorType;
   35|      1|  typedef Eigen::Matrix<AnnoyingScalar, Dynamic, Dynamic> MatrixType;
   36|       |
   37|      1|  {
   38|      1|    AnnoyingScalar::dont_throw = false;
   39|      1|    int n = 50;
   40|      1|    VectorType v0(n), v1(n);
   41|      1|    MatrixType m0(n, n), m1(n, n), m2(n, n);
   42|      1|    v0.setOnes();
   43|      1|    v1.setOnes();
   44|      1|    m0.setOnes();
   45|      1|    m1.setOnes();
   46|      1|    m2.setOnes();
   47|      1|    CHECK_MEMLEAK(v0 = m0 * m1 * v1);
   48|      1|    CHECK_MEMLEAK(m2 = m0 * m1 * m2);
   49|      1|    CHECK_MEMLEAK((v0 + v1).dot(v0 + v1));
   50|      1|  }
   51|      1|  VERIFY(AnnoyingScalar::instances == 0 && "global memory leak detected in " && EIGEN_MAKESTRING(OP));
   52|      1|}

/home/kidus/Desktop/GNNs/eigen/eigen/test/main.h:
    1|       |// This file is part of Eigen, a lightweight C++ template library
    2|       |// for linear algebra.
    3|       |//
    4|       |// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
    5|       |// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
    6|       |//
    7|       |// This Source Code Form is subject to the terms of the Mozilla
    8|       |// Public License v. 2.0. If a copy of the MPL was not distributed
    9|       |// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
   10|       |
   11|       |#include <cstdlib>
   12|       |#include <cerrno>
   13|       |#include <ctime>
   14|       |#include <iostream>
   15|       |#include <iomanip>
   16|       |#include <fstream>
   17|       |#include <string>
   18|       |#include <sstream>
   19|       |#include <vector>
   20|       |#include <typeinfo>
   21|       |#include <type_traits>
   22|       |#include <functional>
   23|       |#ifdef EIGEN_USE_SYCL
   24|       |#include <CL/sycl.hpp>
   25|       |#endif
   26|       |
   27|       |// The following includes of STL headers have to be done _before_ the
   28|       |// definition of macros min() and max().  The reason is that many STL
   29|       |// implementations will not work properly as the min and max symbols collide
   30|       |// with the STL functions std::min() and std::max().  The STL headers may check
   31|       |// for the macro definition of min/max and issue a warning or undefine the
   32|       |// macros.
   33|       |//
   34|       |// Still, Windows defines min() and max() in windef.h as part of the regular
   35|       |// Windows system interfaces and many other Windows APIs depend on these
   36|       |// macros being available.  To prevent the macro expansion of min/max and to
   37|       |// make Eigen compatible with the Windows environment all function calls of
   38|       |// std::min() and std::max() have to be written with parenthesis around the
   39|       |// function name.
   40|       |//
   41|       |// All STL headers used by Eigen should be included here.  Because main.h is
   42|       |// included before any Eigen header and because the STL headers are guarded
   43|       |// against multiple inclusions, no STL header will see our own min/max macro
   44|       |// definitions.
   45|       |#include <limits>
   46|       |#include <algorithm>
   47|       |// Disable ICC's std::complex operator specializations so we can use our own.
   48|       |#define _OVERRIDE_COMPLEX_SPECIALIZATION_ 1
   49|       |#include <complex>
   50|       |#include <deque>
   51|       |#include <queue>
   52|       |#include <cassert>
   53|       |#include <list>
   54|       |#if __cplusplus >= 201103L || (defined(_MSVC_LANG) && _MSVC_LANG >= 201103L)
   55|       |#include <random>
   56|       |#include <chrono>
   57|       |#endif
   58|       |#if __cplusplus > 201703L
   59|       |// libstdc++ 9's <memory> indirectly uses max() via <bit>.
   60|       |// libstdc++ 10's <memory> indirectly uses max() via ranges headers.
   61|       |#include <memory>
   62|       |// libstdc++ 11's <thread> indirectly uses max() via semaphore headers.
   63|       |#include <thread>
   64|       |#endif
   65|       |
   66|       |// Configure GPU.
   67|       |#if defined(EIGEN_USE_HIP)
   68|       |#if defined(__HIPCC__) && !defined(EIGEN_NO_HIP)
   69|       |#define EIGEN_HIPCC __HIPCC__
   70|       |#include <hip/hip_runtime.h>
   71|       |#include <hip/hip_runtime_api.h>
   72|       |#endif
   73|       |#elif defined(__CUDACC__) && !defined(EIGEN_NO_CUDA)
   74|       |#define EIGEN_CUDACC __CUDACC__
   75|       |#include <cuda.h>
   76|       |#include <cuda_runtime.h>
   77|       |#include <cuda_runtime_api.h>
   78|       |#if CUDA_VERSION >= 7050
   79|       |#include <cuda_fp16.h>
   80|       |#endif
   81|       |#endif
   82|       |
   83|       |#if defined(EIGEN_CUDACC) || defined(EIGEN_HIPCC)
   84|       |#define EIGEN_TEST_NO_LONGDOUBLE
   85|       |#define EIGEN_DEFAULT_DENSE_INDEX_TYPE int
   86|       |#endif
   87|       |
   88|       |// To test that all calls from Eigen code to std::min() and std::max() are
   89|       |// protected by parenthesis against macro expansion, the min()/max() macros
   90|       |// are defined here and any not-parenthesized min/max call will cause a
   91|       |// compiler error.
   92|       |#if !defined(__HIPCC__) && !defined(EIGEN_USE_SYCL) && !defined(EIGEN_POCKETFFT_DEFAULT)
   93|       |//
   94|       |// HIP header files include the following files
   95|       |//  <thread>
   96|       |//  <regex>
   97|       |//  <unordered_map>
   98|       |// which seem to contain not-parenthesized calls to "max"/"min", triggering the following check and causing the compile
   99|       |// to fail
  100|       |//
  101|       |// Including those header files before the following macro definition for "min" / "max", only partially resolves the
  102|       |// issue This is because other HIP header files also define "isnan" / "isinf" / "isfinite" functions, which are needed
  103|       |// in other headers.
  104|       |//
  105|       |// So instead choosing to simply disable this check for HIP
  106|       |//
  107|       |#define min(A, B) please_protect_your_min_with_parentheses
  108|       |#define max(A, B) please_protect_your_max_with_parentheses
  109|       |#define isnan(X) please_protect_your_isnan_with_parentheses
  110|       |#define isinf(X) please_protect_your_isinf_with_parentheses
  111|       |#define isfinite(X) please_protect_your_isfinite_with_parentheses
  112|       |#endif
  113|       |
  114|       |// test possible conflicts
  115|       |struct real {};
  116|       |struct imag {};
  117|       |
  118|       |#ifdef M_PI
  119|       |#undef M_PI
  120|       |#endif
  121|       |#define M_PI please_use_EIGEN_PI_instead_of_M_PI
  122|       |
  123|       |#define FORBIDDEN_IDENTIFIER \
  124|       |  (this_identifier_is_forbidden_to_avoid_clashes) this_identifier_is_forbidden_to_avoid_clashes
  125|       |// B0 is defined in POSIX header termios.h
  126|       |#define B0 FORBIDDEN_IDENTIFIER
  127|       |#define I FORBIDDEN_IDENTIFIER
  128|       |
  129|       |// _res is defined by resolv.h
  130|       |#define _res FORBIDDEN_IDENTIFIER
  131|       |
  132|       |// Unit tests calling Eigen's blas library must preserve the default blocking size
  133|       |// to avoid troubles.
  134|       |#ifndef EIGEN_NO_DEBUG_SMALL_PRODUCT_BLOCKS
  135|       |#define EIGEN_DEBUG_SMALL_PRODUCT_BLOCKS
  136|       |#endif
  137|       |
  138|       |// shuts down ICC's remark #593: variable "XXX" was set but never used
  139|       |#define TEST_SET_BUT_UNUSED_VARIABLE(X) EIGEN_UNUSED_VARIABLE(X)
  140|       |
  141|       |#ifdef TEST_ENABLE_TEMPORARY_TRACKING
  142|       |
  143|       |static long int nb_temporaries;
  144|       |static long int nb_temporaries_on_assert = -1;
  145|       |
  146|       |#ifdef TEST_IGNORE_STACK_ALLOCATED_TEMPORARY
  147|       |inline void on_temporary_creation(long int size, int SizeAtCompileTime) {
  148|       |  // ignore stack-allocated temporaries
  149|       |  if (SizeAtCompileTime != -1) return;
  150|       |#else
  151|       |inline void on_temporary_creation(long int size, int) {
  152|       |#endif
  153|       |  // here's a great place to set a breakpoint when debugging failures in this test!
  154|       |  if (size != 0) nb_temporaries++;
  155|       |  if (nb_temporaries_on_assert > 0) assert(nb_temporaries < nb_temporaries_on_assert);
  156|       |}
  157|       |
  158|       |#define EIGEN_DENSE_STORAGE_CTOR_PLUGIN \
  159|       |  { on_temporary_creation(size, Size); }
  160|       |
  161|       |#define VERIFY_EVALUATION_COUNT(XPR, N)                            \
  162|       |  {                                                                \
  163|       |    nb_temporaries = 0;                                            \
  164|       |    XPR;                                                           \
  165|       |    if (nb_temporaries != (N)) {                                   \
  166|       |      std::cerr << "nb_temporaries == " << nb_temporaries << "\n"; \
  167|       |    }                                                              \
  168|       |    VERIFY((#XPR) && nb_temporaries == (N));                       \
  169|       |  }
  170|       |
  171|       |#endif
  172|       |
  173|       |#include "split_test_helper.h"
  174|       |
  175|       |#ifdef NDEBUG
  176|       |#undef NDEBUG
  177|       |#endif
  178|       |
  179|       |// On windows CE, NDEBUG is automatically defined <assert.h> if NDEBUG is not defined.
  180|       |#ifndef DEBUG
  181|       |#define DEBUG
  182|       |#endif
  183|       |
  184|      1|#define DEFAULT_REPEAT 10
  185|       |
  186|       |namespace Eigen {
  187|       |static std::vector<std::string> g_test_stack;
  188|       |// level == 0 <=> abort if test fail
  189|       |// level >= 1 <=> warning message to std::cerr if test fail
  190|       |static int g_test_level = 0;
  191|       |static int g_repeat = 1;
  192|       |static unsigned int g_seed = 0;
  193|       |static bool g_has_set_repeat = false, g_has_set_seed = false;
  194|       |
  195|       |class EigenTest {
  196|       | public:
  197|      0|  EigenTest() : m_func(0) {}
  198|      1|  EigenTest(const char* a_name, void (*func)(void)) : m_name(a_name), m_func(func) {
  199|      1|    get_registered_tests().push_back(this);
  200|      1|  }
  201|      1|  const std::string& name() const { return m_name; }
  202|      1|  void operator()() const { m_func(); }
  203|       |
  204|      4|  static const std::vector<EigenTest*>& all() { return get_registered_tests(); }
  205|       |
  206|       | protected:
  207|      5|  static std::vector<EigenTest*>& get_registered_tests() {
  208|      5|    static std::vector<EigenTest*>* ms_registered_tests = new std::vector<EigenTest*>();
  209|      5|    return *ms_registered_tests;
  210|      5|  }
  211|       |  std::string m_name;
  212|       |  void (*m_func)(void);
  213|       |};
  214|       |
  215|       |// Declare and register a test, e.g.:
  216|       |//    EIGEN_DECLARE_TEST(mytest) { ... }
  217|       |// will create a function:
  218|       |//    void test_mytest() { ... }
  219|       |// that will be automatically called.
  220|       |#define EIGEN_DECLARE_TEST(X)                                                              \
  221|       |  void EIGEN_CAT(test_, X)();                                                              \
  222|       |  static EigenTest EIGEN_CAT(test_handler_, X)(EIGEN_MAKESTRING(X), &EIGEN_CAT(test_, X)); \
  223|       |  void EIGEN_CAT(test_, X)()
  224|       |}  // namespace Eigen
  225|       |
  226|       |#define TRACK std::cerr << __FILE__ << " " << __LINE__ << std::endl
  227|       |
  228|       |#define EIGEN_DEFAULT_IO_FORMAT IOFormat(4, 0, "  ", "\n", "", "", "", "")
  229|       |
  230|       |#if (defined(_CPPUNWIND) || defined(__EXCEPTIONS)) && !defined(__CUDA_ARCH__) && !defined(__HIP_DEVICE_COMPILE__) && \
  231|       |    !defined(__SYCL_DEVICE_ONLY__)
  232|       |#define EIGEN_EXCEPTIONS
  233|       |#endif
  234|       |
  235|       |#ifndef EIGEN_NO_ASSERTION_CHECKING
  236|       |
  237|       |namespace Eigen {
  238|       |static const bool should_raise_an_assert = false;
  239|       |
  240|       |// Used to avoid to raise two exceptions at a time in which
  241|       |// case the exception is not properly caught.
  242|       |// This may happen when a second exceptions is triggered in a destructor.
  243|       |static bool no_more_assert = false;
  244|       |static bool report_on_cerr_on_assert_failure = true;
  245|       |
  246|       |struct eigen_assert_exception {
  247|      0|  eigen_assert_exception(void) {}
  248|      0|  ~eigen_assert_exception() { Eigen::no_more_assert = false; }
  249|       |};
  250|       |
  251|       |struct eigen_static_assert_exception {
  252|      0|  eigen_static_assert_exception(void) {}
  253|      0|  ~eigen_static_assert_exception() { Eigen::no_more_assert = false; }
  254|       |};
  255|       |}  // namespace Eigen
  256|       |// If EIGEN_DEBUG_ASSERTS is defined and if no assertion is triggered while
  257|       |// one should have been, then the list of executed assertions is printed out.
  258|       |//
  259|       |// EIGEN_DEBUG_ASSERTS is not enabled by default as it
  260|       |// significantly increases the compilation time
  261|       |// and might even introduce side effects that would hide
  262|       |// some memory errors.
  263|       |#ifdef EIGEN_DEBUG_ASSERTS
  264|       |
  265|       |namespace Eigen {
  266|       |namespace internal {
  267|       |static bool push_assert = false;
  268|       |}
  269|       |static std::vector<std::string> eigen_assert_list;
  270|       |}  // namespace Eigen
  271|       |#define eigen_assert(a)                                                                                             \
  272|       |  if ((!(a)) && (!no_more_assert)) {                                                                                \
  273|       |    if (report_on_cerr_on_assert_failure) std::cerr << #a << " " __FILE__ << "(" << __LINE__ << ")\n";              \
  274|       |    Eigen::no_more_assert = true;                                                                                   \
  275|       |    EIGEN_THROW_X(Eigen::eigen_assert_exception());                                                                 \
  276|       |  } else if (Eigen::internal::push_assert) {                                                                        \
  277|       |    eigen_assert_list.push_back(std::string(EIGEN_MAKESTRING(__FILE__) " (" EIGEN_MAKESTRING(__LINE__) ") : " #a)); \
  278|       |  }
  279|       |
  280|       |#ifdef EIGEN_EXCEPTIONS
  281|       |#define VERIFY_RAISES_ASSERT(a)                                                                                  \
  282|       |  {                                                                                                              \
  283|       |    Eigen::no_more_assert = false;                                                                               \
  284|       |    Eigen::eigen_assert_list.clear();                                                                            \
  285|       |    Eigen::internal::push_assert = true;                                                                         \
  286|       |    Eigen::report_on_cerr_on_assert_failure = false;                                                             \
  287|       |    try {                                                                                                        \
  288|       |      a;                                                                                                         \
  289|       |      std::cerr << "One of the following asserts should have been triggered:\n";                                 \
  290|       |      for (uint ai = 0; ai < eigen_assert_list.size(); ++ai) std::cerr << "  " << eigen_assert_list[ai] << "\n"; \
  291|       |      VERIFY(Eigen::should_raise_an_assert&& #a);                                                                \
  292|       |    } catch (Eigen::eigen_assert_exception) {                                                                    \
  293|       |      Eigen::internal::push_assert = false;                                                                      \
  294|       |      VERIFY(true);                                                                                              \
  295|       |    }                                                                                                            \
  296|       |    Eigen::report_on_cerr_on_assert_failure = true;                                                              \
  297|       |    Eigen::internal::push_assert = false;                                                                        \
  298|       |  }
  299|       |#endif  // EIGEN_EXCEPTIONS
  300|       |
  301|       |#elif !defined(__CUDACC__) && !defined(__HIPCC__) && !defined(__SYCL_DEVICE_ONLY__)  // EIGEN_DEBUG_ASSERTS
  302|       |#define eigen_assert(a)                               \
  303|  87.2k|  if ((!(a)) && (!no_more_assert)) {                  \
  304|      0|    Eigen::no_more_assert = true;                     \
  305|      0|    if (report_on_cerr_on_assert_failure) {           \
  306|      0|      eigen_plain_assert(a);                          \
  307|      0|    } else {                                          \
  308|      0|      EIGEN_THROW_X(Eigen::eigen_assert_exception()); \
  309|      0|    }                                                 \
  310|      0|  }
  311|       |
  312|       |#ifdef EIGEN_EXCEPTIONS
  313|       |#define VERIFY_RAISES_ASSERT(a)                      \
  314|       |  {                                                  \
  315|       |    Eigen::no_more_assert = false;                   \
  316|       |    Eigen::report_on_cerr_on_assert_failure = false; \
  317|       |    try {                                            \
  318|       |      a;                                             \
  319|       |      VERIFY(Eigen::should_raise_an_assert&& #a);    \
  320|       |    } catch (Eigen::eigen_assert_exception&) {       \
  321|       |      VERIFY(true);                                  \
  322|       |    }                                                \
  323|       |    Eigen::report_on_cerr_on_assert_failure = true;  \
  324|       |  }
  325|       |#endif  // EIGEN_EXCEPTIONS
  326|       |#endif  // EIGEN_DEBUG_ASSERTS
  327|       |
  328|       |#ifndef VERIFY_RAISES_ASSERT
  329|       |#define VERIFY_RAISES_ASSERT(a) std::cout << "Can't VERIFY_RAISES_ASSERT( " #a " ) with exceptions disabled\n";
  330|       |#endif
  331|       |
  332|       |#if !defined(__CUDACC__) && !defined(__HIPCC__) && !defined(SYCL_DEVICE_ONLY)
  333|       |#define EIGEN_USE_CUSTOM_ASSERT
  334|       |#endif
  335|       |
  336|       |#else  // EIGEN_NO_ASSERTION_CHECKING
  337|       |
  338|       |#define VERIFY_RAISES_ASSERT(a) \
  339|       |  {}
  340|       |
  341|       |#endif  // EIGEN_NO_ASSERTION_CHECKING
  342|       |
  343|       |#if !defined(EIGEN_TESTING_CONSTEXPR) && !defined(EIGEN_TESTING_PLAINOBJECT_CTOR)
  344|       |#define EIGEN_INTERNAL_DEBUGGING
  345|       |#endif
  346|       |#include <Eigen/QR>  // required for createRandomPIMatrixOfRank and generateRandomMatrixSvs
  347|       |
  348|       |inline void verify_impl(bool condition, const char* testname, const char* file, int line,
  349|      8|                        const char* condition_as_string) {
  350|      8|  if (!condition) {
  351|      0|    if (Eigen::g_test_level > 0) std::cerr << "WARNING: ";
  352|      0|    std::cerr << "Test " << testname << " failed in " << file << " (" << line << ")" << std::endl
  353|      0|              << "    " << condition_as_string << std::endl;
  354|      0|    std::cerr << "Stack:\n";
  355|      0|    const int test_stack_size = static_cast<int>(Eigen::g_test_stack.size());
  356|      0|    for (int i = test_stack_size - 1; i >= 0; --i) std::cerr << "  - " << Eigen::g_test_stack[i] << "\n";
  357|      0|    std::cerr << "\n";
  358|      0|    if (Eigen::g_test_level == 0) abort();
  359|      0|  }
  360|      8|}
  361|       |
  362|     34|#define VERIFY(a) ::verify_impl(a, g_test_stack.back().c_str(), __FILE__, __LINE__, EIGEN_MAKESTRING(a))
  363|       |
  364|       |#define VERIFY_GE(a, b) ::verify_impl(a >= b, g_test_stack.back().c_str(), __FILE__, __LINE__, EIGEN_MAKESTRING(a >= b))
  365|       |#define VERIFY_LE(a, b) ::verify_impl(a <= b, g_test_stack.back().c_str(), __FILE__, __LINE__, EIGEN_MAKESTRING(a <= b))
  366|       |
  367|       |#define VERIFY_IS_EQUAL(a, b) VERIFY(test_is_equal(a, b, true))
  368|       |#define VERIFY_IS_NOT_EQUAL(a, b) VERIFY(test_is_equal(a, b, false))
  369|       |#define VERIFY_IS_APPROX(a, b) VERIFY(verifyIsApprox(a, b))
  370|       |#define VERIFY_IS_NOT_APPROX(a, b) VERIFY(!test_isApprox(a, b))
  371|       |#define VERIFY_IS_MUCH_SMALLER_THAN(a, b) VERIFY(test_isMuchSmallerThan(a, b))
  372|       |#define VERIFY_IS_NOT_MUCH_SMALLER_THAN(a, b) VERIFY(!test_isMuchSmallerThan(a, b))
  373|       |#define VERIFY_IS_APPROX_OR_LESS_THAN(a, b) VERIFY(test_isApproxOrLessThan(a, b))
  374|       |#define VERIFY_IS_NOT_APPROX_OR_LESS_THAN(a, b) VERIFY(!test_isApproxOrLessThan(a, b))
  375|       |#define VERIFY_IS_CWISE_EQUAL(a, b) VERIFY(verifyIsCwiseApprox(a, b, true))
  376|       |#define VERIFY_IS_CWISE_APPROX(a, b) VERIFY(verifyIsCwiseApprox(a, b, false))
  377|       |
  378|       |#define VERIFY_IS_UNITARY(a) VERIFY(test_isUnitary(a))
  379|       |
  380|       |#define STATIC_CHECK(COND) EIGEN_STATIC_ASSERT((COND), EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT)
  381|       |
  382|       |#define CALL_SUBTEST(FUNC)                          \
  383|       |  do {                                              \
  384|       |    g_test_stack.push_back(EIGEN_MAKESTRING(FUNC)); \
  385|       |    FUNC;                                           \
  386|       |    g_test_stack.pop_back();                        \
  387|       |  } while (0)
  388|       |
  389|       |// Forward declarations to avoid ICC warnings
  390|       |#if EIGEN_COMP_ICC
  391|       |
  392|       |template <typename T>
  393|       |std::string type_name();
  394|       |
  395|       |namespace Eigen {
  396|       |
  397|       |template <typename T, typename U>
  398|       |bool test_is_equal(const T& actual, const U& expected, bool expect_equal = true);
  399|       |
  400|       |}  // end namespace Eigen
  401|       |
  402|       |#endif  // EIGEN_COMP_ICC
  403|       |
  404|       |namespace Eigen {
  405|       |
  406|       |template <typename T1, typename T2>
  407|       |std::enable_if_t<internal::is_same<T1, T2>::value, bool> is_same_type(const T1&, const T2&) {
  408|       |  return true;
  409|       |}
  410|       |
  411|       |template <typename T>
  412|      0|inline typename NumTraits<T>::Real test_precision() {
  413|      0|  return NumTraits<T>::dummy_precision();
  414|      0|}
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionIsEENS_9NumTraitsIT_E4RealEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionItEENS_9NumTraitsIT_E4RealEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionIiEENS_9NumTraitsIT_E4RealEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionIjEENS_9NumTraitsIT_E4RealEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionIlEENS_9NumTraitsIT_E4RealEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionImEENS_9NumTraitsIT_E4RealEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionIxEENS_9NumTraitsIT_E4RealEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionIyEENS_9NumTraitsIT_E4RealEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionINS_4halfEEENS_9NumTraitsIT_E4RealEv
  ------------------
  | Unexecuted instantiation: _ZN5Eigen14test_precisionINS_8bfloat16EEENS_9NumTraitsIT_E4RealEv
  ------------------
  415|       |template <>
  416|      0|inline float test_precision<float>() {
  417|      0|  return 1e-3f;
  418|      0|}
  419|       |template <>
  420|      0|inline double test_precision<double>() {
  421|      0|  return 1e-6;
  422|      0|}
  423|       |template <>
  424|      0|inline long double test_precision<long double>() {
  425|      0|  return 1e-6l;
  426|      0|}
  427|       |template <>
  428|      0|inline float test_precision<std::complex<float> >() {
  429|      0|  return test_precision<float>();
  430|      0|}
  431|       |template <>
  432|      0|inline double test_precision<std::complex<double> >() {
  433|      0|  return test_precision<double>();
  434|      0|}
  435|       |template <>
  436|      0|inline long double test_precision<std::complex<long double> >() {
  437|      0|  return test_precision<long double>();
  438|      0|}
  439|       |
  440|       |#define EIGEN_TEST_SCALAR_TEST_OVERLOAD(TYPE)                                          \
  441|      0|  inline bool test_isApprox(TYPE a, TYPE b) {                                          \
  442|      0|    return numext::equal_strict(a, b) || ((numext::isnan)(a) && (numext::isnan)(b)) || \
  443|      0|           (internal::isApprox(a, b, test_precision<TYPE>()));                         \
  444|      0|  }                                                                                    \
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxEss
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxEtt
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxEii
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxEjj
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxEmm
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxExx
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxEyy
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxEff
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxEdd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxENS_4halfES0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen13test_isApproxENS_8bfloat16ES0_
  ------------------
  445|      0|  inline bool test_isCwiseApprox(TYPE a, TYPE b, bool exact) {                         \
  446|      0|    return numext::equal_strict(a, b) || ((numext::isnan)(a) && (numext::isnan)(b)) || \
  447|      0|           (!exact && internal::isApprox(a, b, test_precision<TYPE>()));               \
  448|      0|  }                                                                                    \
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxEssb
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxEttb
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxEiib
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxEjjb
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxEllb
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxEmmb
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxExxb
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxEyyb
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxEffb
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxEddb
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxENS_4halfES0_b
  ------------------
  | Unexecuted instantiation: _ZN5Eigen18test_isCwiseApproxENS_8bfloat16ES0_b
  ------------------
  449|      0|  inline bool test_isMuchSmallerThan(TYPE a, TYPE b) {                                 \
  450|      0|    return internal::isMuchSmallerThan(a, b, test_precision<TYPE>());                  \
  451|      0|  }                                                                                    \
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanEss
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanEtt
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanEii
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanEjj
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanEmm
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanExx
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanEyy
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanEff
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanEdd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanENS_4halfES0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen22test_isMuchSmallerThanENS_8bfloat16ES0_
  ------------------
  452|      0|  inline bool test_isApproxOrLessThan(TYPE a, TYPE b) {                                \
  453|      0|    return internal::isApproxOrLessThan(a, b, test_precision<TYPE>());                 \
  454|      0|  }
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanEss
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanEtt
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanEii
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanEjj
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanEll
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanEmm
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanExx
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanEyy
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanEff
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanEdd
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanENS_4halfES0_
  ------------------
  | Unexecuted instantiation: _ZN5Eigen23test_isApproxOrLessThanENS_8bfloat16ES0_
  ------------------
  455|       |
  456|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(short)
  457|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(unsigned short)
  458|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(int)
  459|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(unsigned int)
  460|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(long)
  461|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(unsigned long)
  462|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(long long)
  463|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(unsigned long long)
  464|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(float)
  465|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(double)
  466|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(half)
  467|       |EIGEN_TEST_SCALAR_TEST_OVERLOAD(bfloat16)
  468|       |
  469|       |#undef EIGEN_TEST_SCALAR_TEST_OVERLOAD
  470|       |
  471|       |#ifndef EIGEN_TEST_NO_COMPLEX
  472|      0|inline bool test_isApprox(const std::complex<float>& a, const std::complex<float>& b) {
  473|      0|  return internal::isApprox(a, b, test_precision<std::complex<float> >());
  474|      0|}
  475|      0|inline bool test_isMuchSmallerThan(const std::complex<float>& a, const std::complex<float>& b) {
  476|      0|  return internal::isMuchSmallerThan(a, b, test_precision<std::complex<float> >());
  477|      0|}
  478|       |
  479|      0|inline bool test_isApprox(const std::complex<double>& a, const std::complex<double>& b) {
  480|      0|  return internal::isApprox(a, b, test_precision<std::complex<double> >());
  481|      0|}
  482|      0|inline bool test_isMuchSmallerThan(const std::complex<double>& a, const std::complex<double>& b) {
  483|      0|  return internal::isMuchSmallerThan(a, b, test_precision<std::complex<double> >());
  484|      0|}
  485|       |
  486|       |#ifndef EIGEN_TEST_NO_LONGDOUBLE
  487|      0|inline bool test_isApprox(const std::complex<long double>& a, const std::complex<long double>& b) {
  488|      0|  return internal::isApprox(a, b, test_precision<std::complex<long double> >());
  489|      0|}
  490|      0|inline bool test_isMuchSmallerThan(const std::complex<long double>& a, const std::complex<long double>& b) {
  491|      0|  return internal::isMuchSmallerThan(a, b, test_precision<std::complex<long double> >());
  492|      0|}
  493|       |#endif
  494|       |#endif
  495|       |
  496|       |#ifndef EIGEN_TEST_NO_LONGDOUBLE
  497|      0|inline bool test_isApprox(const long double& a, const long double& b) {
  498|      0|  bool ret = internal::isApprox(a, b, test_precision<long double>());
  499|      0|  if (!ret)
  500|      0|    std::cerr << std::endl << "    actual   = " << a << std::endl << "    expected = " << b << std::endl << std::endl;
  501|      0|  return ret;
  502|      0|}
  503|       |
  504|      0|inline bool test_isMuchSmallerThan(const long double& a, const long double& b) {
  505|      0|  return internal::isMuchSmallerThan(a, b, test_precision<long double>());
  506|      0|}
  507|      0|inline bool test_isApproxOrLessThan(const long double& a, const long double& b) {
  508|      0|  return internal::isApproxOrLessThan(a, b, test_precision<long double>());
  509|      0|}
  510|       |#endif  // EIGEN_TEST_NO_LONGDOUBLE
  511|       |
  512|       |// test_relative_error returns the relative difference between a and b as a real scalar as used in isApprox.
  513|       |template <typename T1, typename T2>
  514|       |typename NumTraits<typename T1::RealScalar>::NonInteger test_relative_error(const EigenBase<T1>& a,
  515|       |                                                                            const EigenBase<T2>& b) {
  516|       |  using std::sqrt;
  517|       |  typedef typename NumTraits<typename T1::RealScalar>::NonInteger RealScalar;
  518|       |  typename internal::nested_eval<T1, 2>::type ea(a.derived());
  519|       |  typename internal::nested_eval<T2, 2>::type eb(b.derived());
  520|       |  return sqrt(RealScalar((ea.matrix() - eb.matrix()).cwiseAbs2().sum()) /
  521|       |              RealScalar((std::min)(eb.cwiseAbs2().sum(), ea.cwiseAbs2().sum())));
  522|       |}
  523|       |
  524|       |template <typename T1, typename T2>
  525|       |typename T1::RealScalar test_relative_error(const T1& a, const T2& b, const typename T1::Coefficients* = 0) {
  526|       |  return test_relative_error(a.coeffs(), b.coeffs());
  527|       |}
  528|       |
  529|       |template <typename T1, typename T2>
  530|       |typename T1::Scalar test_relative_error(const T1& a, const T2& b, const typename T1::MatrixType* = 0) {
  531|       |  return test_relative_error(a.matrix(), b.matrix());
  532|       |}
  533|       |
  534|       |template <typename S, int D>
  535|       |S test_relative_error(const Translation<S, D>& a, const Translation<S, D>& b) {
  536|       |  return test_relative_error(a.vector(), b.vector());
  537|       |}
  538|       |
  539|       |template <typename S, int D, int O>
  540|       |S test_relative_error(const ParametrizedLine<S, D, O>& a, const ParametrizedLine<S, D, O>& b) {
  541|       |  return (std::max)(test_relative_error(a.origin(), b.origin()), test_relative_error(a.origin(), b.origin()));
  542|       |}
  543|       |
  544|       |template <typename S, int D>
  545|       |S test_relative_error(const AlignedBox<S, D>& a, const AlignedBox<S, D>& b) {
  546|       |  return (std::max)(test_relative_error((a.min)(), (b.min)()), test_relative_error((a.max)(), (b.max)()));
  547|       |}
  548|       |
  549|       |template <typename Derived>
  550|       |class SparseMatrixBase;
  551|       |template <typename T1, typename T2>
  552|       |typename T1::RealScalar test_relative_error(const MatrixBase<T1>& a, const SparseMatrixBase<T2>& b) {
  553|       |  return test_relative_error(a, b.toDense());
  554|       |}
  555|       |
  556|       |template <typename Derived>
  557|       |class SparseMatrixBase;
  558|       |template <typename T1, typename T2>
  559|       |typename T1::RealScalar test_relative_error(const SparseMatrixBase<T1>& a, const MatrixBase<T2>& b) {
  560|       |  return test_relative_error(a.toDense(), b);
  561|       |}
  562|       |
  563|       |template <typename Derived>
  564|       |class SparseMatrixBase;
  565|       |template <typename T1, typename T2>
  566|       |typename T1::RealScalar test_relative_error(const SparseMatrixBase<T1>& a, const SparseMatrixBase<T2>& b) {
  567|       |  return test_relative_error(a.toDense(), b.toDense());
  568|       |}
  569|       |
  570|       |template <typename T1, typename T2>
  571|       |typename NumTraits<typename NumTraits<T1>::Real>::NonInteger test_relative_error(
  572|      0|    const T1& a, const T2& b, std::enable_if_t<internal::is_arithmetic<typename NumTraits<T1>::Real>::value, T1>* = 0) {
  573|      0|  typedef typename NumTraits<typename NumTraits<T1>::Real>::NonInteger RealScalar;
  574|      0|  return numext::sqrt(RealScalar(numext::abs2(a - b)) /
  575|      0|                      (numext::mini)(RealScalar(numext::abs2(a)), RealScalar(numext::abs2(b))));
  576|      0|}
  577|       |
  578|       |template <typename T>
  579|       |T test_relative_error(const Rotation2D<T>& a, const Rotation2D<T>& b) {
  580|       |  return test_relative_error(a.angle(), b.angle());
  581|       |}
  582|       |
  583|       |template <typename T>
  584|       |T test_relative_error(const AngleAxis<T>& a, const AngleAxis<T>& b) {
  585|       |  return (std::max)(test_relative_error(a.angle(), b.angle()), test_relative_error(a.axis(), b.axis()));
  586|       |}
  587|       |
  588|       |template <typename Type1, typename Type2>
  589|       |inline bool test_isApprox(const Type1& a, const Type2& b, typename Type1::Scalar* = 0)  // Enabled for Eigen's type only
  590|       |{
  591|       |  return a.isApprox(b, test_precision<typename Type1::Scalar>());
  592|       |}
  593|       |
  594|       |// get_test_precision is a small wrapper to test_precision allowing to return the scalar precision for either scalars or
  595|       |// expressions
  596|       |template <typename T>
  597|       |typename NumTraits<typename T::Scalar>::Real get_test_precision(const T&, const typename T::Scalar* = 0) {
  598|       |  return test_precision<typename NumTraits<typename T::Scalar>::Real>();
  599|       |}
  600|       |
  601|       |template <typename T>
  602|       |typename NumTraits<T>::Real get_test_precision(
  603|       |    const T&, std::enable_if_t<internal::is_arithmetic<typename NumTraits<T>::Real>::value, T>* = 0) {
  604|       |  return test_precision<typename NumTraits<T>::Real>();
  605|       |}
  606|       |
  607|       |// verifyIsApprox is a wrapper to test_isApprox that outputs the relative difference magnitude if the test fails.
  608|       |template <typename Type1, typename Type2>
  609|       |inline bool verifyIsApprox(const Type1& a, const Type2& b) {
  610|       |  bool ret = test_isApprox(a, b);
  611|       |  if (!ret) {
  612|       |    std::cerr << "Difference too large wrt tolerance " << get_test_precision(a)
  613|       |              << ", relative error is: " << test_relative_error(a, b) << std::endl;
  614|       |  }
  615|       |  return ret;
  616|       |}
  617|       |
  618|       |// verifyIsCwiseApprox is a wrapper to test_isCwiseApprox that outputs the relative difference magnitude if the test
  619|       |// fails.
  620|       |template <typename Type1, typename Type2>
  621|       |inline bool verifyIsCwiseApprox(const Type1& a, const Type2& b, bool exact) {
  622|       |  bool ret = test_isCwiseApprox(a, b, exact);
  623|       |  if (!ret) {
  624|       |    if (exact) {
  625|       |      std::cerr << "Values are not an exact match";
  626|       |    } else {
  627|       |      std::cerr << "Difference too large wrt tolerance " << get_test_precision(a);
  628|       |    }
  629|       |    std::cerr << ", relative error is: " << test_relative_error(a, b) << std::endl;
  630|       |  }
  631|       |  return ret;
  632|       |}
  633|       |
  634|       |// The idea behind this function is to compare the two scalars a and b where
  635|       |// the scalar ref is a hint about the expected order of magnitude of a and b.
  636|       |// WARNING: the scalar a and b must be positive
  637|       |// Therefore, if for some reason a and b are very small compared to ref,
  638|       |// we won't issue a false negative.
  639|       |// This test could be: abs(a-b) <= eps * ref
  640|       |// However, it seems that simply comparing a+ref and b+ref is more sensitive to true error.
  641|       |template <typename Scalar, typename ScalarRef>
  642|       |inline bool test_isApproxWithRef(const Scalar& a, const Scalar& b, const ScalarRef& ref) {
  643|       |  return test_isApprox(a + ref, b + ref);
  644|       |}
  645|       |
  646|       |template <typename Derived1, typename Derived2>
  647|       |inline bool test_isMuchSmallerThan(const MatrixBase<Derived1>& m1, const MatrixBase<Derived2>& m2) {
  648|       |  return m1.isMuchSmallerThan(m2, test_precision<typename internal::traits<Derived1>::Scalar>());
  649|       |}
  650|       |
  651|       |template <typename Derived>
  652|       |inline bool test_isMuchSmallerThan(const MatrixBase<Derived>& m,
  653|       |                                   const typename NumTraits<typename internal::traits<Derived>::Scalar>::Real& s) {
  654|       |  return m.isMuchSmallerThan(s, test_precision<typename internal::traits<Derived>::Scalar>());
  655|       |}
  656|       |
  657|       |template <typename Derived>
  658|       |inline bool test_isUnitary(const MatrixBase<Derived>& m) {
  659|       |  return m.isUnitary(test_precision<typename internal::traits<Derived>::Scalar>());
  660|       |}
  661|       |
  662|       |// Checks component-wise, works with infs and nans.
  663|       |template <typename Derived1, typename Derived2>
  664|       |bool test_isCwiseApprox(const DenseBase<Derived1>& m1, const DenseBase<Derived2>& m2, bool exact) {
  665|       |  if (m1.rows() != m2.rows()) {
  666|       |    return false;
  667|       |  }
  668|       |  if (m1.cols() != m2.cols()) {
  669|       |    return false;
  670|       |  }
  671|       |  for (Index r = 0; r < m1.rows(); ++r) {
  672|       |    for (Index c = 0; c < m1.cols(); ++c) {
  673|       |      if (m1(r, c) != m2(r, c) && !((numext::isnan)(m1(r, c)) && (numext::isnan)(m2(r, c))) &&
  674|       |          (exact || !test_isApprox(m1(r, c), m2(r, c)))) {
  675|       |        return false;
  676|       |      }
  677|       |    }
  678|       |  }
  679|       |  return true;
  680|       |}
  681|       |
  682|       |template <typename Derived1, typename Derived2>
  683|       |bool test_isCwiseApprox(const SparseMatrixBase<Derived1>& m1, const SparseMatrixBase<Derived2>& m2, bool exact) {
  684|       |  return test_isCwiseApprox(m1.toDense(), m2.toDense(), exact);
  685|       |}
  686|       |
  687|       |template <typename T, typename U>
  688|       |bool test_is_equal(const T& actual, const U& expected, bool expect_equal) {
  689|       |  if (numext::equal_strict(actual, expected) == expect_equal) return true;
  690|       |  // false:
  691|       |  std::cerr << "\n    actual   = " << actual << "\n    expected " << (expect_equal ? "= " : "!=") << expected << "\n\n";
  692|       |  return false;
  693|       |}
  694|       |
  695|       |/**
  696|       | * Check if number is "not a number" (NaN).
  697|       | *
  698|       | * @tparam T input type
  699|       | * @param x input value
  700|       | * @return true, if input value is "not a number" (NaN)
  701|       | */
  702|       |template <typename T>
  703|       |bool isNotNaN(const T& x) {
  704|       |  return x == x;
  705|       |}
  706|       |
  707|       |/**
  708|       | * Check if number is plus infinity.
  709|       | *
  710|       | * @tparam T input type
  711|       | * @param x input value
  712|       | * @return true, if input value is plus infinity
  713|       | */
  714|       |template <typename T>
  715|       |bool isPlusInf(const T& x) {
  716|       |  return x > NumTraits<T>::highest();
  717|       |}
  718|       |
  719|       |/**
  720|       | * Check if number is minus infinity.
  721|       | *
  722|       | * @tparam T input type
  723|       | * @param x input value
  724|       | * @return true, if input value is minus infinity
  725|       | */
  726|       |template <typename T>
  727|       |bool isMinusInf(const T& x) {
  728|       |  return x < NumTraits<T>::lowest();
  729|       |}
  730|       |
  731|       |}  // end namespace Eigen
  732|       |
  733|       |#include "random_matrix_helper.h"
  734|       |
  735|       |template <typename T>
  736|       |struct GetDifferentType;
  737|       |
  738|       |template <>
  739|       |struct GetDifferentType<float> {
  740|       |  typedef double type;
  741|       |};
  742|       |template <>
  743|       |struct GetDifferentType<double> {
  744|       |  typedef float type;
  745|       |};
  746|       |template <typename T>
  747|       |struct GetDifferentType<std::complex<T> > {
  748|       |  typedef std::complex<typename GetDifferentType<T>::type> type;
  749|       |};
  750|       |
  751|       |template <typename T>
  752|       |std::string type_name(T) {
  753|       |  return typeid(T).name();
  754|       |}
  755|       |template <>
  756|      0|std::string type_name<float>(float) {
  757|      0|  return "float";
  758|      0|}
  759|       |template <>
  760|      0|std::string type_name<double>(double) {
  761|      0|  return "double";
  762|      0|}
  763|       |template <>
  764|      0|std::string type_name<long double>(long double) {
  765|      0|  return "long double";
  766|      0|}
  767|       |template <>
  768|      0|std::string type_name<Eigen::half>(Eigen::half) {
  769|      0|  return "half";
  770|      0|}
  771|       |template <>
  772|      0|std::string type_name<Eigen::bfloat16>(Eigen::bfloat16) {
  773|      0|  return "bfloat16";
  774|      0|}
  775|       |template <>
  776|      0|std::string type_name<int8_t>(int8_t) {
  777|      0|  return "int8_t";
  778|      0|}
  779|       |template <>
  780|      0|std::string type_name<int16_t>(int16_t) {
  781|      0|  return "int16_t";
  782|      0|}
  783|       |template <>
  784|      0|std::string type_name<int32_t>(int32_t) {
  785|      0|  return "int32_t";
  786|      0|}
  787|       |template <>
  788|      0|std::string type_name<int64_t>(int64_t) {
  789|      0|  return "int64_t";
  790|      0|}
  791|       |template <>
  792|      0|std::string type_name<uint8_t>(uint8_t) {
  793|      0|  return "uint8_t";
  794|      0|}
  795|       |template <>
  796|      0|std::string type_name<uint16_t>(uint16_t) {
  797|      0|  return "uint16_t";
  798|      0|}
  799|       |template <>
  800|      0|std::string type_name<uint32_t>(uint32_t) {
  801|      0|  return "uint32_t";
  802|      0|}
  803|       |template <>
  804|      0|std::string type_name<uint64_t>(uint64_t) {
  805|      0|  return "uint64_t";
  806|      0|}
  807|       |template <>
  808|      0|std::string type_name<std::complex<float> >(std::complex<float>) {
  809|      0|  return "complex<float>";
  810|      0|}
  811|       |template <>
  812|      0|std::string type_name<std::complex<double> >(std::complex<double>) {
  813|      0|  return "complex<double>";
  814|      0|}
  815|       |template <>
  816|      0|std::string type_name<std::complex<long double> >(std::complex<long double>) {
  817|      0|  return "complex<long double>";
  818|      0|}
  819|       |template <>
  820|      0|std::string type_name<std::complex<int> >(std::complex<int>) {
  821|      0|  return "complex<int>";
  822|      0|}
  823|       |template <typename T>
  824|       |std::string type_name() {
  825|       |  return type_name(T());
  826|       |}
  827|       |
  828|       |using namespace Eigen;
  829|       |
  830|       |/**
  831|       | * Set number of repetitions for unit test from input string.
  832|       | *
  833|       | * @param str input string
  834|       | */
  835|      0|inline void set_repeat_from_string(const char* str) {
  836|      0|  errno = 0;
  837|      0|  g_repeat = int(strtoul(str, 0, 10));
  838|      0|  if (errno || g_repeat <= 0) {
  839|      0|    std::cout << "Invalid repeat value " << str << std::endl;
  840|      0|    exit(EXIT_FAILURE);
  841|      0|  }
  842|      0|  g_has_set_repeat = true;
  843|      0|}
  844|       |
  845|       |/**
  846|       | * Set seed for randomized unit tests from input string.
  847|       | *
  848|       | * @param str input string
  849|       | */
  850|      0|inline void set_seed_from_string(const char* str) {
  851|      0|  errno = 0;
  852|      0|  g_seed = int(strtoul(str, 0, 10));
  853|      0|  if (errno || g_seed == 0) {
  854|      0|    std::cout << "Invalid seed value " << str << std::endl;
  855|      0|    exit(EXIT_FAILURE);
  856|      0|  }
  857|      0|  g_has_set_seed = true;
  858|      0|}
  859|       |
  860|      1|int main(int argc, char* argv[]) {
  861|      1|  g_has_set_repeat = false;
  862|      1|  g_has_set_seed = false;
  863|      1|  bool need_help = false;
  864|       |
  865|      1|  for (int i = 1; i < argc; i++) {
  866|      0|    if (argv[i][0] == 'r') {
  867|      0|      if (g_has_set_repeat) {
  868|      0|        std::cout << "Argument " << argv[i] << " conflicting with a former argument" << std::endl;
  869|      0|        return 1;
  870|      0|      }
  871|      0|      set_repeat_from_string(argv[i] + 1);
  872|      0|    } else if (argv[i][0] == 's') {
  873|      0|      if (g_has_set_seed) {
  874|      0|        std::cout << "Argument " << argv[i] << " conflicting with a former argument" << std::endl;
  875|      0|        return 1;
  876|      0|      }
  877|      0|      set_seed_from_string(argv[i] + 1);
  878|      0|    } else {
  879|      0|      need_help = true;
  880|      0|    }
  881|      0|  }
  882|       |
  883|      1|  if (need_help) {
  884|      0|    std::cout << "This test application takes the following optional arguments:" << std::endl;
  885|      0|    std::cout << "  rN     Repeat each test N times (default: " << DEFAULT_REPEAT << ")" << std::endl;
  886|      0|    std::cout << "  sN     Use N as seed for random numbers (default: based on current time)" << std::endl;
  887|      0|    std::cout << std::endl;
  888|      0|    std::cout << "If defined, the environment variables EIGEN_REPEAT and EIGEN_SEED" << std::endl;
  889|      0|    std::cout << "will be used as default values for these parameters." << std::endl;
  890|      0|    return 1;
  891|      0|  }
  892|       |
  893|      1|  char* env_EIGEN_REPEAT = getenv("EIGEN_REPEAT");
  894|      1|  if (!g_has_set_repeat && env_EIGEN_REPEAT) set_repeat_from_string(env_EIGEN_REPEAT);
  895|      1|  char* env_EIGEN_SEED = getenv("EIGEN_SEED");
  896|      1|  if (!g_has_set_seed && env_EIGEN_SEED) set_seed_from_string(env_EIGEN_SEED);
  897|       |
  898|      1|  if (!g_has_set_seed) g_seed = (unsigned int)time(NULL);
  899|      1|  if (!g_has_set_repeat) g_repeat = DEFAULT_REPEAT;
  900|       |
  901|      1|  std::cout << "Initializing random number generator with seed " << g_seed << std::endl;
  902|      1|  std::stringstream ss;
  903|      1|  ss << "Seed: " << g_seed;
  904|      1|  g_test_stack.push_back(ss.str());
  905|      1|  srand(g_seed);
  906|      1|  std::cout << "Repeating each test " << g_repeat << " times" << std::endl;
  907|       |
  908|      1|  VERIFY(EigenTest::all().size() > 0);
  909|       |
  910|      2|  for (std::size_t i = 0; i < EigenTest::all().size(); ++i) {
  911|      1|    const EigenTest& current_test = *EigenTest::all()[i];
  912|      1|    Eigen::g_test_stack.push_back(current_test.name());
  913|      1|    current_test();
  914|      1|    Eigen::g_test_stack.pop_back();
  915|      1|  }
  916|       |
  917|      1|  return 0;
  918|      1|}
  919|       |
  920|       |// These warning are disabled here such that they are still ON when parsing Eigen's header files.
  921|       |#if defined __INTEL_COMPILER
  922|       |// remark #383: value copied to temporary, reference to temporary used
  923|       |//  -> this warning is raised even for legal usage as: g_test_stack.push_back("foo"); where g_test_stack is a
  924|       |//  std::vector<std::string>
  925|       |// remark #1418: external function definition with no prior declaration
  926|       |//  -> this warning is raised for all our test functions. Declaring them static would fix the issue.
  927|       |// warning #279: controlling expression is constant
  928|       |// remark #1572: floating-point equality and inequality comparisons are unreliable
  929|       |#pragma warning disable 279 383 1418 1572
  930|       |#endif
  931|       |
  932|       |#ifdef _MSC_VER
  933|       |// 4503 - decorated name length exceeded, name was truncated
  934|       |#pragma warning(disable : 4503)
  935|       |#endif
  936|       |
  937|       |#include "gpu_test_helper.h"

