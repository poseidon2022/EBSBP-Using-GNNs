    1|       |/**
    2|       | * \addtogroup machine_learning Machine Learning Algorithms
    3|       | * @{
    4|       | * \file
    5|       | * \author [Krishna Vedala](https://github.com/kvedala)
    6|       | *
    7|       | * \brief [Kohonen self organizing
    8|       | * map](https://en.wikipedia.org/wiki/Self-organizing_map) (topological map)
    9|       | *
   10|       | * \details
   11|       | * This example implements a powerful unsupervised learning algorithm called as
   12|       | * a self organizing map. The algorithm creates a connected network of weights
   13|       | * that closely follows the given data points. This thus creates a topological
   14|       | * map of the given data i.e., it maintains the relationship between varipus
   15|       | * data points in a much higher dimesional space by creating an equivalent in a
   16|       | * 2-dimensional space.
   17|       | * <img alt="Trained topological maps for the test cases in the program"
   18|       | * src="https://raw.githubusercontent.com/TheAlgorithms/C-Plus-Plus/docs/images/machine_learning/2D_Kohonen_SOM.svg"
   19|       | * />
   20|       | * \note This C++ version of the program is considerable slower than its [C
   21|       | * counterpart](https://github.com/kvedala/C/blob/master/machine_learning/kohonen_som_trace.c)
   22|       | * \note The compiled code is much slower when compiled with MS Visual C++ 2019
   23|       | * than with GCC on windows
   24|       | * \see kohonen_som_trace.cpp
   25|       | */
   26|       |#define _USE_MATH_DEFINES  //< required for MS Visual C++
   27|       |#include <algorithm>
   28|       |#include <array>
   29|       |#include <cerrno>
   30|       |#include <cmath>
   31|       |#include <cstdlib>
   32|       |#include <cstring>
   33|       |#include <ctime>
   34|       |#include <fstream>
   35|       |#include <iostream>
   36|       |#include <valarray>
   37|       |#include <vector>
   38|       |#ifdef _OPENMP  // check if OpenMP based parallellization is available
   39|       |#include <omp.h>
   40|       |#endif
   41|       |
   42|       |/**
   43|       | * Helper function to generate a random number in a given interval.
   44|       | * \n Steps:
   45|       | * 1. `r1 = rand() % 100` gets a random number between 0 and 99
   46|       | * 2. `r2 = r1 / 100` converts random number to be between 0 and 0.99
   47|       | * 3. scale and offset the random number to given range of \f$[a,b]\f$
   48|       | *
   49|       | * \param[in] a lower limit
   50|       | * \param[in] b upper limit
   51|       | * \returns random number in the range \f$[a,b]\f$
   52|       | */
   53|  10.2k|double _random(double a, double b) {
   54|  10.2k|    return ((b - a) * (std::rand() % 100) / 100.f) + a;
   55|  10.2k|}
   56|       |
   57|       |/**
   58|       | * Save a given n-dimensional data martix to file.
   59|       | *
   60|       | * \param[in] fname filename to save in (gets overwriten without confirmation)
   61|       | * \param[in] X matrix to save
   62|       | * \returns 0 if all ok
   63|       | * \returns -1 if file creation failed
   64|       | */
   65|       |int save_2d_data(const char *fname,
   66|      3|                 const std::vector<std::valarray<double>> &X) {
   67|      3|    size_t num_points = X.size();       // number of rows
   68|      3|    size_t num_features = X[0].size();  // number of columns
   69|       |
   70|      3|    std::ofstream fp;
   71|      3|    fp.open(fname);
   72|      3|    if (!fp.is_open()) {
   73|       |        // error with opening file to write
   74|      0|        std::cerr << "Error opening file " << fname << ": "
   75|      0|                  << std::strerror(errno) << "\n";
   76|      0|        return -1;
   77|      0|    }
   78|       |
   79|       |    // for each point in the array
   80|  1.10k|    for (int i = 0; i < num_points; i++) {
   81|       |        // for each feature in the array
   82|  4.10k|        for (int j = 0; j < num_features; j++) {
   83|  3.00k|            fp << X[i][j];               // print the feature value
   84|  3.00k|            if (j < num_features - 1) {  // if not the last feature
   85|  1.90k|                fp << ",";               // suffix comma
   86|  1.90k|            }
   87|  3.00k|        }
   88|  1.10k|        if (i < num_points - 1) {  // if not the last row
   89|  1.09k|            fp << "\n";            // start a new line
   90|  1.09k|        }
   91|  1.10k|    }
   92|       |
   93|      3|    fp.close();
   94|      3|    return 0;
   95|      3|}
   96|       |
   97|       |/**
   98|       | * Get minimum value and index of the value in a matrix
   99|       | * \param[in] X matrix to search
  100|       | * \param[in] N number of points in the vector
  101|       | * \param[out] val minimum value found
  102|       | * \param[out] idx_x x-index where minimum value was found
  103|       | * \param[out] idx_y y-index where minimum value was found
  104|       | */
  105|       |void get_min_2d(const std::vector<std::valarray<double>> &X, double *val,
  106|  4.10M|                int *x_idx, int *y_idx) {
  107|  4.10M|    val[0] = INFINITY;  // initial min value
  108|  4.10M|    size_t N = X.size();
  109|       |
  110|   127M|    for (int i = 0; i < N; i++) {  // traverse each x-index
  111|   123M|        auto result = std::min_element(std::begin(X[i]), std::end(X[i]));
  112|   123M|        double d_min = *result;
  113|   123M|        std::ptrdiff_t j = std::distance(std::begin(X[i]), result);
  114|       |
  115|   123M|        if (d_min < val[0]) {  // if a lower value is found
  116|       |                               // save the value and its index
  117|  40.0M|            x_idx[0] = i;
  118|  40.0M|            y_idx[0] = j;
  119|  40.0M|            val[0] = d_min;
  120|  40.0M|        }
  121|   123M|    }
  122|  4.10M|}
  123|       |
  124|       |/** \namespace machine_learning
  125|       | * \brief Machine learning algorithms
  126|       | */
  127|       |namespace machine_learning {
  128|       |/** Minimum average distance of image nodes */
  129|       |constexpr double MIN_DISTANCE = 1e-4;
  130|       |
  131|       |/**
  132|       | * Create the distance matrix or
  133|       | * [U-matrix](https://en.wikipedia.org/wiki/U-matrix) from the trained
  134|       | * 3D weiths matrix and save to disk.
  135|       | *
  136|       | * \param [in] fname filename to save in (gets overwriten without
  137|       | * confirmation)
  138|       | * \param [in] W model matrix to save
  139|       | * \returns 0 if all ok
  140|       | * \returns -1 if file creation failed
  141|       | */
  142|       |int save_u_matrix(const char *fname,
  143|      6|                  const std::vector<std::vector<std::valarray<double>>> &W) {
  144|      6|    std::ofstream fp(fname);
  145|      6|    if (!fp) {  // error with fopen
  146|      0|        std::cerr << "File error (" << fname << "): " << std::strerror(errno)
  147|      0|                  << std::endl;
  148|      0|        return -1;
  149|      0|    }
  150|       |
  151|       |    // neighborhood range
  152|      6|    unsigned int R = 1;
  153|       |
  154|    186|    for (int i = 0; i < W.size(); i++) {         // for each x
  155|  5.58k|        for (int j = 0; j < W[0].size(); j++) {  // for each y
  156|  5.40k|            double distance = 0.f;
  157|       |
  158|  5.40k|            int from_x = std::max<int>(0, i - R);
  159|  5.40k|            int to_x = std::min<int>(W.size(), i + R + 1);
  160|  5.40k|            int from_y = std::max<int>(0, j - R);
  161|  5.40k|            int to_y = std::min<int>(W[0].size(), j + R + 1);
  162|  5.40k|            int l = 0, m = 0;
  163|       |#ifdef _OPENMP
  164|       |#pragma omp parallel for reduction(+ : distance)
  165|       |#endif
  166|  21.2k|            for (l = from_x; l < to_x; l++) {      // scan neighborhoor in x
  167|  62.3k|                for (m = from_y; m < to_y; m++) {  // scan neighborhood in y
  168|  46.4k|                    auto d = W[i][j] - W[l][m];
  169|  46.4k|                    double d2 = std::pow(d, 2).sum();
  170|  46.4k|                    distance += std::sqrt(d2);
  171|       |                    // distance += d2;
  172|  46.4k|                }
  173|  15.8k|            }
  174|       |
  175|  5.40k|            distance /= R * R;          // mean distance from neighbors
  176|  5.40k|            fp << distance;             // print the mean separation
  177|  5.40k|            if (j < W[0].size() - 1) {  // if not the last column
  178|  5.22k|                fp << ',';              // suffix comma
  179|  5.22k|            }
  180|  5.40k|        }
  181|    180|        if (i < W.size() - 1) {  // if not the last row
  182|    174|            fp << '\n';          // start a new line
  183|    174|        }
  184|    180|    }
  185|       |
  186|      6|    fp.close();
  187|      6|    return 0;
  188|      6|}
  189|       |
  190|       |/**
  191|       | * Update weights of the SOM using Kohonen algorithm
  192|       | *
  193|       | * \param[in] X data point - N features
  194|       | * \param[in,out] W weights matrix - PxQxN
  195|       | * \param[in,out] D temporary vector to store distances PxQ
  196|       | * \param[in] alpha learning rate \f$0<\alpha\le1\f$
  197|       | * \param[in] R neighborhood range
  198|       | * \returns minimum distance of sample and trained weights
  199|       | */
  200|       |double update_weights(const std::valarray<double> &X,
  201|       |                      std::vector<std::vector<std::valarray<double>>> *W,
  202|       |                      std::vector<std::valarray<double>> *D, double alpha,
  203|  4.10M|                      int R) {
  204|  4.10M|    int x = 0, y = 0;
  205|  4.10M|    int num_out_x = static_cast<int>(W->size());       // output nodes - in X
  206|  4.10M|    int num_out_y = static_cast<int>(W[0][0].size());  // output nodes - in Y
  207|       |    // int num_features = static_cast<int>(W[0][0][0].size());  //  features =
  208|       |    // in Z
  209|  4.10M|    double d_min = 0.f;
  210|       |
  211|       |#ifdef _OPENMP
  212|       |#pragma omp for
  213|       |#endif
  214|       |    // step 1: for each output point
  215|   127M|    for (x = 0; x < num_out_x; x++) {
  216|  3.81G|        for (y = 0; y < num_out_y; y++) {
  217|  3.69G|            (*D)[x][y] = 0.f;
  218|       |            // compute Euclidian distance of each output
  219|       |            // point from the current sample
  220|  3.69G|            auto d = ((*W)[x][y] - X);
  221|  3.69G|            (*D)[x][y] = (d * d).sum();
  222|  3.69G|            (*D)[x][y] = std::sqrt((*D)[x][y]);
  223|  3.69G|        }
  224|   123M|    }
  225|       |
  226|       |    // step 2:  get closest node i.e., node with snallest Euclidian distance
  227|       |    // to the current pattern
  228|  4.10M|    int d_min_x = 0, d_min_y = 0;
  229|  4.10M|    get_min_2d(*D, &d_min, &d_min_x, &d_min_y);
  230|       |
  231|       |    // step 3a: get the neighborhood range
  232|  4.10M|    int from_x = std::max(0, d_min_x - R);
  233|  4.10M|    int to_x = std::min(num_out_x, d_min_x + R + 1);
  234|  4.10M|    int from_y = std::max(0, d_min_y - R);
  235|  4.10M|    int to_y = std::min(num_out_y, d_min_y + R + 1);
  236|       |
  237|       |    // step 3b: update the weights of nodes in the
  238|       |    // neighborhood
  239|       |#ifdef _OPENMP
  240|       |#pragma omp for
  241|       |#endif
  242|  23.6M|    for (x = from_x; x < to_x; x++) {
  243|   148M|        for (y = from_y; y < to_y; y++) {
  244|       |            /* you can enable the following normalization if needed.
  245|       |   personally, I found it detrimental to convergence */
  246|       |            // const double s2pi = sqrt(2.f * M_PI);
  247|       |            // double normalize = 1.f / (alpha * s2pi);
  248|       |
  249|       |            /* apply scaling inversely proportional to distance from the
  250|       |               current node */
  251|   129M|            double d2 =
  252|   129M|                (d_min_x - x) * (d_min_x - x) + (d_min_y - y) * (d_min_y - y);
  253|   129M|            double scale_factor = std::exp(-d2 / (2.f * alpha * alpha));
  254|       |
  255|   129M|            (*W)[x][y] += (X - (*W)[x][y]) * alpha * scale_factor;
  256|   129M|        }
  257|  19.5M|    }
  258|  4.10M|    return d_min;
  259|  4.10M|}
  260|       |
  261|       |/**
  262|       | * Apply incremental algorithm with updating neighborhood and learning
  263|       | * rates on all samples in the given datset.
  264|       | *
  265|       | * \param[in] X data set
  266|       | * \param[in,out] W weights matrix
  267|       | * \param[in] alpha_min terminal value of alpha
  268|       | */
  269|       |void kohonen_som(const std::vector<std::valarray<double>> &X,
  270|       |                 std::vector<std::vector<std::valarray<double>>> *W,
  271|      3|                 double alpha_min) {
  272|      3|    size_t num_samples = X.size();  // number of rows
  273|       |    // size_t num_features = X[0].size();  // number of columns
  274|      3|    size_t num_out = W->size();  // output matrix size
  275|      3|    size_t R = num_out >> 2, iter = 0;
  276|      3|    double alpha = 1.f;
  277|       |
  278|      3|    std::vector<std::valarray<double>> D(num_out);
  279|     93|    for (int i = 0; i < num_out; i++) D[i] = std::valarray<double>(num_out);
  280|       |
  281|      3|    double dmin = 1.f;        // average minimum distance of all samples
  282|      3|    double past_dmin = 1.f;   // average minimum distance of all samples
  283|      3|    double dmin_ratio = 1.f;  // change per step
  284|       |
  285|       |    // Loop alpha from 1 to slpha_min
  286|  12.4k|    for (; alpha > 0 && dmin_ratio > 1e-5; alpha -= 1e-4, iter++) {
  287|       |        // Loop for each sample pattern in the data set
  288|  4.11M|        for (int sample = 0; sample < num_samples; sample++) {
  289|       |            // update weights for the current input pattern sample
  290|  4.10M|            dmin += update_weights(X[sample], W, &D, alpha, R);
  291|  4.10M|        }
  292|       |
  293|       |        // every 100th iteration, reduce the neighborhood range
  294|  12.4k|        if (iter % 300 == 0 && R > 1) {
  295|     15|            R--;
  296|     15|        }
  297|       |
  298|  12.4k|        dmin /= num_samples;
  299|       |
  300|       |        // termination condition variable -> % change in minimum distance
  301|  12.4k|        dmin_ratio = (past_dmin - dmin) / past_dmin;
  302|  12.4k|        if (dmin_ratio < 0) {
  303|  1.55k|            dmin_ratio = 1.f;
  304|  1.55k|        }
  305|  12.4k|        past_dmin = dmin;
  306|       |
  307|  12.4k|        std::cout << "iter: " << iter << "\t alpha: " << alpha << "\t R: " << R
  308|  12.4k|                  << "\t d_min: " << dmin_ratio << "\r";
  309|  12.4k|    }
  310|       |
  311|      3|    std::cout << "\n";
  312|      3|}
  313|       |
  314|       |}  // namespace machine_learning
  315|       |
  316|       |using machine_learning::kohonen_som;
  317|       |using machine_learning::save_u_matrix;
  318|       |
  319|       |/** @} */
  320|       |
  321|       |/** Creates a random set of points distributed in four clusters in
  322|       | * 3D space with centroids at the points
  323|       | * * \f$(0,5, 0.5, 0.5)\f$
  324|       | * * \f$(0,5,-0.5, -0.5)\f$
  325|       | * * \f$(-0,5, 0.5, 0.5)\f$
  326|       | * * \f$(-0,5,-0.5, -0.5)\f$
  327|       | *
  328|       | * \param[out] data matrix to store data in
  329|       | */
  330|      1|void test_2d_classes(std::vector<std::valarray<double>> *data) {
  331|      1|    const int N = data->size();
  332|      1|    const double R = 0.3;  // radius of cluster
  333|      1|    int i = 0;
  334|      1|    const int num_classes = 4;
  335|      1|    std::array<std::array<double, 2>, num_classes> centres = {
  336|       |        // centres of each class cluster
  337|      1|        std::array<double, 2>({.5, .5}),   // centre of class 1
  338|      1|        std::array<double, 2>({.5, -.5}),  // centre of class 2
  339|      1|        std::array<double, 2>({-.5, .5}),  // centre of class 3
  340|      1|        std::array<double, 2>({-.5, -.5})  // centre of class 4
  341|      1|    };
  342|       |
  343|       |#ifdef _OPENMP
  344|       |#pragma omp for
  345|       |#endif
  346|    301|    for (i = 0; i < N; i++) {
  347|       |        // select a random class for the point
  348|    300|        int cls = std::rand() % num_classes;
  349|       |
  350|       |        // create random coordinates (x,y,z) around the centre of the class
  351|    300|        data[0][i][0] = _random(centres[cls][0] - R, centres[cls][0] + R);
  352|    300|        data[0][i][1] = _random(centres[cls][1] - R, centres[cls][1] + R);
  353|       |
  354|       |        /* The follosing can also be used
  355|       |        for (int j = 0; j < 2; j++)
  356|       |            data[i][j] = _random(centres[class][j] - R, centres[class][j] + R);
  357|       |        */
  358|    300|    }
  359|      1|}
  360|       |
  361|       |/** Test that creates a random set of points distributed in four clusters in
  362|       | * circumference of a circle and trains an SOM that finds that circular pattern.
  363|       | * The following [CSV](https://en.wikipedia.org/wiki/Comma-separated_values)
  364|       | * files are created to validate the execution:
  365|       | * * `test1.csv`: random test samples points with a circular pattern
  366|       | * * `w11.csv`: initial random map
  367|       | * * `w12.csv`: trained SOM map
  368|       | */
  369|      1|void test1() {
  370|      1|    int j = 0, N = 300;
  371|      1|    int features = 2;
  372|      1|    int num_out = 30;
  373|      1|    std::vector<std::valarray<double>> X(N);
  374|      1|    std::vector<std::vector<std::valarray<double>>> W(num_out);
  375|    301|    for (int i = 0; i < std::max(num_out, N); i++) {
  376|       |        // loop till max(N, num_out)
  377|    300|        if (i < N) {  // only add new arrays if i < N
  378|    300|            X[i] = std::valarray<double>(features);
  379|    300|        }
  380|    300|        if (i < num_out) {  // only add new arrays if i < num_out
  381|     30|            W[i] = std::vector<std::valarray<double>>(num_out);
  382|    930|            for (int k = 0; k < num_out; k++) {
  383|    900|                W[i][k] = std::valarray<double>(features);
  384|       |#ifdef _OPENMP
  385|       |#pragma omp for
  386|       |#endif
  387|  2.70k|                for (j = 0; j < features; j++) {
  388|       |                    // preallocate with random initial weights
  389|  1.80k|                    W[i][k][j] = _random(-10, 10);
  390|  1.80k|                }
  391|    900|            }
  392|     30|        }
  393|    300|    }
  394|       |
  395|      1|    test_2d_classes(&X);  // create test data around circumference of a circle
  396|      1|    save_2d_data("test1.csv", X);  // save test data points
  397|      1|    save_u_matrix("w11.csv", W);   // save initial random weights
  398|      1|    kohonen_som(X, &W, 1e-4);      // train the SOM
  399|      1|    save_u_matrix("w12.csv", W);   // save the resultant weights
  400|      1|}
  401|       |
  402|       |/** Creates a random set of points distributed in four clusters in
  403|       | * 3D space with centroids at the points
  404|       | * * \f$(0,5, 0.5, 0.5)\f$
  405|       | * * \f$(0,5,-0.5, -0.5)\f$
  406|       | * * \f$(-0,5, 0.5, 0.5)\f$
  407|       | * * \f$(-0,5,-0.5, -0.5)\f$
  408|       | *
  409|       | * \param[out] data matrix to store data in
  410|       | */
  411|      1|void test_3d_classes1(std::vector<std::valarray<double>> *data) {
  412|      1|    const size_t N = data->size();
  413|      1|    const double R = 0.3;  // radius of cluster
  414|      1|    int i = 0;
  415|      1|    const int num_classes = 4;
  416|      1|    const std::array<std::array<double, 3>, num_classes> centres = {
  417|       |        // centres of each class cluster
  418|      1|        std::array<double, 3>({.5, .5, .5}),    // centre of class 1
  419|      1|        std::array<double, 3>({.5, -.5, -.5}),  // centre of class 2
  420|      1|        std::array<double, 3>({-.5, .5, .5}),   // centre of class 3
  421|      1|        std::array<double, 3>({-.5, -.5 - .5})  // centre of class 4
  422|      1|    };
  423|       |
  424|       |#ifdef _OPENMP
  425|       |#pragma omp for
  426|       |#endif
  427|    301|    for (i = 0; i < N; i++) {
  428|       |        // select a random class for the point
  429|    300|        int cls = std::rand() % num_classes;
  430|       |
  431|       |        // create random coordinates (x,y,z) around the centre of the class
  432|    300|        data[0][i][0] = _random(centres[cls][0] - R, centres[cls][0] + R);
  433|    300|        data[0][i][1] = _random(centres[cls][1] - R, centres[cls][1] + R);
  434|    300|        data[0][i][2] = _random(centres[cls][2] - R, centres[cls][2] + R);
  435|       |
  436|       |        /* The follosing can also be used
  437|       |        for (int j = 0; j < 3; j++)
  438|       |            data[i][j] = _random(centres[class][j] - R, centres[class][j] + R);
  439|       |        */
  440|    300|    }
  441|      1|}
  442|       |
  443|       |/** Test that creates a random set of points distributed in 4 clusters in
  444|       | * 3D space and trains an SOM that finds the topological pattern. The following
  445|       | * [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) files are created
  446|       | * to validate the execution:
  447|       | * * `test2.csv`: random test samples points with a lamniscate pattern
  448|       | * * `w21.csv`: initial random map
  449|       | * * `w22.csv`: trained SOM map
  450|       | */
  451|      1|void test2() {
  452|      1|    int j = 0, N = 300;
  453|      1|    int features = 3;
  454|      1|    int num_out = 30;
  455|      1|    std::vector<std::valarray<double>> X(N);
  456|      1|    std::vector<std::vector<std::valarray<double>>> W(num_out);
  457|    301|    for (int i = 0; i < std::max(num_out, N); i++) {
  458|       |        // loop till max(N, num_out)
  459|    300|        if (i < N) {  // only add new arrays if i < N
  460|    300|            X[i] = std::valarray<double>(features);
  461|    300|        }
  462|    300|        if (i < num_out) {  // only add new arrays if i < num_out
  463|     30|            W[i] = std::vector<std::valarray<double>>(num_out);
  464|    930|            for (int k = 0; k < num_out; k++) {
  465|    900|                W[i][k] = std::valarray<double>(features);
  466|       |#ifdef _OPENMP
  467|       |#pragma omp for
  468|       |#endif
  469|  3.60k|                for (j = 0; j < features; j++) {
  470|       |                    // preallocate with random initial weights
  471|  2.70k|                    W[i][k][j] = _random(-10, 10);
  472|  2.70k|                }
  473|    900|            }
  474|     30|        }
  475|    300|    }
  476|       |
  477|      1|    test_3d_classes1(&X);  // create test data around circumference of a circle
  478|      1|    save_2d_data("test2.csv", X);  // save test data points
  479|      1|    save_u_matrix("w21.csv", W);   // save initial random weights
  480|      1|    kohonen_som(X, &W, 1e-4);      // train the SOM
  481|      1|    save_u_matrix("w22.csv", W);   // save the resultant weights
  482|      1|}
  483|       |
  484|       |/** Creates a random set of points distributed in four clusters in
  485|       | * 3D space with centroids at the points
  486|       | * * \f$(0,5, 0.5, 0.5)\f$
  487|       | * * \f$(0,5,-0.5, -0.5)\f$
  488|       | * * \f$(-0,5, 0.5, 0.5)\f$
  489|       | * * \f$(-0,5,-0.5, -0.5)\f$
  490|       | *
  491|       | * \param[out] data matrix to store data in
  492|       | */
  493|      1|void test_3d_classes2(std::vector<std::valarray<double>> *data) {
  494|      1|    const size_t N = data->size();
  495|      1|    const double R = 0.2;  // radius of cluster
  496|      1|    int i = 0;
  497|      1|    const int num_classes = 8;
  498|      1|    const std::array<std::array<double, 3>, num_classes> centres = {
  499|       |        // centres of each class cluster
  500|      1|        std::array<double, 3>({.5, .5, .5}),    // centre of class 1
  501|      1|        std::array<double, 3>({.5, .5, -.5}),   // centre of class 2
  502|      1|        std::array<double, 3>({.5, -.5, .5}),   // centre of class 3
  503|      1|        std::array<double, 3>({.5, -.5, -.5}),  // centre of class 4
  504|      1|        std::array<double, 3>({-.5, .5, .5}),   // centre of class 5
  505|      1|        std::array<double, 3>({-.5, .5, -.5}),  // centre of class 6
  506|      1|        std::array<double, 3>({-.5, -.5, .5}),  // centre of class 7
  507|      1|        std::array<double, 3>({-.5, -.5, -.5})  // centre of class 8
  508|      1|    };
  509|       |
  510|       |#ifdef _OPENMP
  511|       |#pragma omp for
  512|       |#endif
  513|    501|    for (i = 0; i < N; i++) {
  514|       |        // select a random class for the point
  515|    500|        int cls = std::rand() % num_classes;
  516|       |
  517|       |        // create random coordinates (x,y,z) around the centre of the class
  518|    500|        data[0][i][0] = _random(centres[cls][0] - R, centres[cls][0] + R);
  519|    500|        data[0][i][1] = _random(centres[cls][1] - R, centres[cls][1] + R);
  520|    500|        data[0][i][2] = _random(centres[cls][2] - R, centres[cls][2] + R);
  521|       |
  522|       |        /* The follosing can also be used
  523|       |        for (int j = 0; j < 3; j++)
  524|       |            data[i][j] = _random(centres[class][j] - R, centres[class][j] + R);
  525|       |        */
  526|    500|    }
  527|      1|}
  528|       |
  529|       |/** Test that creates a random set of points distributed in eight clusters in
  530|       | * 3D space and trains an SOM that finds the topological pattern. The following
  531|       | * [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) files are created
  532|       | * to validate the execution:
  533|       | * * `test3.csv`: random test samples points with a circular pattern
  534|       | * * `w31.csv`: initial random map
  535|       | * * `w32.csv`: trained SOM map
  536|       | */
  537|      1|void test3() {
  538|      1|    int j = 0, N = 500;
  539|      1|    int features = 3;
  540|      1|    int num_out = 30;
  541|      1|    std::vector<std::valarray<double>> X(N);
  542|      1|    std::vector<std::vector<std::valarray<double>>> W(num_out);
  543|    501|    for (int i = 0; i < std::max(num_out, N); i++) {
  544|       |        // loop till max(N, num_out)
  545|    500|        if (i < N) {  // only add new arrays if i < N
  546|    500|            X[i] = std::valarray<double>(features);
  547|    500|        }
  548|    500|        if (i < num_out) {  // only add new arrays if i < num_out
  549|     30|            W[i] = std::vector<std::valarray<double>>(num_out);
  550|    930|            for (int k = 0; k < num_out; k++) {
  551|    900|                W[i][k] = std::valarray<double>(features);
  552|       |#ifdef _OPENMP
  553|       |#pragma omp for
  554|       |#endif
  555|  3.60k|                for (j = 0; j < features; j++) {
  556|       |                    // preallocate with random initial weights
  557|  2.70k|                    W[i][k][j] = _random(-10, 10);
  558|  2.70k|                }
  559|    900|            }
  560|     30|        }
  561|    500|    }
  562|       |
  563|      1|    test_3d_classes2(&X);  // create test data around circumference of a circle
  564|      1|    save_2d_data("test3.csv", X);  // save test data points
  565|      1|    save_u_matrix("w31.csv", W);   // save initial random weights
  566|      1|    kohonen_som(X, &W, 1e-4);      // train the SOM
  567|      1|    save_u_matrix("w32.csv", W);   // save the resultant weights
  568|      1|}
  569|       |
  570|       |/**
  571|       | * Convert clock cycle difference to time in seconds
  572|       | *
  573|       | * \param[in] start_t start clock
  574|       | * \param[in] end_t end clock
  575|       | * \returns time difference in seconds
  576|       | */
  577|      3|double get_clock_diff(clock_t start_t, clock_t end_t) {
  578|      3|    return static_cast<double>(end_t - start_t) / CLOCKS_PER_SEC;
  579|      3|}
  580|       |
  581|       |/** Main function */
  582|      1|int main(int argc, char **argv) {
  583|       |#ifdef _OPENMP
  584|       |    std::cout << "Using OpenMP based parallelization\n";
  585|       |#else
  586|      1|    std::cout << "NOT using OpenMP based parallelization\n";
  587|      1|#endif
  588|       |
  589|      1|    std::srand(std::time(nullptr));
  590|       |
  591|      1|    std::clock_t start_clk = std::clock();
  592|      1|    test1();
  593|      1|    auto end_clk = std::clock();
  594|      1|    std::cout << "Test 1 completed in " << get_clock_diff(start_clk, end_clk)
  595|      1|              << " sec\n";
  596|       |
  597|      1|    start_clk = std::clock();
  598|      1|    test2();
  599|      1|    end_clk = std::clock();
  600|      1|    std::cout << "Test 2 completed in " << get_clock_diff(start_clk, end_clk)
  601|      1|              << " sec\n";
  602|       |
  603|      1|    start_clk = std::clock();
  604|      1|    test3();
  605|      1|    end_clk = std::clock();
  606|      1|    std::cout << "Test 3 completed in " << get_clock_diff(start_clk, end_clk)
  607|      1|              << " sec\n";
  608|       |
  609|      1|    std::cout
  610|      1|        << "(Note: Calculated times include: creating test sets, training "
  611|      1|           "model and writing files to disk.)\n\n";
  612|      1|    return 0;
  613|      1|}

